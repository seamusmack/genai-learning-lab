{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f63ad51",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa72e274",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"Using numpy version:\", np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf68c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "## VAE Class Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dcfce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DemoVAE:\n",
    "    \n",
    "    def __init__(self, input_dim=784, latent_dim=2):\n",
    "        self.input_dim = input_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        print(f\"Created VAE: {input_dim}D input → {latent_dim}D latent space\")\n",
    "        \n",
    "    def encode(self, x):\n",
    "        \"\"\"Encoder: x → (μ, log σ²)\"\"\"\n",
    "        mu = np.random.randn(self.latent_dim) * 0.5\n",
    "        log_var = np.random.randn(self.latent_dim) * 0.1 - 1\n",
    "        return mu, log_var\n",
    "    \n",
    "    def reparameterize(self, mu, log_var):\n",
    "        \"\"\"The Reparameterization Trick\"\"\"\n",
    "        epsilon = np.random.standard_normal(mu.shape)\n",
    "        z = mu + np.exp(0.5 * log_var) * epsilon\n",
    "        return z\n",
    "    \n",
    "    def decode(self, z):\n",
    "        \"\"\"Decoder: z → x̂\"\"\"\n",
    "        raw_output = np.dot(z, np.random.randn(self.latent_dim, self.input_dim))\n",
    "        return 1 / (1 + np.exp(-np.clip(raw_output, -500, 500)))  # Manual sigmoid\n",
    "\n",
    "vae = DemoVAE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0b8d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_input = np.random.randn(784) * 0.5 + 0.5\n",
    "\n",
    "# Step 1: Encoding\n",
    "mu, log_var = vae.encode(sample_input)\n",
    "print(f\"1. Encoded to μ={mu[:2]}..., log_var={log_var[:2]}...\")\n",
    "\n",
    "# Step 2: Reparameterization  \n",
    "z = vae.reparameterize(mu, log_var)\n",
    "print(f\"2. Sampled z={z}\")\n",
    "\n",
    "# Step 3: Decoding\n",
    "reconstructed = vae.decode(z)\n",
    "print(f\"3. Reconstructed shape: {reconstructed.shape}\")\n",
    "print(\"Complete! Input → Distribution → Sample → Output\")\n",
    "\n",
    "# CELL 6\n",
    "print(\"VAE Loss = Reconstruction Loss + KL Divergence\")\n",
    "print()\n",
    "print(\"Reconstruction Loss: How well did we recreate the input?\")\n",
    "print(\"KL Divergence: How close is our distribution to standard normal?\")\n",
    "print()\n",
    "print(\"KL divergence organizes the ENTIRE latent space!\")\n",
    "print(\"   Every point fits the global structure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f199fb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Demo with Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643f10a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Traditional Autoencoder - chaotic latent space\n",
    "np.random.seed(42)\n",
    "chaotic_points = np.random.randn(200, 2) * 3 + np.random.randn(200, 2) * 2\n",
    "ax1.scatter(chaotic_points[:, 0], chaotic_points[:, 1], alpha=0.6, c='red', s=30)\n",
    "ax1.set_title('Traditional Autoencoder\\n(Chaotic Latent Space)', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('Latent Dimension 1')\n",
    "ax1.set_ylabel('Latent Dimension 2')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_xlim(-8, 8)\n",
    "ax1.set_ylim(-8, 8)\n",
    "\n",
    "# VAE - organized latent space\n",
    "organized_points = np.random.randn(200, 2)  # Standard normal\n",
    "ax2.scatter(organized_points[:, 0], organized_points[:, 1], alpha=0.6, c='blue', s=30)\n",
    "ax2.set_title('VAE\\n(Organized Latent Space)', fontsize=14, fontweight='bold')\n",
    "ax2.set_xlabel('Latent Dimension 1')\n",
    "ax2.set_ylabel('Latent Dimension 2')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.set_xlim(-4, 4)\n",
    "ax2.set_ylim(-4, 4)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"VAE forces latent space to follow standard normal distribution\")\n",
    "print(\"Random sampling reliable for generation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5ab1c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
