{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IPNfNQMHsTzw"
   },
   "source": [
    "# **Demo: MultiPDF QA Retriever with FAISS and LangChain**\n",
    "\n",
    "In this demo, you will learn how to use LangChain to create a MultiPDF retriever with FAISS. This demo is performed on new generative AI research paper PDFs. You will understand how to load and process documents, create a database, make a retriever, create a chain, and use the retriever to ask questions and get answers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UHNcYIClspLl"
   },
   "source": [
    "## **Steps to Perform:**\n",
    "\n",
    "*   Step 1: Importing the Necessary Libraries\n",
    "*   Step 2: Loading and Splitting\n",
    "*   Step 3: Loading the OpenAI Embeddings\n",
    "*   Step 4: Creating and Loading the Database\n",
    "*   Step 5: Creating and Using the Retriever\n",
    "*   Step 6: Passing the Query\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uiVumMWatiZP"
   },
   "source": [
    "### **Step 1: Importing the Necessary Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"Gen_AI_Papers\", exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "-rlv9F3SsZBz"
   },
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import TextLoader, PyPDFLoader, DirectoryLoader\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "import os\n",
    "import openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "os.chdir( - define yorur working directory - )\n",
    "os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf',\n",
       " 'LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf',\n",
       " 'Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "sorted([p.name for p in Path(\"Gen_AI_Papers\").glob(\"*.pdf\")])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mAT815IEtnw0"
   },
   "source": [
    "### **Step 2: Loading and Splitting**\n",
    "\n",
    "\n",
    "*   Create a directory named `GenAI_Papers`.\n",
    "*   Load the PDF documents in the directory.\n",
    "*   Split the documents into smaller chunks using the **RecursiveCharacterTextSplitter**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf',\n",
       "  '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf',\n",
       "  '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf'],\n",
       " 130,\n",
       " 565)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RESET\n",
    "documents, texts = [], []\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from pathlib import Path\n",
    "\n",
    "def long(p): return \"\\\\\\\\?\\\\\" + str(Path(p).resolve())\n",
    "\n",
    "for p in Path(\"Gen_AI_Papers\").glob(\"*.pdf\"):\n",
    "    documents.extend(PyPDFLoader(long(p)).load())\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "# confirm only the 3 sources are present\n",
    "sorted({d.metadata.get(\"source\") for d in texts})[:10], len(documents), len(texts)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 0, 'page_label': '1'}, page_content='Chain-of-Thought Prompting Elicits Reasoning\\nin Large Language Models\\nJason Wei Xuezhi Wang Dale Schuurmans Maarten Bosma\\nBrian Ichter Fei Xia Ed H. Chi Quoc V . Le Denny Zhou\\nGoogle Research, Brain Team\\n{jasonwei,dennyzhou}@google.com\\nAbstract\\nWe explore how generating a chain of thought—a series of intermediate reasoning\\nsteps—signiﬁcantly improves the ability of large language models to perform\\ncomplex reasoning. In particular, we show how such reasoning abilities emerge\\nnaturally in sufﬁciently large language models via a simple method called chain-of-\\nthought prompting, where a few chain of thought demonstrations are provided as\\nexemplars in prompting.\\nExperiments on three large language models show that chain-of-thought prompting\\nimproves performance on a range of arithmetic, commonsense, and symbolic\\nreasoning tasks. The empirical gains can be striking. For instance, prompting a\\nPaLM 540B with just eight chain-of-thought exemplars achieves state-of-the-art'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 0, 'page_label': '1'}, page_content='reasoning tasks. The empirical gains can be striking. For instance, prompting a\\nPaLM 540B with just eight chain-of-thought exemplars achieves state-of-the-art\\naccuracy on the GSM8K benchmark of math word problems, surpassing even\\nﬁnetuned GPT-3 with a veriﬁer.\\nA: The cafeteria had 23 apples originally. They used \\n20 to make lunch. So they had 23 - 20 = 3. They \\nbought 6 more apples, so they have 3 + 6 = 9. The \\nanswer is 9.\\nChain-of-Thought Prompting\\nQ: Roger has 5 tennis balls. He buys 2 more cans of \\ntennis balls. Each can has 3 tennis balls. How many \\ntennis balls does he have now? \\nA: The answer is 11. \\nQ: The cafeteria had 23 apples. If they used 20 to \\nmake lunch and bought 6 more, how many apples \\ndo they have?\\nA: The answer is 27.\\nStandard Prompting\\nQ: Roger has 5 tennis balls. He buys 2 more cans of \\ntennis balls. Each can has 3 tennis balls. How many \\ntennis balls does he have now? \\nA: Roger started with 5 balls. 2 cans of 3 tennis balls'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 0, 'page_label': '1'}, page_content='Q: Roger has 5 tennis balls. He buys 2 more cans of \\ntennis balls. Each can has 3 tennis balls. How many \\ntennis balls does he have now? \\nA: Roger started with 5 balls. 2 cans of 3 tennis balls \\neach is 6 tennis balls. 5 + 6 = 11. The answer is 11. \\nQ: The cafeteria had 23 apples. If they used 20 to \\nmake lunch and bought 6 more, how many apples \\ndo they have?\\nModel Input\\nModel Output Model Output\\nModel Input\\nFigure 1: Chain-of-thought prompting enables large language models to tackle complex arithmetic,\\ncommonsense, and symbolic reasoning tasks. Chain-of-thought reasoning processes are highlighted.\\n36th Conference on Neural Information Processing Systems (NeurIPS 2022).\\narXiv:2201.11903v6  [cs.CL]  10 Jan 2023'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 1, 'page_label': '2'}, page_content='1 Introduction\\nMath Word Problems (GSM8K)\\n0\\n20\\n40\\n60\\n80\\n100\\n33\\n55\\n18\\n57\\nSolve rate (%)\\nFinetuned GPT-3 175B\\nPrior best\\nPaLM 540B: standard prompting\\nPaLM 540B: chain-of-thought prompting\\nFigure 2: PaLM 540B uses chain-of-\\nthought prompting to achieve new state-\\nof-the-art performance on the GSM8K\\nbenchmark of math word problems.\\nFinetuned GPT-3 and prior best are from\\nCobbe et al. (2021).\\nThe NLP landscape has recently been revolutionized by\\nlanguage models (Peters et al., 2018; Devlin et al., 2019;\\nBrown et al., 2020, inter alia). Scaling up the size of lan-\\nguage models has been shown to confer a range of beneﬁts,\\nsuch as improved performance and sample efﬁciency (Ka-\\nplan et al., 2020; Brown et al., 2020, inter alia). However,\\nscaling up model size alone has not proved sufﬁcient for\\nachieving high performance on challenging tasks such as\\narithmetic, commonsense, and symbolic reasoning (Rae\\net al., 2021).\\nThis work explores how the reasoning ability of large'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 1, 'page_label': '2'}, page_content='achieving high performance on challenging tasks such as\\narithmetic, commonsense, and symbolic reasoning (Rae\\net al., 2021).\\nThis work explores how the reasoning ability of large\\nlanguage models can be unlocked by a simple method\\nmotivated by two ideas. First, techniques for arithmetic\\nreasoning can beneﬁt from generating natural language\\nrationales that lead to the ﬁnal answer. Prior work has\\ngiven models the ability to generate natural language inter-\\nmediate steps by training from scratch (Ling et al., 2017)\\nor ﬁnetuning a pretrained model (Cobbe et al., 2021), in\\naddition to neuro-symbolic methods that use formal lan-\\nguages instead of natural language (Roy and Roth, 2015;\\nChiang and Chen, 2019; Amini et al., 2019; Chen et al.,\\n2019). Second, large language models offer the exciting\\nprospect of in-context few-shot learning via prompting. That is, instead of ﬁnetuning a separate\\nlanguage model checkpoint for each new task, one can simply “prompt” the model with a few'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 1, 'page_label': '2'}, page_content='prospect of in-context few-shot learning via prompting. That is, instead of ﬁnetuning a separate\\nlanguage model checkpoint for each new task, one can simply “prompt” the model with a few\\ninput–output exemplars demonstrating the task. Remarkably, this has been successful for a range of\\nsimple question-answering tasks (Brown et al., 2020).\\nBoth of the above ideas, however, have key limitations. For rationale-augmented training and\\nﬁnetuning methods, it is costly to create a large set of high quality rationales, which is much more\\ncomplicated than simple input–output pairs used in normal machine learning. For the traditional few-\\nshot prompting method used in Brown et al. (2020), it works poorly on tasks that require reasoning\\nabilities, and often does not improve substantially with increasing language model scale (Rae et al.,\\n2021). In this paper, we combine the strengths of these two ideas in a way that avoids their limitations.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 1, 'page_label': '2'}, page_content='2021). In this paper, we combine the strengths of these two ideas in a way that avoids their limitations.\\nSpeciﬁcally, we explore the ability of language models to perform few-shot prompting for reasoning\\ntasks, given a prompt that consists of triples: ⟨input, chain of thought, output⟩. A chain of thought is\\na series of intermediate natural language reasoning steps that lead to the ﬁnal output, and we refer to\\nthis approach as chain-of-thought prompting. An example prompt is shown in Figure 1.\\nWe present empirical evaluations on arithmetic, commonsense, and symbolic reasoning benchmarks,\\nshowing that chain-of-thought prompting outperforms standard prompting, sometimes to a striking\\ndegree. Figure 2 illustrates one such result—on the GSM8K benchmark of math word problems\\n(Cobbe et al., 2021), chain-of-thought prompting with PaLM 540B outperforms standard prompting\\nby a large margin and achieves new state-of-the-art performance. A prompting only approach is'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 1, 'page_label': '2'}, page_content='(Cobbe et al., 2021), chain-of-thought prompting with PaLM 540B outperforms standard prompting\\nby a large margin and achieves new state-of-the-art performance. A prompting only approach is\\nimportant because it does not require a large training dataset and because a single model checkpoint\\ncan perform many tasks without loss of generality. This work underscores how large language models\\ncan learn via a few examples with natural language data about the task (c.f. automatically learning\\nthe patterns underlying inputs and outputs via a large training dataset).\\n2 Chain-of-Thought Prompting\\nConsider one’s own thought process when solving a complicated reasoning task such as a multi-step\\nmath word problem. It is typical to decompose the problem into intermediate steps and solve each\\nbefore giving the ﬁnal answer: “After Jane gives 2 ﬂowers to her mom she has 10 ... then after she\\ngives 3 to her dad she will have 7 ... so the answer is 7. ”The goal of this paper is to endow language'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 1, 'page_label': '2'}, page_content='gives 3 to her dad she will have 7 ... so the answer is 7. ”The goal of this paper is to endow language\\nmodels with the ability to generate a similar chain of thought—a coherent series of intermediate\\nreasoning steps that lead to the ﬁnal answer for a problem. We will show that sufﬁciently large\\n2'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 2, 'page_label': '3'}, page_content='language models can generate chains of thought if demonstrations of chain-of-thought reasoning are\\nprovided in the exemplars for few-shot prompting.\\nFigure 1 shows an example of a model producing a chain of thought to solve a math word problem\\nthat it would have otherwise gotten incorrect. The chain of thought in this case resembles a solution\\nand can interpreted as one, but we still opt to call it a chain of thought to better capture the idea that it\\nmimics a step-by-step thought process for arriving at the answer (and also, solutions/explanations\\ntypically come after the ﬁnal answer (Narang et al., 2020; Wiegreffe et al., 2022; Lampinen et al.,\\n2022, inter alia)).\\nChain-of-thought prompting has several attractive properties as an approach for facilitating reasoning\\nin language models.\\n1. First, chain of thought, in principle, allows models to decompose multi-step problems into\\nintermediate steps, which means that additional computation can be allocated to problems'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 2, 'page_label': '3'}, page_content='1. First, chain of thought, in principle, allows models to decompose multi-step problems into\\nintermediate steps, which means that additional computation can be allocated to problems\\nthat require more reasoning steps.\\n2. Second, a chain of thought provides an interpretable window into the behavior of the model,\\nsuggesting how it might have arrived at a particular answer and providing opportunities\\nto debug where the reasoning path went wrong (although fully characterizing a model’s\\ncomputations that support an answer remains an open question).\\n3. Third, chain-of-thought reasoning can be used for tasks such as math word problems,\\ncommonsense reasoning, and symbolic manipulation, and is potentially applicable (at least\\nin principle) to any task that humans can solve via language.\\n4. Finally, chain-of-thought reasoning can be readily elicited in sufﬁciently large off-the-shelf\\nlanguage models simply by including examples of chain of thought sequences into the'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 2, 'page_label': '3'}, page_content='4. Finally, chain-of-thought reasoning can be readily elicited in sufﬁciently large off-the-shelf\\nlanguage models simply by including examples of chain of thought sequences into the\\nexemplars of few-shot prompting.\\nIn empirical experiments, we will observe the utility of chain-of-thought prompting for arithmetic\\nreasoning (Section 3), commonsense reasoning (Section 4), and symbolic reasoning (Section 5).\\n3 Arithmetic Reasoning\\nWe begin by considering math word problems of the form in Figure 1, which measure the arithmetic\\nreasoning ability of language models. Though simple for humans, arithmetic reasoning is a task where\\nlanguage models often struggle (Hendrycks et al., 2021; Patel et al., 2021,inter alia). Strikingly, chain-\\nof-thought prompting when used with the 540B parameter language model performs comparably with\\ntask-speciﬁc ﬁnetuned models on several tasks, even achieving new state of the art on the challenging\\nGSM8K benchmark (Cobbe et al., 2021).\\n3.1 Experimental Setup'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 2, 'page_label': '3'}, page_content='task-speciﬁc ﬁnetuned models on several tasks, even achieving new state of the art on the challenging\\nGSM8K benchmark (Cobbe et al., 2021).\\n3.1 Experimental Setup\\nWe explore chain-of-thought prompting for various language models on multiple benchmarks.\\nBenchmarks. We consider the following ﬁve math word problem benchmarks: (1) the GSM8K\\nbenchmark of math word problems (Cobbe et al., 2021), (2) the SV AMPdataset of math word\\nproblems with varying structures (Patel et al., 2021), (3) the ASDiv dataset of diverse math word\\nproblems (Miao et al., 2020), (4) the AQuA dataset of algebraic word problems, and (5) the MA WPS\\nbenchmark (Koncel-Kedziorski et al., 2016). Example problems are given in Appendix Table 12.\\nStandard prompting. For the baseline, we consider standard few-shot prompting, popularized by\\nBrown et al. (2020), in which a language model is given in-context exemplars of input–output pairs'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 2, 'page_label': '3'}, page_content='Standard prompting. For the baseline, we consider standard few-shot prompting, popularized by\\nBrown et al. (2020), in which a language model is given in-context exemplars of input–output pairs\\nbefore outputting a prediction for a test-time example. Exemplars are formatted as questions and\\nanswers. The model gives the answer directly, as shown in Figure 1 (left).\\nChain-of-thought prompting. Our proposed approach is to augment each exemplar in few-shot\\nprompting with a chain of thought for an associated answer, as illustrated in Figure 1 (right). As most\\nof the datasets only have an evaluation split, we manually composed a set of eight few-shot exemplars\\nwith chains of thought for prompting—Figure 1 (right) shows one chain of thought exemplar, and the\\nfull set of exemplars is given in Appendix Table 20. (These particular exemplars did not undergo\\nprompt engineering; robustness is studied in Section 3.4 and Appendix A.2.) To investigate whether'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 2, 'page_label': '3'}, page_content='full set of exemplars is given in Appendix Table 20. (These particular exemplars did not undergo\\nprompt engineering; robustness is studied in Section 3.4 and Appendix A.2.) To investigate whether\\nchain-of-thought prompting in this form can successfully elicit successful reasoning across a range of\\n3'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 3, 'page_label': '4'}, page_content=\"Q: Roger has 5 tennis balls. He buys \\n2 more cans of tennis balls. Each can \\nhas 3 tennis balls. How many tennis \\nballs does he have now? \\nA: Roger started with 5 balls. 2 cans \\nof 3 tennis balls each is 6 tennis \\nballs. 5 + 6 = 11. The answer is 11.\\nQ: Sammy wanted to go to where the \\npeople were. Where might he go? \\nOptions: (a) race track (b) populated areas \\n(c) desert (d) apartment (e) roadblock \\nA: The answer must be a place with a \\nlot of people. Race tracks, desert, \\napartments, and roadblocks don't \\nhave a lot of people, but populated \\nareas do. So the answer is (b). \\nQ: Yes or no: Would a pear sink in \\nwater? \\nA: The density of a pear is about 0.6 \\ng/cm^3, which is less than water. \\nThus, a pear would float. So the \\nanswer is no.\\nQ: The concert was scheduled to be \\non 06/01/1943, but was delayed by \\none day to today. What is the date 10 \\ndays ago in MM/DD/YYYY?  \\nA: One day after 06/01/1943 is \\n06/02/1943, so today is 06/02/1943. \\n10 days before today is 05/23/1943.\"),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 3, 'page_label': '4'}, page_content='one day to today. What is the date 10 \\ndays ago in MM/DD/YYYY?  \\nA: One day after 06/01/1943 is \\n06/02/1943, so today is 06/02/1943. \\n10 days before today is 05/23/1943. \\nSo the answer is 05/23/1943. \\nQ: Is the following sentence \\nplausible? \"Joao Moutinho caught the \\nscreen pass in the NFC \\nchampionship.\"  \\nA: Joao Moutinho is a soccer player. \\nThe NFC championship is part of \\nAmerican football, not soccer. So the \\nanswer is no.\\nQ: Take the last letters of the words \\nin “Lady Gaga” and concatenate \\nthem. \\nA: The last letter of “Lady” is “y”. The \\nlast letter of “Gaga” is “a”. \\nConcatenating them is “ya”. So the \\nanswer is ya.\\nQ: A coin is heads up. Maybelle flips \\nthe coin. Shalonda does not flip the \\ncoin. Is the coin still heads up? \\nA: The coin was flipped by Maybelle. \\nSo the coin was flipped 1 time, which \\nis an odd number. The coin started \\nheads up, so after an odd number of \\nflips, it will be tails up. So the answer \\nis no.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 3, 'page_label': '4'}, page_content='A: The coin was flipped by Maybelle. \\nSo the coin was flipped 1 time, which \\nis an odd number. The coin started \\nheads up, so after an odd number of \\nflips, it will be tails up. So the answer \\nis no.\\nMath Word Problems (free response) Math Word Problems (multiple choice) CSQA (commonsense)\\nStrategyQA Date Understanding Sports Understanding\\nLast Letter Concatenation Coin Flip (state tracking)\\nQ: How many keystrokes are needed \\nto type the numbers from 1 to 500?\\nAnswer Choices: (a) 1156 (b) 1392 (c) 1480 \\n(d) 1562 (e) 1788 \\nA: There are 9 one-digit numbers \\nfrom 1 to 9. There are 90 two-digit \\nnumbers from 10 to 99. There are \\n401 three-digit numbers from 100 to \\n500. 9 + 90(2) + 401(3) = 1392. The \\nanswer is (b).\\nSayCan (Instructing a robot)\\nHuman: How would you bring me \\nsomething that isn’t a fruit? \\nExplanation: the user wants \\nsomething to eat that isn’t a fruit. An \\nenergy bar is not a fruit, so I will bring \\nthe user an energy bar.  \\nPlan: 1. find(energy bar) 2.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 3, 'page_label': '4'}, page_content='Explanation: the user wants \\nsomething to eat that isn’t a fruit. An \\nenergy bar is not a fruit, so I will bring \\nthe user an energy bar.  \\nPlan: 1. find(energy bar) 2. \\npick(energy bar) 3. find(user) 4. \\nput(energy bar) 5. done().\\nFigure 3: Examples of ⟨input, chain of thought, output⟩triples for arithmetic, commonsense, and\\nsymbolic reasoning benchmarks. Chains of thought are highlighted. Full prompts in Appendix G.\\nmath word problems, we used this single set of eight chain of thought exemplars for all benchmarks\\nexcept AQuA, which is multiple choice instead of free response. For AQuA, we used four exemplars\\nand solutions from the training set, as given in Appendix Table 21.\\nLanguage models. We evaluate ﬁve large language models. The ﬁrst is GPT-3 (Brown et al.,\\n2020), for which we use text-ada-001, text-babbage-001, text-curie-001, and text-davinci-002, which\\npresumably correspond to InstructGPT models of 350M, 1.3B, 6.7B, and 175B parameters (Ouyang'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 3, 'page_label': '4'}, page_content='2020), for which we use text-ada-001, text-babbage-001, text-curie-001, and text-davinci-002, which\\npresumably correspond to InstructGPT models of 350M, 1.3B, 6.7B, and 175B parameters (Ouyang\\net al., 2022).The second is LaMDA (Thoppilan et al., 2022), which has models of 422M, 2B, 8B,\\n68B, and 137B parameters. The third is PaLM, which has models of 8B, 62B, and 540B parameters.\\nThe fourth is UL2 20B (Tay et al., 2022), and the ﬁfth is Codex (Chen et al., 2021, code-davinci-002\\nin the OpenAI API). We sample from the models via greedy decoding (though follow-up work shows\\nchain-of-thought prompting can be improved by taking the majority ﬁnal answer over many sampled\\ngenerations (Wang et al., 2022a)). For LaMDA, we report averaged results over ﬁve random seeds,\\nwhere each seed had a different randomly shufﬂed order of exemplars. As LaMDA experiments\\ndid not show large variance among different seeds, to save compute we report results for a single\\nexemplar order for all other models.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 3, 'page_label': '4'}, page_content='did not show large variance among different seeds, to save compute we report results for a single\\nexemplar order for all other models.\\n3.2 Results\\nThe strongest results of chain-of-thought prompting are summarized in Figure 4, with all experimental\\noutputs for each model collection, model size, and benchmark shown in Table 2 in the Appendix.\\nThere are three key takeaways. First, Figure 4 shows that chain-of-thought prompting is an emergent\\nability of model scale (Wei et al., 2022b). That is, chain-of-thought prompting does not positively\\nimpact performance for small models, and only yields performance gains when used with models of\\n∼100B parameters. We qualitatively found that models of smaller scale produced ﬂuent but illogical\\nchains of thought, leading to lower performance than standard prompting.\\n4'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 4, 'page_label': '5'}, page_content='0\\n20\\n40\\n60\\nGSM8K\\nsolve rate (%)\\nLaMDA GPT PaLM\\nStandard prompting\\nChain-of-thought prompting\\nPrior supervised best\\n0\\n20\\n40\\n60\\n80\\nSV AMP\\nsolve rate (%)\\n0.4 8 137\\n0\\n25\\n50\\n75\\n100\\nMAWPS\\nsolve rate (%)\\n0.4 7 175 8 62 540\\nModel scale (# parameters in billions)\\nFigure 4: Chain-of-thought prompting enables\\nlarge language models to solve challenging math\\nproblems. Notably, chain-of-thought reasoning\\nis an emergent ability of increasing model scale.\\nPrior best numbers are from Cobbe et al. (2021)\\nfor GSM8K, Jie et al. (2022) for SV AMP, and Lan\\net al. (2021) for MAWPS.\\nSecond, chain-of-thought prompting has larger\\nperformance gains for more-complicated prob-\\nlems. For instance, for GSM8K (the dataset\\nwith the lowest baseline performance), perfor-\\nmance more than doubled for the largest GPT\\nand PaLM models. On the other hand, for Sin-\\ngleOp, the easiest subset of MAWPS which only\\nrequires a single step to solve, performance im-\\nprovements were either negative or very small\\n(see Appendix Table 3).'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 4, 'page_label': '5'}, page_content='gleOp, the easiest subset of MAWPS which only\\nrequires a single step to solve, performance im-\\nprovements were either negative or very small\\n(see Appendix Table 3).\\nThird, chain-of-thought prompting via GPT-3\\n175B and PaLM 540B compares favorably to\\nprior state of the art, which typically ﬁnetunes a\\ntask-speciﬁc model on a labeled training dataset.\\nFigure 4 shows how PaLM 540B uses chain-of-\\nthought prompting to achieve new state of the art\\non GSM8K, SV AMP, and MAWPS (though note\\nthat standard prompting already passed the prior\\nbest for SV AMP). On the other two datasets,\\nAQuA and ASDiv, PaLM with chain-of-thought\\nprompting reaches within 2% of the state of the\\nart (Appendix Table 2).\\nTo better understand why chain-of-thought\\nprompting works, we manually examined model-\\ngenerated chains of thought by LaMDA 137B\\nfor GSM8K. Of 50 random examples where the\\nmodel returned the correct ﬁnal answer, all of\\nthe generated chains of thought were also log-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 4, 'page_label': '5'}, page_content='generated chains of thought by LaMDA 137B\\nfor GSM8K. Of 50 random examples where the\\nmodel returned the correct ﬁnal answer, all of\\nthe generated chains of thought were also log-\\nically and mathematically correct except two\\nthat coincidentally arrived at the correct answer\\n(see Appendix D.1, and Table 8 for examples\\nof correct model-generated chains of thought).\\nWe also randomly examined 50 random sam-\\nples for which the model gave the wrong answer.\\nThe summary of this analysis is that 46% of the\\nchains of thought were almost correct, barring\\nminor mistakes (calculator error, symbol map-\\nping error, or one reasoning step missing), and that the other 54% of the chains of thought had major\\nerrors in semantic understanding or coherence (see Appendix D.2). To provide a small insight into\\nwhy scaling improves chain-of-thought reasoning ability, we performed a similar analysis of errors\\nmade by PaLM 62B and whether those errors were ﬁxed by scaling to PaLM 540B. The summary'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 4, 'page_label': '5'}, page_content='why scaling improves chain-of-thought reasoning ability, we performed a similar analysis of errors\\nmade by PaLM 62B and whether those errors were ﬁxed by scaling to PaLM 540B. The summary\\nis that scaling PaLM to 540B ﬁxes a large portion of one-step missing and semantic understanding\\nerrors in the 62B model (see Appendix A.1).\\n3.3 Ablation Study\\nThe observed beneﬁts of using chain-of-thought prompting raises the natural question of whether the\\nsame performance improvements can be conferred via other types of prompting. Figure 5 shows an\\nablation study with three variations of chain of thought described below.\\nEquation only. One reason for why chain-of-thought prompting might help is that it produces the\\nmathematical equation to be evaluated, and so we test a variation where the model is prompted\\nto output only a mathematical equation before giving the answer. Figure 5 shows that equation\\nonly prompting does not help much for GSM8K, which implies that the semantics of the questions'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 4, 'page_label': '5'}, page_content='to output only a mathematical equation before giving the answer. Figure 5 shows that equation\\nonly prompting does not help much for GSM8K, which implies that the semantics of the questions\\nin GSM8K are too challenging to directly translate into an equation without the natural language\\nreasoning steps in chain of thought. For datasets of one-step or two-step problems, however, we ﬁnd\\nthat equation only prompting does improve performance, since the equation can be easily derived\\nfrom the question (see Appendix Table 6).\\n5'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 5, 'page_label': '6'}, page_content='LaMDA PaLM\\n0\\n20\\n40\\n60\\nGSM8K solve rate (%)\\nStandard prompting\\nEquation only\\nVariable compute only\\nReasoning after answer\\nChain-of-thought prompting\\nFigure 5: Ablation study for dif-\\nferent variations of prompting us-\\ning LaMDA 137B and PaLM 540B.\\nResults for other datasets are given\\nin Appendix Table 6 and Table 7.\\nVariable compute only. Another intuition is that chain of\\nthought allows the model to spend more computation (i.e.,\\nintermediate tokens) on harder problems. To isolate the effect\\nof variable computation from chain-of-thought reasoning, we\\ntest a conﬁguration where the model is prompted to output a\\nonly sequence of dots (... ) equal to the number of characters in\\nthe equation needed to solve the problem. This variant performs\\nabout the same as the baseline, which suggests that variable\\ncomputation by itself is not the reason for the success of chain-\\nof-thought prompting, and that there appears to be utility from\\nexpressing intermediate steps via natural language.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 5, 'page_label': '6'}, page_content='computation by itself is not the reason for the success of chain-\\nof-thought prompting, and that there appears to be utility from\\nexpressing intermediate steps via natural language.\\nChain of thought after answer. Another potential beneﬁt of\\nchain-of-thought prompting could simply be that such prompts\\nallow the model to better access relevant knowledge acquired\\nduring pretraining. Therefore, we test an alternative conﬁgura-\\ntion where the chain of thought prompt is only given after the\\nanswer, isolating whether the model actually depends on the\\nproduced chain of thought to give the ﬁnal answer. This variant\\nperforms about the same as the baseline, which suggests that\\nthe sequential reasoning embodied in the chain of thought is\\nuseful for reasons beyond just activating knowledge.\\n3.4 Robustness of Chain of Thought\\nGSM8K\\n0\\n5\\n10\\n15\\n20Solve rate (%)\\nStandard prompting\\nChain-of-thought prompting\\n·different annotator (B)\\n·different annotator (C)\\n·intentionally concise style'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 5, 'page_label': '6'}, page_content='3.4 Robustness of Chain of Thought\\nGSM8K\\n0\\n5\\n10\\n15\\n20Solve rate (%)\\nStandard prompting\\nChain-of-thought prompting\\n·different annotator (B)\\n·different annotator (C)\\n·intentionally concise style\\n·exemplars from GSM8K (α)\\n·exemplars from GSM8K (β)\\n·exemplars from GSM8K (γ)\\nMAWPS\\n0\\n20\\n40\\n60\\nFigure 6: Chain-of-thought prompting\\nhas variance for different prompt exam-\\nples (as expected) but outperforms stan-\\ndard prompting for various annotators as\\nwell as for different exemplars.\\nSensitivity to exemplars is a key consideration of prompt-\\ning approaches—for instance, varying the permutation of\\nfew-shot exemplars can cause the accuracy of GPT-3 on\\nSST-2 to range from near chance (54.3%) to near state of\\nthe art (93.4%) (Zhao et al., 2021). In this ﬁnal subsec-\\ntion, we evaluate robustness to chains of thought written\\nby different annotators. In addition to the results above,\\nwhich used chains of thought written by an Annotator\\nA, two other co-authors of this paper (Annotators B and'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 5, 'page_label': '6'}, page_content='by different annotators. In addition to the results above,\\nwhich used chains of thought written by an Annotator\\nA, two other co-authors of this paper (Annotators B and\\nC) independently wrote chains of thought for the same\\nfew-shot exemplars (shown in Appendix H). Annotator A\\nalso wrote another chain of thought that was more concise\\nthan the original, following the style of solutions given in\\nCobbe et al. (2021).1\\nFigure 6 shows these results for LaMDA 137B on GSM8K\\nand MAWPS (ablation results for other datasets are given\\nin Appendix Table 6 / Table 7). Although there is variance\\namong different chain of thought annotations, as would be\\nexpected when using exemplar-based prompting (Le Scao\\nand Rush, 2021; Reynolds and McDonell, 2021; Zhao\\net al., 2021), all sets of chain of thought prompts outper-\\nform the standard baseline by a large margin. This result\\nimplies that successful use of chain of thought does not\\ndepend on a particular linguistic style.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 5, 'page_label': '6'}, page_content='form the standard baseline by a large margin. This result\\nimplies that successful use of chain of thought does not\\ndepend on a particular linguistic style.\\nTo conﬁrm that successful chain-of-thought prompting\\nworks for other sets of exemplars, we also run experiments\\nwith three sets of eight exemplars randomly sampled from the GSM8K training set, an independent\\n1For instance, whereas original chain of thought uses several short sentences ( “’There were originally 9\\ncomputers. For each of 4 days, 5 more computers were added. So 5 * 4 = 20 computers were added. 9 + 20 is\\n29. ”), the concise chain of thought would read “5 * 4 = 20 new computers were added. So there are 9 + 20 = 29\\nnew computers in the server room now”.\\n6'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 6, 'page_label': '7'}, page_content='source (examples in this dataset already included reasoning steps like a chain of thought). 2 Fig-\\nure 6 shows that these prompts performed comparably with our manually written exemplars, also\\nsubstantially outperforming standard prompting.\\nIn addition to robustness to annotators, independently-written chains of thought, different exemplars,\\nand various language models, we also ﬁnd that chain-of-thought prompting for arithmetic reasoning\\nis robust to different exemplar orders and varying numbers of exemplars (see Appendix A.2).\\n4 Commonsense Reasoning\\nAlthough chain of thought is particularly suitable for math word problems, the language-based nature\\nof chain of thought actually makes it applicable to a broad class of commonsense reasoning problems,\\nwhich involve reasoning about physical and human interactions under the presumption of general\\nbackground knowledge. Commonsense reasoning is key for interacting with the world and is still'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 6, 'page_label': '7'}, page_content='which involve reasoning about physical and human interactions under the presumption of general\\nbackground knowledge. Commonsense reasoning is key for interacting with the world and is still\\nbeyond the reach of current natural language understanding systems (Talmor et al., 2021).\\nBenchmarks. We consider ﬁve datasets covering a diverse range of commonsense reasoning types.\\nThe popular CSQA (Talmor et al., 2019) asks commonsense questions about the world involving\\ncomplex semantics that often require prior knowledge. StrategyQA (Geva et al., 2021) requires\\nmodels to infer a multi-hop strategy to answer questions. We choose two specialized evaluation sets\\nfrom the BIG-bench effort (BIG-bench collaboration, 2021): Date Understanding, which involves\\ninferring a date from a given context, andSports Understanding, which involves determining whether\\na sentence relating to sports is plausible or implausible. Finally, the SayCan dataset (Ahn et al.,'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 6, 'page_label': '7'}, page_content='inferring a date from a given context, andSports Understanding, which involves determining whether\\na sentence relating to sports is plausible or implausible. Finally, the SayCan dataset (Ahn et al.,\\n2022) involves mapping a natural language instruction to a sequence of robot actions from a discrete\\nset. Figure 3 shows examples with chain of thought annotations for all datasets.\\nPrompts. We follow the same experimental setup as the prior section. For CSQA and StrategyQA,\\nwe randomly selected examples from the training set and manually composed chains of thought for\\nthem to use as few-shot exemplars. The two BIG-bench tasks do not have training sets, so we selected\\nthe ﬁrst ten examples as exemplars in the evaluation set as few-shot exemplars and report numbers on\\nthe rest of the evaluation set. For SayCan, we use six examples from the training set used in Ahn et al.\\n(2022) and also manually composed chains of thought.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 6, 'page_label': '7'}, page_content='the rest of the evaluation set. For SayCan, we use six examples from the training set used in Ahn et al.\\n(2022) and also manually composed chains of thought.\\nResults. Figure 7 highlights these results for PaLM (full results for LaMDA, GPT-3, and different\\nmodel scales are shown in Table 4). For all tasks, scaling up model size improved the performance\\nof standard prompting; chain-of-thought prompting led to further gains, with improvements appear-\\ning to be largest for PaLM 540B. With chain-of-thought prompting, PaLM 540B achieved strong\\nperformance relative to baselines, outperforming the prior state of the art on StrategyQA (75.6% vs\\n69.4%) and outperforming an unaided sports enthusiast on sports understanding (95.4% vs 84%).\\nThese results demonstrate that chain-of-thought prompting can also improve performance on tasks\\nrequiring a range of commonsense reasoning abilities (though note that gain was minimal on CSQA).\\n8 62 540\\n20\\n40\\n60\\n80\\n100Solve rate (%)\\nCSQA\\n8 62 540\\n50\\n60\\n70\\n80\\n90'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 6, 'page_label': '7'}, page_content='requiring a range of commonsense reasoning abilities (though note that gain was minimal on CSQA).\\n8 62 540\\n20\\n40\\n60\\n80\\n100Solve rate (%)\\nCSQA\\n8 62 540\\n50\\n60\\n70\\n80\\n90\\nStrategyQA\\nStandard prompting\\nChain of thought\\nPrior supervised best\\nHuman\\n8 62 540\\n0\\n20\\n40\\n60\\n80\\nModel scale (# parameters in billions)\\nDate\\n8 62 540\\n40\\n60\\n80\\n100\\nSports\\n8 62 540\\n20\\n40\\n60\\n80\\n100\\nSayCan\\nFigure 7: Chain-of-thought prompting also improves the commonsense reasoning abilities of\\nlanguage models. The language model shown here is PaLM. Prior best numbers are from the\\nleaderboards of CSQA (Talmor et al., 2019) and StrategyQA (Geva et al., 2021) (single-model only,\\nas of May 5, 2022). Additional results using various sizes of LaMDA, GPT-3, and PaLM are shown\\nin Table 4.\\n2We sample examples ≤60 tokens to ﬁt into our input context window, and also limit the examples to ≤2\\nsteps to solve for a fair comparison with the eight exemplars that we composed.\\n7'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 7, 'page_label': '8'}, page_content='5 Symbolic Reasoning\\n0\\n25\\n50\\n75\\n100Solve rate (%)\\nLetter Concat: 2\\n(in domain)\\nLetter Concat: 4\\n(OOD)\\nStandard prompting\\nChain-of-thought prompting\\n8 62 540\\n40\\n60\\n80\\n100Solve rate (%)\\nCoin Flip: 2\\n(in domain)\\n8 62 540\\nModel scale (# parameters in billions)\\nCoin Flip: 4\\n(OOD)\\nFigure 8: Using chain-of-thought\\nprompting facilitates generalization to\\nlonger sequences in two symbolic rea-\\nsoning tasks.\\nOur ﬁnal experimental evaluation considers symbolic rea-\\nsoning, which is simple for humans but potentially chal-\\nlenging for language models. We show that chain-of-\\nthought prompting not only enables language models to\\nperform symbolic reasoning tasks that are challenging in\\nthe standard prompting setting, but also facilitates length\\ngeneralization to inference-time inputs longer than those\\nseen in the few-shot exemplars.\\nTasks. We use the following two toy tasks.\\n• Last letter concatenation. This task asks the model\\nto concatenate the last letters of words in a name (e.g.,'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 7, 'page_label': '8'}, page_content='seen in the few-shot exemplars.\\nTasks. We use the following two toy tasks.\\n• Last letter concatenation. This task asks the model\\nto concatenate the last letters of words in a name (e.g.,\\n“Amy Brown” →“yn”). It is a more challenging version\\nof ﬁrst letter concatenation, which language models can\\nalready perform without chain of thought.3 We generate\\nfull names by randomly concatenating names from the\\ntop one-thousand ﬁrst and last names from name census\\ndata (https://namecensus.com/).\\n• Coin ﬂip. This task asks the model to answer whether a\\ncoin is still heads up after people either ﬂip or don’t ﬂip\\nthe coin (e.g., “A coin is heads up. Phoebe ﬂips the coin.\\nOsvaldo does not ﬂip the coin. Is the coin still heads up?”\\n→“no”).\\nAs the construction of these symbolic reasoning tasks is\\nwell-deﬁned, for each task we consider an in-domain test\\nset for which examples had the same number of steps as\\nthe training/few-shot exemplars, as well as an out-of-domain (OOD) test set, for which evaluation'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 7, 'page_label': '8'}, page_content='set for which examples had the same number of steps as\\nthe training/few-shot exemplars, as well as an out-of-domain (OOD) test set, for which evaluation\\nexamples had more steps than those in the exemplars. For last letter concatenation, the model only\\nsees exemplars of names with two words, and then performs last letter concatenation on names with 3\\nand 4 words.4 We do the same for the number of potential ﬂips in the coin ﬂip task. Our experimental\\nsetup uses the same methods and models as in the prior two sections. We again manually compose\\nchains of thought for the few-shot exemplars for each task, which are given in Figure 3.\\nResults. The results of these in-domain and OOD evaluations are shown in Figure 8 for PaLM,\\nwith results for LaMDA shown in Appendix Table 5. With PaLM 540B, chain-of-thought prompting\\nleads to almost 100% solve rates (note that standard prompting already solves coin ﬂip with PaLM'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 7, 'page_label': '8'}, page_content='with results for LaMDA shown in Appendix Table 5. With PaLM 540B, chain-of-thought prompting\\nleads to almost 100% solve rates (note that standard prompting already solves coin ﬂip with PaLM\\n540, though not for LaMDA 137B). Note that these in-domain evaluations are “toy tasks” in the\\nsense that perfect solution structures are already provided by the chains of thought in the few-shot\\nexemplars; all the model has to do is repeat the same steps with the new symbols in the test-time\\nexample. And yet, small models still fail—the ability to perform abstract manipulations on unseen\\nsymbols for these three tasks only arises at the scale of 100B model parameters.\\nAs for the OOD evaluations, standard prompting fails for both tasks. With chain-of-thought prompting,\\nlanguage models achieve upward scaling curves (though performance is lower than in the in-domain\\nsetting). Hence, chain-of-thought prompting facilitates length generalization beyond seen chains of'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 7, 'page_label': '8'}, page_content='language models achieve upward scaling curves (though performance is lower than in the in-domain\\nsetting). Hence, chain-of-thought prompting facilitates length generalization beyond seen chains of\\nthought for language models of sufﬁcient scale.\\n6 Discussion\\nWe have explored chain-of-thought prompting as a simple mechanism for eliciting multi-step rea-\\nsoning behavior in large language models. We ﬁrst saw that chain-of-thought prompting improves\\nperformance by a large margin on arithmetic reasoning, yielding improvements that are much stronger\\nthan ablations and robust to different annotators, exemplars, and language models (Section 3). Next,\\n3We tested 10 common names using GPT-3davinci and it got all but one correct.\\n4For names of length longer than 2 words, we concatenate multiple ﬁrst and last names together.\\n8'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 8, 'page_label': '9'}, page_content='experiments on commonsense reasoning underscored how the linguistic nature of chain-of-thought\\nreasoning makes it generally applicable (Section 4). Finally, we showed that for symbolic reasoning,\\nchain-of-thought prompting facilitates OOD generalization to longer sequence lengths (Section 5). In\\nall experiments, chain-of-thought reasoning is elicited simply by prompting an off-the-shelf language\\nmodel. No language models were ﬁnetuned in the process of writing this paper.\\nThe emergence of chain-of-thought reasoning as a result of model scale has been a prevailing theme\\n(Wei et al., 2022b). For many reasoning tasks where standard prompting has a ﬂat scaling curve, chain-\\nof-thought prompting leads to dramatically increasing scaling curves. Chain-of-thought prompting\\nappears to expand the set of tasks that large language models can perform successfully—in other\\nwords, our work underscores that standard prompting only provides a lower bound on the capabilities'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 8, 'page_label': '9'}, page_content='appears to expand the set of tasks that large language models can perform successfully—in other\\nwords, our work underscores that standard prompting only provides a lower bound on the capabilities\\nof large language models. This observation likely raises more questions than it answers—for instance,\\nhow much more can we expect reasoning ability to improve with a further increase in model scale?\\nWhat other prompting methods might expand the range of tasks that language models can solve?\\nAs for limitations, we ﬁrst qualify that although chain of thought emulates the thought processes of\\nhuman reasoners, this does not answer whether the neural network is actually “reasoning,” which\\nwe leave as an open question. Second, although the cost of manually augmenting exemplars with\\nchains of thought is minimal in the few-shot setting, such annotation costs could be prohibitive for\\nﬁnetuning (though this could potentially be surmounted with synthetic data generation, or zero-shot'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 8, 'page_label': '9'}, page_content='ﬁnetuning (though this could potentially be surmounted with synthetic data generation, or zero-shot\\ngeneralization). Third, there is no guarantee of correct reasoning paths, which can lead to both correct\\nand incorrect answers; improving factual generations of language models is an open direction for\\nfuture work (Rashkin et al., 2021; Ye and Durrett, 2022; Wiegreffe et al., 2022,inter alia). Finally,\\nthe emergence of chain-of-thought reasoning only at large model scales makes it costly to serve in\\nreal-world applications; further research could explore how to induce reasoning in smaller models.\\n7 Related Work\\nThis work is inspired by many research areas, which we detail in an extended related work section\\n(Appendix C). Here we describe two directions and associated papers that are perhaps most relevant.\\nThe ﬁrst relevant direction is using intermediate steps to solve reasoning problems. Ling et al. (2017)'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 8, 'page_label': '9'}, page_content='The ﬁrst relevant direction is using intermediate steps to solve reasoning problems. Ling et al. (2017)\\npioneer the idea of using natural language rationales to solve math word problems through a series\\nof intermediate steps. Their work is a remarkable contrast to the literature using formal languages\\nto reason (Roy et al., 2015; Chiang and Chen, 2019; Amini et al., 2019; Chen et al., 2019). Cobbe\\net al. (2021) extend Ling et al. (2017) by creating a larger dataset and using it to ﬁnetune a pretrained\\nlanguage model rather than training a model from scratch. In the domain of program synthesis,\\nNye et al. (2021) leverage language models to predict the ﬁnal outputs of Python programs via\\nﬁrst line-to-line predicting the intermediate computational results, and show that their step-by-step\\nprediction method performs better than directly predicting the ﬁnal outputs.\\nNaturally, this paper also relates closely to the large body of recent work on prompting. Since the'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 8, 'page_label': '9'}, page_content='prediction method performs better than directly predicting the ﬁnal outputs.\\nNaturally, this paper also relates closely to the large body of recent work on prompting. Since the\\npopularization of few-shot prompting as given by Brown et al. (2020), several general approaches\\nhave improved the prompting ability of models, such as automatically learning prompts (Lester et al.,\\n2021) or giving models instructions describing a task (Wei et al., 2022a; Sanh et al., 2022; Ouyang\\net al., 2022). Whereas these approaches improve or augment the input part of the prompt (e.g.,\\ninstructions that are prepended to inputs), our work takes the orthogonal direction of augmenting the\\noutputs of language models with a chain of thought.\\n8 Conclusions\\nWe have explored chain-of-thought prompting as a simple and broadly applicable method for enhanc-\\ning reasoning in language models. Through experiments on arithmetic, symbolic, and commonsense'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 8, 'page_label': '9'}, page_content='We have explored chain-of-thought prompting as a simple and broadly applicable method for enhanc-\\ning reasoning in language models. Through experiments on arithmetic, symbolic, and commonsense\\nreasoning, we ﬁnd that chain-of-thought reasoning is an emergent property of model scale that allows\\nsufﬁciently large language models to perform reasoning tasks that otherwise have ﬂat scaling curves.\\nBroadening the range of reasoning tasks that language models can perform will hopefully inspire\\nfurther work on language-based approaches to reasoning.\\n9'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 9, 'page_label': '10'}, page_content='Acknowledgements\\nWe thank Jacob Devlin, Claire Cui, Andrew Dai, and Ellie Pavlick for providing feedback on the\\npaper. We thank Jacob Austin, Yuhuai Wu, Henryk Michalewski, Aitor Lewkowycz, Charles Sutton,\\nand Aakanksha Chowdhery for helpful discussions. We thank Sid Maxwell for notifying us about a\\nmistake in the manual error analysis in the original manuscript.\\nReferences\\nMichael Ahn, Anthony Brohan, Noah Brown, Yevgen Chebotar, Omar Cortes, Byron David, Chelsea\\nFinn, Keerthana Gopalakrishnan, Karol Hausman, Alex Herzog, et al. 2022. Do as I can, not as I\\nsay: Grounding language in robotic affordances. arXiv preprint arXiv:2204.01691.\\nAida Amini, Saadia Gabriel, Shanchuan Lin, Rik Koncel-Kedziorski, Yejin Choi, and Hannaneh\\nHajishirzi. 2019. MathQA: Towards interpretable math word problem solving with operation-\\nbased formalisms. In Proceedings of the 2019 Conference of the North American Chapter of the'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 9, 'page_label': '10'}, page_content='Hajishirzi. 2019. MathQA: Towards interpretable math word problem solving with operation-\\nbased formalisms. In Proceedings of the 2019 Conference of the North American Chapter of the\\nAssociation for Computational Linguistics: Human Language Technologies, Volume 1 (Long and\\nShort Papers), Minneapolis, Minnesota. Association for Computational Linguistics.\\nDaniel Andor, Luheng He, Kenton Lee, and Emily Pitler. 2019. Giving BERT a calculator: Finding\\noperations and arguments with reading comprehension. EMNLP.\\nJacob Andreas, Dan Klein, and Sergey Levine. 2018. Learning with latent language. NAACL.\\nJacob Austin, Augustus Odena, Maxwell Nye, Maarten Bosma, Henryk Michalewski, David Dohan,\\nEllen Jiang, Carrie Cai, Michael Terry, Quoc Le, et al. 2021. Program synthesis with large language\\nmodels. arXiv preprint arXiv:2108.07732.\\nBIG-bench collaboration. 2021. Beyond the imitation game: Measuring and extrapolating the\\ncapabilities of language models. In preparation.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 9, 'page_label': '10'}, page_content='models. arXiv preprint arXiv:2108.07732.\\nBIG-bench collaboration. 2021. Beyond the imitation game: Measuring and extrapolating the\\ncapabilities of language models. In preparation.\\nKaj Bostrom, Xinyu Zhao, Swarat Chaudhuri, and Greg Durrett. 2021. Flexible generation of natural\\nlanguage deductions. EMNLP.\\nTom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal,\\nArvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel\\nHerbert-V oss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler,\\nJeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray,\\nBenjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever,\\nand Dario Amodei. 2020. Language models are few-shot learners. NeurIPS.\\nJonathon Cai, Richard Shin, and Dawn Song. 2017. Making neural programming architectures\\ngeneralize via recursion. ICLR.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 9, 'page_label': '10'}, page_content='and Dario Amodei. 2020. Language models are few-shot learners. NeurIPS.\\nJonathon Cai, Richard Shin, and Dawn Song. 2017. Making neural programming architectures\\ngeneralize via recursion. ICLR.\\nOana-Maria Camburu, Tim Rocktäschel, Thomas Lukasiewicz, and Phil Blunsom. 2018. e-SNLI:\\nNatural language inference with natural language explanations. NeurIPS.\\nHoward Chen, Jacqueline He, Karthik Narasimhan, and Danqi Chen. 2022. Can rationalization\\nimprove robustness? NAACL.\\nMark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared\\nKaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, et al. 2021. Evaluating\\nlarge language models trained on code. arXiv preprint arXiv:2107.03374.\\nXinyun Chen, Chen Liang, Adams Wei Yu, Denny Zhou, Dawn Song, and Quoc V . Le. 2019. Neural\\nsymbolic reader: Scalable integration of distributed and symbolic representations for reading\\ncomprehension. ICLR.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 9, 'page_label': '10'}, page_content='symbolic reader: Scalable integration of distributed and symbolic representations for reading\\ncomprehension. ICLR.\\nTing-Rui Chiang and Yun-Nung Chen. 2019. Semantically-aligned equation generation for solving\\nand reasoning math word problems. In Proceedings of the 2019 Conference of the North Ameri-\\ncan Chapter of the Association for Computational Linguistics: Human Language Technologies,\\nVolume 1 (Long and Short Papers), pages 2656–2668, Minneapolis, Minnesota. Association for\\nComputational Linguistics.\\n10'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 10, 'page_label': '11'}, page_content='Peter Clark, Oyvind Tafjord, and Kyle Richardson. 2020. Transformers as soft reasoners over\\nlanguage. IJCAI.\\nKarl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Jacob Hilton, Reiichiro Nakano, Christopher\\nHesse, and John Schulman. 2021. Training veriﬁers to solve math word problems. arXiv preprint\\narXiv:2110.14168.\\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of\\ndeep bidirectional transformers for language understanding. NAACL.\\nHonghua Dong, Jiayuan Mao, Tian Lin, Chong Wang, Lihong Li, and Denny Zhou. 2019. Neural\\nlogic machines. ICLR.\\nDheeru Dua, Sameer Singh, and Matt Gardner. 2020. Beneﬁts of intermediate annotations in reading\\ncomprehension. ACL.\\nMor Geva, Daniel Khashabi, Elad Segal, Tushar Khot, Dan Roth, and Jonathan Berant. 2021. Did\\naristotle use a laptop? A question answering benchmark with implicit reasoning strategies. TACL.\\nYuling Gu, Bhavana Dalvi Mishra, and Peter Clark. 2022. DREAM: Uncovering mental models'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 10, 'page_label': '11'}, page_content='aristotle use a laptop? A question answering benchmark with implicit reasoning strategies. TACL.\\nYuling Gu, Bhavana Dalvi Mishra, and Peter Clark. 2022. DREAM: Uncovering mental models\\nbehind language models. NAACL.\\nBraden Hancock, Paroma Varma, Stephanie Wang, Martin Bringmann, Percy Liang, and Christopher\\nRé. 2018. Training classiﬁers with natural language explanations. ACL.\\nPeter Hase and Mohit Bansal. 2022. When can models learn from explanations? a formal framework\\nfor understanding the roles of explanation data. ACL.\\nDan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang, Dawn Song,\\nand Jacob Steinhardt. 2021. Measuring mathematical problem solving with the math dataset. arXiv\\npreprint arXiv:2103.03874.\\nMohammad Javad Hosseini, Hannaneh Hajishirzi, Oren Etzioni, and Nate Kushman. 2014. Learning\\nto solve arithmetic word problems with verb categorization. EMNLP.\\nZhanming Jie, Jierui Li, and Wei Lu. 2022. Learning to reason deductively: Math word problem'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 10, 'page_label': '11'}, page_content='to solve arithmetic word problems with verb categorization. EMNLP.\\nZhanming Jie, Jierui Li, and Wei Lu. 2022. Learning to reason deductively: Math word problem\\nsolving as complex relation extraction. arXiv preprint arXiv:2203.10316.\\nJared Kaplan, Sam McCandlish, Tom Henighan, Tom B Brown, Benjamin Chess, Rewon Child,\\nScott Gray, Alec Radford, Jeffrey Wu, and Dario Amodei. 2020. Scaling laws for neural language\\nmodels. arXiv preprint arXiv:2001.08361.\\nRik Koncel-Kedziorski, Subhro Roy, Aida Amini, Nate Kushman, and Hannaneh Hajishirzi. 2016.\\nMAWPS: A math word problem repository. NAACL.\\nAndrew K. Lampinen, Ishita Dasgupta, Stephanie C.Y . Chan, Kory Matthewson, Michael Henry\\nTessler, Antonia Creswell, James L. McClelland, Jane X. Wang, and Felix Hill. 2022. Can language\\nmodels learn from explanations in context? arXiv preprint arXiv:2204.02329.\\nYihuai Lan, Lei Wang, Qiyuan Zhang, Yunshi Lan, Bing Tian Dai, Yan Wang, Dongxiang Zhang,'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 10, 'page_label': '11'}, page_content='models learn from explanations in context? arXiv preprint arXiv:2204.02329.\\nYihuai Lan, Lei Wang, Qiyuan Zhang, Yunshi Lan, Bing Tian Dai, Yan Wang, Dongxiang Zhang,\\nand Ee-Peng Lim. 2021. MWPToolkit: An open-source framework for deep learning-based math\\nword problem solvers. arXiv preprint arXiv:2109.00799.\\nTeven Le Scao and Alexander Rush. 2021. How many data points is a prompt worth? NAACL.\\nBrian Lester, Rami Al-Rfou, and Noah Constant. 2021. The power of scale for parameter-efﬁcient\\nprompt tuning. EMNLP.\\nIddo Lev, Bill MacCartney, Christopher Manning, and Roger Levy. 2004. Solving logic puzzles:\\nFrom robust processing to precise semantics. Proceedings of the 2nd Workshop on Text Meaning\\nand Interpretation.\\nXiang Lisa Li and Percy Liang. 2021. Preﬁx-tuning: Optimizing continuous prompts for generation.\\nACL.\\n11'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 11, 'page_label': '12'}, page_content='Zhengzhong Liang, Steven Bethard, and Mihai Surdeanu. 2021. Explainable multi-hop verbal\\nreasoning through internal monologue. NAACL.\\nWang Ling, Dani Yogatama, Chris Dyer, and Phil Blunsom. 2017. Program induction by rationale\\ngeneration: Learning to solve and explain algebraic word problems. ACL.\\nPengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki Hayashi, and Graham Neubig. 2021.\\nPre-train, prompt, and predict: A systematic survey of prompting methods in natural language\\nprocessing. arXiv preprint arXiv:2107.13586.\\nBodhisattwa Prasad Majumder, Oana-Maria Camburu, Thomas Lukasiewicz, and Julian McAuley.\\n2021. Rationale-inspired natural language explanations with commonsense. arXiv preprint\\narXiv:2106.13876.\\nAna Marasovi´c, Iz Beltagy, Doug Downey, and Matthew E Peters. 2022. Few-shot self-rationalization\\nwith natural language prompts. NAACL Findings.\\nJoshua Maynez, Shashi Narayan, Bernd Bohnet, and Ryan McDonald. 2020. On faithfulness and'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 11, 'page_label': '12'}, page_content='with natural language prompts. NAACL Findings.\\nJoshua Maynez, Shashi Narayan, Bernd Bohnet, and Ryan McDonald. 2020. On faithfulness and\\nfactuality in abstractive summarization. In ACL.\\nShen Yun Miao, Chao Chun Liang, and Keh Yih Su. 2020. A diverse corpus for evaluating and\\ndeveloping English math word problem solvers. ACL.\\nSewon Min, Xinxi Lyu, Ari Holtzman, Mikel Artetxe, Mike Lewis, Hannaneh Hajishirzi, and Luke\\nZettlemoyer. 2022. Rethinking the role of demonstrations: What makes in-context learning work?\\narXiv preprint arXiv:2202.12837.\\nSharan Narang, Colin Raffel, Katherine Lee, Adam Roberts, Noah Fiedel, and Karishma Malkan.\\n2020. WT5?! Training text-to-text models to explain their predictions. arXiv preprint\\narXiv:2004.14546.\\nMaxwell Nye, Anders Johan Andreassen, Guy Gur-Ari, Henryk Michalewski, Jacob Austin, David\\nBieber, David Dohan, Aitor Lewkowycz, Maarten Bosma, David Luan, et al. 2021. Show your work:'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 11, 'page_label': '12'}, page_content='Maxwell Nye, Anders Johan Andreassen, Guy Gur-Ari, Henryk Michalewski, Jacob Austin, David\\nBieber, David Dohan, Aitor Lewkowycz, Maarten Bosma, David Luan, et al. 2021. Show your work:\\nScratchpads for intermediate computation with language models. arXiv preprint arXiv:2112.00114.\\nLong Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela Mishkin, Chong\\nZhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. 2022. Training language models to\\nfollow instructions with human feedback. arXiv preprint arXiv:2203.02155.\\nArkil Patel, Satwik Bhattamishra, and Navin Goyal. 2021. Are NLP models really able to solve\\nsimple math word problems? NAACL.\\nMatthew E. Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark, Kenton Lee, and\\nLuke Zettlemoyer. 2018. Deep contextualized word representations. NAACL.\\nXinyu Pi, Qian Liu, Bei Chen, Morteza Ziyadi, Zeqi Lin, Yan Gao, Qiang Fu, Jian-Guang Lou, and'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 11, 'page_label': '12'}, page_content='Luke Zettlemoyer. 2018. Deep contextualized word representations. NAACL.\\nXinyu Pi, Qian Liu, Bei Chen, Morteza Ziyadi, Zeqi Lin, Yan Gao, Qiang Fu, Jian-Guang Lou, and\\nWeizhu Chen. 2022. Reasoning like program executors. arXiv preprint arXiv:2201.11473.\\nPiotr Pi˛ ekos, Mateusz Malinowski, and Henryk Michalewski. 2021. Measuring and improving\\nBERT’s mathematical abilities by predicting the order of reasoning.ACL.\\nJack W. Rae, Sebastian Borgeaud, Trevor Cai, Katie Millican, Jordan Hoffmann, Francis Song, John\\nAslanides, Sarah Henderson, Roman Ring, Susannah Young, et al. 2021. Scaling language models:\\nMethods, analysis & insights from training Gopher. arXiv preprint arXiv:2112.11446.\\nColin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi\\nZhou, Wei Li, and Peter J Liu. 2020. Exploring the limits of transfer learning with a uniﬁed\\ntext-to-text transformer. Journal of Machine Learning Research, 21:1–67.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 11, 'page_label': '12'}, page_content='Zhou, Wei Li, and Peter J Liu. 2020. Exploring the limits of transfer learning with a uniﬁed\\ntext-to-text transformer. Journal of Machine Learning Research, 21:1–67.\\nDheeraj Rajagopal, Vidhisha Balachandran, Eduard H. Hovy, and Yulia Tsvetkov. 2021. SelfExplain:\\nA self-explaining architecture for neural text classiﬁers. EMNLP.\\nNazneen Fatema Rajani, Bryan McCann, Caiming Xiong, and Richard Socher. 2019. Explain\\nyourself! Leveraging language models for commonsense reasoning. ACL.\\n12'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 12, 'page_label': '13'}, page_content='Qiu Ran, Yankai Lin, Peng Li, Jie Zhou, and Zhiyuan Liu. 2019. NumNet: Machine reading\\ncomprehension with numerical reasoning. EMNLP.\\nHannah Rashkin, Vitaly Nikolaev, Matthew Lamm, Michael Collins, Dipanjan Das, Slav Petrov,\\nGaurav Singh Tomar, Iulia Turc, and David Reitter. 2021. Measuring attribution in natural language\\ngeneration models. arXiv preprint arXiv:2112.12870.\\nGabriel Recchia. 2021. Teaching autoregressive language models complex tasks by demonstration.\\narXiv preprint arXiv:2109.02102.\\nEmily Reif, Daphne Ippolito, Ann Yuan, Andy Coenen, Chris Callison-Burch, and Jason Wei. 2022.\\nA recipe for arbitrary text style transfer with large language models. ACL.\\nLaria Reynolds and Kyle McDonell. 2021. Prompt programming for large language models: Beyond\\nthe few-shot paradigm. Extended Abstracts of the 2021 CHI Conference on Human Factors in\\nComputing Systems.\\nSubhro Roy and Dan Roth. 2015. Solving general arithmetic word problems. EMNLP.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 12, 'page_label': '13'}, page_content='the few-shot paradigm. Extended Abstracts of the 2021 CHI Conference on Human Factors in\\nComputing Systems.\\nSubhro Roy and Dan Roth. 2015. Solving general arithmetic word problems. EMNLP.\\nSubhro Roy, Tim Vieira, and Dan Roth. 2015. Reasoning about Quantities in Natural Language.\\nTACL.\\nMohammed Saeed, Naser Ahmadi, Preslav Nakov, and Paolo Papotti. 2021. RuleBERT: Teaching\\nsoft rules to pre-trained language models. EMNLP.\\nVictor Sanh, Albert Webson, Colin Raffel, Stephen H. Bach, Lintang Sutawika, Zaid Alyafeai,\\nAntoine Chafﬁn, Arnaud Stiegler, Teven Le Scao, Arun Raja, et al. 2022. Multitask prompted\\ntraining enables zero-shot task generalization. ICLR.\\nJianhao Shen, Yichun Yin, Lin Li, Lifeng Shang, Xin Jiang, Ming Zhang, and Qun Liu. 2021.\\nGenerate & rank: A multi-task framework for math word problems. In Findings of the Association\\nfor Computational Linguistics: EMNLP 2021.\\nAlon Talmor, Jonathan Herzig, Nicholas Lourie, and Jonathan Berant. 2019. CommonsenseQA: A'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 12, 'page_label': '13'}, page_content='for Computational Linguistics: EMNLP 2021.\\nAlon Talmor, Jonathan Herzig, Nicholas Lourie, and Jonathan Berant. 2019. CommonsenseQA: A\\nquestion answering challenge targeting commonsense knowledge. NAACL.\\nAlon Talmor, Oyvind Tafjord, Peter Clark, Yoav Goldberg, and Jonathan Berant. 2020. Leap-of-\\nthought: Teaching pre-trained models to systematically reason over implicit knowledge. NeurIPS.\\nAlon Talmor, Ori Yoran, Ronan Le Bras, Chandra Bhagavatula, Yoav Goldberg, Yejin Choi, and\\nJonathan Berant. 2021. CommonsenseQA 2.0: Exposing the limits of ai through gamiﬁcation.\\nNeurIPS Track on Datasets and Benchmarks.\\nYi Tay, Mostafa Dehghani, Vinh Q Tran, Xavier Garcia, Dara Bahri, Tal Schuster, Huaixiu Steven\\nZheng, Neil Houlsby, and Donald Metzler. 2022. Unifying language learning paradigms. arXiv\\npreprint arXiv:2205.05131.\\nRomal Thoppilan, Daniel De Freitas, Jamie Hall, Noam Shazeer, Apoorv Kulshreshtha, Heng-Tze'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 12, 'page_label': '13'}, page_content='preprint arXiv:2205.05131.\\nRomal Thoppilan, Daniel De Freitas, Jamie Hall, Noam Shazeer, Apoorv Kulshreshtha, Heng-Tze\\nCheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu Du, et al. 2022. LaMDA: Language models for\\ndialog applications. arXiv preprint arXiv:2201.08239.\\nXuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, and Denny Zhou. 2022a.\\nSelf-consistency improves chain of thought reasoning in language models. arXiv preprint\\narXiv:2203.11171.\\nYizhong Wang, Swaroop Mishra, Pegah Alipoormolabashi, Yeganeh Kordi, Amirreza Mirzaei, Anjana\\nArunkumar, Arjun Ashok, Arut Selvan Dhanasekaran, Atharva Naik, David Stap, et al. 2022b.\\nBenchmarking generalization via in-context instructions on 1,600+ language tasks. arXiv preprint\\narXiv:2204.07705.\\nJason Wei, Maarten Bosma, Vincent Y . Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du,\\nAndrew M. Dai, and Quoc V . Le. 2022a. Finetuned language models are zero-shot learners.ICLR.\\n13'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 13, 'page_label': '14'}, page_content='Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama,\\nMaarten Bosma, Denny Zhou, Donald Metzler, et al. 2022b. Emergent abilities of large language\\nmodels. Transactions on Machine Learning Research.\\nSarah Wiegreffe, Jack Hessel, Swabha Swayamdipta, Mark Riedl, and Yejin Choi. 2022. Reframing\\nhuman-AI collaboration for generating free-text explanations. NAACL.\\nSarah Wiegreffe and Ana Marasovi´c. 2021. Teach me to explain: A review of datasets for explainable\\nNLP. NeurIPS.\\nSarah Wiegreffe, Ana Marasovi´c, and Noah A. Smith. 2021. Measuring association between labels\\nand free-text rationales. EMNLP.\\nTongshuang Wu, Ellen Jiang, Aaron Donsbach, Jeff Gray, Alejandra Molina, Michael Terry, and\\nCarrie J Cai. 2022a. PromptChainer: Chaining large language model prompts through visual\\nprogramming. CHI Extended Abstracts.\\nTongshuang Wu, Michael Terry, and Carrie Jun Cai. 2022b. AI chains: Transparent and controllable'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 13, 'page_label': '14'}, page_content='programming. CHI Extended Abstracts.\\nTongshuang Wu, Michael Terry, and Carrie Jun Cai. 2022b. AI chains: Transparent and controllable\\nhuman-AI interaction by chaining large language model prompts. CHI.\\nYujun Yan, Kevin Swersky, Danai Koutra, Parthasarathy Ranganathan, and Milad Hashemi. 2020.\\nNeural execution engines: Learning to execute subroutines. NeurIPS.\\nHuihan Yao, Ying Chen, Qinyuan Ye, Xisen Jin, and Xiang Ren. 2021. Reﬁning language models\\nwith compositional explanations. NeurIPS.\\nXi Ye and Greg Durrett. 2022. The unreliability of explanations in few-shot in-context learning.\\narXiv preprint arXiv:2205.03401.\\nYordan Yordanov, Vid Kocijan, Thomas Lukasiewicz, and Oana-Maria Camburu. 2021. Few-shot\\nout-of-domain transfer learning of natural language explanations.arXiv preprint arXiv:2112.06204.\\nOmar Zaidan, Jason Eisner, and Christine Piatko. 2007. Using “annotator rationales” to improve\\nmachine learning for text categorization. NAACL.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 13, 'page_label': '14'}, page_content='Omar Zaidan, Jason Eisner, and Christine Piatko. 2007. Using “annotator rationales” to improve\\nmachine learning for text categorization. NAACL.\\nWojciech Zaremba and Ilya Sutskever. 2014. Learning to execute. arXiv preprint arXiv:1410.4615.\\nEric Zelikman, Yuhuai Wu, and Noah D. Goodman. 2022. STaR: Bootstrapping reasoning with\\nreasoning. arXiv preprint arXiv:2203.14465.\\nTony Z. Zhao, Eric Wallace, Shi Feng, Dan Klein, and Sameer Singh. 2021. Calibrate before use:\\nImproving few-shot performance of language models. ICML.\\nWangchunshu Zhou, Jinyi Hu, Hanlin Zhang, Xiaodan Liang, Maosong Sun, Chenyan Xiong, and\\nJian Tang. 2020. Towards interpretable natural language understanding with explanations as latent\\nvariables. NeurIPS.\\n14'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 14, 'page_label': '15'}, page_content='Checklist\\n1. For all authors...\\n(a) Do the main claims made in the abstract and introduction accurately reﬂect the paper’s\\ncontributions and scope? [Yes]\\n(b) Did you describe the limitations of your work? [Yes] See Section 6 and Appendix A.2.\\n(c) Did you discuss any potential negative societal impacts of your work? [Yes] We don’t\\nexpect negative societal impacts as a direct result of the contributions in our paper. One\\nconsideration, however, is that generated chain of thought is not always factual, which\\nis noted as a limitation in Appendix D.1 (and note that we do not suggest using such\\nchains of thought in a factual manner or in any real-world scenario).\\n(d) Have you read the ethics review guidelines and ensured that your paper conforms to\\nthem? [Yes]\\n2. If you are including theoretical results...\\n(a) Did you state the full set of assumptions of all theoretical results? [N/A]\\n(b) Did you include complete proofs of all theoretical results? [N/A]\\n3. If you ran experiments...'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 14, 'page_label': '15'}, page_content='(a) Did you state the full set of assumptions of all theoretical results? [N/A]\\n(b) Did you include complete proofs of all theoretical results? [N/A]\\n3. If you ran experiments...\\n(a) Did you include the code, data, and instructions needed to reproduce the main experi-\\nmental results (either in the supplemental material or as a URL)? [Yes] We included\\ninputs, outputs, and targets for LaMDA and GPT-3 in the supplementary material.\\nAlthough we use proprietary models, we GPT-3 results are fully reproducible. Repro-\\nducibility is further discussed in Appendix E.1.\\n(b) Did you specify all the training details (e.g., data splits, hyperparameters, how they\\nwere chosen)? [Yes] Data splits were speciﬁed, N/A for hyperparams.\\n(c) Did you report error bars (e.g., with respect to the random seed after running exper-\\niments multiple times)? [Yes] Standard deviation for multiple seeds using LaMDA\\n137B, where each seed is a different random order of exemplars, is given in Table 6\\nand Table 7.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 14, 'page_label': '15'}, page_content='iments multiple times)? [Yes] Standard deviation for multiple seeds using LaMDA\\n137B, where each seed is a different random order of exemplars, is given in Table 6\\nand Table 7.\\n(d) Did you include the total amount of compute and the type of resources used (e.g., type\\nof GPUs, internal cluster, or cloud provider)? [Yes] Type of resources are described in\\nAppendix E.2, though we did not estimate the total amount of compute.\\n4. If you are using existing assets (e.g., code, data, models) or curating/releasing new assets...\\n(a) If your work uses existing assets, did you cite the creators? [Yes] We used two models\\nthat we anonymized based on the recommendation of the NeurIPS chairs. These models\\nwill be cited in the camera-ready version of the paper.\\n(b) Did you mention the license of the assets? [Yes] See Appendix E.3.\\n(c) Did you include any new assets either in the supplemental material or as a URL? [Yes]'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 14, 'page_label': '15'}, page_content='(b) Did you mention the license of the assets? [Yes] See Appendix E.3.\\n(c) Did you include any new assets either in the supplemental material or as a URL? [Yes]\\nThe coinﬂip and last letter concatenation datasets are the only new assets, and they are\\ngiven in the Supplementary Materials.\\n(d) Did you discuss whether and how consent was obtained from people whose data you’re\\nusing/curating? [N/A] No human data collected.\\n(e) Did you discuss whether the data you are using/curating contains personally identiﬁable\\ninformation or offensive content? [N/A] No human data collected.\\n5. If you used crowdsourcing or conducted research with human subjects...\\n(a) Did you include the full text of instructions given to participants and screenshots, if\\napplicable? [N/A]\\n(b) Did you describe any potential participant risks, with links to Institutional Review\\nBoard (IRB) approvals, if applicable? [N/A]\\n(c) Did you include the estimated hourly wage paid to participants and the total amount'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 14, 'page_label': '15'}, page_content='Board (IRB) approvals, if applicable? [N/A]\\n(c) Did you include the estimated hourly wage paid to participants and the total amount\\nspent on participant compensation? [N/A]\\n15'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 15, 'page_label': '16'}, page_content='A Frequently Asked Questions\\nA.1 Why does increasing model scale improve chain-of-thought prompting?\\nThe ﬁnding that successful chain-of-thought reasoning predictably emerges only at certain model\\nscales is intriguing. Scaling up language models has been shown to confer beneﬁts such as improved\\nperformance and sample efﬁciency (Kaplan et al., 2020), but chain-of-thought reasoning is emergent\\nin the sense that its success cannot be predicted only by extrapolating the performance of small scale\\nmodels, as chain of thought actually hurts performance for most models smaller than 10B parameters.\\nThe question of why model scale improves chain-of-thought prompting is certainly multi-faceted, and\\nwe made a preliminary attempt to shed insight into it via error analysis. This small analysis involved\\nmanually reading 45 errors made by PaLM 62B and categorizing them into semantic understanding\\n(20 errors), one step missing (18 errors), and other errors (7 errors). The “other category” included'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 15, 'page_label': '16'}, page_content='manually reading 45 errors made by PaLM 62B and categorizing them into semantic understanding\\n(20 errors), one step missing (18 errors), and other errors (7 errors). The “other category” included\\nhallucinations, repetitive outputs, and symbol mapping errors. This categorization is a coarse one\\nborrowed from the initial error analysis done on LaMDA in Appendix D.2, for which categories were\\nconceived based on what improvements were needed to make the chain of thought correct.\\nAs shown in Figure 9, scaling PaLM to 540B parameters ﬁxed a substantial portion of errors in all\\nthree categories. Examples of semantic understanding and one-step missing errors that were ﬁxed by\\nscaling PaLM to 540B are given in Figure 10. This result appears consistent with a hypothesis that\\nlanguage models acquire a range of semantic understanding and logical reasoning skills as a function\\nof model scale (though note that model scale is often conﬂated with other factors, such as amount of\\ntraining compute).'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 15, 'page_label': '16'}, page_content='of model scale (though note that model scale is often conﬂated with other factors, such as amount of\\ntraining compute).\\nSemantic understanding\\n(62B made 20 errors of this type, \\n540B ﬁxes 6 of them)\\nOne step missing\\n(62B made 18 errors of this type, \\n540B ﬁxes 12 of them)\\nOther\\n(62B made 7 errors of this type, \\n540B ﬁxes 4 of them)\\nTypes of errors made by \\na 62B language model:\\nErrors ﬁxed by \\nscaling from \\n62B to 540B\\nFigure 9: Error analysis of 45 problems that PaLM 62B got incorrect. These errors were categorized\\nthat semantic understanding, one step missing, and other. The other category includes hallucinations,\\nrepetitive outputs, and symbol mapping errors. Scaling PaLM to 540B ﬁxed a substantial portion of\\nerrors in all categories.\\nThere are also three notable points regarding why small language models fail. The ﬁrst observation\\nis that small language models fail at even relatively easy symbol mapping tasks. As demonstrated'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 15, 'page_label': '16'}, page_content='There are also three notable points regarding why small language models fail. The ﬁrst observation\\nis that small language models fail at even relatively easy symbol mapping tasks. As demonstrated\\nin Section 5, for even symbolic reasoning tasks that only require generalization to new examples\\nusing the same chain of thought logical structure that was given in the few-shot exemplars, small\\nlanguage models still failed. The second observation is that small language models seem to have\\ninherently weaker arithmetic abilities, as shown by Brown et al. (2020), the ability to do simple\\narithmetic operations (without semantic understanding) requires sufﬁcient model scale. Finally, we\\nnoticed qualitatively that small language models often did not generate a ﬁnal answer that could be\\nparsed, due to either repetitions or logic that never arrived at a ﬁnal answer.\\nIn summary, the success of chain-of-thought reasoning as a result of model scale is a complicated'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 15, 'page_label': '16'}, page_content='parsed, due to either repetitions or logic that never arrived at a ﬁnal answer.\\nIn summary, the success of chain-of-thought reasoning as a result of model scale is a complicated\\nphenomena that likely involves a variety of emergent abilities (semantic understanding, symbol\\nmapping, staying on topic, arithmetic ability, faithfulness, etc). Future work could more thoroughly\\ninvestigate what properties of pretraining data, model architecture, and optimization objective causally\\nenable such reasoning capabilities.\\n16'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 16, 'page_label': '17'}, page_content=\"Tracy used a piece of wire 4 \\nfeet long to support tomato \\nplants in the garden. The \\nwire was cut into pieces 6 \\ninches long. How many \\npieces did she obtain?\\nShe cut the wire into 6 inch pieces. \\nThis means she got 4 * 6 = 24 \\npieces. The answer is 24. \\n(Incorrect: semantic \\nunderstanding error)\\n62B Model OutputQuestion 540B Model Output\\nThe wire was 4 feet long. This \\nmeans it was 4 * 12 = 48 inches \\nlong. It was cut into pieces 6 inches \\nlong. This means she obtained 48 / \\n6 = 8 pieces. The answer is 8. \\n(Correct)\\nTom's ship can travel at 10 \\nmiles per hour. He is sailing \\nfrom 1 to 4 PM. He then \\ntravels back at a rate of 6 \\nmph. How long does it take \\nhim to get back?\\nHe travels from 1 to 4 PM. That \\nmeans he travels for 3 hours. He \\ntravels back at 6 mph. That means \\nhe travels for 3 * 6 = 18 miles. The \\nanswer is 18. (Incorrect: semantic \\nunderstanding error)\\nHe travels at 10 mph from 1 to 4 \\nPM. This means he travels 3 hours. \\n3 hours at 10 mph means he travels\"),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 16, 'page_label': '17'}, page_content=\"answer is 18. (Incorrect: semantic \\nunderstanding error)\\nHe travels at 10 mph from 1 to 4 \\nPM. This means he travels 3 hours. \\n3 hours at 10 mph means he travels \\n3 * 10 = 30 miles. He then travels \\nback at 6 mph. This means he \\ntravels 6 miles per hour. He has to \\ntravel 30 miles, so it takes him 30 / 6 \\n= 5 hours. The answer is 5. \\n(Correct)\\nStephen placed an online \\norder for groceries. His final \\nbill came to $40.00. \\nBecause this was through a \\ndelivery vendor, they tacked \\non a 25% fee to his final \\ntotal and charged him $3.00 \\nin delivery fees. Stephen \\nalso added a $4.00 tip. After \\nthe extra fees, what was the \\nfinal price of Stephen's \\ngroceries?\\nThe final price of Stephen's \\ngroceries was $40.00. The delivery \\nvendor added 25% to the final total, \\nso the final total was 125% of \\n$40.00. This means the final total \\nwas 125% * $40.00 = $50.00. The \\ndelivery vendor also charged $3.00 \\nin delivery fees. So the final price of \\nStephen's groceries was $50.00 +\"),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 16, 'page_label': '17'}, page_content=\"$40.00. This means the final total \\nwas 125% * $40.00 = $50.00. The \\ndelivery vendor also charged $3.00 \\nin delivery fees. So the final price of \\nStephen's groceries was $50.00 + \\n$3.00 = $53.00. The answer is \\n$53.00. (Incorrect: one step \\nmissing error)\\nStephen's bill was $40.00. The \\ndelivery vendor added 25% to the \\nbill. This means the bill was \\nincreased by 25% of $40.00. This is \\n0.25 * $40.00 = $10.00. The delivery \\nfee was $3.00. The tip was $4.00. \\nSo the total bill was $40.00 + $10.00 \\n+ $3.00 + 540b model $4.00 = \\n$57.00. The answer is 57. (Correct)\\nThere are four schools \\ncompeting at a basketball \\ntournament. Each school \\nhas sent a girls’ basketball \\nteam and a boys’ basketball \\nteam and each team has 5 \\nplayers each. Each school \\nhas also sent a coach for \\neach team. In total, how \\nmany people have all of the \\nschools sent?\\nThere are 4 schools. Each school \\nhas sent a girls’ basketball team and \\na boys’ basketball team. Each team \\nhas 5 players each. That means\"),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 16, 'page_label': '17'}, page_content='many people have all of the \\nschools sent?\\nThere are 4 schools. Each school \\nhas sent a girls’ basketball team and \\na boys’ basketball team. Each team \\nhas 5 players each. That means \\nthere are 4 * 2 * 5 = 40 players. \\nEach team has a coach. That \\nmeans there are 40 + 4 = 44 \\ncoaches. The answer is 44. \\n(Incorrect: one step missing \\nerror)\\nEach school has sent 2 teams, each \\nwith 5 players. This means each \\nschool has sent 2 * 5 = 10 players. \\nEach school has also sent 2 \\ncoaches. This means each school \\nhas sent 10 + 2 = 12 people. There \\nare 4 schools, so in total all of the \\nschools have sent 4 * 12 = 48 \\npeople. The answer is 48. (Correct)\\n62B Model Output\\n62B Model Output\\n62B Model Output\\n540B Model Output\\n540B Model Output\\n540B Model Output\\nQuestion\\nQuestion\\nQuestion\\nFigure 10: Examples of semantic understanding and one-step missing errors that were ﬁxed by\\nscaling PaLM from 62B to 540B.\\nA.2 What is the role of prompt engineering?'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 16, 'page_label': '17'}, page_content='Question\\nQuestion\\nQuestion\\nFigure 10: Examples of semantic understanding and one-step missing errors that were ﬁxed by\\nscaling PaLM from 62B to 540B.\\nA.2 What is the role of prompt engineering?\\nOne of the key considerations of prompting is sensitivity to the exact prompt. There is no shortage\\nof work showing that prompts affect language models in unexpected ways (Min et al., 2022). The\\ngeneral way that we created chain of thought annotations was by taking eight exemplars from the\\ntraining set and decomposing the reasoning process into multiple steps leading to the ﬁnal answer.\\nExamples of chain of thought annotations are provided in Figure 3, with full prompts given in\\nAppendix G. To analyze how sensitive chain of thought is to prompt engineering, we performed\\nrobustness experiments with respect to various factors.\\n• Different annotators. We ﬁrst analyze robustness to three different annotators (Section 3.4 and'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 16, 'page_label': '17'}, page_content='robustness experiments with respect to various factors.\\n• Different annotators. We ﬁrst analyze robustness to three different annotators (Section 3.4 and\\nFigure 6). Although there is notable variance in performance (which we will discuss later), chain\\nof thought performed better than the baseline by a large margin for all three annotators on eight\\ndatasets in arithmetic, commonsense, and symbolic reasoning (Table 6 and Table 7). Similar to the\\nannotation process in Cobbe et al. (2021), annotators were not given speciﬁc instructions about\\n17'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 17, 'page_label': '18'}, page_content='how to write the chain of thought annotations other than to simply write the step-by-step reasoning\\nprocess that led to the ﬁnal answer. Thus, the annotations were written in each annotator’s own\\nlinguistic “chain of thought” writing style.\\n• Annotators without machine learning background. The GSM8K dataset (Cobbe et al., 2021)\\nconveniently provides a training set with reasoning chains written by crowd compute workers,\\nwhich enables us to investigate whether chain of thought still works with reasoning chains from an\\nindependent source without a background in machine learning. So we randomly sampled three sets\\nof eight exemplars with chains of thought from GSM8K. These chain of thought annotations also\\noutperformed the baseline by a large margin for all four arithmetic datasets (Table 6), indicating\\nthat chain of thought is not dependent on a particular set of annotators.\\n• Different exemplars. The different GSM8K exemplars experiment above (Table 6) also shows'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 17, 'page_label': '18'}, page_content='that chain of thought is not dependent on a particular set of annotators.\\n• Different exemplars. The different GSM8K exemplars experiment above (Table 6) also shows\\nthat chain-of-thought prompting works for different sets of exemplars. Notably, we test every set of\\nexemplars on all four arithmetic datasets (instead of picking exemplars from the training set for\\neach dataset), which suggests that the exemplars do not necessarily have to come from the same\\ndataset distribution as the test examples.\\n• Different order of exemplars. Prior work has shown that in some cases (e.g., classiﬁcation) even\\nthe order of prompts matter—varying the permutation of few-shot exemplars can cause the accuracy\\nof GPT-3 on SST-2 to range from near chance (54.3%) to near SOTA (93.4%) (Zhao et al., 2021).\\nWe show the standard deviation of performance from different exemplars in Table 6 and Table 7.\\nStandard deviations with respect to prompt order are relatively minimal in almost all cases. The'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 17, 'page_label': '18'}, page_content='We show the standard deviation of performance from different exemplars in Table 6 and Table 7.\\nStandard deviations with respect to prompt order are relatively minimal in almost all cases. The\\none exception is the coin ﬂip task, for which exemplar orders have high standard deviation, likely\\nfor the reason cited in Zhao et al. (2021)—for classiﬁcation, many exemplars of the same category\\nin a row biases the model outputs).\\n• Different number of exemplars. We also found that gains from chain-of-thought prompting\\ngenerally still held when there was a varying number of few-shot exemplars. This is shown for ﬁve\\ndatasets in Figure 11 (we did not have the compute to run this for all datasets). We also found in\\npreliminary experiments that further increasing the number of exemplars in standard prompting\\ndid not lead to signiﬁcant gains (e.g., increasing from 8 to 16 exemplars did not improve the\\nperformance of standard prompting enough to catch up with chain-of-thought prompting).'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 17, 'page_label': '18'}, page_content='did not lead to signiﬁcant gains (e.g., increasing from 8 to 16 exemplars did not improve the\\nperformance of standard prompting enough to catch up with chain-of-thought prompting).\\n• Different language models. Another interesting question is whether certain prompts that work\\nbetter for one model work better for other large language models. We ﬁnd that with the same\\nprompts, chain-of-thought prompting improves performance across all three models (LaMDA,\\nGPT-3, and PaLM) for all datasets except CSQA and StrategyQA for GPT-3 (Table 1, Table 4,\\nTable 5). The fact that gains from chain of thought did not transfer perfectly among models is\\na limitation; further work could investigate why how different pre-training datasets and model\\narchitectures affect the performance gain from chain-of-thought prompting.\\nPrompt engineering still matters, though. Although the results are relatively robust to the prompt'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 17, 'page_label': '18'}, page_content='architectures affect the performance gain from chain-of-thought prompting.\\nPrompt engineering still matters, though. Although the results are relatively robust to the prompt\\nfor arithmetic reasoning, we want to be clear that prompt engineering still does matter, and can\\nimprove performance signiﬁcantly in many cases. Though most chain of thought annotations\\noutperform standard prompting, there is large variation in many cases. For instance, for the coin\\nﬂip task, the performance varied from 99.6% for Annotator A to 71.4% for Annotator C, though\\nboth were above standard prompting = 50.0% (see Table 7). There are even tasks where prompt\\nengineering is a requirement for good performance. In preliminary experiments, we tried using chain\\nof thought to enable language models to reverse the order of a list of 5 items. While two co-authors\\nwere not able to write chain of thought prompts that solved the task despite their best attempts, a third'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 17, 'page_label': '18'}, page_content='were not able to write chain of thought prompts that solved the task despite their best attempts, a third\\nco-author was able to write a chain of thought that perfectly solved the task.\\nHow to generate chain of thought annotations in a robust fashion could be an interesting direction\\nfor future work. For instance, an idea here could be to use a large language model to automatically\\ngenerate chains of thought via prompting (and potentially optimize this over a validation set).\\nA.3 Will chain-of-thought prompting improve performance for my task of interest?\\nWhile chain-of-thought prompting is in principle applicable for any text-to-text task, it is more\\nhelpful for some tasks than others. Based on the experiments in this paper, our intuition is that chain\\nof thought helps the most when three conditions are met: (1) the task is challenging and requires\\n18'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 18, 'page_label': '19'}, page_content='multi-step reasoning, (2) a large language model is used, and (3) the scaling curve is relatively ﬂat.\\nConversely, the beneﬁts are smaller when one or more of these conditions are not met.\\nThese intuitions are perhaps supported by the arithmetic reasoning results. The performance gain\\nfrom chain-of-thought prompting is largest for PaLM 540B on GSM8K (challenging multi-step\\nproblems, ﬂat scaling curve), which meets these conditions. The performance gain is small for the\\nsubsets of MAWPS that only require one or two steps (SingleOP, SingleEq, and AddSub), for which\\nPaLM 540B already achieves performance of 90% or higher (and it is also generally true that there is\\nless headroom for improvement when performance is already strong).\\nAlthough in this paper we focused on multi-step reasoning tasks (arithmetic, commonsense, and\\nsymbolic), chain-of-thought prompting can potentially be applied to any task for which humans use a'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 18, 'page_label': '19'}, page_content='Although in this paper we focused on multi-step reasoning tasks (arithmetic, commonsense, and\\nsymbolic), chain-of-thought prompting can potentially be applied to any task for which humans use a\\n“chain of thought” to solve (at least in principle). We leave the empirical evaluation of chain-of-thought\\nprompting on such diverse tasks (e.g., machine translation, etc.) to future work.\\nA.4 Why is prompting with the equation only not enough for some arithmetic reasoning\\ndatasets?\\nPrompting with the equation only as an intermediate step does help on many datasets, especially when\\nthe datasets only require a few reasoning steps (SV AMP, ASDiv, MAWPS). For GSM8K, however,\\nusing the equation only did not improve performance substantially. Based on qualitative analysis, we\\nbelieve that these questions are too semantically challenging for the model to directly translate them\\ninto a math equation. Consider this example from LaMDA 137B:'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 18, 'page_label': '19'}, page_content='believe that these questions are too semantically challenging for the model to directly translate them\\ninto a math equation. Consider this example from LaMDA 137B:\\nQUESTION : Mike plays ping pong for 40 minutes. In the ﬁrst 20 minutes, he scores 4\\npoints. In the second 20 minutes, he scores 25% more points. How many total points did he\\nscore?\\nEQUATION ONLY (WRONG ANSWER ): (4 + 20 * 0.25) = 6. The answer is 6.\\nCHAIN OF THOUGHT (CORRECT ): Mike played ping pong for 40 minutes. In the ﬁrst\\n20 minutes, he scored 4 points. In the second 20 minutes, he scored 25% more points. So\\nhe scored 25% more in the second 20 minutes. 4 x 1.25 = 5. So he scored 5 points in the\\nsecond 20 minutes. So he scored 9 points in total. The answer is 9.\\nIt is hard for the model to directly translate all of the semantics into a single equation, but chain of\\nthought allows it to better reason about each part of the question via intermediate steps in natural\\nlanguage.\\n19'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 19, 'page_label': '20'}, page_content='B All Experimental Results\\nThis section contains tables for experimental results for varying models and model sizes, on all\\nbenchmarks, for standard prompting vs. chain-of-thought prompting.\\nFor the arithmetic reasoning benchmarks, some chains of thought (along with the equations produced)\\nwere correct, except the model performed an arithmetic operation incorrectly. A similar observation\\nwas made in Cobbe et al. (2021). Hence, we can further add a Python program as an external\\ncalculator (using the Python eval function) to all the equations in the generated chain of thought.\\nWhen there are multiple equations in a chain of thought, we propagate the external calculator results\\nfrom one equation to the following equations via string matching. As shown in Table 1, we see that\\nadding a calculator signiﬁcantly boosts performance of chain-of-thought prompting on most tasks.\\nTable 1: Chain of thought prompting outperforms standard prompting for various large language'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 19, 'page_label': '20'}, page_content='adding a calculator signiﬁcantly boosts performance of chain-of-thought prompting on most tasks.\\nTable 1: Chain of thought prompting outperforms standard prompting for various large language\\nmodels on ﬁve arithmetic reasoning benchmarks. All metrics are accuracy (%). Ext. calc.: post-hoc\\nexternal calculator for arithmetic computations only. Prior best numbers are from the following. a:\\nCobbe et al. (2021). b& e: Pi et al. (2022), c: Lan et al. (2021), d: Pi˛ ekos et al. (2021).\\nPrompting GSM8K SV AMP ASDiv AQuA MAWPS\\nPrior best N/A (ﬁnetuning) 55 a 57.4b 75.3c 37.9d 88.4e\\nUL2 20B Standard 4.1 10.1 16.0 20.5 16.6\\nChain of thought 4.4 (+0.3) 12.5 (+2.4) 16.9 (+0.9) 23.6 (+3.1) 19.1 (+2.5)\\n+ ext. calc 6.9 28.3 34.3 23.6 42.7\\nLaMDA 137B Standard 6.5 29.5 40.1 25.5 43.2\\nChain of thought 14.3 (+7.8) 37.5 (+8.0) 46.6 (+6.5) 20.6 (-4.9) 57.9 (+14.7)\\n+ ext. calc 17.8 42.1 53.4 20.6 69.3\\nGPT-3 175B Standard 15.6 65.7 70.3 24.8 72.7'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 19, 'page_label': '20'}, page_content='Chain of thought 14.3 (+7.8) 37.5 (+8.0) 46.6 (+6.5) 20.6 (-4.9) 57.9 (+14.7)\\n+ ext. calc 17.8 42.1 53.4 20.6 69.3\\nGPT-3 175B Standard 15.6 65.7 70.3 24.8 72.7\\n(text-davinci-002) Chain of thought 46.9 (+31.3) 68.9 (+3.2) 71.3 (+1.0) 35.8 (+11.0) 87.1 (+14.4)\\n+ ext. calc 49.6 70.3 71.1 35.8 87.5\\nCodex Standard 19.7 69.9 74.0 29.5 78.7\\n(code-davinci-002) Chain of thought 63.1 (+43.4) 76.4 (+6.5) 80.4 (+6.4) 45.3 (+15.8) 92.6 (+13.9)\\n+ ext. calc 65.4 77.0 80.0 45.3 93.3\\nPaLM 540B Standard 17.9 69.4 72.1 25.2 79.2\\nChain of thought 56.9 (+39.0) 79.0 (+9.6) 73.9 (+1.8) 35.8 (+10.6) 93.3 (+14.2)\\n+ ext. calc 58.6 79.8 72.6 35.8 93.5\\n20'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 20, 'page_label': '21'}, page_content='Table 2: Standard prompting versus chain of thought prompting on ﬁve arithmetic reasoning bench-\\nmarks. Note that chain of thought prompting is an emergent ability of model scale—it does not\\npositively impact performance until used with a model of sufﬁcient scale.\\nGSM8K SV AMP ASDiv AQuA MAWPS\\nModel standard CoT standard CoT standard CoT standard CoT standard CoT\\nUL2 20B 4.1 4.4 10.1 12.5 16.0 16.9 20.5 23.6 16.6 19.1\\nLaMDA 420M 2.6 0.4 2.5 1.6 3.2 0.8 23.5 8.3 3.2 0.9\\n2B 3.6 1.9 3.3 2.4 4.1 3.8 22.9 17.7 3.9 3.1\\n8B 3.2 1.6 4.3 3.4 5.9 5.0 22.8 18.6 5.3 4.8\\n68B 5.7 8.2 13.6 18.8 21.8 23.1 22.3 20.2 21.6 30.6\\n137B 6.5 14.3 29.5 37.5 40.1 46.6 25.5 20.6 43.2 57.9\\nGPT 350M 2.2 0.5 1.4 0.8 2.1 0.8 18.1 8.7 2.4 1.1\\n1.3B 2.4 0.5 1.5 1.7 2.6 1.4 12.6 4.3 3.1 1.7\\n6.7B 4.0 2.4 6.1 3.1 8.6 3.6 15.4 13.4 8.8 3.5\\n175B 15.6 46.9 65.7 68.9 70.3 71.3 24.8 35.8 72.7 87.1\\nCodex - 19.7 63.1 69.9 76.4 74.0 80.4 29.5 45.3 78.7 92.6\\nPaLM 8B 4.9 4.1 15.1 16.8 23.7 25.2 19.3 21.7 26.2 30.5'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 20, 'page_label': '21'}, page_content='175B 15.6 46.9 65.7 68.9 70.3 71.3 24.8 35.8 72.7 87.1\\nCodex - 19.7 63.1 69.9 76.4 74.0 80.4 29.5 45.3 78.7 92.6\\nPaLM 8B 4.9 4.1 15.1 16.8 23.7 25.2 19.3 21.7 26.2 30.5\\n62B 9.6 29.9 48.2 46.7 58.7 61.9 25.6 22.4 61.8 80.3\\n540B 17.9 56.9 69.4 79.0 72.1 73.9 25.2 35.8 79.2 93.3\\nTable 3: Standard prompting versus chain of thought prompting on the four subsets of the MAWPS\\nbenchmark. The point of stratifying the MAWPS benchmark is to show that performance gains are\\nminimal on easy one-step or two-step problems where large language models already achieve high\\nperformance (e.g., SingleOp, SingleEq, and AddSub).\\nSingleOp SingleEq AddSub MultiArith\\nModel standard CoT standard CoT standard CoT standard CoT\\nUL2 20B 24.9 27.2 18.0 20.2 18.5 18.2 5.0 10.7\\nLaMDA 420M 2.8 1.0 2.4 0.4 1.9 0.7 5.8 1.5\\n2B 4.6 4.1 2.4 3.3 2.7 3.2 5.8 1.8\\n8B 8.0 7.0 4.5 4.4 3.4 5.2 5.2 2.4\\n68B 36.5 40.8 23.9 26.0 17.3 23.2 8.7 32.4\\n137B 73.2 76.2 48.8 58.7 43.0 51.9 7.6 44.9\\nGPT 350M 3.2 1.8 2.0 0.2 2.0 1.5 2.3 0.8'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 20, 'page_label': '21'}, page_content='2B 4.6 4.1 2.4 3.3 2.7 3.2 5.8 1.8\\n8B 8.0 7.0 4.5 4.4 3.4 5.2 5.2 2.4\\n68B 36.5 40.8 23.9 26.0 17.3 23.2 8.7 32.4\\n137B 73.2 76.2 48.8 58.7 43.0 51.9 7.6 44.9\\nGPT 350M 3.2 1.8 2.0 0.2 2.0 1.5 2.3 0.8\\n1.3B 5.3 3.0 2.4 1.6 2.3 1.5 2.2 0.5\\n6.7B 13.5 3.9 8.7 4.9 8.6 2.5 4.5 2.8\\n175B 90.9 88.8 82.7 86.6 83.3 81.3 33.8 91.7\\nCodex - 93.1 91.8 86.8 93.1 90.9 89.1 44.0 96.2\\nPaLM 8B 41.8 46.6 29.5 28.2 29.4 31.4 4.2 15.8\\n62B 87.9 85.6 77.2 83.5 74.7 78.2 7.3 73.7\\n540B 94.1 94.1 86.5 92.3 93.9 91.9 42.2 94.7\\n21'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 21, 'page_label': '22'}, page_content='Table 4: Standard prompting versus chain of thought prompting on ﬁve commonsense reasoning\\nbenchmarks. Chain of thought prompting is an emergent ability of model scale—it does not positively\\nimpact performance until used with a model of sufﬁcient scale.\\nCSQA StrategyQA Date Sports SayCan\\nModel standard CoT standard CoT standard CoT standard CoT standard CoT\\nUL2 20B 34.2 51.4 59.0 53.3 13.5 14.0 57.9 65.3 20.0 41.7\\nLaMDA 420M 20.1 19.2 46.4 24.9 1.9 1.6 50.0 49.7 7.5 7.5\\n2B 20.2 19.6 52.6 45.2 8.0 6.8 49.3 57.5 8.3 8.3\\n8B 19.0 20.3 54.1 46.8 9.5 5.4 50.0 52.1 28.3 33.3\\n68B 37.0 44.1 59.6 62.2 15.5 18.6 55.2 77.5 35.0 42.5\\n137B 53.6 57.9 62.4 65.4 21.5 26.8 59.5 85.8 43.3 46.6\\nGPT 350M 14.7 15.2 20.6 0.9 4.3 0.9 33.8 41.6 12.5 0.8\\n1.3B 12.0 19.2 45.8 35.7 4.0 1.4 0.0 26.9 20.8 9.2\\n6.7B 19.0 24.0 53.6 50.0 8.9 4.9 0.0 4.4 17.5 35.0\\n175B 79.5 73.5 65.9 65.4 43.8 52.1 69.6 82.4 81.7 87.5\\nCodex - 82.3 77.9 67.1 73.2 49.0 64.8 71.7 98.5 85.8 88.3'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 21, 'page_label': '22'}, page_content='6.7B 19.0 24.0 53.6 50.0 8.9 4.9 0.0 4.4 17.5 35.0\\n175B 79.5 73.5 65.9 65.4 43.8 52.1 69.6 82.4 81.7 87.5\\nCodex - 82.3 77.9 67.1 73.2 49.0 64.8 71.7 98.5 85.8 88.3\\nPaLM 8B 19.8 24.9 55.6 53.5 12.9 13.1 55.1 75.2 34.2 40.0\\n62B 65.4 68.1 58.4 63.4 29.8 44.7 72.1 93.6 65.8 70.0\\n540B 78.1 79.9 68.6 77.8 49.0 65.3 80.5 95.4 80.8 91.7\\nTable 5: Standard prompting versus chain of thought prompting enables length generalization to\\nlonger inference examples on two symbolic manipulation tasks.\\nLast Letter Concatenation Coin Flip (state tracking)\\n2 OOD: 3 OOD: 4 2 OOD: 3 OOD: 4\\nModel standard CoT standard CoT standard CoT standard CoT standard CoT standard CoT\\nUL2 20B 0.6 18.8 0.0 0.2 0.0 0.0 70.4 67.1 51.6 52.2 48.7 50.4\\nLaMDA 420M 0.3 1.6 0.0 0.0 0.0 0.0 52.9 49.6 50.0 50.5 49.5 49.1\\n2B 2.3 6.0 0.0 0.0 0.0 0.0 54.9 55.3 47.4 48.7 49.8 50.2\\n8B 1.5 11.5 0.0 0.0 0.0 0.0 52.9 55.5 48.2 49.6 51.2 50.6\\n68B 4.4 52.0 0.0 0.8 0.0 2.5 56.2 83.2 50.4 69.1 50.9 59.6'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 21, 'page_label': '22'}, page_content='2B 2.3 6.0 0.0 0.0 0.0 0.0 54.9 55.3 47.4 48.7 49.8 50.2\\n8B 1.5 11.5 0.0 0.0 0.0 0.0 52.9 55.5 48.2 49.6 51.2 50.6\\n68B 4.4 52.0 0.0 0.8 0.0 2.5 56.2 83.2 50.4 69.1 50.9 59.6\\n137B 5.8 77.5 0.0 34.4 0.0 13.5 49.0 99.6 50.7 91.0 49.1 74.5\\nPaLM 8B 2.6 18.8 0.0 0.0 0.0 0.2 60.0 74.4 47.3 57.1 50.9 51.8\\n62B 6.8 85.0 0.0 59.6 0.0 13.4 91.4 96.8 43.9 91.0 38.3 72.4\\n540B 7.6 99.4 0.2 94.8 0.0 63.0 98.1 100.0 49.3 98.6 54.8 90.2\\n22'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 22, 'page_label': '23'}, page_content='Table 6: Ablation and robustness results for arithmetic reasoning datasets. Chain of thought generally\\noutperforms ablations by a large amount. “Equation only” performs in between standard prompting\\nand chain of thought prompting, as it allows for intermediate reasoning steps via equations but does\\nnot leverage natural language. Chain of thought prompting has variance (as expected) when used\\nwith prompts written by different annotators or when using other exemplars, but still outperforms\\nstandard prompting by a large margin. Standard deviation shown is for different order of few-shot\\nprompting exemplars, with ﬁve different random seeds. Results here are shown for LaMDA 137B, as\\nadditional queries for GPT-3 and PaLM are both limited and expensive.\\nGSM8K SV AMP ASDiv MAWPS\\nStandard prompting 6.5 ±0.4 29.5 ±0.6 40.1 ±0.6 43.2 ±0.9\\nChain of thought prompting 14.3 ±0.4 36.7 ±0.4 46.6 ±0.7 57.9 ±1.5\\nAblations\\n·equation only 5.4 ±0.2 35.1 ±0.4 45.9 ±0.6 50.1 ±1.0'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 22, 'page_label': '23'}, page_content='Standard prompting 6.5 ±0.4 29.5 ±0.6 40.1 ±0.6 43.2 ±0.9\\nChain of thought prompting 14.3 ±0.4 36.7 ±0.4 46.6 ±0.7 57.9 ±1.5\\nAblations\\n·equation only 5.4 ±0.2 35.1 ±0.4 45.9 ±0.6 50.1 ±1.0\\n·variable compute only 6.4 ±0.3 28.0 ±0.6 39.4 ±0.4 41.3 ±1.1\\n·reasoning after answer 6.1 ±0.4 30.7 ±0.9 38.6 ±0.6 43.6 ±1.0\\nRobustness\\n·different annotator (B) 15.5 ±0.6 35.2 ±0.4 46.5 ±0.4 58.2 ±1.0\\n·different annotator (C) 17.6 ±1.0 37.5 ±2.0 48.7 ±0.7 60.1 ±2.0\\n·intentionally concise style 11.1 ±0.3 38.7 ±0.8 48.0 ±0.3 59.6 ±0.7\\n·exemplars from GSM8K (α) 12.6 ±0.6 32.8 ±1.1 44.1 ±0.9 53.9 ±1.1\\n·exemplars from GSM8K (β) 12.7 ±0.5 34.8 ±1.1 46.9 ±0.6 60.9 ±0.8\\n·exemplars from GSM8K (γ) 12.6 ±0.7 35.6 ±0.5 44.4 ±2.6 54.2 ±4.7\\nTable 7: Ablation and robustness results for four datasets in commonsense and symbolic reasoning.\\nChain of thought generally outperforms ablations by a large amount. Chain of thought prompting has'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 22, 'page_label': '23'}, page_content='Table 7: Ablation and robustness results for four datasets in commonsense and symbolic reasoning.\\nChain of thought generally outperforms ablations by a large amount. Chain of thought prompting has\\nvariance (as expected) when used with prompts written by different annotators or when using other\\nexemplars, but still outperforms standard prompting by a large margin. Standard deviation shown\\nis for different order of few-shot prompting exemplars, with ﬁve different random seeds. Results\\nhere are shown for LaMDA 137B, as additional queries for GPT-3 and PaLM are both limited and\\nexpensive. The exception is that we run SayCan using PaLM here, as the SayCan evaluation set is\\nonly 120 examples and therefore less expensive to run multiple times.\\nCommonsense Symbolic\\nDate Sports SayCan Concat Coin\\nStandard prompting 21.5 ±0.6 59.5 ±3.0 80.8 ±1.8 5.8 ±0.6 49.0 ±2.1\\nChain of thought prompting 26.8 ±2.1 85.8 ±1.8 91.7 ±1.4 77.5 ±3.8 99.6 ±0.3\\nAblations'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 22, 'page_label': '23'}, page_content='Date Sports SayCan Concat Coin\\nStandard prompting 21.5 ±0.6 59.5 ±3.0 80.8 ±1.8 5.8 ±0.6 49.0 ±2.1\\nChain of thought prompting 26.8 ±2.1 85.8 ±1.8 91.7 ±1.4 77.5 ±3.8 99.6 ±0.3\\nAblations\\n·variable compute only 21.3 ±0.7 61.6 ±2.2 74.2 ±2.3 7.2 ±1.6 50.7 ±0.7\\n·reasoning after answer 20.9 ±1.0 63.0 ±2.0 83.3 ±0.6 0.0 ±0.0 50.2 ±0.5\\nRobustness\\n·different annotator (B) 27.4 ±1.7 75.4 ±2.7 88.3 ±1.4 76.0 ±1.9 77.5 ±7.9\\n·different annotator (C) 25.5 ±2.5 81.1 ±3.6 85.0 ±1.8 68.1 ±2.2 71.4 ±11.1\\n23'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 23, 'page_label': '24'}, page_content='C Extended Related Work\\nChain-of-thought prompting is a general approach that is inspired by several prior directions: prompt-\\ning, natural language explanations, program synthesis/execution, numeric and logical reasoning, and\\nintermediate language steps.\\nC.1 Prompting\\nThe recent success of large-scale language models has led to growing interest in improving their\\ncapability to perform tasks via prompting (Brown et al. (2020), and see Liu et al. (2021) for a\\nsurvey). This paper falls in the category of general prompting approaches, whereby input prompts are\\noptimized to allow a single large language model to better perform a variety of tasks (Li and Liang,\\n2021; Lester et al., 2021; Reif et al., 2022, inter alia).\\nOne recent line of work aims to improve the ability of language models to perform a task by providing\\ninstructions that describe the task (Raffel et al., 2020; Wei et al., 2022a; Ouyang et al., 2022; Sanh'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 23, 'page_label': '24'}, page_content='instructions that describe the task (Raffel et al., 2020; Wei et al., 2022a; Ouyang et al., 2022; Sanh\\net al., 2022; Wang et al., 2022b). This line of work is related because it also augments input–output\\npairs with meta-data. But whereas an instruction augments the input to a task (instructions are typically\\nprepended to the inputs), chain-of-thought prompting augments the outputs of language models.\\nAnother related direction is sequentially combining the outputs of language models; human–computer\\ninteraction (HCI) work (Wu et al., 2022a,b) has shown that combining sequential generations of\\nlanguage models improves task outcomes in a 20-person user study.\\nC.2 Natural language explanations\\nAnother closely related direction uses natural language explanations (NLEs), often with the goal of\\nimproving model interpretability (Zhou et al., 2020; Wiegreffe and Marasovi´c, 2021, inter alia). That'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 23, 'page_label': '24'}, page_content='improving model interpretability (Zhou et al., 2020; Wiegreffe and Marasovi´c, 2021, inter alia). That\\nline of work typically focuses on natural language inference (Camburu et al., 2018; Yordanov et al.,\\n2021; Bostrom et al., 2021), and produces explanations either simultaneously to or after the ﬁnal\\nprediction (Narang et al., 2020; Majumder et al., 2021; Wiegreffe et al., 2021, 2022). By contrast,\\nthe chain of thought processing considered in this paper occurs before the ﬁnal answer. And while\\nNLE aims mostly to improve neural network interpretability (Rajagopal et al., 2021), the goal of\\nchain-of-thought prompting is to allow models to decompose multi-hop reasoning tasks into multiple\\nsteps—interpretability is just a side effect. Marasovi ´c et al. (2022) show that prompt-based ﬁnetuning\\nwith NLE improves NLI and classiﬁcation performance, though they largely focus on evaluating\\nexplanation plausibility. In comparison, our work focuses on a range of arithmetic, commonsense,'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 23, 'page_label': '24'}, page_content='with NLE improves NLI and classiﬁcation performance, though they largely focus on evaluating\\nexplanation plausibility. In comparison, our work focuses on a range of arithmetic, commonsense,\\nand symbolic tasks that require multi-hop reasoning.\\nC.3 Program synthesis and execution\\nUsing intermediate reasoning steps has a long history in program synthesis and execution (Zaremba\\nand Sutskever, 2014, inter alia). Recent work along in this direction has included a number of\\narchitectural innovations (Cai et al., 2017; Dong et al., 2019; Yan et al., 2020), as well as the use of\\nlarge language models (Chen et al., 2021; Austin et al., 2021). The program execution work closest to\\nours is perhaps Nye et al. (2021), which show that large language models can perform up to 10-digit\\naddition, evaluate polynomials, and execute python programs. Whereas generating a program and\\nthen executing it can be viewed as a type of reasoning, our work generalizes such domain-speciﬁc'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 23, 'page_label': '24'}, page_content='addition, evaluate polynomials, and execute python programs. Whereas generating a program and\\nthen executing it can be viewed as a type of reasoning, our work generalizes such domain-speciﬁc\\nprimitives to natural language, which is open-domain and relevant to any text-to-text NLP task in\\nprinciple.\\nC.4 Numeric and logical reasoning\\nNumeric and logical reasoning has been a long-studied task in machine learning and natural language\\nprocessing (Lev et al., 2004, inter alia). Recent work has also aimed to inject numeric reasoning\\nabilities in language models in various ways, such as augmenting BERT with a predeﬁned set of\\nexecutable operations (Andor et al., 2019), including a graph neural network (Ran et al., 2019), and\\nusing specialized training procedures (Pi˛ ekos et al., 2021). Another line of work aims to enable\\nlanguage models to perform logical or formal reasoning, often by verablizing the rules in natural'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 23, 'page_label': '24'}, page_content='using specialized training procedures (Pi˛ ekos et al., 2021). Another line of work aims to enable\\nlanguage models to perform logical or formal reasoning, often by verablizing the rules in natural\\nlanguage formal rules using language (Clark et al., 2020; Saeed et al., 2021; Liang et al., 2021).\\n24'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 24, 'page_label': '25'}, page_content='Perhaps the most-related work here is Recchia (2021), which shows that ﬁnetuning enables longhand\\nmodule operations, which has previously been difﬁcult for performers. Whereas work in this direction\\nis often task-speciﬁc and uses ﬁnetuning, we show that chain-of-thought prompting works for a broad\\nrange of tasks without any ﬁnetuning.\\nC.5 Intermediate language steps\\nExtensive prior work has shown the beneﬁts of endowing neural networks with the ability to produce\\nintermediate steps via training or ﬁnetuning confers various beneﬁts in a range of scenarios. As\\nexamples, it has been shown that natural language intermediate steps can improve performance\\n(Zaidan et al., 2007; Yao et al., 2021; Hase and Bansal, 2022; Gu et al., 2022), improve robustness\\n(Chen et al., 2022), speed up training (Hancock et al., 2018), mitigate bias (Dua et al., 2020), and\\neven help in image and reinforcement learning settings (Andreas et al., 2018). To endow models with'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 24, 'page_label': '25'}, page_content='even help in image and reinforcement learning settings (Andreas et al., 2018). To endow models with\\nthe ability to produce intermediate steps, prior work typically ﬁnetunes models on either manually\\nannotated training datasets (Camburu et al., 2018; Rajani et al., 2019,inter alia) or generates synthetic\\ndatasets (Talmor et al., 2020; Zelikman et al., 2022). Compared with these training or ﬁnetuning\\nmethods, our work shows that various natural language reasoning abilities can be elicited in off-the-\\nshelf language models of sufﬁcient scale simply via prompting. This prompting setup is important\\nbecause it allows for intermediate step reasoning without a large number of labeled annotations, and\\nbecause a single model can perform a range of reasoning tasks without any gradient updates.\\nD Appendix: Additional Analysis\\nD.1 Correct Chain of Thought Analysis\\nAs mentioned in the main text, we analyze 50 chains of thought from LaMDA 137B that led to'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 24, 'page_label': '25'}, page_content='D Appendix: Additional Analysis\\nD.1 Correct Chain of Thought Analysis\\nAs mentioned in the main text, we analyze 50 chains of thought from LaMDA 137B that led to\\ncorrect answers in the GSM8K dataset. Of these 50, only one arrived at the correct answer through\\nincorrect reasoning (shown in Table 9: “correct by chance”). The other 49 had correct logic and\\nmath, with examples shown in Table 8. Five had minor imperfections while maintaining coherent and\\nunderstandable logic:\\n• One had underspeciﬁed statements (shown in Table 9: “correct but underspeciﬁed statements”).\\n• One made an unrelated but correct statement (shown in Table 9: “correct but unrelated statement”).\\n• Two had the correct logic but omitted speciﬁc steps in the equation, though it was still understand-\\nable (shown in Table 9: “correct but imperfect equation”).\\n• One had the correct math but inverted the semantics (shown in Table 9: “correct but inverted\\nsemantics”)'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 24, 'page_label': '25'}, page_content='able (shown in Table 9: “correct but imperfect equation”).\\n• One had the correct math but inverted the semantics (shown in Table 9: “correct but inverted\\nsemantics”)\\nTable 8: Example of correct chains of thought produced by the model for the GSM8K dataset.\\nQUESTION : James decides to run 3 sprints 3 times a week. He runs 60 meters each sprint. How many total\\nmeters does he run a week?\\nMODEL ANSWER (CORRECT): James decides to run 3 sprints 3 times a week. He runs 60 meters each\\nsprint. So he runs 60 meters x 3 sprints x 3 times a week. That is 60 meters x 9. The answer is 540. ✓\\nQUESTION : Brandon’s iPhone is four times as old as Ben’s iPhone. Ben’s iPhone is two times older than Suzy’s\\niPhone. If Suzy’s iPhone is 1 year old, how old is Brandon’s iPhone?\\nMODEL ANSWER (CORRECT): Brandon’s iPhone is 4 times as old as Ben’s iPhone. Ben’s iPhone is 2\\ntimes older than Suzy’s iPhone. So Brandon’s iPhone is 4 x 2 = 8 times older than Suzy’s iPhone. Suzy’s iPhone'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 24, 'page_label': '25'}, page_content='times older than Suzy’s iPhone. So Brandon’s iPhone is 4 x 2 = 8 times older than Suzy’s iPhone. Suzy’s iPhone\\nis 1 year old. So Brandon’s iPhone is 8 x 1 = 8 years old. The answer is 8. ✓\\nQUESTION : Jean has 30 lollipops. Jean eats 2 of the lollipops. With the remaining lollipops, Jean wants to\\npackage 2 lollipops in one bag. How many bags can Jean ﬁll?\\nMODEL ANSWER (CORRECT): Jean started with 30 lollipops. She ate 2 of them. So she has 28 lollipops\\nleft. She wants to package 2 lollipops in one bag. So she can package 28 / 2 = 14 bags. The answer is 14. ✓\\nAlthough we ﬁnd that chain-of-thought reasoning is mostly correct for math questions where the ﬁnal\\nanswer was correct, this is likely because it is hard to arrive at the correct ﬁnal answer by coincidence\\nfor free response questions. For multiple choice or binary classiﬁcation problems, it was much more\\n25'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 25, 'page_label': '26'}, page_content='likely that models could arrive at the correct answer via an incorrect reasoning path (e.g., all the\\ncommmonsense reasoning datasets we evaluate). This is a limitation, and future work should perform\\nan analysis of the factuality of such chains of thought.\\nTable 9: Of 50 examples that the model got correct, there were 7 salient cases where the chain of\\nthought the model generated was imperfect. We found the other 43 to be equivalent to what a human\\nwould potentially generate as a ground truth.\\nQUESTION : There are 36 penguins sunbathing in the snow. One-third of them jump in and swim in the ocean.\\nAnother one-third go inside the cave to eat their dinner. How many penguins are still left sunbathing?\\nMODEL ANSWER (CORRECT BY CHANCE ): There are 36 penguins. One-third of them jump in and swim in\\nthe ocean. So that is 12 penguins. Another one-third go inside the cave to eat their dinner. So that is 12 penguins.\\nThe answer is 12.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 25, 'page_label': '26'}, page_content='the ocean. So that is 12 penguins. Another one-third go inside the cave to eat their dinner. So that is 12 penguins.\\nThe answer is 12.\\nQUESTION : John has 2 houses with 3 bedrooms each. Each bedroom has 2 windows each. There are an\\nadditional 4 windows in each house not connected to bedrooms. How many total windows are there between the\\nhouses?\\nMODEL ANSWER (CORRECT BUT UNDERSPECIFIED STATEMENTS ): There are 2 houses with 3 bedrooms\\neach. Each bedroom has 2 windows each. So there are 2 x 3 = 6 windows in each house. There are an additional\\n4 windows in each house not connected to bedrooms. So there are 4 + 4 = 8 windows in each house. So there are\\n6 x 2 = 12 windows in each house. So there are 12 + 8 = 20 windows in both houses. The answer is 20.\\nQUESTION : If Ann is 9 years old and her brother is twice her age, how old will her brother be in 3 years?\\nMODEL ANSWER (CORRECT BUT UNRELATED STATEMENT ): Ann is 9 years old. Her brother is twice her'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 25, 'page_label': '26'}, page_content='MODEL ANSWER (CORRECT BUT UNRELATED STATEMENT ): Ann is 9 years old. Her brother is twice her\\nage. So her brother is 18 years old. In 3 years, she will be 12. So her brother will be 18 + 3 = 21 years old. The\\nanswer is 21.\\nQUESTION : A local gas station is selling gas for $3.00 a gallon. An app company is offering $.20 cashback per\\ngallon if you ﬁll up at this station. If someone buys 10 gallons of gas, how much with their gas be, after the\\ncashback rewards?\\nMODEL ANSWER (CORRECT BUT IMPERFECT EQUATION ): The gas is originally 3 dollars per gallon. If\\nyou buy 10 gallons, that is 3 x 10 = 30 dollars. If you get 20 cents off per gallon, that is 20 x 10 = 2 dollars. So\\nthe total is 30 - 2 = 28 dollars. The answer is 28 dollars.\\nQUESTION : Nissa hires 60 seasonal workers to play elves in her department store’s Santa village. A third of\\nthe elves quit after children vomit on them, then 10 of the remaining elves quit after kids kick their shins. How\\nmany elves are left?'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 25, 'page_label': '26'}, page_content='the elves quit after children vomit on them, then 10 of the remaining elves quit after kids kick their shins. How\\nmany elves are left?\\nMODEL ANSWER (CORRECT BUT IMPERFECT EQUATION ): Nissa hires 60 seasonal workers. A third of\\nthem quit. So 60 - 1/3 = 40 elves are left. Then 10 elves quit. So 40 - 10 = 30 elves are left. The answer is 30\\nelves.\\nQUESTION : Grandma Jones baked 5 apple pies for the ﬁreman’s luncheon. She cut each pie into 8 pieces and\\nset the ﬁve pies out on the buffet table for the guests to serve themselves. At the end of the evening, after the\\nguests had taken and eaten their pieces of pie, there were 14 pieces of pie remaining. How many pieces were\\ntaken by the guests?\\nMODEL ANSWER (CORRECT BUT INVERTED SEMANTICS ): 5 pies were baked and cut into 8 pieces each.\\nThe 5 pies were then served to the guests. 8 x 5 = 40 pieces of pie. The guests ate 14 pieces of pie. 40 - 14 = 26\\npieces of pie were left. The answer is 26. ✓\\n26'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 26, 'page_label': '27'}, page_content='D.2 Incorrect Chain of Thought Analysis\\nWe also manually analyze 50 randomly sampled outputs of the model that were incorrect on GSM8K\\nfor LaMDA 137B. There are many ways that a chain of thought can be incorrect, making the design\\nof error categorization non-trivial. We decided to categorize errors into what changes are needed to\\nmake the chain of thought correct, with the goal of elucidating how the model can be improved in the\\nfuture.\\nWe found that many chains of thought can be made correct with one of the following three classes of\\nmodiﬁcation.\\n• Calculator error only. We found that 8% of the chains of thought were completely correct except\\nfor a calculator error—in other words, applying an external calculator to equations, as done in\\nCobbe et al. (2021), would make the chain of thought correct. An example of this type of error is\\nshown in Table 10: “calculator error only”. Indeed, the solve rate of chain-of-thought prompting'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 26, 'page_label': '27'}, page_content='Cobbe et al. (2021), would make the chain of thought correct. An example of this type of error is\\nshown in Table 10: “calculator error only”. Indeed, the solve rate of chain-of-thought prompting\\non for LaMDA 137B GSM8K went up from 14.3% to 17.3% when we added a Python program\\nas an external calculator, as shown in Table 2. Also, 34% of the examples contained calculator\\nerrors in addition to other types of errors. However, we perform the rest of the error categorization\\nindependently of calculator errors.\\n• Symbol mapping error. We next found that 16% percent of the chains of thought were correct\\nexcept for what we call symbol mapping errors. We deﬁne a symbol mapping error as when the\\nchain of thought is correct except for the number symbols, and it could be made totally correct by\\nmodifying only the equations and not the words. As one might argue that they could simply place\\nthe correct ﬁnal equation in any chain of thought, we constrain this category to chains of thought'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 26, 'page_label': '27'}, page_content='modifying only the equations and not the words. As one might argue that they could simply place\\nthe correct ﬁnal equation in any chain of thought, we constrain this category to chains of thought\\nwhere the chain of thought can be modiﬁed to be a completely correct reasoning process (not just\\nﬁnal answer). An example of this error category is shown in Table 10: “symbol mapping error”.\\n• One step missing error. Our next category of error is chains of thought which were correct except\\nthat they were missing a single step. In other words, these chains of thoughts could be rewritten to\\nbe correct by adding in an additional reasoning step that was missed by the model. An example of\\nthis error category is shown in Table 10: “one step missing error”. We found that 22% percent of\\nthe errors fell into this category.\\nTable 10: Example of incorrect chains of thought, categorized as described in Appendix D.2.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 26, 'page_label': '27'}, page_content='the errors fell into this category.\\nTable 10: Example of incorrect chains of thought, categorized as described in Appendix D.2.\\nQUESTION : Dan plants 3 rose bushes. Each rose bush has 25 roses. Each rose has 8 thorns. How many thorns\\nare there total?\\nMODEL ANSWER (INCORRECT ; CALCULATOR ERROR ONLY ): Dan plants 3 rose bushes. Each rose bush\\nhas 25 roses. Each rose has 8 thorns. So 3 x 25 x 8 = 300. The answer is 300. \\x17\\nEXPLANATION FOR ERROR CATEGORY : The produced chain of thought could be made correct just by\\nrunning the equation through an external calculator, instead of asking the model to do the computation.\\nQUESTION : Jill gets paid $20 per hour to teach and $30 to be a cheerleading coach. If she works 50 weeks a\\nyear, 35 hours a week as a teacher and 15 hours a week as a coach, what’s her annual salary?\\nMODEL ANSWER (INCORRECT ; SYMBOL MAPPING ERROR ): Jill gets paid 20 dollars per hour to teach'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 26, 'page_label': '27'}, page_content='year, 35 hours a week as a teacher and 15 hours a week as a coach, what’s her annual salary?\\nMODEL ANSWER (INCORRECT ; SYMBOL MAPPING ERROR ): Jill gets paid 20 dollars per hour to teach\\nand 30 dollars per hour to be a cheerleading coach. If she works 50 weeks a year, 35 hours a week as a teacher\\nand 15 hours a week as a coach, then she works 50 x 35 = 1750 hours as a teacher and 15 x 30 = 450 hours as a\\ncoach. So she works 1750 + 450 = 2200 hours. She gets paid 20 dollars per hour for 1750 hours and 30 dollars\\nper hour for 450 hours. So her annual salary is 20 x 1750 + 30 x 450 = $36,500. The answer is $36,500. \\x17\\nEXPLANATION FOR ERROR CATEGORY : The model incorrectly mapped “15 x 30” instead of “15 x 50”, and\\nthe chain of thought would be made correct by ﬁxing just that one change (with an external calculator).\\nQUESTION : Kelian has two recipes for preparing dishes, one having 20 instructions and the second one having'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 26, 'page_label': '27'}, page_content='QUESTION : Kelian has two recipes for preparing dishes, one having 20 instructions and the second one having\\ntwice as many instructions as the ﬁrst one. How many instructions does Kelian have to read to prepare the two\\ndishes?\\nMODEL ANSWER (INCORRECT ; ONE STEP MISSING ERROR ): Kelian has two recipes. One has 20 instruc-\\ntions. The other has twice as many instructions as the ﬁrst one. So the second one has 40 instructions. So Kelian\\nhas to read 40 instructions to prepare the two dishes. The answer is 40. \\x17\\nEXPLANATION FOR ERROR CATEGORY : The model answer could be made correct just adding one additional\\nstep (in this case, adding 20 and 40).\\n27'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 27, 'page_label': '28'}, page_content='We found that the remaining chains of thought (27 of 50; 54%) would require substantial edits to make\\ninto a correct chain of thought. Almost all cases here involved some error in semantic understanding\\n(see Table 11: “semantic understanding error”), and 8 of the 27 also had incoherent chain of thoughts,\\nmeaning that some statements in the generated chain of thought did not follow from prior ones or\\nviolated basic world knowledge (see Table 11: “incoherent chain of thought error”).\\nTable 11: Example of incorrect chains of thought, categorized as described in Appendix D.2. These\\nchains of thought had multiple mistakes that could not be ﬁxed with minor edits.\\nQUESTION : Gretchen has 110 coins. There are 30 more gold coins than silver coins. How many gold coins\\ndoes Gretchen have?\\nMODEL ANSWER (INCORRECT ; SEMANTIC UNDERSTANDING ERROR ): Gretchen has 110 coins. There\\nare 30 more gold coins than silver coins. So there are 110 - 30 = 80 silver coins. So there are 80 silver coins and'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 27, 'page_label': '28'}, page_content='are 30 more gold coins than silver coins. So there are 110 - 30 = 80 silver coins. So there are 80 silver coins and\\n110 - 80 = 30 gold coins. The answer is 30. \\x17\\nEXPLANATION FOR ERROR CATEGORY : The model does not understand that 110 coins are in total and that\\nit must solve an equation to get the number of gold and silver coins.\\nQUESTION : In a dance class of 20 students, 20% enrolled in contemporary dance, 25% of the remaining\\nenrolled in jazz dance, and the rest enrolled in hip-hop dance. What percentage of the entire students enrolled in\\nhip-hop dance?\\nMODEL ANSWER (INCORRECT ; INCOHERENT CHAIN OF THOUGHT ERROR ): 20% of the students en-\\nrolled in contemporary dance. 25% of the remaining students enrolled in jazz dance. The rest enrolled in hip-hop\\ndance. So the percentage of the entire students enrolled in hip-hop dance is the percentage of the students\\nenrolled in hip-hop dance, minus the percentage of the students enrolled in contemporary dance, minus the'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 27, 'page_label': '28'}, page_content='enrolled in hip-hop dance, minus the percentage of the students enrolled in contemporary dance, minus the\\npercentage of the students enrolled in jazz dance. So the percentage of the entire students enrolled in hip-hop\\ndance is (25 + 20) - (25 + 20) = 100%. The answer is 100%. \\x17\\nEXPLANATION FOR ERROR CATEGORY : This chain of thought is incoherent in that the percent of entire\\nstudents enrolled in hip-hope dance cannot be the percent of student enrolled in hip-hop dance minus another\\nterm.\\nOverall, there are no guarantees that the reasoning processes generated by large language models\\nare coherent or factually correct, as underscored by the recent work evaluating the factuality of\\nlanguage model generations and explanations (Maynez et al., 2020; Rashkin et al., 2021; Ye and\\nDurrett, 2022; Marasovi´c et al., 2022; Wiegreffe et al., 2022). Incorrect reasoning processes can lead\\nto both incorrect ﬁnal answers as well as accidentally correct ﬁnal answers (with accidentally correct'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 27, 'page_label': '28'}, page_content='to both incorrect ﬁnal answers as well as accidentally correct ﬁnal answers (with accidentally correct\\nﬁnal answers being more likely for tasks such as binary classiﬁcation as opposed to free response).\\nImproving the factuality of language model generations with respect to context and world knowledge\\nis an important direction open problems in language model research and could also be expected to\\npotentially improve multi-step reasoning abilities of language models. One potential method for\\nimproving the quality of decoding could involve generating multiple reasoning paths and scoring\\neach of them with a veriﬁer, though this requires training the veriﬁer (Cobbe et al., 2021; Shen et al.,\\n2021; Thoppilan et al., 2022).\\nD.3 Additional Robustness Analysis\\nAs the experiments in the main paper use a ﬁxed number of few-shot exemplars (8; as constrained by\\nthe input length of 1024 tokens), we verify that the chain-of-thought prompting is robust to various'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 27, 'page_label': '28'}, page_content='As the experiments in the main paper use a ﬁxed number of few-shot exemplars (8; as constrained by\\nthe input length of 1024 tokens), we verify that the chain-of-thought prompting is robust to various\\nnumbers of few-shot exemplars. We run experiments for LaMDA 137B, comparing chain-of-thought\\nprompting with standard prompting for the ﬁve datasets where standard prompting had a mostly ﬂat\\nscaling curve (the largest model did not achieve high performance). As shown in Figure 11, the\\nimprovement of chain-of-thought prompting over standard prompting remains robust to varying the\\nnumber of few-shot exemplars in the prompt.\\n28'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 28, 'page_label': '29'}, page_content='1 2 4 6 80\\n5\\n10\\n15Solve rate (%)\\nGSM8K\\n1 2 4 6 80\\n20\\n40\\n60\\nMultiArith\\n(MAWPS)\\n1 2 4 6 80\\n25\\n50\\n75\\n100\\nNumber of few-shot exemplars\\nSports\\nUnderstanding\\nStandard prompting\\nChain of thought prompting\\n1 2 4 6 80\\n25\\n50\\n75\\n100\\nCoin Flip\\n1 2 3 40\\n25\\n50\\n75\\n100\\nLast Letter\\nConcatenation\\nFigure 11: The improvement of chain of thought prompting over standard prompting appears robust\\nto varying the number of few-shot exemplars in the prompt.\\nTable 12: Summary of math word problem benchmarks we use in this paper with examples. N:\\nnumber of evaluation examples.\\nDataset N Example problem\\nGSM8K 1,319 Josh decides to try ﬂipping a house. He buys a house for $80,000 and then puts\\nin $50,000 in repairs. This increased the value of the house by 150%. How\\nmuch proﬁt did he make?\\nSV AMP 1,000 Each pack of dvds costs 76 dollars. If there is a discount of 25 dollars on each\\npack. How much do you have to pay to buy each pack?'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 28, 'page_label': '29'}, page_content='much proﬁt did he make?\\nSV AMP 1,000 Each pack of dvds costs 76 dollars. If there is a discount of 25 dollars on each\\npack. How much do you have to pay to buy each pack?\\nASDiv 2,096 Ellen has six more balls than Marin. Marin has nine balls. How many balls does\\nEllen have?\\nAQuA 254 A car is being driven, in a straight line and at a uniform speed, towards the base\\nof a vertical tower. The top of the tower is observed from the car and, in the\\nprocess, it takes 10 minutes for the angle of elevation to change from 45◦ to 60◦.\\nAfter how much more time will this car reach the base of the tower? Answer\\nChoices: (a) 5\\n√\\n3 + 1 (b) 6\\n√\\n3 +\\n√\\n2 (c) 7\\n√\\n3 - 1 (d) 8\\n√\\n3 - 2 (e) None of these\\nMAWPS: SingleOp 562 If there are 7 bottle caps in a box and Linda puts 7 more bottle caps inside, how\\nmany bottle caps are in the box?\\nMAWPS: SingleEq 508 Benny bought a soft drink for 2 dollars and 5 candy bars. He spent a total of 27\\ndollars. How much did each candy bar cost?'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 28, 'page_label': '29'}, page_content='many bottle caps are in the box?\\nMAWPS: SingleEq 508 Benny bought a soft drink for 2 dollars and 5 candy bars. He spent a total of 27\\ndollars. How much did each candy bar cost?\\nMAWPS: AddSub 395 There were 6 roses in the vase. Mary cut some roses from her ﬂower garden.\\nThere are now 16 roses in the vase. How many roses did she cut?\\nMAWPS: MultiArith 600 The school cafeteria ordered 42 red apples and 7 green apples for students\\nlunches. But, if only 9 students wanted fruit, how many extra did the cafeteria\\nend up with?\\n29'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 29, 'page_label': '30'}, page_content='E Additional Details\\nVersion Control\\nV5 →V6. Fixed minor typo in Figure 3.\\nV4 →V5. Added Codex and UL2 results. Small changes to writing and style of paper.\\nV3 →V4. Fixed typo in Figure 3 and added a couple citations.\\nV2 →V3. Added GPT-3 results. Added SV AMP and AQuA eval datasets for math. Added SayCan\\neval for commonsense. Added Extended Related Work section (Appendix C). Added ablations for\\nCommonsense and Symbolic Reasoning (Table 7). Added FAQ section (Appendix A). Added raw\\nresults in Appendix B.\\nV1 →V2. Added PaLM results (V1 only had LaMDA).\\nE.1 Reproducibility Statement\\nAs our results make use of two sets of large language models that is not publicly available, we take\\nthe following actions to facilitate reproducibility. First, we provide the exact input prompts for all\\ntasks in Table 20–Table 27 in Appendix G (and emphasize that we do not perform any ﬁnetuning and\\nonly apply prompting to off-the-shelf language models). Second, we conduct experiments using the'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 29, 'page_label': '30'}, page_content='tasks in Table 20–Table 27 in Appendix G (and emphasize that we do not perform any ﬁnetuning and\\nonly apply prompting to off-the-shelf language models). Second, we conduct experiments using the\\npublicly available GPT-3 API for four model scales text-ada-001, text-babbage-001, text-curie-001,\\ntext-davinci-002). Finally, we make exact inputs, targets, and predictions for LaMDA 137B for each\\ntask available as a zip ﬁle in the supplementary material.\\nE.2 Computational Resources\\nFor all three language models we evaluated, we did prompting-based inference only. No ﬁnetuning\\nwas done for this paper. For inference on LaMDA 137B we use TPU v3 (8x8 conﬁguration, 64 chips\\n/ 128 cores), and for inference on PaLM 540B we use TPU v4 (4x4x12 conﬁguration, 192 chips / 384\\ncores). GPT-3 experiments were done using the public API.5\\nE.3 Dataset Details and Licenses\\nWe list the details and licenses for all arithmetic and commonsense datasets used in this paper. The'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 29, 'page_label': '30'}, page_content='cores). GPT-3 experiments were done using the public API.5\\nE.3 Dataset Details and Licenses\\nWe list the details and licenses for all arithmetic and commonsense datasets used in this paper. The\\nsymbolic reasoning datasets were created synthetically, as described in Section 4.\\nArithmetic reasoning\\n• Math Word Problem Repository (Koncel-Kedziorski et al., 2016): AddSub (Hosseini\\net al., 2014): https://www.cs.washington.edu/nlp/arithmetic; MultiArith (Roy\\nand Roth, 2015), license: CC BY 4.0.\\n• ASDiv (Miao et al., 2020): https://github.com/chaochun/nlu-asdiv-dataset.\\n• AQuA (Ling et al., 2017): https://github.com/deepmind/AQuA, license: https://\\ngithub.com/deepmind/AQuA/blob/master/LICENSE.\\n• GSM8K (Cobbe et al., 2021): https://github.com/openai/grade-school-math,\\nMIT license: https://github.com/openai/grade-school-math/blob/master/\\nLICENSE.\\n• SV AMP (Patel et al., 2021): https://github.com/arkilpatel/SVAMP, MIT license:\\nhttps://github.com/arkilpatel/SVAMP/blob/main/LICENSE.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 29, 'page_label': '30'}, page_content='LICENSE.\\n• SV AMP (Patel et al., 2021): https://github.com/arkilpatel/SVAMP, MIT license:\\nhttps://github.com/arkilpatel/SVAMP/blob/main/LICENSE.\\nCommonsense reasoning\\n• CSQA (Talmor et al., 2019): https://www.tau-nlp.org/commonsenseqa, https://\\ngithub.com/jonathanherzig/commonsenseqa.\\n5https://beta.openai.com/docs/api-reference/making-requests\\n30'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 30, 'page_label': '31'}, page_content='• StrategyQA (Geva et al., 2021): we use the open-domain setting (question-only set)\\nfrom BIG-bench collaboration (2021): https://github.com/google/BIG-bench/\\ntree/main/bigbench/benchmark_tasks/strategyqa. The original dataset is from\\nhttps://github.com/eladsegal/strategyqa, MIT license: https://github.com/\\neladsegal/strategyqa/blob/main/LICENSE.\\n• Date understanding and sports understanding from BIG-Bench (BIG-bench collaboration,\\n2021): Apache License v.2: https://github.com/google/BIG-bench/blob/main/\\nLICENSE.\\n• SayCan (Ahn et al., 2022): SayCan dataset can be accessed at https://say-can.github.\\nio/ under CC BY 4.0 license.\\n31'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 31, 'page_label': '32'}, page_content='F Appendix: Input/Output Examples\\nTable 13: Examples of correct and incorrect chains of thought produced by LaMDA 137B on the\\nletter concatenation task.\\nQUESTION : Take the last letters of the words in “Waldo Schmidt” and concatenate them.\\nMODEL ANSWER (CORRECT): The last letter of “Waldo” is “o”. The last letter of “Schmidt” is “t”.\\nConcatenating them is “ot”. So the answer is ot. ✓\\nQUESTION : Take the last letters of the words in “Daniel Friedman” and concatenate them.\\nMODEL ANSWER (INCORRECT): The last letter of “Daniel” is “l”. The last letter of “Friedman” is “m”.\\nConcatenating them is “lm”. So the answer is lm. \\x17\\nTable 14: Examples of correct and incorrect chains of thought produced by LaMDA 137B on the\\ncoinﬂip task.\\nQUESTION : A coin is heads up. Andree ﬂips the coin. Audrie does not ﬂip the coin. Is the coin still heads up?\\nMODEL ANSWER (CORRECT): The coin was ﬂipped by Andree. So the coin was ﬂipped 1 time, which is'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 31, 'page_label': '32'}, page_content='MODEL ANSWER (CORRECT): The coin was ﬂipped by Andree. So the coin was ﬂipped 1 time, which is\\nan odd number. The coin started heads up, so after an odd number of ﬂips, it will be tails up. So the answer is no.\\n✓\\nQUESTION : A coin is heads up. Kristian does not ﬂip the coin. Dallas does not ﬂip the coin. Is the coin still\\nheads up?\\nMODEL ANSWER (INCORRECT): The coin was ﬂipped by Kristian. So the coin was ﬂipped 1 time, which\\nis an odd number. The coin started heads up, so after an odd number of ﬂips, it will be tails up. So the answer is\\nno. \\x17\\nTable 15: Examples of correct and incorrect chains of thought produced by LaMDA 137B on CSQA.\\nQUESTION : When a person is beginning work, what are they building?\\nAnswer Choices: (a) time (b) accomplishing (c) working (d) momentum (e) tiredness\\nMODEL ANSWER (CORRECT): The answer must be something that is built. Of the above choices, only\\nmomentum is built. So the answer is (d). ✓\\nQUESTION : Where are you likely to ﬁnd a hamburger?'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 31, 'page_label': '32'}, page_content='MODEL ANSWER (CORRECT): The answer must be something that is built. Of the above choices, only\\nmomentum is built. So the answer is (d). ✓\\nQUESTION : Where are you likely to ﬁnd a hamburger?\\nAnswer Choices: (a) fast food restaurant (b) pizza (c) ground up dead cows (d) mouth (e) cow carcus\\nMODEL ANSWER (CORRECT): The answer must be a place where hamburgers are found. Of the above\\nchoices, only fast food restaurants serve hamburgers. So the answer is (a). ✓\\nQUESTION : Aside from water and nourishment what does your dog need?\\nAnswer Choices: (a) bone (b) charm (c) petted (d) lots of attention (e) walked\\nMODEL ANSWER (INCORRECT): The answer must be something that a dog needs. Of the above choices,\\nonly bone is something that a dog needs. So the answer is (a). \\x17 (Ground truth is (d).)\\nQUESTION : What are you waiting alongside with when you’re in a reception area?\\nAnswer Choices: (a) motel (b) chair (c) hospital (d) people (e) hotels'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 31, 'page_label': '32'}, page_content='QUESTION : What are you waiting alongside with when you’re in a reception area?\\nAnswer Choices: (a) motel (b) chair (c) hospital (d) people (e) hotels\\nMODEL ANSWER (INCORRECT): The answer must be something that is waiting with you in a reception\\narea. Of the above choices, only people are waiting with you in a reception area. So the answer is (e). \\x17 (Ground\\ntruth is (d).)\\n32'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 32, 'page_label': '33'}, page_content='Table 16: Examples of correct and incorrect chains of thought produced by LaMDA 137B on\\nStrategyQA.\\nQUESTION : Will The Exorcist stimulate limbic system?\\nMODEL ANSWER (CORRECT): The Exorcist is a horror movie. Horror movies are scary. The limbic system\\nis involved in fear. Thus, The Exorcist will stimulate the limbic system. So the answer is yes. ✓\\nQUESTION : Was Jackson Pollock trained by Leonardo da Vinci?\\nMODEL ANSWER (CORRECT): Leonardo da Vinci lived in the 15th century. Jackson Pollock lived in the\\n20th century. Thus, Jackson Pollock could not have been trained by Leonardo da Vinci. So the answer is no. ✓\\nQUESTION : Can Harry Potter book a ﬂight on Asiana Airlines?\\nMODEL ANSWER (INCORRECT): Harry Potter is a ﬁctional character. Thus, Harry Potter can do anything.\\nSo the answer is yes. \\x17 (Ground truth is “no”.)\\nQUESTION : Would a sophist use an épée?\\nMODEL ANSWER (INCORRECT): A sophist is a person who is skilled in the art of persuasion. An épée is'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 32, 'page_label': '33'}, page_content='So the answer is yes. \\x17 (Ground truth is “no”.)\\nQUESTION : Would a sophist use an épée?\\nMODEL ANSWER (INCORRECT): A sophist is a person who is skilled in the art of persuasion. An épée is\\na type of sword. Thus, a sophist could use an épée. So the answer is yes. \\x17 (Ground truth is “no”.)\\nTable 17: Examples of correct and incorrect chains of thought produced by LaMDA 137B on Date\\nUnderstanding.\\nQUESTION : May 6, 1992 is like yesterday to Jane, but that is actually ten years ago. What is the date a month\\nago in MM/DD/YYYY?\\nMODEL ANSWER (CORRECT): May 6, 1992 is ten years ago, so today is May 6, 2002. So a month ago will\\nbe April 6, 2002. So the answer is 04/06/2002. ✓\\nQUESTION : This is the last day of 1899. What is the date 24 hours later in MM/DD/YYYY?\\nMODEL ANSWER (CORRECT): Today is 12/31/1899. 24 hours later will be 01/01/1900. So the answer is\\n01/01/1900. ✓\\nQUESTION : Jane scheduled 3 apointments with 5 poeple for tomorrow (Tue, 7/9/1972). What is the date one'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 32, 'page_label': '33'}, page_content='01/01/1900. ✓\\nQUESTION : Jane scheduled 3 apointments with 5 poeple for tomorrow (Tue, 7/9/1972). What is the date one\\nweek ago from today in MM/DD/YYYY?\\nMODEL ANSWER (INCORRECT): Tomorrow is 7/9/1972. One week ago from today is 7/2/1972. So the\\nanswer is 7/2/1972. \\x17 (Ground truth is 07/01/1972.)\\nQUESTION : Today is the palindrome day of 2020, because the MMDDYYYY format of the date is the same\\nbackwards as forwards. What is the date tomorrow in MM/DD/YYYY?\\nMODEL ANSWER (INCORRECT): Today is 02/29/2020. Tomorrow will be 03/01/2020. So the answer is\\n03/01/2020. \\x17 (Ground truth is “02/03/2020”.)\\nTable 18: Examples of correct and incorrect chains of thought produced by LaMDA 137B on Sports\\nUnderstanding.\\nQUESTION : Is the following sentence plausible? “Joao Moutinho was out at third.”\\nMODEL ANSWER (CORRECT): Joao Moutinho is a soccer player. Being out at third is part of baseball, not\\nsoccer. So the answer is no. ✓'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 32, 'page_label': '33'}, page_content='MODEL ANSWER (CORRECT): Joao Moutinho is a soccer player. Being out at third is part of baseball, not\\nsoccer. So the answer is no. ✓\\nQUESTION : Is the following sentence plausible? “Malcolm Brogdon eurostepped to the basket in the NBA\\nChampionship.”\\nMODEL ANSWER (CORRECT): Malcolm Brogdon is a basketball player. Eurostepping to the basket is part\\nof basketball. So the answer is yes. ✓\\nQUESTION : Is the following sentence plausible? “Derrick White backhanded a shot.”\\nMODEL ANSWER (INCORRECT): Derrick White is a basketball player. Backhanding a shot is part of\\nbasketball. So the answer is yes. \\x17 (Ground truth is “no”, backhanding a shot is part of hockey.)\\nQUESTION : Is the following sentence plausible? “Nazem Kadri was out at home.”\\nMODEL ANSWER (INCORRECT): Nazem Kadri is a hockey player. Being out at home is part of hockey.\\nSo the answer is yes. \\x17 (Ground truth is “no”, being out at home is part of baseball.)\\n33'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 33, 'page_label': '34'}, page_content='Table 19: Examples of correct and incorrect chains of thought produced by PaLM 540B on SayCan\\nrobot planning tasks.\\nQUESTION : I spilled my coke on the table, could you throw it away and then bring me something to help clean?\\nMODEL ANSWER (CORRECT): Explanation: The user has spilled their coke on the table. I will throw away\\nthe coke and then bring the user a sponge. Plan: ﬁnd(coke), pick(coke), ﬁnd(trash), put(coke), ﬁnd(sponge),\\npick(sponge), ﬁnd(table), put(sponge). ✓\\nQUESTION : Could you compost that apple for me?\\nMODEL ANSWER (CORRECT): Explanation: The user would like me to compost the apple. I will move the\\napple to the compost. Plan: ﬁnd(apple), pick(apple), ﬁnd(trash), put(apple). ✓\\nQUESTION : Can you bring me a drink that is not coke?\\nMODEL ANSWER (INCORRECT): Explanation: The user asked me to bring a drink that is not coke, I will\\nbring a sprite. Plan: ﬁnd(sprite), pick(sprite), ﬁnd(user), put(sprite). \\x17 (Feasible answers including ﬁnding lime'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 33, 'page_label': '34'}, page_content='bring a sprite. Plan: ﬁnd(sprite), pick(sprite), ﬁnd(user), put(sprite). \\x17 (Feasible answers including ﬁnding lime\\nsoda, pepsi, grapefruit soda or water, because there is no sprite in the scene as deﬁned in Table 28.)\\nQUESTION : Can you bring me something salty?\\nMODEL ANSWER (INCORRECT): Explanation: The user would like something salty. There are several\\noptions in the objects list, so I will bring the user a lime soda. Plan: ﬁnd(lime soda), pick(lime soda), ﬁnd(user),\\nput(lime soda). \\x17 (Feasible answers including ﬁnding chips. The model misidentify lime soda as salty.)\\n34'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 34, 'page_label': '35'}, page_content='G Appendix: Full Prompts\\nTable 20: Few-shot exemplars for full chain of thought prompt for math word problems. This set of\\nexemplars was used for all math word problem datasets except AQuA.\\nPROMPT FOR MATH WORD PROBLEMS\\nQ: There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there\\nwill be 21 trees. How many trees did the grove workers plant today?\\nA: There are 15 trees originally. Then there were 21 trees after some more were planted. So there must have\\nbeen 21 - 15 = 6. The answer is 6.\\nQ: If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\\nA: There are originally 3 cars. 2 more cars arrive. 3 + 2 = 5. The answer is 5.\\nQ: Leah had 32 chocolates and her sister had 42. If they ate 35, how many pieces do they have left in total?\\nA: Originally, Leah had 32 chocolates. Her sister had 42. So in total they had 32 + 42 = 74. After eating 35, they\\nhad 74 - 35 = 39. The answer is 39.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 34, 'page_label': '35'}, page_content='A: Originally, Leah had 32 chocolates. Her sister had 42. So in total they had 32 + 42 = 74. After eating 35, they\\nhad 74 - 35 = 39. The answer is 39.\\nQ: Jason had 20 lollipops. He gave Denny some lollipops. Now Jason has 12 lollipops. How many lollipops did\\nJason give to Denny?\\nA: Jason started with 20 lollipops. Then he had 12 after giving some to Denny. So he gave Denny 20 - 12 = 8.\\nThe answer is 8.\\nQ: Shawn has ﬁve toys. For Christmas, he got two toys each from his mom and dad. How many toys does he\\nhave now?\\nA: Shawn started with 5 toys. If he got 2 toys each from his mom and dad, then that is 4 more toys. 5 + 4 = 9.\\nThe answer is 9.\\nQ: There were nine computers in the server room. Five more computers were installed each day, from monday\\nto thursday. How many computers are now in the server room?\\nA: There were originally 9 computers. For each of 4 days, 5 more computers were added. So 5 * 4 = 20\\ncomputers were added. 9 + 20 is 29. The answer is 29.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 34, 'page_label': '35'}, page_content='A: There were originally 9 computers. For each of 4 days, 5 more computers were added. So 5 * 4 = 20\\ncomputers were added. 9 + 20 is 29. The answer is 29.\\nQ: Michael had 58 golf balls. On tuesday, he lost 23 golf balls. On wednesday, he lost 2 more. How many golf\\nballs did he have at the end of wednesday?\\nA: Michael started with 58 golf balls. After losing 23 on tuesday, he had 58 - 23 = 35. After losing 2 more, he\\nhad 35 - 2 = 33 golf balls. The answer is 33.\\nQ: Olivia has $23. She bought ﬁve bagels for $3 each. How much money does she have left?\\nA: Olivia had 23 dollars. 5 bagels for 3 dollars each will be 5 x 3 = 15 dollars. So she has 23 - 15 dollars left. 23\\n- 15 is 8. The answer is 8.\\n35'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 35, 'page_label': '36'}, page_content='Table 21: Few-shot exemplars for full chain of thought prompt for AQuA.\\nPROMPT FOR AQUA ALGEBRAIC WORD PROBLEMS\\nQ: John found that the average of 15 numbers is 40. If 10 is added to each number then the mean of the numbers\\nis?\\nAnswer Choices: (a) 50 (b) 45 (c) 65 (d) 78 (e) 64\\nA: If 10 is added to each number, then the mean of the numbers also increases by 10. So the new mean would be\\n50. The answer is (a).\\nQ: If a / b = 3/4 and 8a + 5b = 22,then ﬁnd the value of a.\\nAnswer Choices: (a) 1/2 (b) 3/2 (c) 5/2 (d) 4/2 (e) 7/2\\nA: If a / b = 3/4, then b = 4a / 3. So 8a + 5(4a / 3) = 22. This simpliﬁes to 8a + 20a / 3 = 22, which means 44a / 3\\n= 22. So a is equal to 3/2. The answer is (b).\\nQ: A person is traveling at 20 km/hr and reached his destiny in 2.5 hr then ﬁnd the distance?\\nAnswer Choices: (a) 53 km (b) 55 km (c) 52 km (d) 60 km (e) 50 km\\nA: The distance that the person traveled would have been 20 km/hr * 2.5 hrs = 50 km. The answer is (e).'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 35, 'page_label': '36'}, page_content='Answer Choices: (a) 53 km (b) 55 km (c) 52 km (d) 60 km (e) 50 km\\nA: The distance that the person traveled would have been 20 km/hr * 2.5 hrs = 50 km. The answer is (e).\\nQ: How many keystrokes are needed to type the numbers from 1 to 500?\\nAnswer Choices: (a) 1156 (b) 1392 (c) 1480 (d) 1562 (e) 1788\\nA: There are 9 one-digit numbers from 1 to 9. There are 90 two-digit numbers from 10 to 99. There are 401\\nthree-digit numbers from 100 to 500. 9 + 90(2) + 401(3) = 1392. The answer is (b).\\nTable 22: Few-shot exemplars for full chain of thought prompt for the last letter concatenation task.\\nPROMPT FOR LAST LETTER CONCATENATION\\nQ: Take the last letters of the words in \"Elon Musk\" and concatenate them.\\nA: The last letter of \"Elon\" is \"n\". The last letter of \"Musk\" is \"k\". Concatenating them is \"nk\". The answer is nk.\\nQ: Take the last letters of the words in \"Larry Page\" and concatenate them.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 35, 'page_label': '36'}, page_content='A: The last letter of \"Elon\" is \"n\". The last letter of \"Musk\" is \"k\". Concatenating them is \"nk\". The answer is nk.\\nQ: Take the last letters of the words in \"Larry Page\" and concatenate them.\\nA: The last letter of \"Larry\" is \"y\". The last letter of \"Page\" is \"e\". Concatenating them is \"ye\". The answer is ye.\\nQ: Take the last letters of the words in \"Sergey Brin\" and concatenate them.\\nA: The last letter of \"Sergey\" is \"y\". The last letter of \"Brin\" is \"n\". Concatenating them is \"yn\". The answer is\\nyn.\\nQ: Take the last letters of the words in \"Bill Gates\" and concatenate them.\\nA: The last letter of \"Bill\" is \"l\". The last letter of \"Gates\" is \"s\". Concatenating them is \"ls\". The answer is ls.\\n36'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 36, 'page_label': '37'}, page_content='Table 23: Few-shot exemplars for full chain of thought prompt for the coinﬂip task.\\nPROMPT FOR COIN FLIP\\nQ: Q: A coin is heads up. Ka ﬂips the coin. Sherrie ﬂips the coin. Is the coin still heads up?\\nA: The coin was ﬂipped by Ka and Sherrie. So the coin was ﬂipped 2 times, which is an even number. The coin\\nstarted heads up, so after an even number of ﬂips, it will still be heads up. So the answer is yes.\\nQ: A coin is heads up. Jamey ﬂips the coin. Teressa ﬂips the coin. Is the coin still heads up?\\nA: The coin was ﬂipped by Jamey and Teressa. So the coin was ﬂipped 2 times, which is an even number. The\\ncoin started heads up, so after an even number of ﬂips, it will still be heads up. So the answer is yes.\\nQ: A coin is heads up. Maybelle ﬂips the coin. Shalonda does not ﬂip the coin. Is the coin still heads up?\\nA: The coin was ﬂipped by Maybelle. So the coin was ﬂipped 1 time, which is an odd number. The coin started'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 36, 'page_label': '37'}, page_content='A: The coin was ﬂipped by Maybelle. So the coin was ﬂipped 1 time, which is an odd number. The coin started\\nheads up, so after an odd number of ﬂips, it will be tails up. So the answer is no.\\nQ: A coin is heads up. Millicent does not ﬂip the coin. Conception ﬂips the coin. Is the coin still heads up?\\nA: The coin was ﬂipped by Conception. So the coin was ﬂipped 1 time, which is an odd number. The coin\\nstarted heads up, so after an odd number of ﬂips, it will be tails up. So the answer is no.\\nQ: A coin is heads up. Sal ﬂips the coin. Raymond does not ﬂip the coin. Is the coin still heads up?\\nA: The coin was ﬂipped by Sal. So the coin was ﬂipped 1 time, which is an odd number. The coin started heads\\nup, so after an odd number of ﬂips, it will be tails up. So the answer is no.\\nQ: A coin is heads up. Conception ﬂips the coin. Kristian does not ﬂip the coin. Is the coin still heads up?\\nA: The coin was ﬂipped by Conception. So the coin was ﬂipped 1 time, which is an odd number. The coin'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 36, 'page_label': '37'}, page_content='A: The coin was ﬂipped by Conception. So the coin was ﬂipped 1 time, which is an odd number. The coin\\nstarted heads up, so after an odd number of ﬂips, it will be tails up. So the answer is no.\\nQ: A coin is heads up. Inga does not ﬂip the coin. Elanor does not ﬂip the coin. Is the coin still heads up?\\nA: The coin was ﬂipped by no one. So the coin was ﬂipped 0 times. The coin started heads up, and it was not\\nﬂipped, so it is still heads up. So the answer is yes.\\nQ: A coin is heads up. Ryan ﬂips the coin. Shaunda ﬂips the coin. Is the coin still heads up?\\nA: The coin was ﬂipped by Ryan and Shaunda. So the coin was ﬂipped 2 times, which is an even number. The\\ncoin started heads up, so after an even number of ﬂips, it will still be heads up. So the answer is yes.\\n37'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 37, 'page_label': '38'}, page_content='Table 24: Few-shot exemplars for full chain of thought prompt for CSQA. There are newlines\\nbetween the answer choices that are omitted in the table for space reasons.\\nPROMPT FOR CSQA\\nQ: What do people use to absorb extra ink from a fountain pen? Answer Choices: (a) shirt pocket (b)\\ncalligrapher’s hand (c) inkwell (d) desk drawer (e) blotter\\nA: The answer must be an item that can absorb ink. Of the above choices, only blotters are used to absorb ink.\\nSo the answer is (e).\\nQ: What home entertainment equipment requires cable?\\nAnswer Choices: (a) radio shack (b) substation (c) television (d) cabinet\\nA: The answer must require cable. Of the above choices, only television requires cable. So the answer is (c).\\nQ: The fox walked from the city into the forest, what was it looking for? Answer Choices: (a) pretty ﬂowers (b)\\nhen house (c) natural habitat (d) storybook\\nA: The answer must be something in the forest. Of the above choices, only natural habitat is in the forest. So the\\nanswer is (b).'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 37, 'page_label': '38'}, page_content='hen house (c) natural habitat (d) storybook\\nA: The answer must be something in the forest. Of the above choices, only natural habitat is in the forest. So the\\nanswer is (b).\\nQ: Sammy wanted to go to where the people were. Where might he go? Answer Choices: (a) populated areas\\n(b) race track (c) desert (d) apartment (e) roadblock\\nA: The answer must be a place with a lot of people. Of the above choices, only populated areas have a lot of\\npeople. So the answer is (a).\\nQ: Where do you put your grapes just before checking out? Answer Choices: (a) mouth (b) grocery cart (c)super\\nmarket (d) fruit basket (e) fruit market\\nA: The answer should be the place where grocery items are placed before checking out. Of the above choices,\\ngrocery cart makes the most sense for holding grocery items. So the answer is (b).\\nQ: Google Maps and other highway and street GPS services have replaced what? Answer Choices: (a) united\\nstates (b) mexico (c) countryside (d) atlas'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 37, 'page_label': '38'}, page_content='Q: Google Maps and other highway and street GPS services have replaced what? Answer Choices: (a) united\\nstates (b) mexico (c) countryside (d) atlas\\nA: The answer must be something that used to do what Google Maps and GPS services do, which is to give\\ndirections. Of the above choices, only atlases are used to give directions. So the answer is (d).\\nQ: Before getting a divorce, what did the wife feel who was doing all the work? Answer Choices: (a) harder (b)\\nanguish (c) bitterness (d) tears (e) sadness\\nA: The answer should be the feeling of someone getting divorced who was doing all the work. Of the above\\nchoices, the closest feeling is bitterness. So the answer is (c).\\n38'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 38, 'page_label': '39'}, page_content='Table 25: Few-shot exemplars for full chain of thought prompt for StrategyQA.\\nPROMPT FOR STRATEGY QA\\nQ: Do hamsters provide food for any animals?\\nA: Hamsters are prey animals. Prey are food for predators. Thus, hamsters provide food for some animals. So\\nthe answer is yes.\\nQ: Could Brooke Shields succeed at University of Pennsylvania?\\nA: Brooke Shields went to Princeton University. Princeton University is about as academically rigorous as the\\nUniversity of Pennsylvania. Thus, Brooke Shields could also succeed at the University of Pennsylvania. So the\\nanswer is yes.\\nQ: Yes or no: Hydrogen’s atomic number squared exceeds number of Spice Girls?\\nA: Hydrogen has an atomic number of 1. 1 squared is 1. There are 5 Spice Girls. Thus, Hydrogen’satomic\\nnumber squared is less than 5. So the answer is no.\\nQ: Yes or no: Is it common to see frost during some college commencements?\\nA: College commencement ceremonies can happen in December, May, and June. December is in the winter, so'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 38, 'page_label': '39'}, page_content='Q: Yes or no: Is it common to see frost during some college commencements?\\nA: College commencement ceremonies can happen in December, May, and June. December is in the winter, so\\nthere can be frost. Thus, there could be frost at some commencements. So the answer is yes.\\nQ: Yes or no: Could a llama birth twice during War in Vietnam (1945-46)?\\nA: The War in Vietnam was 6 months. The gestation period for a llama is 11 months, which is more than 6\\nmonths. Thus, a llama could not give birth twice during the War in Vietnam. So the answer is no.\\nQ: Yes or no: Would a pear sink in water?\\nA: The density of a pear is about 0.6g/cm3, which is less than water. Objects less dense than water ﬂoat. Thus,\\na pear would ﬂoat. So the answer is no.\\nTable 26: Few-shot exemplars for full chain of thought prompt for Date Understanding.\\nPROMPT FOR DATE UNDERSTANDING\\nQ: 2015 is coming in 36 hours. What is the date one week from today in MM/DD/YYYY?'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 38, 'page_label': '39'}, page_content='Table 26: Few-shot exemplars for full chain of thought prompt for Date Understanding.\\nPROMPT FOR DATE UNDERSTANDING\\nQ: 2015 is coming in 36 hours. What is the date one week from today in MM/DD/YYYY?\\nA: If 2015 is coming in 36 hours, then it is coming in 2 days. 2 days before 01/01/2015 is 12/30/2014, so today\\nis 12/30/2014. So one week from today will be 01/05/2015. So the answer is 01/05/2015.\\nQ: The ﬁrst day of 2019 is a Tuesday, and today is the ﬁrst Monday of 2019. What is the date today in\\nMM/DD/YYYY?\\nA: If the ﬁrst day of 2019 was Tuesday, then 01/01/2019 was a Tuesday. Today is the ﬁrst monday, would be six\\ndays later. So today is 01/07/2019. So the answer is 01/07/2019.\\nQ: The concert was scheduled to be on 06/01/1943, but was delayed by one day to today. What is the date 10\\ndays ago in MM/DD/YYYY?\\nA: One day after 06/01/1943 is 06/02/1943, so today is 06/02/1943. 10 days before today is 05/23/1943. So the\\nanswer is 05/23/1943.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 38, 'page_label': '39'}, page_content='days ago in MM/DD/YYYY?\\nA: One day after 06/01/1943 is 06/02/1943, so today is 06/02/1943. 10 days before today is 05/23/1943. So the\\nanswer is 05/23/1943.\\nQ: It is 4/19/1969 today. What is the date 24 hours later in MM/DD/YYYY?\\nA: Today is 04/19/1969. 24 hours later is one day after today, which would be 04/20/1969. So the answer is\\n04/20/1969.\\nQ: Jane thought today is 3/11/2002, but today is in fact Mar 12, which is 1 day later. What is the date 24 hours\\nlater in MM/DD/YYYY?\\nA: Today is 03/12/2002. So the date 24 hours later will be 03/13/2002. So the answer is 03/13/2002.\\nQ: Jane was born on the last day of Feburary in 2001. Today is her 16-year-old birthday. What is the date\\nyesterday in MM/DD/YYYY?\\nA: The last day of February is the 28th, so Jane was born on 02/28/2001. Today is her 16-year old birthday, so\\ntoday is 02/28/2017. So yesterday was 02/27/2017. So the answer is 02/27/2017.\\n39'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 39, 'page_label': '40'}, page_content='Table 27: Few-shot exemplars for full chain of thought prompt for Sports Understanding.\\nPROMPT FOR SPORTS UNDERSTANDING\\nQ: Is the following sentence plausible? “Kyle Palmieri was called for slashing.”\\nA: Kyle Palmieri is a hockey player. Being called for slashing is part of hockey. So the answer is yes.\\nQ: Is the following sentence plausible? “Joao Moutinho caught the screen pass in the NFC championship.”\\nA: Joao Moutinho is a soccer player. The NFC championship is part of American football, not soccer. So the\\nanswer is no.\\nQ: Is the following sentence plausible? “Carson Wentz set the pick and roll.”\\nA: Carson Wentz is an American football player. Pick and roll is part of basketball, not football. So the answer\\nis no.\\nQ: Is the following sentence plausible? “Jonas Valanciunas beat the buzzer.”\\nA: Jonas Valanciunas is a basketball player. Beating the buzzer is part of basketball. So the answer is yes.\\nQ: Is the following sentence plausible? “Jamel Murray was perfect from the line.”'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 39, 'page_label': '40'}, page_content='A: Jonas Valanciunas is a basketball player. Beating the buzzer is part of basketball. So the answer is yes.\\nQ: Is the following sentence plausible? “Jamel Murray was perfect from the line.”\\nA: Jamal Murray is a basketball player. Being perfect from the line is part of basketball. So the answer is yes.\\nQ: Is the following sentence plausible? “Sam Darnold passed the puck.”\\nA: Sam Darnold is a American football player. Passing the puck is part of hockey, not American football. So the\\nanswer is no.\\nQ: Is the following sentence plausible? “Draymond Green threw a touchdown.”\\nA: Draymond Green is an basketball player. Throwing a touchdown is part of football, not basketball. So the\\nanswer is no.\\nQ: Is the following sentence plausible? “Malcolm Brogdon banked the shot in.”\\nA: Malcolm Brogdon is a basketball player. Banking the shot in is part of basketball. So the answer is yes.\\n40'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 40, 'page_label': '41'}, page_content='Table 28: Few-shot exemplars for full chain of thought prompt for SayCan robot planning tasks.\\nPROMPT FOR SAYCAN ROBOT PLANNING\\nLocations = [counter, table, user, trash, bowl].\\nObjects = [7up, apple, kettle chips, tea, multigrain chips, coke, lime soda, jalapeno chips, rice chips, orange,\\ngrapefruit soda, pepsi, redbull, energy bar, sponge, water].\\nThe robot can pick up items with pick(object) and put down items with put(object) as well as ﬁnd objects or\\nlocations with ﬁnd(). The robot can only understand the explicit locations and objects listed.\\nHuman: I’m hungry, can you bring me some chips.\\nExplanation: The user is hungry and has asked for chips. There are several types of chips available, I will bring\\nthe user the kettle chips.\\nPlan: 1. ﬁnd(kettle chips), 2. pick(kettle chips), 3. ﬁnd(user), 4. put(kettle chips), 5. done().\\nHuman: How would you move the grapefruit drink from the table to the counter?\\nExplanation: The user has asked me to move the grapefruit drink to the counter.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 40, 'page_label': '41'}, page_content='Human: How would you move the grapefruit drink from the table to the counter?\\nExplanation: The user has asked me to move the grapefruit drink to the counter.\\nPlan: 1. ﬁnd(grapefruit soda), 2. pick(grapefruit soda), 3. ﬁnd(counter), 4. put(grapefruit soda), 5. done().\\nHuman: How would you bring me some snacks?\\nExplanation: The user has asked for snacks, I will choose two items and bring them. I will bring jalapeno chips\\nand an apple.\\nPlan: 1. ﬁnd(jalapeno chips), 2. pick(jalapeno chips), 3. ﬁnd(user), 4. put(jalapeno chips), 5. ﬁnd(apple), 6.\\npick(apple), 7. ﬁnd(user), 8. put(apple), 9. done().\\nHuman: How would you bring me something to eat that isn’t a fruit?\\nExplanation: The user has asked for a food that isn’ta fruit, I will bring an energy bar to them.\\nPlan: 1. ﬁnd(energy bar), 2. pick(energy bar), 3. ﬁnd(user), 4. put(energy bar), 5. done().\\nHuman: How would you put the rice chips in the bowl and then move the tea to the table?'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 40, 'page_label': '41'}, page_content='Plan: 1. ﬁnd(energy bar), 2. pick(energy bar), 3. ﬁnd(user), 4. put(energy bar), 5. done().\\nHuman: How would you put the rice chips in the bowl and then move the tea to the table?\\nExplanation: The user has asked me to do two tasks, I will do one and then the other.\\nPlan: 1. ﬁnd(rice chips), 2. pick(rice chips), 3. ﬁnd(bowl), 4. put(rice chips), 5. ﬁnd(tea), 6. pick(tea), 7.\\nﬁnd(table), 8. put(tea), 9. done().\\nHuman: How would you throw away a redbull?\\nExplanation: The user has asked me to throw away the redbull, I will move it to the trash.\\nPlan: 1. ﬁnd(redbull), 2. pick(redbull), 3. ﬁnd(trash), 4. put(redbull), 5. done().\\nHuman: Bring me a drink.\\nExplanation: The user has asked for a drink and there are many options. I will bring them a water.\\nPlan: 1. ﬁnd(water), 2. pick(water), 3. ﬁnd(user), 4. put(water), 5. done().\\n41'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 41, 'page_label': '42'}, page_content='H Appendix: Alternate Annotators for MWP\\nTable 29: Few-shot exemplars for full chain of thought prompt for math word problems. These\\nexemplars are the same as in Table 20, except that the chains of thought were written by a different\\nannotator (“Annotator B” instead of “Annotator A”). Annotators were co-authors and familiar with\\nthe goal of chain of thought prompting.\\nPROMPT FOR MATH WORD PROBLEMS\\nQ: There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there\\nwill be 21 trees. How many trees did the grove workers plant today?\\nA: There are 21 trees now and there are 15 trees in the beginning, so the workers plant 21 - 15 = 6 trees. The\\nanswer is 6.\\nQ: If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\\nA: There are 3 cars in the beginning, 2 more arrive, so now there should be 3 + 2 = 5 cars. The answer is 5.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 41, 'page_label': '42'}, page_content='A: There are 3 cars in the beginning, 2 more arrive, so now there should be 3 + 2 = 5 cars. The answer is 5.\\nQ: Leah had 32 chocolates and her sister had 42. If they ate 35, how many pieces do they have left in total?\\nA: Leah had 32 chocolates and her sister had 42, in total they have 32 + 42 = 74 chocolates. After they ate 35,\\nnow there are 74 - 35 = 39 chocolates. The answer is 39.\\nQ: Jason had 20 lollipops. He gave Denny some lollipops. Now Jason has 12 lollipops. How many lollipops did\\nJason give to Denny?\\nA: Jason started with 20 lollipops, but now he only has 12, so he gave Denny 20 - 12 = 8 lollipops. The answer\\nis 8.\\nQ: Shawn has ﬁve toys. For Christmas, he got two toys each from his mom and dad. How many toys does he\\nhave now?\\nA: Shawn got 2 toys each from his mom and dad, so he got 2 * 2 = 4 more, now he will have 5 + 4 = 9 toys. The\\nanswer is 9.\\nQ: There were nine computers in the server room. Five more computers were installed each day, from monday'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 41, 'page_label': '42'}, page_content='answer is 9.\\nQ: There were nine computers in the server room. Five more computers were installed each day, from monday\\nto thursday. How many computers are now in the server room?\\nA: 5 computers were installed from monday to thursday, so in total 5 * 4 = 20 computers are installed. 9\\ncomputers are there in the beginning, so now there are 20 + 9 = 29 computers. The answer is 29.\\nQ: Michael had 58 golf balls. On tuesday, he lost 23 golf balls. On wednesday, he lost 2 more. How many golf\\nballs did he have at the end of wednesday?\\nA: Michael started with 58 golf balls and lost 23, so he has 58 - 23 = 35. After he lost 2 more, he has 35 - 2 = 33\\nballs now. The answer is 33.\\nQ: Olivia has $23. She bought ﬁve bagels for $3 each. How much money does she have left?\\nA: 5 bagels for $3 each should cost 5 * 3 = 15 dollars. Olivia had $23 in the beginning, so now she has 23 - 15 =\\n8 dollars left. The answer is 8.\\n42'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 42, 'page_label': '43'}, page_content='Table 30: Few-shot exemplars for full chain of thought prompt for math word problems. These\\nexemplars are the same as in Table 20, except that the chains of thought were written by a different\\nannotator (“Annotator C” instead of “Annotator A”).\\nPROMPT FOR MATH WORD PROBLEMS\\nQ: There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there\\nwill be 21 trees. How many trees did the grove workers plant today?\\nA: We start with 15 trees. Later we have 21 trees. The difference must be the number of trees they planted. So,\\nthey must have planted 21 - 15 = 6 trees. The answer is 6.\\nQ: If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\\nA: There are 3 cars in the parking lot already. 2 more arrive. Now there are 3 + 2 = 5 cars. The answer is 5.\\nQ: Leah had 32 chocolates and her sister had 42. If they ate 35, how many pieces do they have left in total?'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 42, 'page_label': '43'}, page_content='Q: Leah had 32 chocolates and her sister had 42. If they ate 35, how many pieces do they have left in total?\\nA: Leah had 32 chocolates and Leah’ssister had 42. That means there were originally 32 + 42 = 74 chocolates.\\n35 have been eaten. So in total they still have 74 - 35 = 39 chocolates. The answer is 39.\\nQ: Jason had 20 lollipops. He gave Denny some lollipops. Now Jason has 12 lollipops. How many lollipops did\\nJason give to Denny?\\nA: Jason had 20 lollipops. Since he only has 12 now, he must have given the rest to Denny. The number of\\nlollipops he has given to Denny must have been 20 - 12 = 8 lollipops. The answer is 8.\\nQ: Shawn has ﬁve toys. For Christmas, he got two toys each from his mom and dad. How many toys does he\\nhave now?\\nA: He has 5 toys. He got 2 from mom, so after that he has 5 + 2 = 7 toys. Then he got 2 more from dad, so in\\ntotal he has 7 + 2 = 9 toys. The answer is 9.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 42, 'page_label': '43'}, page_content='have now?\\nA: He has 5 toys. He got 2 from mom, so after that he has 5 + 2 = 7 toys. Then he got 2 more from dad, so in\\ntotal he has 7 + 2 = 9 toys. The answer is 9.\\nQ: There were nine computers in the server room. Five more computers were installed each day, from monday\\nto thursday. How many computers are now in the server room?\\nA: There are 4 days from monday to thursday. 5 computers were added each day. That means in total 4 * 5 = 20\\ncomputers were added. There were 9 computers in the beginning, so now there are 9 + 20 = 29 computers. The\\nanswer is 29.\\nQ: Michael had 58 golf balls. On tuesday, he lost 23 golf balls. On wednesday, he lost 2 more. How many golf\\nballs did he have at the end of wednesday?\\nA: Michael initially had 58 balls. He lost 23 on Tuesday, so after that he has 58 - 23 = 35 balls. On Wednesday\\nhe lost 2 more so now he has 35 - 2 = 33 balls. The answer is 33.\\nQ: Olivia has $23. She bought ﬁve bagels for $3 each. How much money does she have left?'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 42, 'page_label': '43'}, page_content='he lost 2 more so now he has 35 - 2 = 33 balls. The answer is 33.\\nQ: Olivia has $23. She bought ﬁve bagels for $3 each. How much money does she have left?\\nA: She bought 5 bagels for $3 each. This means she spent 5 * $3 = $15 on the bagels. She had $23 in beginning,\\nso now she has $23 - $15 = $8. The answer is 8.\\n43'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 0, 'page_label': '1'}, page_content='A Path Towards Autonomous Machine Intelligence\\nVersion 0.9.2, 2022-06-27\\nYann LeCun\\nCourant Institute of Mathematical Sciences, New York Universityyann@cs.nyu.edu\\nMeta - Fundamental AI Researchyann@fb.com\\nJune 27, 2022\\nAbstract\\nHow could machines learn as eﬃciently as humans and animals? How could ma-\\nchines learn to reason and plan? How could machines learn representations of percepts\\nand action plans at multiple levels of abstraction, enabling them to reason, predict,\\nand plan at multiple time horizons? This position paper proposes an architecture and\\ntraining paradigms with which to construct autonomous intelligent agents. It combines\\nconcepts such as conﬁgurable predictive world model, behavior driven through intrinsic\\nmotivation, and hierarchical joint embedding architectures trained with self-supervised\\nlearning.\\nKeywords: Artiﬁcial Intelligence, Machine Common Sense, Cognitive Architecture, Deep'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 0, 'page_label': '1'}, page_content='motivation, and hierarchical joint embedding architectures trained with self-supervised\\nlearning.\\nKeywords: Artiﬁcial Intelligence, Machine Common Sense, Cognitive Architecture, Deep\\nLearning, Self-Supervised Learning, Energy-Based Model, World Models, Joint Embedding\\nArchitecture, Intrinsic Motivation.\\n1 Prologue\\nThis document is not a technical nor scholarly paper in the traditional sense, but a position\\npaper expressing my vision for a path towards intelligent machines that learn more like\\nanimals and humans, that can reason and plan, and whose behavior is driven by intrinsic\\nobjectives, rather than by hard-wired programs, external supervision, or external rewards.\\nMany ideas described in this paper (almost all of them) have been formulated by many\\nauthors in various contexts in various form. The present piece does not claim priority for\\nany of them but presents a proposal for how to assemble them into a consistent whole. In'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 0, 'page_label': '1'}, page_content='authors in various contexts in various form. The present piece does not claim priority for\\nany of them but presents a proposal for how to assemble them into a consistent whole. In\\nparticular, the piece pinpoints the challenges ahead. It also lists a number of avenues that\\nare likely or unlikely to succeed.\\nThe text is written with as little jargon as possible, and using as little mathematical\\nprior knowledge as possible, so as to appeal to readers with a wide variety of backgrounds\\nincluding neuroscience, cognitive science, and philosophy, in addition to machine learning,\\nrobotics, and other ﬁelds of engineering. I hope that this piece will help contextualize some\\nof the research in AI whose relevance is sometimes diﬃcult to see.\\n1'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 1, 'page_label': '2'}, page_content='2 Introduction\\nAnimals and humans exhibit learning abilities and understandings of the world that are far\\nbeyond the capabilities of current AI and machine learning (ML) systems.\\nHow is it possible for an adolescent to learn to drive a car in about 20 hours of practice\\nand for children to learn language with what amounts to a small exposure. How is it that\\nmost humans will know how to act in many situation they have never encountered? By\\ncontrast, to be reliable, current ML systems need to be trained with very large numbers of\\ntrials so that even the rarest combination of situations will be encountered frequently during\\ntraining. Still, our best ML systems are still very far from matching human reliability in\\nreal-world tasks such as driving, even after being fed with enormous amounts of supervisory\\ndata from human experts, after going through millions of reinforcement learning trials in\\nvirtual environments, and after engineers have hardwired hundreds of behaviors into them.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 1, 'page_label': '2'}, page_content='data from human experts, after going through millions of reinforcement learning trials in\\nvirtual environments, and after engineers have hardwired hundreds of behaviors into them.\\nThe answer may lie in the ability of humans and many animals to learn world models,\\ninternal models of how the world works.\\nThere are three main challenges that AI research must address today:\\n1. How can machines learn to represent the world, learn to predict, and learn to act\\nlargely by observation?\\nInteractions in the real world are expensive and dangerous, intelligent agents should\\nlearn as much as they can about the world without interaction (by observation) so\\nas to minimize the number of expensive and dangerous trials necessary to learn a\\nparticular task.\\n2. How can machine reason and plan in ways that are compatible with gradient-based\\nlearning?\\nOur best approaches to learning rely on estimating and using the gradient of a loss,'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 1, 'page_label': '2'}, page_content='particular task.\\n2. How can machine reason and plan in ways that are compatible with gradient-based\\nlearning?\\nOur best approaches to learning rely on estimating and using the gradient of a loss,\\nwhich can only be performed with diﬀerentiable architectures and is diﬃcult to rec-\\noncile with logic-based symbolic reasoning.\\n3. How can machines learn to represent percepts and action plans in a hierarchical man-\\nner, at multiple levels of abstraction, and multiple time scales?\\nHumans and many animals are able to conceive multilevel abstractions with which\\nlong-term predictions and long-term planning can be performed by decomposing com-\\nplex actions into sequences of lower-level ones.\\nThe present piece proposes an architecture for intelligent agents with possible solutions to\\nall three challenges.\\nThe main contributions of this paper are the following:\\n1. an overall cognitive architecture in which all modules are diﬀerentiable and many of\\nthem are trainable (Section 3, Figure 2).'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 1, 'page_label': '2'}, page_content='The main contributions of this paper are the following:\\n1. an overall cognitive architecture in which all modules are diﬀerentiable and many of\\nthem are trainable (Section 3, Figure 2).\\n2. JEPA and Hierarchical JEPA: a non-generative architecture for predictive world mod-\\nels that learn a hierarchy of representations (Sections 4.4 and 4.6, Figures 12 and 15).\\n3. a non-contrastive self-supervised learning paradigm that produces representations that\\nare simultaneously informative and predictable (Section 4.5, Figure 13).\\n2'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 2, 'page_label': '3'}, page_content='4. A way to use H-JEPA as the basis of predictive world models for hierarchical planning\\nunder uncertainty (section 4.7, Figure 16 and 17).\\nImpatient readers may prefer to jump directly to the aforementioned sections and ﬁgures.\\n2.1 Learning World Models\\nHuman and non-human animals seem able to learn enormous amounts of background knowl-\\nedge about how the world works through observation and through an incomprehensibly\\nsmall amount of interactions in a task-independent, unsupervised way. It can be hypoth-\\nesized that this accumulated knowledge may constitute the basis for what is often called\\ncommon sense . Common sense can be seen as a collection of models of the world that\\ncan tell an agent what is likely, what is plausible, and what is impossible. Using such\\nworld models, animals can learn new skills with very few trials. They can predict the con-\\nsequences of their actions, they can reason, plan, explore, and imagine new solutions to'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 2, 'page_label': '3'}, page_content='world models, animals can learn new skills with very few trials. They can predict the con-\\nsequences of their actions, they can reason, plan, explore, and imagine new solutions to\\nproblems. Importantly, they can also avoid making dangerous mistakes when facing an\\nunknown situation.\\nThe idea that humans, animals, and intelligent systems use world models goes back a\\nlong time in psychology (Craik, 1943). The use of forward models that predict the next\\nstate of the world as a function of the current state and the action being considered has been\\nstandard procedure in optimal control since the 1950s (Bryson and Ho, 1969) and bears\\nthe name model-predictive control. The use of diﬀerentiable world models in reinforcement\\nlearning has long been neglected but is making a comeback (see for example (Levine, 2021))\\nA self-driving system for cars may require thousands of trials of reinforcement learning\\nto learn that driving too fast in a turn will result in a bad outcome, and to learn to slow'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 2, 'page_label': '3'}, page_content='A self-driving system for cars may require thousands of trials of reinforcement learning\\nto learn that driving too fast in a turn will result in a bad outcome, and to learn to slow\\ndown to avoid skidding. By contrast, humans can draw on their intimate knowledge of\\nintuitive physics to predict such outcomes, and largely avoid fatal courses of action when\\nlearning a new skill.\\nCommon sense knowledge does not just allow animals to predict future outcomes, but\\nalso to ﬁll in missing information, whether temporally or spatially. It allows them to produce\\ninterpretations of percepts that are consistent with common sense. When faced with an\\nambiguous percept, common sense allows animals to dismiss interpretations that are not\\nconsistent with their internal world model, and to pay special attention as it may indicate\\na dangerous situation and an opportunity for learning a reﬁned world model.\\nI submit that devising learning paradigms and architectures that would allow machines'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 2, 'page_label': '3'}, page_content='a dangerous situation and an opportunity for learning a reﬁned world model.\\nI submit that devising learning paradigms and architectures that would allow machines\\nto learn world models in an unsupervised (or self-supervised) fashion, and to use those\\nmodels to predict, to reason, and to plan is one of the main challenges of AI and ML today.\\nOne major technical hurdle is how to devise trainable world models that can deal with\\ncomplex uncertainty in the predictions.\\n2.2 Humans and Animals learn Hierarchies of Models\\nHumans and non-human animals learn basic knowledge about how the world works in the\\nﬁrst days, weeks, and months of life. Although enormous quantities of such knowledge are\\nacquired quite quickly, the knowledge seems so basic that we take it for granted. In the\\nﬁrst few months of life, we learn that the world is three-dimensional. We learn that every\\n3'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 3, 'page_label': '4'}, page_content='Perception Production\\nPhysics\\nActions\\nObjects\\n0 1 2 3 4 5 6 7 8 9 10 11 12 13 14\\nAge (months)\\nstability,\\nsupport\\ngravity, iner�a\\nconserva�on of\\nmomentum\\nObject permanence\\nsolidity, rigidity\\nshape\\nconstancy\\ncrawling walking\\nemo�onal contagion\\nra�onal, goal-\\ndirected ac�ons\\nface tracking\\nproto-imita�on\\npoin�ng\\nbiological\\nmo�on\\nfalse perceptual\\nbeliefs\\nhelping vs\\nhindering\\nnatural kind categories\\nSocial\\nCommunication\\nFigure 1: This chart, (courtesy of Emmanuel Dupoux), indicates at what age infants generally\\nacquire various concepts about how the world works. It is consistent with the idea that abstract\\nconcepts, such as the fact that objects are subject to gravity and inertia, are acquired on top of less\\nabstract concepts, like object permanence and the assignment of objects to broad categories. Much\\nof this knowledge is acquired mostly by observation, with very little direct intervention, particularly\\nin the ﬁrst few weeks and months.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 3, 'page_label': '4'}, page_content='of this knowledge is acquired mostly by observation, with very little direct intervention, particularly\\nin the ﬁrst few weeks and months.\\nsource of light, sound, and touch in the world has a distance from us. The fact that every\\npoint in a visual percept has a distance is the best way to explain how our view of the\\nworld changes from our left eye to our right eye, or when our head is being moved. Parallax\\nmotion makes depth obvious, which in turn makes the notion of object obvious, as well\\nas the fact that objects can occlude more distant ones. Once the existence of objects is\\nestablished, they can be automatically assigned to broad categories as a function of their\\nappearance or behavior. On top of the notion of object comes the knowledge that objects\\ndo not spontaneously appear, disappear, change shape, or teleport: they move smoothly\\nand can only be in one place at any one time. Once such concepts are acquired, it becomes'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 3, 'page_label': '4'}, page_content='do not spontaneously appear, disappear, change shape, or teleport: they move smoothly\\nand can only be in one place at any one time. Once such concepts are acquired, it becomes\\neasy to learn that some objects are static, some have predictable trajectories (inanimate\\nobjects), some behave in somewhat unpredictable ways (collective phenomena like water,\\nsand, tree leaves in the wind, etc), and some seem to obey diﬀerent rules (animate objects).\\nNotions of intuitive physics such as stability, gravity, inertia, and others can emerge on top\\nof that. The eﬀect of animate objects on the world (including the eﬀects of the subject’s\\nown actions) can be used to deduce cause-and-eﬀect relationships, on top of which linguistic\\nand social knowledge can be acquired.\\nFigure 1, courtesy of Emmanuel Dupoux, shows at what age infants seem to acquire\\nbasic concepts such as object permanence, basic categories, intuitive physics, etc. Concepts'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 3, 'page_label': '4'}, page_content='Figure 1, courtesy of Emmanuel Dupoux, shows at what age infants seem to acquire\\nbasic concepts such as object permanence, basic categories, intuitive physics, etc. Concepts\\nat higher levels of abstraction seem to develop on top of lower-level ones.\\nEquipped with this knowledge of the world, combined with simple hard-wired behav-\\niors and intrinsic motivations/objectives, animals can quickly learn new tasks, predict the\\n4'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 4, 'page_label': '5'}, page_content='consequences of their actions and plan ahead, foreseeing successful courses of actions and\\navoiding dangerous situations.\\nBut can a human or animal brain contain all the world models that are necessary for\\nsurvival? One hypothesis in this paper is that animals and humans have only one world\\nmodel engine somewhere in their prefrontal cortex. That world model engine is dynamically\\nconﬁgurable for the task at hand. With a single, conﬁgurable world model engine, rather\\nthan a separate model for every situation, knowledge about how the world works may\\nbe shared across tasks. This may enable reasoning by analogy, by applying the model\\nconﬁgured for one situation to another situation.\\nTo make things concrete, I will directly dive into a description of the proposed model.\\n5'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 5, 'page_label': '6'}, page_content='percept\\naction\\nActor\\nWorld Model\\nIntrinsic\\ncost\\nPerception\\nShort-term\\nmemory\\nconfigurator\\nCritic\\nCost\\nFigure 2: A system architecture for autonomous intelligence. All modules in this model are as-\\nsumed to be “diﬀerentiable”, in that a module feeding into another one (through an arrow connecting\\nthem) can get gradient estimates of the cost’s scalar output with respect to its own output.\\nThe conﬁgurator module takes inputs (not represented for clarity) from all other modules and\\nconﬁgures them to perform the task at hand.\\nThe perception module estimates the current state of the world.\\nThe world model module predicts possible future world states as a function of imagined actions\\nsequences proposed by the actor.\\nThe cost module computes a single scalar output called “energy” that measures the level of dis-\\ncomfort of the agent. It is composed of two sub-modules, the intrinsic cost, which is immutable (not'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 5, 'page_label': '6'}, page_content='The cost module computes a single scalar output called “energy” that measures the level of dis-\\ncomfort of the agent. It is composed of two sub-modules, the intrinsic cost, which is immutable (not\\ntrainable) and computes the immediate energy of the current state (pain, pleasure, hunger, etc), and\\nthe critic, a trainable module that predicts future values of the intrinsic cost.\\nThe short-term memory module keeps track of the current and predicted world states and as-\\nsociated intrinsic costs.\\nThe actor module computes proposals for action sequences. The world model and the critic com-\\npute the possible resulting outcomes. The actor can ﬁnd an optimal action sequence that minimizes\\nthe estimated future cost, and output the ﬁrst action in the optimal sequence.\\nSee Section 3 for details.\\n6'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 6, 'page_label': '7'}, page_content='3 A Model Architecture for Autonomous Intelligence\\nThe proposed architecture for autonomous intelligent agents is depicted in Figure 2.\\nIt is composed of a number of modules whose functions are described below. Some\\nof the modules are conﬁgurable on the ﬂy, i.e. their precise function is determined by the\\nconﬁgurator module. The role of the conﬁgurator is executive control: given a task to be\\nexecuted, it pre-conﬁgures the perception, the world model, the cost and the actor for the\\ntask at hand. The conﬁgurator modulates the parameters of the modules it feeds into.\\nThe conﬁgurator module takes input from all other modules and conﬁgures them for\\nthe task at hand by modulating their parameters and their attention circuits. In particular,\\nthe conﬁgurator may prime the perception, world model, and cost modules to fulﬁll a\\nparticular goal.\\nThe perception module receives signals from sensors and estimates the current state'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 6, 'page_label': '7'}, page_content='the conﬁgurator may prime the perception, world model, and cost modules to fulﬁll a\\nparticular goal.\\nThe perception module receives signals from sensors and estimates the current state\\nof the world. For a given task, only a small subset of the perceived state of the world\\nis relevant and useful. The perception module may represent the state of the world in\\na hierarchical fashion, with multiple levels of abstraction. The conﬁgurator primes the\\nperception system to extract the relevant information from the percept for the task at\\nhand.\\nThe world model module constitutes the most complex piece of the architecture. Its\\nrole is twofold: (1) estimate missing information about the state of the world not provided\\nby perception, (2) predict plausible future states of the world. The world model may predict\\nnatural evolutions of the world, or may predict future world states resulting from a sequence\\nof actions proposed by the actor module. The world model may predict multiple plausible'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 6, 'page_label': '7'}, page_content='natural evolutions of the world, or may predict future world states resulting from a sequence\\nof actions proposed by the actor module. The world model may predict multiple plausible\\nworld states, parameterized by latent variables that represent the uncertainty about the\\nworld state. The world model is a kind of “simulator” of the relevant aspects of world.\\nWhat aspects of the world state is relevant depends on the task at hand. The conﬁgurator\\nconﬁgures the world model to handle the situation at hand. The predictions are performed\\nwithin an abstract representation space that contains information relevant to the task at\\nhand. Ideally, the world model would manipulate representations of the world state at\\nmultiple levels of abstraction, allowing it to predict over multiple time scales.\\nA key issue is that the world model must be able to represent multiple possible predic-\\ntions of the world state. The natural world is not completely predictable. This is particularly'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 6, 'page_label': '7'}, page_content='A key issue is that the world model must be able to represent multiple possible predic-\\ntions of the world state. The natural world is not completely predictable. This is particularly\\ntrue if it contains other intelligent agents that are potentially adversarial. But it is often\\ntrue even when the world only contains inanimate objects whose behavior is chaotic, or\\nwhose state is not fully observable.\\nThere are two essential questions to answer when building the proposed architectures:\\n(1) How to allow the world model to make multiple plausible prediction and represent\\nuncertainty in the predictions, and (2) how to train the world model.\\nThe cost module measures the level of “discomfort” of the agent, in the form of a\\nscalar quantity called the energy. The energy is the sum of two energy terms computed by\\ntwo sub-modules: the Intrinsic Cost module and the Trainable Critic module. The overall\\nobjective of the agent is to take actions so as to remain in states that minimize the average'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 6, 'page_label': '7'}, page_content='two sub-modules: the Intrinsic Cost module and the Trainable Critic module. The overall\\nobjective of the agent is to take actions so as to remain in states that minimize the average\\nenergy.\\nThe Intrinsic Cost module is hard-wired (immutable, non trainable) and computes a\\nsingle scalar, the intrinsic energy that measures the instantaneous “discomfort” of the agent\\n7'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 7, 'page_label': '8'}, page_content='– think pain (high intrinsic energy), pleasure (low or negative intrinsic energy), hunger, etc.\\nThe input to the module is the current state of the world, produced by the perception\\nmodule, or potential future states predicted by the world model. The ultimate goal of the\\nagent is minimize the intrinsic cost over the long run . This is where basic behavioral drives\\nand intrinsic motivations reside. The design of the intrinsic cost module determines the\\nnature of the agent’s behavior. Basic drives can be hard-wired in this module. This may\\ninclude feeling “good” (low energy) when standing up to motivate a legged robot to walk,\\nwhen inﬂuencing the state of the world to motivate agency, when interacting with humans\\nto motivate social behavior, when perceiving joy in nearby humans to motivate empathy,\\nwhen having a full energy supplies (hunger/satiety), when experiencing a new situation to\\nmotivate curiosity and exploration, when fulﬁlling a particular program, etc. Conversely, the'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 7, 'page_label': '8'}, page_content='when having a full energy supplies (hunger/satiety), when experiencing a new situation to\\nmotivate curiosity and exploration, when fulﬁlling a particular program, etc. Conversely, the\\nenergy would be high when facing a painful situation or an easily-recognizable dangerous\\nsituation (proximity to extreme heat, ﬁre, etc), or when wielding dangerous tools. The\\nintrinsic cost module may be modulated by the conﬁgurator, to drive diﬀerent behavior at\\ndiﬀerent times.\\nThe Trainable Critic module predicts an estimate of future intrinsic energies. Like the\\nintrinsic cost, its input is either the current state of the world or possible states predicted by\\nthe world model. For training, the critic retrieves past states and subsequent intrinsic costs\\nstored in the associative memory module, and trains itself to predict the latter from the\\nformer. The function of the critic module can be dynamically conﬁgured by the conﬁgurator'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 7, 'page_label': '8'}, page_content='stored in the associative memory module, and trains itself to predict the latter from the\\nformer. The function of the critic module can be dynamically conﬁgured by the conﬁgurator\\nto direct the system towards a particular sub-goal, as part of a bigger task.\\nBecause both sub-modules of the cost module are diﬀerentiable, the gradient of the\\nenergy can be back-propagated through the other modules, particularly the world model,\\nthe actor and the perception, for planning, reasoning, and learning.\\nThe short-term memory modulestores relevant information about the past, current,\\nand future states of the world, as well as the corresponding value of the intrinsic cost.\\nThe world model accesses and updates the short-term memory while temporally predicting\\nfuture (or past) states of the world, and while spatially completing missing information or\\ncorrecting inconsistent information about the current world state. The world model can'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 7, 'page_label': '8'}, page_content='future (or past) states of the world, and while spatially completing missing information or\\ncorrecting inconsistent information about the current world state. The world model can\\nsend queries to the short-term memory and receive retrieved values, or store new values of\\nstates. The critic module can be trained by retrieving past states and associated intrinsic\\ncosts from the memory. The architecture may be similar to that of Key-Value Memory\\nNetworks (Miller et al., 2016) This module can be seen as playing some of same roles as the\\nhippocampus in vertebrates.\\nThe actor module computes proposals for sequences of actions and outputs actions to\\nthe eﬀectors. The actor proposes a sequence of actions to the world model. The world model\\npredicts future world state sequences from the action sequence, and feeds it to the cost.\\nGiven a goal deﬁned by the cost (as conﬁgured by the conﬁgurator), the cost computes the'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 7, 'page_label': '8'}, page_content='predicts future world state sequences from the action sequence, and feeds it to the cost.\\nGiven a goal deﬁned by the cost (as conﬁgured by the conﬁgurator), the cost computes the\\nestimated future energy associated with the proposed action sequence. Since the actor has\\naccess to the gradient of the estimated cost with respect to the proposed action sequence, it\\ncan compute an optimal action sequence that minimizes the estimated cost using gradient-\\nbased methods. If the action space is discrete, dynamic programming may be used to\\nﬁnd an optimal action sequence. Once the optimization is completed, the actor outputs\\nthe ﬁrst action (or a short sequence of actions) to the eﬀectors. This process is akin to\\nmodel-predictive control in optimal control (Bryson and Ho, 1969).\\n8'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 8, 'page_label': '9'}, page_content='Pred(s,a)\\nC(s[1])\\ns[1]\\naction\\ns[0]\\nActor\\nA(s)\\na[0]\\nC(s[0])\\nFigure 3: Mode-1 perception-action episode. The perception module estimates the state of the\\nworld s[0] = Enc(x). The actor directly computes an action, or a short sequence of actions, through\\na policy module a[0] = A(s[0]).\\nThis reactive process does not make use of the world model nor of the cost. The cost module computes\\nthe energy of the initial state f[0] = C(s[0]) and stores the pairs (s[0],f[0]) in the short-term memory.\\nOptionally, it may also predict the next state using the world model s[1] = Pred(s[0],a[0]), and the\\nassociated energy f[0] = C(s[0]) so that the world model can be adjusted once the next observation\\nresulting from the action taken becomes available.\\nThe actor may comprise two components: (1) a policy module that directly produces\\nan action from the world state estimate produced by the perception and retrieved from the'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 8, 'page_label': '9'}, page_content='The actor may comprise two components: (1) a policy module that directly produces\\nan action from the world state estimate produced by the perception and retrieved from the\\nshort-term memory, and (2) the action optimizer, as described above, for model-predictive\\ncontrol. The ﬁrst mode is similar to Daniel Kahneman’s “System 1”, while the second mode\\nis similar to “System 2” (Kahneman, 2011)\\nIn the following, we will use speciﬁc symbols to represent various components in archi-\\ntectural diagrams. An brief explanation is given in Appendix 8.3.3.\\n3.1 Typical Perception-Action Loops\\nThere are two possible modes that the model can employ for a perception-action episode.\\nThe ﬁrst one involves no complex reasoning, and produces an action directly from the output\\nof the perception and a possible short-term memory access. We will call it “Mode-1”, by\\nanalogy with Kahneman’s “System 1”. The second mode involves reasoning and planning'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 8, 'page_label': '9'}, page_content='of the perception and a possible short-term memory access. We will call it “Mode-1”, by\\nanalogy with Kahneman’s “System 1”. The second mode involves reasoning and planning\\nthrough the world model and the cost. It is akin to model-predictive control (MPC), a\\nclassical planning and reasoning paradigm in optimal control and robotics. We will call\\nit “Mode-2” by analogy to Kahneman’s “System 2”. We use the term “reasoning” in a\\nbroad sense here to mean constraint satisfaction (or energy minimization). Many types of\\nreasoning can be viewed as forms of energy minimization.\\n3.1.1 Mode-1: Reactive behavior\\nA perception-action episode for Mode-1 is depicted in Figure 3.\\nThe perception module, through an encoder module, extracts a representation of the\\nstate of the world s[0] = Enc( x) containing relevant information for the task at hand. A\\n9'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 9, 'page_label': '10'}, page_content='policy module, a component of the actor, produces an action as a function of the state\\na[0] = A(s[0]). The resulting action is sent to the eﬀectors.\\nThe function of the policy module is modulated by the conﬁgurator, which conﬁgures\\nit for the task at hand.\\nThe policy module implements a purely reactive policy that does not involve delib-\\nerate planning nor prediction through the world model. Yet, its structure can be quite\\nsophisticated. For example, in addition to the state s[0], the policy module may access the\\nshort-term memory to acquire a more complete information about previous world states. It\\nmay use the short-term memory for the associative retrieval of an action given the current\\nstate.\\nWhile the cost module is diﬀerentiable, its output f[0] = C(s[0]) is indirectly inﬂuenced\\nby previous actions through the external world. Since the world is not diﬀerentiable, one\\ncannot back-propagate gradients from the cost through the chain cost ← perception ←'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 9, 'page_label': '10'}, page_content='by previous actions through the external world. Since the world is not diﬀerentiable, one\\ncannot back-propagate gradients from the cost through the chain cost ← perception ←\\nworld ← action. In this mode, gradients of the cost f[0] with respect to actions can only\\nbe estimated by polling the world with multiple perturbed actions, but that is slow and\\npotentially dangerous. This process would correspond to classical policy gradient methods\\nin reinforcement learning.\\nDuring Mode-1, the system can optionally adjust the world model. It runs the world\\nmodel for one step, predicting the next state s[1], then it waits for the next percept resulting\\nfrom the action taken, and uses the observed world state as a target for the predictor.\\nWith the use of a world model, the agent can imagine courses of actions and predict\\ntheir eﬀect and outcome, lessening the need to perform an expensive and dangerous search'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 9, 'page_label': '10'}, page_content='With the use of a world model, the agent can imagine courses of actions and predict\\ntheir eﬀect and outcome, lessening the need to perform an expensive and dangerous search\\nfor good actions and policies by trying multiple actions in the external world and measuring\\nthe result.\\n3.1.2 Mode-2: reasoning and planning using the world model\\nA typical perception-action episode for Mode 2 is depicted in Figure 4.\\n1. perception: the perception system extract a representation of the current state of\\nthe world s[0] = P(x). The cost module computes and stores the immediate cost\\nassociated with that state.\\n2. action proposal: the actor proposes an initial sequence of actions to be fed to the\\nworld model for evaluation ( a[0],...,a[t],...,a[T]).\\n3. simulation: the world model predicts one or several likely sequence of world state\\nrepresentations resulting from the proposed action sequence ( s[1],...,s[t],...,s[T]).'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 9, 'page_label': '10'}, page_content='3. simulation: the world model predicts one or several likely sequence of world state\\nrepresentations resulting from the proposed action sequence ( s[1],...,s[t],...,s[T]).\\n4. evaluation: the cost module estimates a total cost from the predicted state sequence,\\ngenerally as a sum over time steps F(x) = ∑T\\nt=1 C(s[t])\\n5. planning: the actor proposes a new action sequence with lower cost. This can be done\\nthrough a gradient-based procedure in which gradients of the cost are back-propagated\\nthrough the compute graph to the action variables. The resulting minimum-cost\\naction sequence is denoted (ˇa[0],...,ˇa[T]). Full optimization may require iterating\\nsteps 2-5.\\n10'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 10, 'page_label': '11'}, page_content='Pred(s,a)\\nC(s[t])\\n Pred(s,a)\\nC(s[t+1])\\n Pred(s,a)\\nC(s[T-1])\\n Pred(s,a)\\nC(s[T])\\n  \\ns[t] s[t+1]\\naction\\ns[0]\\na[0]\\nActor\\nC(s[0])\\ns[T-1]\\na[t] a[t+1] a[T-1]\\nFigure 4: Mode-2 perception-action episode. The perception module estimates the state of the world\\ns[0]. The actor proposes a sequence of actions a[0],a[1],...,a[t],a[t+ 1],...,a[T]. The world model\\nrecursively predicts an estimate of the world state sequence using s[t+ 1] = Pred(s[t],a[t]). The cost\\nC(s[t]) computes an energy for each predicted state in the sequence, the total energy being the sum\\nof them. Through an optimization or search procedure, the actor infers a sequence of actions that\\nminimizes the total energy. It then sends the ﬁrst action in the sequence (or the ﬁrst few actions)\\nto the eﬀectors. This is, in eﬀect, an instance of classical model-predictive control with receding-\\nhorizon planning. Since the cost and the model are diﬀerentiable, gradient-based methods can be'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 10, 'page_label': '11'}, page_content='to the eﬀectors. This is, in eﬀect, an instance of classical model-predictive control with receding-\\nhorizon planning. Since the cost and the model are diﬀerentiable, gradient-based methods can be\\nused to search for optimal action sequences as in classical optimal control. Since the total energy\\nis additive over time, dynamic programming can also be used, particularly when the action space is\\nsmall and discretized. Pairs of states (computed by the encoder or predicted by the predictor) and\\ncorresponding energies from the intrinsic cost and the trainable critic are stored in the short-term\\nmemory for subsequent training of the critic.\\n6. acting: after converging on a low-cost action sequence, the actor sends the ﬁrst action\\n(or ﬁrst few actions) in the low-cost sequence to the eﬀectors. The entire process is\\nrepeated for the next perception-action episode.\\n7. memory: after every action, the states and associated costs from the intrinsic cost'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 10, 'page_label': '11'}, page_content='repeated for the next perception-action episode.\\n7. memory: after every action, the states and associated costs from the intrinsic cost\\nand the critic are stored in the short-term memory. These pairs can be used later to\\ntrain or adapt the critic.\\nThis procedure is essentially what is known as Model-Predictive Control (MPC) with\\nreceding horizon in the optimal control literature. The diﬀerence with classical optimal\\ncontrol is that the world model and the cost function are learned.\\nIn principle, any form of optimization strategy can be used, for step 5. While gradient-\\nbased optimization methods can be eﬃcient when the world model and cost are well-\\nbehaved, situations in which the action-cost mapping has discontinuities may require to\\nuse other optimization strategies, particularly if the state and/or action spaces can be\\ndiscretized. These strategies include dynamic programming, combinatorial optimization,'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 10, 'page_label': '11'}, page_content='use other optimization strategies, particularly if the state and/or action spaces can be\\ndiscretized. These strategies include dynamic programming, combinatorial optimization,\\nsimulate annealing and other gradient-free methods, heuristic search techniques (e.g. tree\\nsearch with pruning), etc.\\nTo simplify, the process was described in the deterministic case, i.e. when there is no\\nneed to handle the possibility of multiple predictions for s[t+ 1] resulting from a given\\ninitial state s[t] and action a[t]. In real situations, the world is likely to be somewhat\\nunpredictable. Multiple states may result from a single initial state and action due to\\nthe fact that the world is intrinsically stochastic (aleatoric uncertainty), or that the state\\nrepresentation s[t] contains incomplete information about the true world state (epistemic\\nuncertainty), or that the world model’s prediction accuracy is imperfect due to limited\\ntraining data, representational power, or computational constraints.\\n11'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 11, 'page_label': '12'}, page_content='Pred(s,a) Pred(s,a) Pred(s,a)\\nC(s[T])\\ns[t] s[t+1]\\naction\\ns[0]\\na[t] a[T-1]a[0]\\nActor\\n A(s[0])  A(s[t])   A(s[t+1])D D\\nC(s[t]) C(s[t+1])C(s[0])\\nFigure 5: Training a reactive policy module from the result of Mode-2 reasoning. Using Mode-2 is\\nonerous, because it mobilizes all the resources of the agent for the task at hand. It involves running\\nthe world model for multiple time steps repeatedly. This diagram depicts how to train a policy module\\nA(s[t]) to approximate the action that results from Mode-2 optimization. The system ﬁrst operates\\nin Mode-2 and produces an optimal sequence of actions (ˇa[0],...,ˇa[T]). Then the parameters of the\\npolicy module are adjusted to minimize a divergence D(ˇa[t]),A(s[t])) between the optimal action and\\nthe output of the policy module. This results in a policy module that performs amortized inference,\\nand produces an approximation for a good action sequence. The policy module can then be used to'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 11, 'page_label': '12'}, page_content='the output of the policy module. This results in a policy module that performs amortized inference,\\nand produces an approximation for a good action sequence. The policy module can then be used to\\nproduce actions reactively in Mode-1, or to initialize the action sequence prior to Mode-2 inference\\nand thereby accelerate the optimization.\\n3.1.3 From Mode-2 to Mode-1: Learning New Skills\\nUsing Mode-2 is onerous. The agent only possesses one world model “engine”. It is conﬁg-\\nurable by the conﬁgurator for the task at hand, but it can only be used for a single task\\nat a time. Hence, similarly to humans, the agent can only focus on one complex task at a\\ntime.\\nMode-1 is considerably less onerous, since it only requires a single pass through a policy\\nmodule. The agent may possess multiple policy modules working simultaneously, each\\nspecialized for a particular set of tasks.\\nThe process described in Figure 5 shows how a policy module A(s[t]) can be trained'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 11, 'page_label': '12'}, page_content='specialized for a particular set of tasks.\\nThe process described in Figure 5 shows how a policy module A(s[t]) can be trained\\nto produce approximations of the optimal actions resulting from Mode-2 reasoning. The\\nsystem is run on Mode-2, producing an optimal action sequence (ˇ a[0],...,ˇa[t],...,ˇa[T]).\\nThen, the parameters of the policy module A(s[t]) are updated to minimize a divergence\\nmeasure between its output and the optimal action at that time D(ˇa[t],A(s[t])). Once\\nproperly trained, the policy module can be used to directly produce an action in Mode-1\\n˜a[0] = A(s[0]). It can also be used to recursively compute an initial action sequence proposal\\nbefore Mode-2 optimization:\\ns[t+ 1] = Pred(s[t],a[t]) ; ˜ a[t+ 1] = A(s[t+ 1])\\nThe policy module can be seen as performing a form of amortized inference.\\nThis process allows the agent to use the full power of its world model and reasoning\\ncapabilities to acquire new skills that are then “compiled” into a reactive policy module'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 11, 'page_label': '12'}, page_content='This process allows the agent to use the full power of its world model and reasoning\\ncapabilities to acquire new skills that are then “compiled” into a reactive policy module\\nthat no longer requires careful planning.\\n3.1.4 Reasoning as Energy Minimization\\nThe process of elaborating a suitable action sequence in Mode-2 can be seen as a form\\nof reasoning. This form of reasoning is based on simulation using the world model, and\\n12'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 12, 'page_label': '13'}, page_content='TC1(s)\\n s\\n IC1(s)  IC2(s)  ICk(s)... TC2(s) TCl(s)...\\nIntrinsic Cost (IC) Trainable Cost / Critic (TC)\\nFigure 6: Architecture of the cost module. The cost module comprises the intrinsic cost module\\nwhich is immutable ICi(s) (left) and the critic or Trainable Cost TCj(s) (right), which is trainable.\\nBoth IC and TC are composed of multiple submodules whose output energies are linearly combined.\\nEach submodule imparts a particular behavioral drive in the agent. The weights in the linear com-\\nbination, ui and vj, are determined by the conﬁgurator module and allow the agent to focus on\\ndiﬀerent subgoals at diﬀerent times.\\noptimization of the energy with respect to action sequences. More generally, the “actions”\\ncan be seen as latent variables representing abstract transformations from one state to the\\nnext. This type of planning though simulation and optimization may constitute the kind\\nof reasoning that is most frequent in natural intelligence.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 12, 'page_label': '13'}, page_content='next. This type of planning though simulation and optimization may constitute the kind\\nof reasoning that is most frequent in natural intelligence.\\nMany classical forms of reasoning in AI can actually be formulated as optimization\\nproblems (or constraint satisfaction problems). It is certainly the case for the kind of\\nprobabilistic inference performed with factor graphs and probabilistic graphical models.\\nThe proposed architecture is, in fact, a factor graph in which the cost modules are log\\nfactors. But the kind of reasoning that the proposed architecture enables goes beyond\\ntraditional logical and probabilistic reasoning. It allows reasoning by simulation and by\\nanalogy.\\n3.2 The Cost Module as the Driver of Behavior\\nThe overall architecture of the cost module is shown in Figure 6. It is composed of the\\nintrinsic cost module which is immutable IC i(s) and the critic or Trainable Cost TC j(s),\\nwhich is trainable. Both IC and TC are composed of multiple submodules whose output'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 12, 'page_label': '13'}, page_content='intrinsic cost module which is immutable IC i(s) and the critic or Trainable Cost TC j(s),\\nwhich is trainable. Both IC and TC are composed of multiple submodules whose output\\nenergies are linearly combined\\nC(s) = IC( s) + TC(s) (1)\\nIC(s) =\\nk∑\\ni=1\\nuiICi(s) (2)\\n13'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 13, 'page_label': '14'}, page_content='TC(s) =\\nl∑\\nj=1\\nvjTCj(s) (3)\\nEach submodule imparts a particular behavioral drive to the agent. The weights in the\\nlinear combination, ui and vj, are modulated by the conﬁgurator module and allow the\\nagent to focus on diﬀerent subgoals at diﬀerent times.\\nThe intrinsic cost module (IC) is where the basic behavioral nature of the agent is\\ndeﬁned. It is where basic behaviors can be indirectly speciﬁed.\\nFor a robot, these terms would include obvious proprioceptive measurements corre-\\nsponding to “pain”, “hunger”, and “instinctive fears”, measuring such things as external\\nforce overloads, dangerous electrical, chemical, or thermal environments, excessive power\\nconsumption, low levels of energy reserves in the power source, etc.\\nThey may also include basic drives to help the agent learn basic skills or accomplish its\\nmissions. For example, a legged robot may comprise an intrinsic cost to drive it to stand\\nup and walk. This may also include social drives such as seeking the company of humans,'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 13, 'page_label': '14'}, page_content='missions. For example, a legged robot may comprise an intrinsic cost to drive it to stand\\nup and walk. This may also include social drives such as seeking the company of humans,\\nﬁnding interactions with humans and praises from them rewarding, and ﬁnding their pain\\nunpleasant (akin to empathy in social animals). Other intrinsic behavioral drives, such as\\ncuriosity, or taking actions that have an observable impact, may be included to maximize\\nthe diversity of situations with which the world model is trained (Gottlieb et al., 2013)\\nThe IC can be seen as playing a role similar to that of the amygdala in the mammalian\\nbrain and similar structures in other vertebrates.\\nTo prevent a kind of behavioral collapse or an uncontrolled drift towards bad behaviors,\\nthe IC must be immutable and not subject to learning (nor to external modiﬁcations).\\nThe role of the critic (TC) is twofold: (1) to anticipate long-term outcomes with minimal'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 13, 'page_label': '14'}, page_content='the IC must be immutable and not subject to learning (nor to external modiﬁcations).\\nThe role of the critic (TC) is twofold: (1) to anticipate long-term outcomes with minimal\\nuse of the onerous world model, and (2) to allow the conﬁgurator to make the agent focus\\non accomplishing subgoals with a learned cost.\\nIn general, the behavioral nature of an AI agent can be speciﬁed in four ways:\\n1. by explicitly programming a speciﬁc behavior activated when speciﬁc conditions are\\nmet\\n2. by deﬁning an objective function in such a way that the desired behavior is executed\\nby the agent as a result of ﬁnding action sequences that minimize the objective.\\n3. by training the agent to behave a certain way through direct supervision. The agent\\nobserves the actions of an expert teacher, and trains a Mode-1 policy module to\\nreproduce it.\\n4. by training the agent through imitation learning. The agent observes expert teachers,'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 13, 'page_label': '14'}, page_content='observes the actions of an expert teacher, and trains a Mode-1 policy module to\\nreproduce it.\\n4. by training the agent through imitation learning. The agent observes expert teachers,\\nand infers an objective function that their behavior appears to be optimizing when\\nthey act. This produces a critic submodule for Mode-2 behavior. This process is\\nsometimes called inverse reinforcement learning.\\nThe second method is considerably simpler to engineer than the ﬁrst one, because it\\nmerely requires to design an objective, and not design a complete behavior. The second\\nmethod is also more robust: a preordained behavior may be invalidated by unexpected\\nconditions or a changing environment. With an objective, the agent may adapt its behavior\\n14'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 14, 'page_label': '15'}, page_content='... ...\\n ... ...\\nwrite write\\nread read\\nLoss\\nwrite\\nShort-Term\\nAssociative\\nMemory\\nIntrinsic Cost\\nCritic\\nState Sequence\\nFigure 7: Training the critic. During planning episodes, the intrinsic cost module stores triplets\\n(time, state, intrinsic energy): (τ,sτ,IC(sτ)) into the associative short-term memory. During critic\\ntraining episodes, the critic retrieves a past state vectorsτ, together with an intrinsic energy at a later\\ntime IC(sτ+δ). In the simplest scenario, the critic adjusts its parameters to minimize a divergence\\nmeasure between the target IC(stau+δ) and the predicted energy C(sτ). In more complex schemes,\\nit may use combinations of future intrinsic energies as targets. Note that the state sequence may\\ncontain information about the actions planned or taken by the agent.\\nto satisfy the objective despite unexpected conditions and changes in the environment. The\\nsecond method exploits the learning and inference abilities of the agent to minimize the'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 14, 'page_label': '15'}, page_content='to satisfy the objective despite unexpected conditions and changes in the environment. The\\nsecond method exploits the learning and inference abilities of the agent to minimize the\\namount of priors hard-wired by the designer that are likely to be brittle.\\n3.3 Training the Critic\\nAn essential question is how to train the critic.\\nThe principal role of the critic is to predict future values of the intrinsic energy. To do\\nso, it uses the short-term memory module. This module is an associative memory in which\\nthe intrinsic cost module stores triplets (time, state, intrinsic energy): ( τ,sτ,IC(sτ)). The\\nstored states and corresponding intrinsic energies may correspond to a perceived state or to\\na state imagined by the world model during a Mode-2 episode. The memory may retrieve\\na state sτ given a time τ, and may retrieve an energy IC(sτ) given a time τor a state sτ.\\nWith a suitable memory architecture, the retrieval may involve interpolations of keys and'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 14, 'page_label': '15'}, page_content='a state sτ given a time τ, and may retrieve an energy IC(sτ) given a time τor a state sτ.\\nWith a suitable memory architecture, the retrieval may involve interpolations of keys and\\nretrieved values. The process is shown in Figure 7\\nThe critic can be trained to predict future intrinsic energy values by retrieving a past\\nstate vector sτ together with an intrinsic energy at a later time IC( sτ+δ). The parameters\\nof the critic can then be optimized to minimize a prediction loss, for example ||IC(sτ+δ) −\\nTC(sτ)||2. This is a simple scenario. More complex schemes can be devised to predict\\nexpectations of discounted future energies, or distributions thereof. Note that the state\\nvectors may contain information about the actions taken or imagined by the actor.\\nAt a general level, this is similar to critic training methods used in such reinforcement\\nlearning approaches as A2C.\\n15'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 15, 'page_label': '16'}, page_content='The short-term memory can be implemented as the memory module in a key-value\\nmemory network ??: a query vector is compared to a number of key vectors, producing\\na vector of scores. The scores are normalized and used as coeﬃcients to output a linear\\ncombination of the stored values. It can be seen as a “soft” associative memory capable of\\ninterpolation. One advantage of it is that, with a proper allocation scheme of new key/value\\nslots, it is capable of one-shot learning, yet can interpolate between keys and is end-to-end\\ndiﬀerentiable.\\n4 Designing and Training the World Model\\nArguably, designing architectures and training paradigms for the world model constitute\\nthe main obstacles towards real progress in AI over the next decades. One of the main\\ncontributions of the present proposal is precisely a hierarchical architecture and a training\\nprocedure for world models that can represent multiple outcomes in their predictions.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 15, 'page_label': '16'}, page_content='contributions of the present proposal is precisely a hierarchical architecture and a training\\nprocedure for world models that can represent multiple outcomes in their predictions.\\nTraining the world model is a prototypical example of Self-Supervised Learning (SSL),\\nwhose basic idea is pattern completion. The prediction of future inputs (or temporarily\\nunobserved inputs) is a special case of pattern completion. In this work, the primary\\npurpose of the world model is seen as predicting future representations of the state of the\\nworld.\\nThere are three main issues to address. First, quite evidently, the quality of the world\\nmodel will greatly depend on the diversity of state sequences, or triplets of (state, action,\\nresulting state) it is able to observe while training. Second, because the world is not entirely\\npredictable, there may be multiple plausible world state representations that follow a given'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 15, 'page_label': '16'}, page_content='resulting state) it is able to observe while training. Second, because the world is not entirely\\npredictable, there may be multiple plausible world state representations that follow a given\\nworld state representation and an action from the agent. The world model must be able to\\nmeaningfully represent this possibly-inﬁnite collection of plausible predictions. Third, the\\nworld model must be able to make predictions at diﬀerent time scales and diﬀerent levels\\nof abstraction.\\nThe ﬁrst issue touches on one of the main questions surrounding learning for sequential\\ndecision processes: the diversity of the “training set” depends on the actions taken. The\\nissue is discussed in Section 4.10 below.\\nThe second issue is even more dire: the world is not entirely predictable. Hence, the\\nworld model should be able to represent multiple plausible outcomes from a given state and\\n(optionally) an action. This may constitute one of the most diﬃcult challenges to which'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 15, 'page_label': '16'}, page_content='world model should be able to represent multiple plausible outcomes from a given state and\\n(optionally) an action. This may constitute one of the most diﬃcult challenges to which\\nthe present proposal brings a solution. This issue is discussed in Section 4.8 below.\\nThe third issue relates to the problem of long-term prediction and planning. Humans\\nplan complex goals at an abstract level and use high-level descriptions of the world states\\nand actions to make predictions. High-level goals are then decomposed into sequences of\\nmore elementary sequences of subgoals, using shorter-term prediction from the world model\\nto produce lower-level actions. This decomposition process is repeated all the way down\\nto millisecond-by-millisecond muscle control, informed by local conditions. The question of\\nhow world models could represent action plans at multiple time scales and multiple levels\\nof abstraction is discussed in Section 4.6\\n16'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 16, 'page_label': '17'}, page_content='4.1 Self-Supervised Learning\\nSelf-Supervised Learning (SSL) is a paradigm in which a learning system is trained to\\ncapture the mutual dependencies between its inputs. Concretely, this often comes down to\\ntraining a system to tell us if various parts of its input are consistent with each other.\\nFor example, in a video prediction scenario, the system is given two video clips, and\\nmust tell us to what degree the second video clip is a plausible continuation of the ﬁrst one.\\nIn a pattern completion scenario, the system is given part of an input (image, text, audio\\nsignal) together with a proposal for the rest of the input, and tells us whether the proposal\\nis a plausible completion of the ﬁrst part. In the following, we will denote the observed part\\nof the input by x and the possibly-unobserved part by y.\\nImportantly, we do not impose that the model be able to predict y from x. The reason\\nis that there may be an inﬁnite number of y that are compatible with a given x. In a video'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 16, 'page_label': '17'}, page_content='Importantly, we do not impose that the model be able to predict y from x. The reason\\nis that there may be an inﬁnite number of y that are compatible with a given x. In a video\\nprediction setting, there is an inﬁnite number of video clips that are plausible continuations\\nof a given clip. It may be diﬃcult, or intractable, to explicitly represent the set of plausible\\npredictions. But it seems less inconvenient to merely ask the system to tell us if a proposed\\ny is compatible with a given x.\\nA general formulation can be done with the framework of Energy-Based Models (EBM).\\nThe system is a scalar-valued function F(x,y) that produces low energy values when xand\\ny are compatible and higher values when they are not. The concept is depicted in Figure 8.\\nData points are black dots. The energy function produces low energy values around the data\\npoints, and higher energies away from the regions of high data density, as symbolized by the'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 16, 'page_label': '17'}, page_content='Data points are black dots. The energy function produces low energy values around the data\\npoints, and higher energies away from the regions of high data density, as symbolized by the\\ncontour lines of the energy landscape. The EBM implicit function formulation enables the\\nsystem to represent multi-modal dependencies in which multiple values of y are compatible\\nwith a given x. The set of y compatible with a given x may be a single point, multiple\\ndiscrete points, a manifold, or a collection of points and manifolds.\\nTo enable Mode-2 planning, a predictive world model should be trained to capture the\\ndependencies between past and future percepts. It should be able to predict representations\\nof the future from representations of the past and present . The general learning principle\\nis as follows: given two inputs x and y, learn two functions that compute representations\\nsx = gx(x) and sy = gy(y) such that (1) sx and sy are maximally informative about x and'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 16, 'page_label': '17'}, page_content='is as follows: given two inputs x and y, learn two functions that compute representations\\nsx = gx(x) and sy = gy(y) such that (1) sx and sy are maximally informative about x and\\ny and (2) sy can easily be predicted from sx. This principle ensures a trade-oﬀ between\\nmaking the evolution of the world predictable in the representation space, and capturing as\\nmuch information as possible about the world state in the representation.\\nWhat concepts could such an SSL system learn by being trained on video? Our hypoth-\\nesis is that a hierarchy of abstract concepts about how the world works could be acquired.\\nLearning a representation of a small image region such that it is predictable from neigh-\\nboring regions surrounding it in space and time would cause the system to extract local\\nedges and contours in images, and to detect moving contours in videos. Learning a repre-\\nsentation of images such that the representation of a scene from one viewpoint is predictable'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 16, 'page_label': '17'}, page_content='edges and contours in images, and to detect moving contours in videos. Learning a repre-\\nsentation of images such that the representation of a scene from one viewpoint is predictable\\nfrom the representation of the same scene from a slightly diﬀerent viewpoint would cause\\nthe system to implicitly represent a depth map. A depth map is the simplest way to explain\\nhow a view of a scene changes when the camera moves slightly. Once the notion of depth has\\nbeen learned, it would become simple for the system to identify occlusion edges, as well as\\nthe collective motion of regions belonging to a rigid object. An implicit representation of 3D\\n17'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 17, 'page_label': '18'}, page_content='time or space → \\nEnergy\\nFunction\\nx\\nF(x,y)\\ny\\nx\\ny\\nFigure 8: Self-Supervised Learning (SSL) and Energy-Based Models (EBM). SSL is a learning\\nparadigm in which a learning system is trained to “ﬁll in the blanks”, or more precisely to capture the\\ndependencies between observed parts of the input and possibly unobserved parts of the input. Part of\\nthe input signal is observed and denoted x (in pink), and part of the input signal is either observed\\nor unobserved and denoted y (in blue). In a temporal prediction scenario, x represents past and\\npresent observations, and y represent future observations. In a general pattern completion scenario,\\nvarious parts of the input may be observed or unobserved at various times. The learning system is\\ntrained to capture the dependencies between x and y through a scalar-valued energy function F(x,y)\\nthat takes low values when x and y are consistent or compatible, and higher values if x and y are'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 17, 'page_label': '18'}, page_content='trained to capture the dependencies between x and y through a scalar-valued energy function F(x,y)\\nthat takes low values when x and y are consistent or compatible, and higher values if x and y are\\ninconsistent or incompatible. In a video prediction scenario, the system would produce a low energy\\nvalue if a video clip yis a plausible continuation of the video clip x. This energy-based model (EBM)\\nformulation enables the system to represent multi-modal dependencies in which multiple values of y\\n(perhaps an inﬁnite set) may be compatible with a given x. In the right panel, an energy landscape\\nis represented in which dark discs represent data points, and closed lines represents contours (level\\nsets) of the energy function.\\nobjects may spontaneously emerge. Once the notion of object emerges in the representation,\\nconcepts like object permanence may become easy to learn: objects that disappear behind\\nothers due to parallax motion will invariably reappear. The distinction between inanimate'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 17, 'page_label': '18'}, page_content='concepts like object permanence may become easy to learn: objects that disappear behind\\nothers due to parallax motion will invariably reappear. The distinction between inanimate\\nand animate object would follow: inanimate object are those whose trajectories are easily\\npredictable. Intuitive physics concepts such as stability, gravity, momentum, may follow by\\ntraining the system to perform longer-term predictions at the object representation level.\\nOne may imagine that through predictions at increasingly abstract levels of representation\\nand increasingly long time scales, more and more complex concepts about how the world\\nworks may be acquired in a hierarchical fashion.\\nThe idea that abstract concepts can be learned through prediction is an old one, for-\\nmulated in various way by many authors in cognitive science, neuroscience, and AI over\\nseveral decades. The question is how to do it, precisely.\\n18'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 18, 'page_label': '19'}, page_content='Figure 9: Latent-Variable Energy-Based Model (LVEBM).\\nTo evaluate the degree of compatibility betweenxand y, an EBM may need the help of a latent variable\\nz. The latent variable can be seen as parameterizing the set of possible relationships between an x\\nand a set of compatible y. Latent variables represent information about y that cannot be extracted\\nfrom x. For example, if x is a view of an object, and y another view of the same object, z may\\nparameterize the camera displacement between the two views. Inference consists in ﬁnding the latent\\nthat minimizes the energy ˇz = argminz∈Z Ew(x,y,z ). The resulting energy Fw(x,y) = Ew(x,y, ˇz)\\nonly depends on x and y. In the dual view example, inference ﬁnds the camera motion that best\\nexplains how x could be transformed into y.\\n4.2 Handling Uncertainty with Latent Variables\\nAs was pointed out above, one of the main issues is enabling the model to represent mul-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 18, 'page_label': '19'}, page_content='explains how x could be transformed into y.\\n4.2 Handling Uncertainty with Latent Variables\\nAs was pointed out above, one of the main issues is enabling the model to represent mul-\\ntiple predictions. This may require the use of a latent variable. A latent variable is an\\ninput variable whose value is not observed but inferred. A latent variable can be seen as\\nparameterizing the set of possible relationships between an x and a set of compatible y.\\nLatent variables are used to represent information about y that cannot be extracted from\\nx.\\nImagine a scenario in which x is a photo of a scene, and y a photo of the same scene\\nfrom a slightly diﬀerent viewpoint. To tell whether x and y are indeed views from the\\nsame scene, one may need to infer the displacement of the camera between the two views.\\nSimilarly, if x is a picture of a car coming to a fork in the road, and y is a picture of the\\nsame car a few seconds later on one of the branches of the fork, the compatibility between'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 18, 'page_label': '19'}, page_content='Similarly, if x is a picture of a car coming to a fork in the road, and y is a picture of the\\nsame car a few seconds later on one of the branches of the fork, the compatibility between\\nx and y depends on a binary latent variable that can be inferred: did the car turn left or\\nright.\\nIn a temporal prediction scenario, the latent variable represents what cannot be pre-\\ndicted about y (the future) solely from x and from past observations (the past). It should\\ncontain all information that would be useful for the prediction, but is not observable, or\\nnot knowable. I may not know whether the driver in front of me will turn left or right,\\naccelerate or brake, but I can represent those options by a latent variable.\\nA latent-variable EBM (LVEBM) is a parameterized energy function that depends on\\nx, y, and z: Ew(x,y,z ). When presented with a pair ( x,y) the inference procedure of the\\nEBM ﬁnds a value of the latent variable z that minimizes the energy\\nˇz= argmin\\nz∈Z\\nEw(x,y,z ) (4)\\n19'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 19, 'page_label': '20'}, page_content='This latent-variable inference by minimization allows us to eliminate z from the energy\\nfunction:\\nFw(x,y) = min\\nz∈Z\\nEw(x,y,z ) = Ew(x,y, ˇz) (5)\\nTechnically, Fw(x,y) should be called a zero-temperature free energy, but we will continue\\nto call it the energy.\\n4.3 Training Energy-Based Models\\nBefore we discuss EBM training, it is important to note that the deﬁnition of EBM does not\\nmake any reference to probabilistic modeling . Although many EBMs can easily be turned\\ninto probabilistic models, e.g. through a Gibbs distribution, this is not at all a necessity.\\nHence the energy function is viewed as the fundamental object and is not assumed to\\nimplicitly represent the unnormalized logarithm of a probability distribution.\\nTraining an EBM consists in constructing an architecture (e.g. a deep neural network)\\nto compute the energy function Fw(x,y) parameterized with a parameter vector w. The\\ntraining process must seek a w vector that gives the right shape to the energy function.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 19, 'page_label': '20'}, page_content='to compute the energy function Fw(x,y) parameterized with a parameter vector w. The\\ntraining process must seek a w vector that gives the right shape to the energy function.\\nFor a given x from the training set, a well-trained Fw(x,y) will produce lower energies for\\nvalues of ythat are associated with xin the training set, and higher energies to other values\\nof y.\\nGiven a training sample (x,y), training an EBM comes down to devising a suitable loss\\nfunctional L(x,y,F w(x,y)), which can be expressed directly as a function of the parameter\\nvector L(x,y,w ), and such that minimizing this loss will make the energy of the training\\nsample Fw(x,y) lower than the energies Fw(x,ˆy) of any ˆy diﬀerent from y.\\nMaking the energy of the training sample low is easy: it is suﬃcient for the loss to be\\nan increasing function of the energy, and for the energy to have a lower bound.\\nThe diﬃcult question is how to ensure that the energies of ˆy diﬀerent from y are higher'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 19, 'page_label': '20'}, page_content='an increasing function of the energy, and for the energy to have a lower bound.\\nThe diﬃcult question is how to ensure that the energies of ˆy diﬀerent from y are higher\\nthan the energy of y. Without a speciﬁc provision to ensure that Fw(x,y′) > Fw(x,y)\\nwhenever ˆy̸= ythe energy landscape may suﬀer a collapse: given an xthe energy landscape\\ncould become “ﬂat”, giving essentially the same energy to all values of y.\\nWhat EBM architectures are susceptible to collapse? Whether an EBM may be\\nsusceptible to collapse depends on its architecture. Figure 10 shows a number of standard\\narchitectures and indicates whether they can be subject to collapse.\\nA regular predictive or deterministic-generative architecture (Figure 10(a)) cannot col-\\nlapse. For any x, a single ˜yis produced. The energy is zero whenever y= ˜y. Any ydiﬀerent\\nfrom ˜y will have a higher energy, as long as D(y,˜y) is strictly larger than zero whenever y\\nis diﬀerent from ˜y.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 19, 'page_label': '20'}, page_content='from ˜y will have a higher energy, as long as D(y,˜y) is strictly larger than zero whenever y\\nis diﬀerent from ˜y.\\nA generative latent-variable architecture (non-deterministic generative) (Figure 10(b))\\ncan collapse when the latent variable has too much information capacity. When the latent\\nvariable z varies over the set Z, the prediction ˜y varies over a set Pred(sx,Z), which must\\nmatch the set of y that are compatible with x. If Zis too “large” then the region of low-\\nenergy y may be larger than the region of high data density. If z has the same dimension\\nas y, the system could very well give zero energy to the entire y space.\\nAn auto-encoder (AE) (Figure 10(c)) can collapse when the representation sy has too\\nmuch information capacity. For example, if the dimension of sy is equal or higher than that\\n20'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 20, 'page_label': '21'}, page_content='d) Joint Embedding Architecture\\n    CAN COLLAPSE\\nb) Generative latent-variable Architecture\\n    CAN COLLAPSE\\na) Prediction / regression\\n    NO COLLAPSE\\nc) Auto-Encoder\\n    CAN COLLAPSE\\nFigure 10: A few standard architectures and their capacity for collapse.\\n(a) Deterministic generative architecture: cannot collapse because it can only produce a single out-\\nput. For a given x, only one value of y may have zero energy: y = ˜y. Other values of y will have\\nhigher energy if D(u,˜y) is larger than zero when y̸= ˜y.\\n(b) Non-deterministic generative architecture: can collapse when the latent variable has excessive\\ninformation capacity. If for a given x and for all y there exists a z that produces zero prediction\\nenergy (e.g. if z has the same or higher dimension as y), the entire y space will have low energy.\\nThe information capacity of z should be just enough so that varying z over its set will produce all\\nthe plausible ˜y for a given x.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 20, 'page_label': '21'}, page_content='The information capacity of z should be just enough so that varying z over its set will produce all\\nthe plausible ˜y for a given x.\\n(c) Auto-encoder: can collapse if the system learns the identity function or if it can correctly recon-\\nstruct a region of y space that is much larger than the region of high data density, thereby giving low\\nenergy to an overly large region.\\n(d) Simple joint embedding architecture: can collapse if the encoders ignore the inputs and produce\\nrepresentations that remain constant and equal, or if the encoders are invariant over overly broad\\nregions of the space.\\nof y, the AE could learn the identity function, producing a reconstruction error equal to\\nzero over the entire y space.\\nLastly, a Joint Embedding Architecture (JEA) (Figure 10(d)) can collapse when the\\ninformation carried by sx and/or sy are insuﬃcient. If the encoders ignore the inputs, and\\nproduce constant and equal codes sx = sy, the entire space will have zero energy.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 20, 'page_label': '21'}, page_content='information carried by sx and/or sy are insuﬃcient. If the encoders ignore the inputs, and\\nproduce constant and equal codes sx = sy, the entire space will have zero energy.\\nThese are but a few examples of architectures.\\nHow do we design the loss to prevent collapse? There are two approaches:\\ncontrastive methods and regularized methods. In the following, I will argue that contrastive\\nmethods have ﬂaws and that regularized (non contrastive) methods are much more likely\\nto be preferable in the long run.\\nContrastive methods consist in using a loss functional whose minimization has the\\neﬀect of pushing down on the energies of training samples ( x,y), and pulling up on the\\nenergies of suitably-hallucinated “contrastive” samples ( x,ˆy). The contrastive sample ˆ y\\nshould be picked in such a way as to ensure that the EBM assigns higher energies to points\\noutside the regions of high data density. This translates into designing a loss that is an'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 20, 'page_label': '21'}, page_content='should be picked in such a way as to ensure that the EBM assigns higher energies to points\\noutside the regions of high data density. This translates into designing a loss that is an\\nincreasing function of Fw(x,y) and a decreasing function of Fw(x,ˆy), at least whenever\\nFw(x,ˆy) is not suﬃciently higher than Fw(x,y). There are many such contrastive loss\\n21'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 21, 'page_label': '22'}, page_content='Contrastive\\nMethod\\nRegularized\\nMethod\\nLow energy\\nregion\\nTraining\\nsamples\\nContrastive\\nsamples\\nx\\nx\\nx\\ny\\ny\\ny\\nFigure 11: Contrastive and regularized methods for EBM training. A conceptual diagram of an\\nenergy landscape is shown on the left. Training samples are blue dots. The region of low energy is\\nshown in orange (a level set of the energy function).\\nContrastive methods (top right) push down on the energy of training samples (blue dots) and\\npulls up on the energies of suitably-placed contrastive samples (green dots).\\nregularized methods (bottom right) push down on the energy of training samples and use a reg-\\nularizer term that minimizes the volume of low-energy regions. This regularization has the eﬀect of\\n“shrink-wrapping” the regions of high data density within the low-energy regions, to the extent that\\nthe ﬂexibility of the energy function permits it.\\nOne issue with contrastive methods is that the energy will only be pulled up wherever contrastive'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 21, 'page_label': '22'}, page_content='the ﬂexibility of the energy function permits it.\\nOne issue with contrastive methods is that the energy will only be pulled up wherever contrastive\\nsamples have been placed. One must devise methods that preferentially place contrastive samples in\\nregions of low energy, which is what Monte-Carlo and MCMC methods do. However, a disadvantage\\nof contrastive methods is that the number of contrastive samples necessary to make an energy surface\\nadopt a good shape may grow exponentially with the dimension of y space.\\nfunctions, some of them taking a single triplet ( x,y, ˆy), others requiring a batch of positive\\nand contrastive values of y.\\nA simple example of contrastive loss functions is as follows:\\nL(w,x,y, ˆy) = H(Fw(x,y),Fw(x,ˆy),m(y,ˆy)) (6)\\nwhere His an increasing function ofFw(x,y), and a decreasing function ofFw(x,ˆy) whenever\\nthe latter is less than the former plus a positive margin function m(y,ˆy). A simple instance\\nof such loss is the distance-dependent hinge loss:\\nL(w,x,y, ˆy) ='),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 21, 'page_label': '22'}, page_content='the latter is less than the former plus a positive margin function m(y,ˆy). A simple instance\\nof such loss is the distance-dependent hinge loss:\\nL(w,x,y, ˆy) =\\n[\\nFw(x,y) −Fw(x,ˆy) + µ||y−ˆy||2\\n]+\\n(7)\\nwhere [a]+ is the identity when a is positive and zero otherwise. This makes the energy\\ngrow at least quadratically with the distance to the data manifold. Other contrastive loss\\n22'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 22, 'page_label': '23'}, page_content='functionals take multiple contrastive samples into consideration:\\nL(w,x,y, ˆy[1],...,ˆy[K]) = H(Fw(x,y),Fw(x,ˆy[1]),...,Fw(x,ˆy[K])) (8)\\nWhich must be an increasing function of the ﬁrst argument, and a decreasing function of\\nall other arguments. An example of such loss is the popular InfoNCE:\\nL(w,x,y, ˆy[1],...,ˆy[K]) = Fw(x,y) + log\\n[\\nexp(−Fw(x,y)) +\\nK∑\\nk=1\\nexp(−Fw(x,ˆy[k]))\\n]\\n(9)\\nContrastive methods are very popular, particularly for Siamese network architectures\\ntrained with pairs where xis a distorted or corrupted version of yand ˆyanother random (or\\nsuitably chosen) training sample. This includes such methods as the original Siamese net,\\nas well as more recent methods including DrLIM, PIRL, MoCO, SimCLR, CPT, and others.\\nContrastive methods also include such classical methods as probabilistic models trained with\\nmaximum likelihood that are not automatically normalized. Contrastive samples ˆyare often'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 22, 'page_label': '23'}, page_content='Contrastive methods also include such classical methods as probabilistic models trained with\\nmaximum likelihood that are not automatically normalized. Contrastive samples ˆyare often\\nproduced using Monte Carlo methods, Markov-Chain Monte Carlo methods, or approximate\\nversions thereof, such as Contrastive Divergence. Generative Adversarial Networks can also\\nbe seen as contrastive methods in which the ˆ y are produced by the trainable generator\\nnetwork. Denoising Auto-Encoders and their special case, Masked Auto-Encoders, are also\\nexamples of contrastive training methods in which the ˆyis generated by corrupting the clean\\ny. A more detailed discussion of various contrastive methods is given in appendix 8.3.3.\\nBut there are two main issues with contrastive methods. First, one has to design a\\nscheme to generate or pick suitable ˆy. Second, when yis in a high-dimensional space, and if\\nthe EBM is ﬂexible, it may require a very large number of contrastive samples to ensure that'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 22, 'page_label': '23'}, page_content='scheme to generate or pick suitable ˆy. Second, when yis in a high-dimensional space, and if\\nthe EBM is ﬂexible, it may require a very large number of contrastive samples to ensure that\\nthe energy is higher in all dimensions unoccupied by the local data distribution. Because of\\nthe curse of dimensionality, in the worst case, the number of contrastive samples may grow\\nexponentially with the dimension of the representation. This is the main reason why I will\\nargue against contrastive methods.\\nRegularized methods for EBM training are much more promising in the long run\\nthan contrastive methods because they can eschew the curse of dimensionality that plagues\\ncontrastive methods. They consist in constructing a loss functional that has the eﬀect\\nof pushing down on the energies of training samples, and simultaneously minimizing the\\nvolume of y space to which the model associates a low energy . The volume of the low-energy'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 22, 'page_label': '23'}, page_content='of pushing down on the energies of training samples, and simultaneously minimizing the\\nvolume of y space to which the model associates a low energy . The volume of the low-energy\\nregion is measured by a regularization term in the energy and/or in the loss. By minimizing\\nthis regularization term while pushing down on the energies of data points, the regions of\\nlow energy will “shrink-wrap” the regions of high data density. The main advantage of\\nnon-contrastive regularized methods is that they are less likely than contrastive methods\\nto fall victim to the curse of dimensionality. The main question is precisely how to design\\nsuch volume-minimizing regularizers. The answer depends greatly on the architecture of\\nthe model, which is discussed in the next sections. However, non-contrastive methods have\\nexisted for a long time. Examples include sparse modeling, sparse auto-encoders, and auto-\\nencoders with noisy latent variables, such as VAE.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 22, 'page_label': '23'}, page_content='existed for a long time. Examples include sparse modeling, sparse auto-encoders, and auto-\\nencoders with noisy latent variables, such as VAE.\\nIt is important to note that contrastive and regularized methods are not incompatible\\nwith each other, and can be used simultaneously on the same model.\\nHow would regularized methods apply to the architectures of Figure 10(b-d)?\\n23'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 23, 'page_label': '24'}, page_content='In the latent-variable generative architecture, restricting the information capacity of z\\nwill restrict the volume of y space that can take low energy. If z is discrete with possible k\\nvalues, at most k points in y space will have zero energy. if Zis a manifold of dimension d\\nthen the region of y space with zero energy will have at most d dimensions.\\nSimilarly, in the auto-encoder architecture, restricting the information capacity of sy\\nwill restrict the volume of y space that can be reconstructed with low energy.\\nLastly, in the Joint Embedding Architecture, Maximizing the information that sx con-\\ntains about x and sy contains about y will minimize the volume of y space that can take\\nlow energy.\\nIn the following, we will focus on an architecture for SSL the Joint Embedding Predictive\\nArchitectures (JEPA) which can seen as a combination of the Joint Embedding Architecture\\nand the Latent-Variable Generative Architecture. The JEPA is non-generative in that it'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 23, 'page_label': '24'}, page_content='Architectures (JEPA) which can seen as a combination of the Joint Embedding Architecture\\nand the Latent-Variable Generative Architecture. The JEPA is non-generative in that it\\ndoes not actually predict y, but predicts the representation of y, sy from that of x, sx.\\n4.4 Joint Embedding Predictive Architecture (JEPA)\\nThe centerpiece of this paper is the Joint Embedding Predictive Architecture (JEPA). JEPA\\nis not generative in the sense that it cannot easily be used to predict y from x. It merely\\ncapture the dependencies between x and y without explicitly generating predictions of y.\\nA generic JEPA is shown in Figure 12. The two variablesxand yare fed to two encoders\\nproducing two presentations sx and sy. These two encoders may be diﬀerent. They are not\\nrequired to possess the same architecture nor are they required to share their parameters.\\nThis allows x and y to be diﬀerent in nature (e.g. video and audio). A predictor module'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 23, 'page_label': '24'}, page_content='required to possess the same architecture nor are they required to share their parameters.\\nThis allows x and y to be diﬀerent in nature (e.g. video and audio). A predictor module\\npredicts the representation of y from the representation of x. The predictor may depend\\non a latent variable z. The energy is simply the prediction error in representation space:\\nEw(x,y,z ) = D(sy,Pred(sx,z)) (10)\\nThe overall energy is obtained by minimizing over z:\\nˇz = argmin\\nz∈Z\\nEw(x,y,z ) = argmin\\nz∈Z\\nD(sy,Pred(sx,z)) (11)\\nFw(x,y) = min\\nz∈Z\\nEw(x,y,z ) = D(sy,Pred(sx,ˇz)) (12)\\n(13)\\nThe main advantage of JEPA is that it performs predictions in representation space ,\\neschewing the need to predict every detail of y. This is enabled by the fact that the encoder\\nof y may choose to produce an abstract representation from which irrelevant details have\\nbeen eliminated.\\nBut there are two ways a JEPA may represent the multiplicity of values ofy compatible'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 23, 'page_label': '24'}, page_content='of y may choose to produce an abstract representation from which irrelevant details have\\nbeen eliminated.\\nBut there are two ways a JEPA may represent the multiplicity of values ofy compatible\\nwith x. The ﬁrst one is invariance properties of the y encoder, the second one is the latent\\nvariable z, as explained below.\\nmulti-modality through encoder invariance : The encoder function sy = Enc(y)\\nmay have invariance properties. If all the y’s in a set map to the same value of sy, all those\\ny’s will have identical energies. With JEPA, we lose the ability to generate outputs, but we\\ngain a powerful way to represent multi-modal dependencies between inputs and outputs.\\n24'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 24, 'page_label': '25'}, page_content='Figure 12: The Joint-Embedding Predictive Architecture (JEPA) consists of two encoding branches.\\nThe ﬁrst branch computes sx, a representation of x and the second branch sy a representation of y.\\nThe encoders do not need to be identical. A predictor module predicts sy from sx with the possible\\nhelp of a latent variable z. The energy is the prediction error. Simple variations of the JEPA may\\nuse no predictor, forcing the two representations to be equal, or may use a ﬁxed predictor with no\\nlatent, or may use simple latents such as discrete variables.\\nThe main advantage of JEPA is that it performs predictions in representation space, eschewing the\\nneed to predict every detail of y, and enabling the elimination of irrelevant details by the encoders.\\nMore precisely, the main advantage of this architecture for representing multi-modal dependencies is\\ntwofold: (1) the encoder function sy = Enc(y) may possess invariance properties that will make it'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 24, 'page_label': '25'}, page_content='More precisely, the main advantage of this architecture for representing multi-modal dependencies is\\ntwofold: (1) the encoder function sy = Enc(y) may possess invariance properties that will make it\\nproduce the same sy for a set of diﬀerent y. This makes the energy constant over this set and allows\\nthe model to capture complex multi-modal dependencies; (2) The latent variable z, when varied over\\na set Z, can produce a set of plausible predictions Pred(sx,Z) = {˜sy = Pred(sx,z) ∀z∈Z}\\nIf x is a video clip of a car approaching a fork in the road, sx and sy may represent the position,\\norientation, velocity and other characteristics of the car before and after the fork, respectively, ig-\\nnoring irrelevant details such as the trees bordering the road or the texture of the sidewalk. z may\\nrepresent whether the car takes the left branch or the right branch of the road.\\nmulti-modality through latent variable predictor: The predictor may use a latent'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 24, 'page_label': '25'}, page_content='represent whether the car takes the left branch or the right branch of the road.\\nmulti-modality through latent variable predictor: The predictor may use a latent\\nvariable zto capture the information necessary to predict sy that is not present in sx. When\\nz is varied over a set Z, the predictor produces a set of plausible predictions Pred( sx,Z) =\\n{˜sy = Pred(sx,z) ∀z ∈Z}. For example, if x is a video clip of a car approaching a fork\\nin the road, sx and sy may represent the past and future positions, orientations, velocities\\nand other characteristics of the car, ignoring irrelevant details such as the trees bordering\\nthe road or the texture of the sidewalk. The latent z may be a binary variable indicating\\nwhether the car takes the left branch ( z = 0) or the right branch ( z = 1 if the road. If the\\ncar takes the left branch, the value z= 0 will produce a lower energy D(sy,˜sy) than z= 1.\\n4.5 Training a JEPA'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 24, 'page_label': '25'}, page_content='car takes the left branch, the value z= 0 will produce a lower energy D(sy,˜sy) than z= 1.\\n4.5 Training a JEPA\\nLike any EBM, a JEPA can be trained with contrastive methods. But, as pointed out\\nabove, contrastive methods tend to become very ineﬃcient in high dimension. The relevant\\n25'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 25, 'page_label': '26'}, page_content='Maximize\\nInformation\\nContent\\nMaximize\\nInformation\\nContent\\nMinimize\\nInformation\\nContent\\nMinimize\\nPrediction\\nError\\nFigure 13: Non-contrastive training of JEPA.\\nThe main attraction of JEPAs is that they can be trained with non-contrastive methods. The basic\\nprinciple of such training is that (1) sx should be maximally informative about x; (2) sy should\\nbe maximally informative about y; (3) sy should be easily predictable from sx; and (4) z should\\nhave minimal information content. Criteria 1, 2, and 4 collectively prevent a collapse of the energy\\nfunction.\\nExamples of such non-contrastive criteria for JEPA training include VICReg and Barlow Twins.\\nAs with every EBM, JEPAs can also be trained with contrastive methods. But doing so runs into\\nthe curse of dimensionality and limits the practical dimension of sy.\\ndimension here is that of sy, which may be considerably smaller than y, but still too high\\nfor eﬃcient training.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 25, 'page_label': '26'}, page_content='the curse of dimensionality and limits the practical dimension of sy.\\ndimension here is that of sy, which may be considerably smaller than y, but still too high\\nfor eﬃcient training.\\nWhat makes JEPAs particularly interesting is that we can devise non-contrastive meth-\\nods to train them. As explained in section 4.3, non-contrastive methods use regularizers\\nthat measure the volume of space that can take low energy values. In the case of the JEPA,\\nthis can be done through four criteria, as depicted in Figure 13:\\n1. maximize the information content of sx about x\\n2. maximize the information content of sy about y\\n3. make sy easily predictable from sx\\n4. minimize the information content of the latent variable z used in the prediction.\\nCriteria 1 and 2 prevent the energy surface from becoming ﬂat by informational col-\\nlapse. They ensure that sx and sy carry as much information as possible about their inputs.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 25, 'page_label': '26'}, page_content='Criteria 1 and 2 prevent the energy surface from becoming ﬂat by informational col-\\nlapse. They ensure that sx and sy carry as much information as possible about their inputs.\\nWithout these criteria the system could choose to make sx and sy constant, or weakly in-\\nformative, which would make the energy constant over large swaths of the input space.\\nCriterion 3 is enforced by the energy term D(sy,˜sy) and ensures that yis predictable from\\nx in representation space.\\nCriterion 4 prevents the system from falling victim to another type of informational col-\\nlapse by forcing the model to predict sy with as little help from the latent as possible. This\\n26'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 26, 'page_label': '27'}, page_content='type of collapse can be understood with the following thought experiment. Imagine that\\nz has the same dimension as sy. Assume that the predictor is a parameterized function\\n(e.g. a neural net) that can choose to ignore sx and to simply copy z on its output ˜sy = z.\\nFor any sy it is possible to set ˇz = sy, which would make the energy D(sy,˜sy) zero. This\\ncorresponds to a totally ﬂat and collapsed energy surface.\\nHow do we prevent this collapse from happening?\\nBy limiting or minimizing the information content of the latent variable.\\nHow can this be done?\\nBy making z discrete, low-dimensional, sparse, or noisy, among other methods.\\nA few concrete examples may help build an intuitive understanding of the phenomenon.\\nSuppose that D(sy,˜sy) = ||sy −˜sy||2 and that z is discrete with K possible integer values\\n[0,K −1]. For a given x, there can be only K possible values of ˜sy:\\nPred(sx,0),Pred(sx,1),...,Pred(sx,K −1).'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 26, 'page_label': '27'}, page_content='[0,K −1]. For a given x, there can be only K possible values of ˜sy:\\nPred(sx,0),Pred(sx,1),...,Pred(sx,K −1).\\nHence, these can be the only values of sy with zero energy, and there are only K of them.\\nConsider a point sy that starts from Pred(sx,0) and moves towards Pred(sx,1). Its energy\\nwill start from zero, increase quadratically as sy moves away from Pred( sx,0), until sy.\\nWhen sy becomes closer to Pred(sx,1) than to Pred(sx,0), the energy will decrease, reaching\\nzero when sy reaches Pred(sx,1). In representation space, the energy will be the minimum\\nof K quadratic energy wells.\\nSimilarly, imagine that z is a vector whose dimension d is lower than that of ˜sy. Then,\\nassuming that Pred( sx,z) is a smooth function of z, the set of possible predictions will be\\nat most a d-dimensional manifold in the space of sy.\\nMore to the point, imagine that the energy function is augmented by a regularization\\nterm on zof the form R(z) = α∑d'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 26, 'page_label': '27'}, page_content='at most a d-dimensional manifold in the space of sy.\\nMore to the point, imagine that the energy function is augmented by a regularization\\nterm on zof the form R(z) = α∑d\\ni=1 |zi|, i.e. the L1 norm of z. This will drive ˇzto be sparse.\\nAs with classical sparse coding, this will cause the region of low energy to be approximated\\nby a union of low-dimensional manifolds (a union of low-dimensional linear subspaces if\\nPred(sx,z) is linear in z), whose dimension will be minimized by the L1 regularizer.\\nMaking z a stochastic sample from a distribution whose entropy is maximized will also\\nhave a proper regularization eﬀect. This is the basis of Variational Auto-Encoders and\\nsimilar models.\\nA more complete discussion of regularizers that can minimize the information content\\nof latent variables is beyond the scope of this paper. For now, we can mention four classes\\nof methods: discretization/quantiﬁcation (e.g. as in VQ-VAE (Walker et al., 2021), dimen-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 26, 'page_label': '27'}, page_content='of latent variables is beyond the scope of this paper. For now, we can mention four classes\\nof methods: discretization/quantiﬁcation (e.g. as in VQ-VAE (Walker et al., 2021), dimen-\\nsionality/rank minimization (e.g. as in Implicit Rank-Minimizing AE (Jing et al., 2020),\\nsparsiﬁcation (as in linear sparse modeling (Olshausen and Field, 1996), LISTA (Gregor\\nand LeCun, 2010b), and non-linear sparse modeling (Evtimova and LeCun, 2022)), and\\nfuzzyﬁcation (as in noisy AE (Doi et al., 2007), VAE (Kingma and Welling, 2013), and\\nvariants used in control problems (Henaﬀ et al., 2019)).\\nThe ability of the JEPA to predict in representation space makes it considerably prefer-\\nable to generative models that directly produce a prediction of y. In a video prediction\\nscenario, it is essentially impossible to predict every pixel value of every future frame. The\\ndetails of the texture on a carpet, the leaves of a tree moving in the wind, or the ripples on'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 26, 'page_label': '27'}, page_content='scenario, it is essentially impossible to predict every pixel value of every future frame. The\\ndetails of the texture on a carpet, the leaves of a tree moving in the wind, or the ripples on\\na pond, cannot be predicted accurately, at least not over long time periods and not without\\nconsuming enormous resources. A considerable advantage of JEPA is that it can choose to\\n27'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 27, 'page_label': '28'}, page_content='Figure 14: Training a JEPA with VICReg.\\nVICReg is a non sample-contrastive method for training embeddings. The information content of the\\nrepresentations sx and sy is maximized by ﬁrst mapping them to higher-dimensional embeddings vx\\nand vy through an expander (e.g. a trainable neural net with a few layers). The loss function drives\\nthe covariance matrix of the embeddings towards the identity (e.g. computed over a batch).\\nVICReg can be seen as a dimension-contrastive method as opposed to sample-contrastive methods.\\nignore details of the inputs that are not easily predictable . Yet, Criteria 1 and 2 will ensure\\nthat the information content of the ignored details are kept to a minimum.\\nHow can we implement Criteria 1 and 2?\\nIn other words, given a parameterized deterministic encoding function sy = Encw(y), how\\ndo we maximize the information content of sy?\\nIf Enc w(y) is invertible, sy contains all the information about y, but that may be sub-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 27, 'page_label': '28'}, page_content='do we maximize the information content of sy?\\nIf Enc w(y) is invertible, sy contains all the information about y, but that may be sub-\\noptimal for Criterion 3, as sy will contain many irrelevant or hard-to-predict details about\\ny. More precisely, sy is maximally informative about y if the function Encw(y) is minimally\\nsurjective, i.e. if the volume of sets of y that map to the same sy is minimal. The same\\nreasoning applies to the xencoder. To turn this criterion into a diﬀerentiable loss, we need\\nto make some assumptions.\\n4.5.1 VICReg\\nThe VICReg method (Bardes et al., 2021) makes a few assumptions about the distributions\\nof sx and sy. A graphical representation is shown in Figure 14. To maximize the information\\ncontent of sx, VICReg uses the following two sub-criteria: (1) the components ofsx must not\\nbe constant, (2) the components ofsx must be as independent of each other as possible. This\\nis approximated by ﬁrst non-linearly mapping sx and sy to higher-dimensional embeddings'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 27, 'page_label': '28'}, page_content='be constant, (2) the components ofsx must be as independent of each other as possible. This\\nis approximated by ﬁrst non-linearly mapping sx and sy to higher-dimensional embeddings\\nvx and vy through a trainable expander module (e.g. a neural net with a few layers), and\\nusing a loss function with two diﬀerentiable loss terms computed over a batch of samples:\\n28'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 28, 'page_label': '29'}, page_content='1. Variance: a hinge loss that maintains the standard deviation of each component of\\nsy and vy above a threshold over a batch.\\n2. Covariance: a covariance loss in which the covariance between pairs of diﬀerent\\ncomponents of vy are pushed towards zero. This has the eﬀect of decorrelating the\\ncomponents of vy, which will in turn make the components of sy somewhat indepen-\\ndent.\\nThe same criteria are applied to sx and vx separately.\\nThe third criterion of VICReg is the representation prediction error D(sy,˜sy). In the\\nsimplest implementations of VICReg, the predictor is constant (equal to the identity func-\\ntion), making the representations invariant to the transformation that turns x into y. In\\nmore sophisticated versions, the predictor may have no latent variable, or may depend on\\na latent variable that is either discrete, low dimensional, or stochastic.\\nThe fourth criterion is necessary when the predictor uses a latent variable whose infor-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 28, 'page_label': '29'}, page_content='a latent variable that is either discrete, low dimensional, or stochastic.\\nThe fourth criterion is necessary when the predictor uses a latent variable whose infor-\\nmation content must be minimized, for example a vector whose dimension approaches or\\nsurpasses that of ˜sy.\\nA simple instantiation of VICReg to learn invariant representations consists in making\\nxand y be diﬀerent views (or distorted versions) of the same content, setting the predictor\\nto the identity function, and deﬁning D(sy,˜sy) = D(sy,sx) = ||sy −sx||2.\\nInferring the latent variable through gradient-based methods may be onerous. But the\\ncomputational cost can be greatly reduced by using amortized inference, as explained in\\nAppendix 8.3.3.\\nWhile contrastive methods ensure that representations of diﬀerent inputs in a batch\\nare diﬀerent, VICReg ensures that diﬀerent components of representations over a batch are\\ndiﬀerent. VICReg is contrastive over components, while traditional contrastive methods'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 28, 'page_label': '29'}, page_content='are diﬀerent, VICReg ensures that diﬀerent components of representations over a batch are\\ndiﬀerent. VICReg is contrastive over components, while traditional contrastive methods\\nare contrastive over vectors, which requires a large number of contrastive samples.\\nBut the most promising aspect of JEPA trained with VICReg and similar non-contrastive\\nmethods is for learning hierarchical predictive world models, as we examine in the next sec-\\ntion.\\n4.5.2 Biasing a JEPA towards learning “useful” representations\\nWith the training criteria listed above, the JEPA ﬁnds a trade-oﬀ between the completeness\\nand the predictability of the representations. What is predictable and what does not get\\nrepresented is determined implicitly by the architectures of the encoders and predictor.\\nThey determine a inductive bias that deﬁnes what information is predictable or not.\\nBut it would be useful to have a way to bias the system towards representations that'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 28, 'page_label': '29'}, page_content='They determine a inductive bias that deﬁnes what information is predictable or not.\\nBut it would be useful to have a way to bias the system towards representations that\\ncontain information relevant to a class of tasks. This can be done by adding prediction\\nheads that take ˜sy as input and are trained to predict variables that are easily derived from\\nthe data and known to be relevant to the task.\\n4.6 Hierarchical JEPA (H-JEPA)\\nJEPA models trained non-contrastively may constitute our best tool for learning world\\nmodels that are able to learn relevant abstractions. When trained with VICReg and similar\\n29'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 29, 'page_label': '30'}, page_content='x y\\nJEPA-1\\nJEPA-2\\nFigure 15: Hierarchical JEPA (H-JEPA)\\nThe ability of the JEPA to learn abstract representations in which accurate prediction can be per-\\nformed allows hierarchical stacking. In this diagram JEPA-1 extracts low-level representations and\\nperforms short-term predictions. JEPA-2 takes the representations extracted by JEPA-1 as inputs\\nand extracts higher-level representations with which longer-term predictions can be performed. More\\nabstract representations ignore details of the inputs that are diﬃcult to predict in the long term,\\nenabling them to perform longer-term predictions with coarser descriptions of the world state.\\ncriteria, a JEPA can choose to train its encoders to eliminate irrelevant details of the inputs\\nso as to make the representations more predictable. In other words, a JEPA will learn\\nabstract representations that make the world predictable. Unpredictable details will be'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 29, 'page_label': '30'}, page_content='so as to make the representations more predictable. In other words, a JEPA will learn\\nabstract representations that make the world predictable. Unpredictable details will be\\neliminated by the invariance properties of the encoder, or will be pushed into the predictor’s\\nlatent variable. The amount of information thereby ignored will be minimized by the\\ntraining criteria and by the latent variable regularizer.\\nIt is important to note that generative latent-variable models are not capable of elimi-\\nnating irrelevant details, other than by pushing them into a latent variable. This is because\\nthey do not produce abstract (and invariant) representations of y. This is why we advocate\\nagainst the use of generative architectures.\\nThe capacity of JEPA to learn abstractions suggests an extension of the architecture to\\nhandle prediction at multiple time scales and multiple levels of abstraction. Intuitively, low-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 29, 'page_label': '30'}, page_content='The capacity of JEPA to learn abstractions suggests an extension of the architecture to\\nhandle prediction at multiple time scales and multiple levels of abstraction. Intuitively, low-\\nlevel representations contain a lot of details about the input, and can be used to predict in\\nthe short term. But it may be diﬃcult to produce accurate long-term predictions with the\\nsame level of details. Conversely high-level, abstract representation may enable long-term\\npredictions, but at the cost of eliminating a lot of details.\\n30'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 30, 'page_label': '31'}, page_content='Let’s take a concrete example. When driving a car, given a proposed sequence of actions\\non the steering wheel and pedals over the next several seconds, drivers can accurately\\npredict the trajectory of their car over the same period. The details of the trajectory over\\nlonger periods are harder to predict because they may depend on other cars, traﬃc lights,\\npedestrians, and other external events that are somewhat unpredictable. But the driver\\ncan still make accurate predictions at a higher level of abstraction: ignoring the details of\\ntrajectories, other cars, traﬃc signals, etc, the car will probably arrive at its destination\\nwithin a predictable time frame. The detailed trajectory will be absent from this level of\\ndescription. But the approximate trajectory, as drawn on a map, is represented. A discrete\\nlatent variable may be used to represent multiple alternative routes.\\nFigure 15 shows a possible architecture for multilevel, multi-scale world state prediction.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 30, 'page_label': '31'}, page_content='latent variable may be used to represent multiple alternative routes.\\nFigure 15 shows a possible architecture for multilevel, multi-scale world state prediction.\\nVariables x0,x1,x2 represent a sequence of observations. The ﬁrst-level network, denoted\\nJEPA-1 performs short-term predictions using low-level representations. The second-level\\nnetwork JEPA-2 performs longer-term predictions using higher-level representations. One\\ncan envision architectures of this type with many levels, possibly using convolutional and\\nother modules, and using temporal pooling between levels to coarse-grain the representation\\nand perform longer-term predictions. Training can be performed level-wise or globally, using\\nany non-contrastive method for JEPA.\\nI submit that the ability to represent sequences of world states at several levels of\\nabstraction is essential to intelligent behavior. With multi-level representations of world'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 30, 'page_label': '31'}, page_content='I submit that the ability to represent sequences of world states at several levels of\\nabstraction is essential to intelligent behavior. With multi-level representations of world\\nstates and actions, a complex task can be decomposed into successively more detailed sub-\\ntasks, instantiated into actions sequences when informed by local conditions. For example,\\nplanning a complex task, like commuting to work, can be decomposed into driving to the\\ntrain station, catching a train, etc. Driving to the train station can be decomposed into\\nwalking out of the house, starting the car, and driving. Getting out of the house requires\\nstanding up, walking to the door, opening the door, etc. This decomposition descends all\\nthe way down to millisecond-by-millisecond muscle controls, which can only be instantiated\\nwhen the relevant environmental conditions are perceived (obstacles, traﬃc lights, moving\\nobjects, etc).\\n4.7 Hierarchical Planning'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 30, 'page_label': '31'}, page_content='when the relevant environmental conditions are perceived (obstacles, traﬃc lights, moving\\nobjects, etc).\\n4.7 Hierarchical Planning\\nIf our world model can perform predictions hierarchically, can it be used to perform Mode-2\\nreasoning and planning hierarchically?\\nHierarchical planning is a diﬃcult topic with few solutions, most of which require that\\nthe intermediate vocabulary of actions be predeﬁned. But if one abides by the deep learning\\nphilosophy, those intermediate representations of action plans should also be learned .\\nFigure 16 shows a possible architecture for hierarchical Mode-2 planning that can exploit\\nthe hierarchical nature of a multi-scale world model.\\nA percept is encoded into representations at multiple levels of abstractions by a cascade\\nof encoders:\\ns[0] = Enc1(x); s2[0] = Enc2(s[0]); ... (14)\\nPrediction takes place at all levels. Higher levels perform longer-term prediction, while lower'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 30, 'page_label': '31'}, page_content='of encoders:\\ns[0] = Enc1(x); s2[0] = Enc2(s[0]); ... (14)\\nPrediction takes place at all levels. Higher levels perform longer-term prediction, while lower\\nlevels perform shorter-term predictions. The overall task is deﬁned by a high-level objective,\\ndepicted as C(s2[4]) in the diagram. The top level infers a sequence of high-level actions\\n31'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 31, 'page_label': '32'}, page_content='Pred1(s,a)  Pred1(s,a)\\nC(s[2])\\n Pred1(s,a)  Pred1(s,a)\\nC(s[4])\\nEnc1(x)\\ns[1] s[2]\\naction\\ns[0]\\nActor1\\n Pred2(s,a)Enc2(s[0])\\ns2[0] s2[2]\\nActor2\\n Pred2(s,a)\\nC(s2[4])\\ns[3] s[4]\\ns2[4]\\na2[2] a2[4]\\na[1] a[2] a[3]a[0]\\nFigure 16: Hierarchical JEPA for Mode-2 hierarchical planning.\\nA complex task is deﬁned by a high-level cost computed from a high-level world-state representation\\nC(s2[4]). A sequence of high-level abstract actions (a2[2],a2[4]) is inferred that minimizes C(s2[4]).\\nThe inferred abstract actions are fed to lower-level cost modules C(s[2]),C(s[4]) which deﬁne subgoals\\nfor the lower layer. The lower layer then infers an action sequence that minimizes the subgoal costs.\\nAlthough only a 2-layer hierarchy is shown here, it is straightforward to extend the concept to multiple\\nlevels.\\nThe process described here is sequential top-down, but a better approach would be to perform a joint\\noptimization of the actions in all the layers.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 31, 'page_label': '32'}, page_content='levels.\\nThe process described here is sequential top-down, but a better approach would be to perform a joint\\noptimization of the actions in all the layers.\\n(a2[2],a2[4]) to optimize this objective. These high-level “actions” are not real actions but\\ntargets for the lower level predicted states. One can think of them as conditions that the\\nlower-level state must satisfy in order for the high-level predictions to be accurate. Whether\\nthese conditions are satisﬁed can be computed by cost modules C(s[2]) and C(s[4]). They\\ntake a lower-level state s[2] and a high-level condition a2[2] and measure to what extent\\nthe state satisﬁes the condition. With these subgoals deﬁned, the lower level can perform\\ninference and ﬁnd a low-level action sequence that minimizes the mid-level subgoals C(s[2])\\nand C(s[4]).\\nThe process just described is top down and greedy. But one may advantageously iterate\\nthe optimization so that high level and low-level action sequences are optimized jointly. The'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 31, 'page_label': '32'}, page_content='and C(s[4]).\\nThe process just described is top down and greedy. But one may advantageously iterate\\nthe optimization so that high level and low-level action sequences are optimized jointly. The\\ncost modules may be conﬁgured by the conﬁgurator for the situation at hand.\\nThe idea that an action is merely a condition to be satisﬁed by the level below is actually\\nan old one in control theory. For a example, a classical proportional servomechanism can be\\nseen as being given a target state. A quadratic cost measures the squared distance between\\nthe target and the current state, and the control is simply proportional to the negative\\ngradient of the cost with respect to the action variables.\\n4.8 Handling uncertainty\\nThe real world is not entirely predictable. Uncertainty in predictions of future world states\\nmay be due to a number of reasons:\\n• the world is intrinsically stochastic (aleatoric uncertainty, type 1)\\n32'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 32, 'page_label': '33'}, page_content='Pred1(s,a,z)  Pred1(s,a,z)\\nC(s[2])\\n Pred1(s,a,z)  Pred1(s,a,z)\\nC(s[4])\\nEnc1(x)\\ns[1] s[2]\\naction\\ns[0]\\na[1] a[2] a[3]a[0]\\nActor1\\n Pred2(s,a,z)Enc2(s[0])\\ns2[0] s2[2]\\na2[2]\\nActor2\\n Pred2(s,a,z)\\nC(s2[4])\\ns[3] s[4]\\ns2[4]\\na2[4]\\nz1[0]R1 z1[1]R1 z1[2]R1 z1[3]R1\\nz2[2]R2 z2[4]R2\\nFigure 17: Hierarchical JEPA for Mode-2 hierarchical planning in an uncertain environment.\\nRealistic environments are not entirely predictable, even when using highly-abstract representations.\\nUncertainty about predictions can be handled by predictors with latent variables. The latent variables\\n(red circles) contain information about the prediction that cannot be derived from the prior observa-\\ntion. The latent variables must be regularized to prevent an energy collapse and to force the system\\nto predict as much as possible without the help of it.\\nAt planning time, latent variables are sampled from distributions obtained by applying a Gibbs dis-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 32, 'page_label': '33'}, page_content='to predict as much as possible without the help of it.\\nAt planning time, latent variables are sampled from distributions obtained by applying a Gibbs dis-\\ntribution to the regularizers. Each sample leads to a diﬀerent prediction. To produce consistent\\nlatent sequences, the parameters of the regularizer can be functions of previous states and retrieved\\nmemories.\\nAs the prediction progresses, the number of generated state trajectories may grow exponentially. If\\neach latent variable has k possible discrete values, the number of possible trajectories will grow as\\nkt, where t is the number of time steps. Directed search and pruning strategies must be employed.\\nWith multiple predicted trajectories, optimal action sequences can be computed that minimize the\\naverage cost, or a combination of average and variance of the cost so as to minimize risk.\\n• the world is deterministic but chaotic, hence diﬃcult to predict without inﬁnitely\\nprecise perception (aleatoric uncertainty, type 2)'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 32, 'page_label': '33'}, page_content='• the world is deterministic but chaotic, hence diﬃcult to predict without inﬁnitely\\nprecise perception (aleatoric uncertainty, type 2)\\n• the world is deterministic but partially observable (aleatoric uncertainty type 3).\\n• the world is fully observable, but the sensors only give partial information about the\\nworld state (epistemic uncertainty, type 1)\\n• the representation of the world state extracted by the perception module does not\\ncontain the full information necessary for accurate prediction (epistemic uncertainty,\\ntype 2).\\n• the world model is inaccurate due to limitations of its representational power (bounded\\nrationality or epistemic uncertainty, type 3).\\n33'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 33, 'page_label': '34'}, page_content='• the world model is inaccurate due to it having been trained with limited amount of\\ndata (epistemic uncertainty, type 4).\\nMuch of the literature in reinforcement learning is focused on dealing with the stochastic\\nnature of the environment. It is often assumed from the start that models, critics and\\npolicies must represent distributions. In the present work, we push the possible stochasticity\\nof a predicted variable into a latent variable, which may be optimized, predicted, or sampled.\\nThis is what is often referred to in the ML literature as “the reparameterization trick”. We\\ndo not need to use this trick here, since we view the latent-variable parameterization of the\\npredictions as fundamental.\\nFigure 17 represents a hierachical planning episode in the presence of uncertainty.\\nA prediction at a given level and time step, e.g. s2[2] requires a sample of the corre-\\nsponding latent variable z2[2]. The sample may come from the distribution whose negative'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 33, 'page_label': '34'}, page_content='A prediction at a given level and time step, e.g. s2[2] requires a sample of the corre-\\nsponding latent variable z2[2]. The sample may come from the distribution whose negative\\nlogarithm is the regularizer R2(z2[2])). The parameters of the regularizer may be constant\\n(e.g. ﬁxed Gaussian), predicted from currently-available data using amortized inference (e.g.\\na multinomial or Gaussian whose parameters are computed from s2[0]) or produced by the\\nconﬁgurator. Using previous predictions to conﬁgure the latent regularizer biases the system\\ntowards generating “good” trajectories.\\nAs the prediction progresses, the number of generated state trajectories may grow ex-\\nponentially: if each latent variable has k possible discrete values, the number of possible\\ntrajectories will grow as kt, where tis the number of time steps. Directed search and prun-\\ning strategies can be employed, as in classical Monte-Carlo Tree Search (MCTS). In the case'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 33, 'page_label': '34'}, page_content='trajectories will grow as kt, where tis the number of time steps. Directed search and prun-\\ning strategies can be employed, as in classical Monte-Carlo Tree Search (MCTS). In the case\\nof continuous latents, one may sample latents from the continuous distributions deﬁned by\\nthe regularizer.\\nGiven a sample of all the latents, the optimal action sequences at every levels can be\\ninferred. However, the prediction process may need to be repeated for multiple drawings\\nof the latents, so as to cover the set of plausible outcomes. The inference process may be\\nused for multiple predictions to produce an action that does not just minimize the expected\\ncost, but also minimizes the uncertainty on the expected cost.\\n4.8.1 World Model Architecture\\nThe details of the architecture of the world model should depend on the type of environment\\nthe agent evolves in.\\nIt is likely that the best module architectures in a JEPA should include some sort of\\ngating or dynamic routing mechanism.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 33, 'page_label': '34'}, page_content='the agent evolves in.\\nIt is likely that the best module architectures in a JEPA should include some sort of\\ngating or dynamic routing mechanism.\\nFor example, the best way to handle low-level, short-term predictions in videos is by\\nextracting simple local feature vectors and displacing those feature vectors from one frame\\nto the next, depending on predicted motions. The latent variables may encode a map of\\ndisplacements, which can modulate routing connections between one frame and the next.\\nFor longer-term prediction at a higher level of abstraction, the relevant features are\\nobjects and their interactions. The evolution may be best modeled by a transformer ar-\\nchitecture, which has the property of being equivariant to permutation and is appropriate\\nto capture interactions between discrete objects (Vaswani et al., 2017; Carion et al., 2020;\\nBattaglia et al., 2016).\\n34'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 34, 'page_label': '35'}, page_content='Separating the World Model from the Ego Model: The natural world is complex\\nand somewhat unpredictable, requiring a powerful model with latent variables to account\\nfor the unpredictability.\\nOn the other hand, the agent itself is somewhat more predictable: a particular ac-\\ntion on eﬀector will produce a motion that can often be predicted deterministically. This\\nsuggests that the agent should possess a separate model of itself, perhaps without latent\\nvariables (Sobal et al., 2022) as the eﬀect of actions on proprioception somewhat easier to\\npredict than the evolution of the external world or the eﬀect of actions on it.\\nIn turn, the ego-model that the agent has of itself can be used as a template for a model\\nof other agents in a multi-agent scenario.\\n4.9 Keeping track of the state of the world\\nTraditionally, modules in deep learning architectures communicate states through vectors\\nor multi-dimensional arrays. But this tends to be a very ineﬃcient method when the state'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 34, 'page_label': '35'}, page_content='Traditionally, modules in deep learning architectures communicate states through vectors\\nor multi-dimensional arrays. But this tends to be a very ineﬃcient method when the state\\nof the object being modeled only changes in minor ways from one time to the next.\\nA typical action of an agent will only modify a small portion of the state of the world.\\nIf a bottle is being moved from the kitchen to the dining room, the states of the bottle, the\\nkitchen, and the dining room will be modiﬁed. But the rest of the world will be unaﬀected.\\nThis suggests that the state of the world should be maintained in some sort of writable\\nmemory. Whenever an event occurs, only the part of the world-state memory aﬀected by\\nthe event is to be updated, while the rest is to be left unchanged.\\nA conventional key-value associative memory can be used for this purpose, similar to\\nwhat has been proposed in the context of memory-augmented networks (Bordes et al., 2015;'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 34, 'page_label': '35'}, page_content='A conventional key-value associative memory can be used for this purpose, similar to\\nwhat has been proposed in the context of memory-augmented networks (Bordes et al., 2015;\\nSukhbaatar et al., 2015; Miller et al., 2016), and entity networks (Henaﬀ et al., 2017).\\nThe output of the world model at a given time step is a set of query-value pairs (q[i],v[i]),\\nwhich are used to modify existing entries in the world-state memory, or to add new entries.\\nGiven a query q, the world-state memory returns\\nMem(q) =\\n∑\\nj\\ncjvj (15)\\n˜cj = Match( kj,q) (16)\\nc = Normalize(˜c) (17)\\nwhere the kj are keys, the vj are stored values, function Match(k,q) measures a divergence\\nor dissimilarity between a key and a query, vector c contains scalar coeﬃcients cj, and\\nfunction Normalize(˜c) performs some sort of competitive normalization or thresholding,\\nsuch as the commonly-used cj = exp(˜cj)/[γ+ ∑\\nkexp(˜ck)], where γis a positive constant.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 34, 'page_label': '35'}, page_content='function Normalize(˜c) performs some sort of competitive normalization or thresholding,\\nsuch as the commonly-used cj = exp(˜cj)/[γ+ ∑\\nkexp(˜ck)], where γis a positive constant.\\nWriting a value r using query (or address) q into the memory can be done by updating\\nexisting entries:\\n˜cj = Match( kj,q) (18)\\nc = Normalize(˜c) (19)\\nvj = Update( r,vj,cj) (20)\\nFunction Update(r,v,c ) may be as simple as cr+ (1 −c)v.\\n35'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 35, 'page_label': '36'}, page_content='If the query is distant from all keys, the memory may allocate a new entry whose key is\\nq and corresponding value is r. The γ constant in the example Normalize function above\\nmay serve as a threshold for acceptable key-query divergence.\\nOne can view each entry as representing the state of an entity in the world. In the\\nabove example of the bottle, the world model may contain keys kbottle,kkitchen,kdining−room\\nrespectively representing the bottle, the kitchen and the dining room. The initial value of\\nvbottle encodes its location as “kitchen”, the inital value of vkitchen encodes its content as\\nincluding the bottle, and the initial value of vdining−room encodes its content as not including\\nthe bottle. After the event, the location and contents are updated.\\nAll of these operations can be done in a diﬀerentiable manner, and would hence allow\\nto back-propagate gradients through them.\\n4.10 Data Streams\\nMuch knowledge about the world is learnable through pure observation. The laws of mo-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 35, 'page_label': '36'}, page_content='to back-propagate gradients through them.\\n4.10 Data Streams\\nMuch knowledge about the world is learnable through pure observation. The laws of mo-\\ntion of physical objects can, in principle, be derived from observation, without a need for\\nintervention. But training a world model eﬃciently may require more active or “agentive”\\ninformation gathering.\\nOne can list ﬁve modes of information gathering with which an agent can learn about\\nhow the world works:\\n1. passive observation: the agent is being fed a sensor stream (e.g. video, audio, etc)\\n2. active foveation: the agent is being fed a stream within which the focus of attention\\ncan be directed without aﬀecting the environment. For example, watching a scene\\nwhile being able to orient the vision and sound sensors, or being being fed a wide-\\nangle, high resolution video and/or audio stream within which the focus of attention\\ncan be directed.\\n3. passive agency: sensory streams in which another agent acting on the environment'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 35, 'page_label': '36'}, page_content='angle, high resolution video and/or audio stream within which the focus of attention\\ncan be directed.\\n3. passive agency: sensory streams in which another agent acting on the environment\\nis being observed, enabling the inference of causal eﬀects of agent actions on the state\\nof the environment.\\n4. active egomotion: the agent receives sensory streams from a real or virtual environ-\\nment within which the position of the sensors can be modiﬁed without signiﬁcantly\\naﬀecting the environment. This may include steerable active sensors (e.g. range sen-\\nsors, heat sensors, chemical sensors) as well as touch sensors.\\n5. active agency : sensory streams that are inﬂuenced by the agent’s actions. This\\nenables the establishment of causal models in which the agent can learn to predict the\\nconsequences of its actions. This mode brings the exploration-exploitation dilemma\\nto the forefront.\\nIn a complex environment, it may not be practical to collect enough passive data for the'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 35, 'page_label': '36'}, page_content='consequences of its actions. This mode brings the exploration-exploitation dilemma\\nto the forefront.\\nIn a complex environment, it may not be practical to collect enough passive data for the\\nworld model to capture a suﬃcient portion of the environment’s behavior. Mode 2, 4, and\\n5 allow the agent to collect information that maximizes its understanding of the environ-\\nment. But to do so may require intrinsic motivation modules that drive attention, curiosity,\\n36'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 36, 'page_label': '37'}, page_content='and exploration into corners of the state space in which the world model’s prediction are\\ncurrently inexact or uncertain.\\nThe main open question is how much can be learned using passive observation (modes\\n1, 2, 4), how much requires egomotion (mode 3), and how much requires full agency (mode\\n5).\\n5 Designing and Training the Actor\\nThe role of the actor module is threefold:\\n1. inferring optimal action sequences that minimize the cost, given the predictions pro-\\nduced by the world model for Mode-2 actions.\\n2. producing multiple conﬁgurations of latent variables that represent the portion of the\\nworld state the agent does not know.\\n3. training policy networks for producing Mode-1 actions.\\nThere is no conceptual diﬀerence between an action and a latent variable. The conﬁgurations\\nof both sets of variables must be explored by the actor. For latent variables, conﬁgurations\\nmust be explored to plan under uncertainty. For action variables conﬁgurations must be'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 36, 'page_label': '37'}, page_content='of both sets of variables must be explored by the actor. For latent variables, conﬁgurations\\nmust be explored to plan under uncertainty. For action variables conﬁgurations must be\\nexplored to produce an optimal one that minimizes the cost. In adversarial scenarios (such\\nas games), the latent conﬁgurations must be explored that maximize the cost. In eﬀect, the\\nactor plays the role of an optimizer and explorer.\\nWhen the world model and the cost are well-behaved, the actor module can use a\\ngradient-based optimization process to infer an optimal action sequence. To do so, it receives\\nestimates of the gradient of the cost computed by backpropagating gradients through the\\ncost and the unfolded world model. It uses those estimates to update the action sequence.\\nWhen the world model or the cost are not so well-behaved, a gradient-based search\\nfor an optimal action sequence may fail. In this case another search/planning method'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 36, 'page_label': '37'}, page_content='When the world model or the cost are not so well-behaved, a gradient-based search\\nfor an optimal action sequence may fail. In this case another search/planning method\\nmay be applied. If the action space is discrete or can be discretized, one can use dynamic\\nprogramming methods or approximate dynamic programming methods such as beam search\\nor Monte-Carlo tree search. In eﬀect, any planning method developed in the context of\\noptimal control, robotic, or “classical” AI may be used in this context.\\nOnce an optimal action sequence is obtained through the planning / inference / opti-\\nmization process, one can use the actions as targets to train a policy network. The policy\\nnetwork may subsequently be used to act quickly, or merely to initialize the proposed action\\nsequence to a good starting point before the optimization phase. Multiple policy networks\\ncan be trained for multiple tasks.\\nThe actor also produces conﬁgurations of latent variables. These latent variables repre-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 36, 'page_label': '37'}, page_content='can be trained for multiple tasks.\\nThe actor also produces conﬁgurations of latent variables. These latent variables repre-\\nsent the portion of the world state that the agent does not know. Ideally, the actor would\\nsystematically explore likely conﬁgurations of the latents. Ideally, the regularizer for the\\nlatents, R1 and R2 in Figure 17, would represent log-priors from which the latent could be\\nsampled. But in a similar way as the policy network, one may devise a latent amortized\\ninference module that learns distributions of latent variables. Good distributions would\\nproduce predictions that are plausible. The distribution primate’s may depend on all the\\nvariables available at that time.\\n37'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 37, 'page_label': '38'}, page_content='6 Designing the Conﬁgurator\\nThe conﬁgurator is the main controller of the agent. It takes input from all other modules\\nand modulates their parameters and connection graphs. The modulation can route signals,\\nactivate sub-networks, focus attention, etc. In a scenario in which the predictor and the\\nupper layers of the perception encoder are transformer blocks, the conﬁgurator outputs\\nmay constitute extra input tokens to these transformer blocks, thereby modulating their\\nconnection graphs and functions.\\nThe conﬁgurator module is necessary for two reasons: hardware reuse, and knowledge\\nsharing. There is an obvious advantage to be able to reuse the same circuit for multiple\\ntasks, particularly if the tasks can be accomplished sequentially, and if the amount of\\nresources (e.g. parameter memory) is limited. But there is another advantage: knowledge\\nreuse. A reasonable hypothesis is that a world model trained for a given environment can be'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 37, 'page_label': '38'}, page_content='resources (e.g. parameter memory) is limited. But there is another advantage: knowledge\\nreuse. A reasonable hypothesis is that a world model trained for a given environment can be\\nused for a range of diﬀerent tasks with minor changes. One can imagine a “generic” world\\nmodel for the environment with a small portion of the parameters being modulated by the\\nconﬁgurator for the task at hand. This would be more data eﬃcient and computationally\\neﬃcient than having separate world models for each skill. The disadvantage is that the\\nagent can only accomplish one task at a time.\\nThe conﬁgurator may prime the perception module for a particular task by modulating\\nthe parameters at various levels. The human perceptual system can be primed for a par-\\nticular task, such as detecting an item in a cluttered drawer, detecting fruits or preys in a\\nforest, reading, counting certain events, assembling two parts, etc. For tasks that require a'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 37, 'page_label': '38'}, page_content='ticular task, such as detecting an item in a cluttered drawer, detecting fruits or preys in a\\nforest, reading, counting certain events, assembling two parts, etc. For tasks that require a\\nrapid detection of simple motifs, the conﬁgurator may modulate the weights of low-level lay-\\ners in a convolutional architecture. For tasks that involve satisfying relationships between\\nobjects (such as assembling two parts with screws) the conﬁguration may be performed by\\nmodulating tokens in high-level transformer modules.\\nThe predictor part of the world model must be able to perform a wide range of functions\\ndepending on the task at hand. For predictors performing short-term predictions at a\\nlow level of abstraction, conﬁguration may mean dynamic signal routing. In a low-level\\nretinotopic feature array representation, prediction may be reduced to local displacements\\nof individual feature vectors, accompanied with small transformations of those vectors.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 37, 'page_label': '38'}, page_content='retinotopic feature array representation, prediction may be reduced to local displacements\\nof individual feature vectors, accompanied with small transformations of those vectors.\\nThis may be advantageously implemented with local gating/routing circuits. For longer-\\nterm prediction at higher-levels of abstraction, it may be preferable to use a transformer\\narchitecture. Transformer blocks are particularly appropriate for object-based reasoning in\\nwhich objects interact. The reason is that the function of transformer blocks is equivariant\\nto permutation. Thanks to that property, one does not need to worry about which object\\nis assigned to which input token: the result will be identical and consistent with the input\\nassignment. Recent work in model-based robotics have proposed to use a transformer\\noperating at the level of an entire trajectory, imposing constraints on the attention circuits\\nto conﬁgure the predictor for causal prediction or other tasks (Janner et al., 2021).'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 37, 'page_label': '38'}, page_content='operating at the level of an entire trajectory, imposing constraints on the attention circuits\\nto conﬁgure the predictor for causal prediction or other tasks (Janner et al., 2021).\\nConveniently, the function of a transformer block is easy to conﬁgure by adding extra\\ninput tokens. Those extra inputs have the eﬀect of modulating the connection graph used\\nby the rest of the network, thereby allowing the speciﬁcation of a wide range of input-output\\nfunctions.\\n38'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 38, 'page_label': '39'}, page_content='Perhaps the most important function of the conﬁgurator is to set subgoals for the agent\\nand to conﬁgure the cost module for this subgoal. As mentioned in Section 3.2, a simple\\nway to make the cost conﬁgurable is by modulating the weights of a linear combination of\\nelementary cost sub-modules. This may be appropriate for the immutable Intrinsic Cost\\nsubmodule: allowing for a complex modulation of the Intrinsic Cost may make the basic\\ndrives of the agent diﬃcult to control, including cost terms that implement safety guardrails.\\nIn contrast, one can imagine more sophisticated architectures allowing the Trainable Critic\\npart of the cost to be ﬂexibly modulated. As with the predictor, if the high-level cost is\\nformulated as a set of desired relationships between objects (“is the nut set on the screw?”)\\none may use a transformer architecture trained to measure to what extent the state of the\\nworld diverges from the condition to be satisﬁed. As with the predictor, extra token inputs'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 38, 'page_label': '39'}, page_content='one may use a transformer architecture trained to measure to what extent the state of the\\nworld diverges from the condition to be satisﬁed. As with the predictor, extra token inputs\\ncan be used to modulate the function.\\nOne question that is left unanswered is how the conﬁgurator can learn to decompose\\na complex task into a sequence of subgoals that can individually be accomplished by the\\nagent. I shall leave this question open for future investigation.\\n7 Related Work\\nMost of the ideas presented in the paper are not new, and have been discussed at length in\\nvarious forms in cognitive science, neuroscience, optimal control, robotics, AI, and machine\\nlearning, particularly in reinforcement learning.\\nPerhaps the main original contributions of the paper reside in\\n• an overall cognitive architecture in which all modules are diﬀerentiable and many of\\nthem are trainable.\\n• H-JEPA: a non-generative hierarchical architecture for predictive world models that'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 38, 'page_label': '39'}, page_content='• an overall cognitive architecture in which all modules are diﬀerentiable and many of\\nthem are trainable.\\n• H-JEPA: a non-generative hierarchical architecture for predictive world models that\\nlearn representations at multiple levels of abstraction and multiple time scales.\\n• a family of non-contrastive self-supervised learning paradigm that produces represen-\\ntations that are simultaneously informative and predictable.\\n• A way to use H-JEPA as the basis of predictive world models for hierarchical planning\\nunder uncertainty.\\nBelow is an attempt to connect the present proposal with relevant prior work. Given\\nthe scope of the proposal, the references cannot possibly be exhaustive.\\n7.1 Trained World Models, Model-Predictive Control, Hierarchical PLan-\\nning\\nThe use of models in optimal control goes back to the early days with the Kelley-Bryson\\nmethod (see (Bryson and Ho, 1969) and reference therein, or the review (Morari and Lee,'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 38, 'page_label': '39'}, page_content='ning\\nThe use of models in optimal control goes back to the early days with the Kelley-Bryson\\nmethod (see (Bryson and Ho, 1969) and reference therein, or the review (Morari and Lee,\\n1997)). Some methods allowed for online system identiﬁcation (Richalet et al., 1978).\\nUsing neural networks to learn models for control is an old idea, going back to the early\\n1990s (Jordan and Rumelhart, 1992; Narendra and Parthasarathy, 1990; Miller et al., 1995).\\n39'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 39, 'page_label': '40'}, page_content='In the context of optimal control, learning a Mode-1 like policy network is known as direct\\ninverse control.\\nThe idea of Mode-2 style inference over actions using a predictive model in the context\\nof reinforcement learning is also an old idea with, for example, Sutton’s Dyna architec-\\nture (Sutton, 1991). See (Bertsekas, 2019) for an extensive review.\\nThe idea of learnable models has recently enjoyed a renewal of interest in various con-\\ntexts (Ha and Schmidhuber, 2018b; Ha and Schmidhuber, 2018a; Hafner et al., 2018; Hafner\\net al., 2020) (see (Moerland et al., 2020) for a recent survey of model-based reinforcement\\nlearning).\\nLearning world models is particularly important in the context of robotics, especially\\nfor grasping and manipulation where sample eﬃciency is paramount and simulation is often\\ninaccurate. In fact, because classical reinforcement learning approaches require too many\\ntrials for real-world applications, interesting advances in learned model for control have'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 39, 'page_label': '40'}, page_content='inaccurate. In fact, because classical reinforcement learning approaches require too many\\ntrials for real-world applications, interesting advances in learned model for control have\\nemerged from ML-based robotics research (Agrawal et al., 2016; Finn and Levine, 2017;\\nChua et al., 2018; Srinivas et al., 2018; Yu et al., 2020; Yarats et al., 2021). For a recent\\nreview, see (Levine, 2021) and references therein.\\nA diﬃcult setting is one in which the main input is visual, and a world model must be\\nlearned from video. Early attempts to train predictive models without latent variables from\\nsimple video produced blurry predictions (Lerer et al., 2016). To handle uncertainty in the\\npredictions, one can use various ﬂavors of latent variable models such as generative adver-\\nsarial networks (GAN) (Goodfellow et al., 2014), variational auto-encoders (VAE) (Kingma\\nand Welling, 2013) vector-quantized VAE (VQ-VAE) (van den Oord et al., 2017). Vari-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 39, 'page_label': '40'}, page_content='sarial networks (GAN) (Goodfellow et al., 2014), variational auto-encoders (VAE) (Kingma\\nand Welling, 2013) vector-quantized VAE (VQ-VAE) (van den Oord et al., 2017). Vari-\\nations of these methods have been applied to video prediction and help represent multi-\\nmodal outputs and reduce blurriness using GAN (Mathieu et al., 2015; Luc et al., 2020),\\nVAE (Babaeizadeh et al., 2017; Denton and Fergus, 2018; Henaﬀ et al., 2019), or VQ-\\nVAE (Walker et al., 2021). Although many of these methods have not been applied to\\ncontrol problems, some have been applied to vehicle trajectory prediction for autonomous\\ndriving (Henaﬀ et al., 2019; Mercat et al., 2020), or various robot control tasks (Oh et al.,\\n2015; Fragkiadaki et al., 2015; Agrawal et al., 2016; Finn et al., 2016; Nagabandi et al.,\\n2017; Babaeizadeh et al., 2017; Srinivas et al., 2018). Unlike the proposed JEPA, these\\nmodels are generative. The key issue of how to represent uncertainty in the prediction\\nremains.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 39, 'page_label': '40'}, page_content='2017; Babaeizadeh et al., 2017; Srinivas et al., 2018). Unlike the proposed JEPA, these\\nmodels are generative. The key issue of how to represent uncertainty in the prediction\\nremains.\\nThe alternative to regularized latent-variable models is constrative methods, such as\\nContrastive Predictive Coding (CPC) (H´ enaﬀ et al., 2019), which has been applied to\\nlearning visual representations through video prediction (van den Oord et al., 2018).\\nTo solve the multi-modality/blurriness problem, other works have proposed to perform\\nvideo prediction in representations spaces. In some works, the representation space is\\nobtained from a vision pipeline that has been trained in supervised mode, for example to\\nperform semantic segmentation (Luc et al., 2017; Luc et al., 2018). Unfortunately, the\\nrequirement for a pre-trained vision pipeline reduces the general usability of these methods\\nfor learning world models by observation.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 39, 'page_label': '40'}, page_content='requirement for a pre-trained vision pipeline reduces the general usability of these methods\\nfor learning world models by observation.\\nIn the same spirit as JEPA, there have been proposals for automatically learning rep-\\nresentations of video frames so they can be easily predicted. These proposals are generally\\nlimited to learning low-level features, and often use reconstruction through a decoder as a\\nway to prevent collapse (Goroshin et al., 2015a; Srivastava et al., 2015). Some authors have\\n40'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 40, 'page_label': '41'}, page_content='proposed to use temporal invariance (or consistency) to separate the content of an image\\nregion from its instantiation parameters (Wiskott and Sejnowski, 2002; Gregor and LeCun,\\n2010a; Goroshin et al., 2015b).\\nAt least one recent work has applied non-contrastive SSL methods to a joint embedding\\narchitecture for robotics control with some success (Pari et al., 2021; ?).\\nContrastive methods applied to joint-embedding and prediction have been applied suc-\\ncessfully to speech recognition (Baevski et al., 2020) (see (Mohamed et al., 2022) for a recent\\nreview of SSL to speech).\\nTo perform state trajectory predictions, recent works have advocated the use of trans-\\nformers, as proposed in the present paper. Transformers are ideal to represent the dynamics\\nof discrete objects in interaction, and have successfully been applied to the prediction of\\ncar trajectories (Mercat et al., 2020).\\nAn interesting proposal is the trajectory transformer architecture in which a transformer'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 40, 'page_label': '41'}, page_content='car trajectories (Mercat et al., 2020).\\nAn interesting proposal is the trajectory transformer architecture in which a transformer\\nis fed with the sequence of predicted states over an entire episode (Janner et al., 2021). The\\npattern of attention can be constrained so as to force the system to only attend to the\\npast so it can be operated in a causal manner (without looking at the future), and trained\\nto predict the next state, actions, and cost from previously observed or predicted states,\\nactions, and costs.\\nHierarchical planning is a largely unsolved problem. Wayne and Abbott proposed an\\narchitecture that uses a stack of trained forward models that specify intermediate goals for\\nthe lower layers (Wayne and Abbott, 2014). Some recent works specify intermediate goals\\nfor robots in terms of pose parameters (Gehring et al., 2021). A more recent proposal is\\nthe Director system (Hafner et al., 2022) which contains a hierarchical world model and'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 40, 'page_label': '41'}, page_content='for robots in terms of pose parameters (Gehring et al., 2021). A more recent proposal is\\nthe Director system (Hafner et al., 2022) which contains a hierarchical world model and\\nplanning architecture trained end-to-end through reinforcement learning.\\nThe idea of intrinsic motivation to train an agent has been studied in the context of\\nrobotics (Gottlieb et al., 2013). The presence of an Intrinsic Cost provides a diﬀerentiable\\nand eﬃcient way to direct the agent to follow certain behaviors and to learn certain skills.\\n7.2 Energy-Based Models and Joint-Embedding Architectures\\nFor many authors, Energy-Based Model (EBM) designates a probabilistic model whose\\ndistribution is the normalized negative exponential of an energy function.\\nIn this paper, EBM designates a much broader category of models that treat the energy\\nfunction as fundamental, and directly manipulate its landscape through learning. Many\\nmethods have been proposed in the past that directly manipulate the energy. In fact, all'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 40, 'page_label': '41'}, page_content='function as fundamental, and directly manipulate its landscape through learning. Many\\nmethods have been proposed in the past that directly manipulate the energy. In fact, all\\ntraditional optimization-based learning methods can be interpreted as energy-based meth-\\nods (LeCun et al., 2006). In particular, discriminative training methods for structure pre-\\ndiction problems can be formulated as EBM (LeCun et al., 1998; LeCun et al., 2006).\\nMost EBM approaches for unsupervised or self-supervised learning have been con-\\ntrastive. The earliest example is the Boltzmann Machine (Hinton and Sejnowski, 1983),\\nwhich is a probabilistic generative energy-based model trained contrastively.\\nJoint Embedding Architectures (JEA) trained with contrastive methods and mutual\\ninformation maximization methods have a long history. The ﬁrst non-contrastive JEA\\nwas (Becker and Hinton, 1992) which was based on maximizing a measure of mutual in-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 40, 'page_label': '41'}, page_content='information maximization methods have a long history. The ﬁrst non-contrastive JEA\\nwas (Becker and Hinton, 1992) which was based on maximizing a measure of mutual in-\\nformation between the representations from two branches seeing to diﬀerent views of the\\n41'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 41, 'page_label': '42'}, page_content='same scene. Perhaps the ﬁrst contrastive method for JEA is the so-called “Siamese Net-\\nwork” (Bromley et al., 1994). This was trained contrastively for the purpose of verifying\\nsignatures handwritten on a pen tablet.\\nThe idea of JEA remained largely untouched for over a decade, until it was revived in\\na series of papers from my group (Chopra et al., 2005; Hadsell et al., 2006), and Geoﬀrey\\nHinton’s group (Goldberger et al., 2005). Following the rebirth of deep learning, a few\\npapers used JEA for ﬁne-grained recognition, including face recognition (Taigman et al.,\\n2014).\\nWith the emergence of SSL approaches, the use of JEA trained contrastively has ex-\\nploded in the last few years with methods such as PIRL (Misra and Maaten, 2020), MoCo\\nand MoCo-v2 (He et al., 2020; Chen et al., 2020b), and SimCLR (Chen et al., 2020a).\\nSome methods can be seen as “distillation” approaches in which one branch of the\\nSiamese network is a teacher whose output are used as targets for the other branch. This'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 41, 'page_label': '42'}, page_content='Some methods can be seen as “distillation” approaches in which one branch of the\\nSiamese network is a teacher whose output are used as targets for the other branch. This\\nincludes methods in which the output vectors are quantized to discrete cluster prototypes\\n(see (Caron et al., 2020) and predecessors).\\nIn recent years, a number of new non-contrastive methods have appeared, such as\\nBYOL (Grill et al., 2020). But the class of non-contrastive methods advocated in the\\npresent proposal prevent collapse by maximizing the information content of the embed-\\ndings. This includes Barlow Twins (Zbontar et al., 2021), VICReg (Bardes et al., 2021),\\nwhitening-based methods (Ermolov et al., 2021), and Maximum Coding Rate Reduction\\nmethods (see (Dai et al., 2022) and references therein).\\n7.3 Human and animal cognition\\nThe limitations of current approaches to machine learning when compared with human\\nlearning are obvious (Lake et al., 2017a; Zaadnoordijk et al., 2022).'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 41, 'page_label': '42'}, page_content='7.3 Human and animal cognition\\nThe limitations of current approaches to machine learning when compared with human\\nlearning are obvious (Lake et al., 2017a; Zaadnoordijk et al., 2022).\\nYoung children quickly learn abstract concepts (Murphy, 2002), and models that allow\\nthem to navigate, to form goals, and to plan complex action sequences to fulﬁll them (Gopnik\\nand Meltzoﬀ, 1997; Spelke and Kinzler, 2007; Carey, 2009; Gopnik et al., 2001).\\nIn cognitive science, the idea that the brain builds predictive world models is a common\\none, and have inspired attempt to reproduce the process in machines (Lake et al., 2017b;\\nOrhan et al., 2020). Some eﬀorts have been devoted to building video datasets to test\\nintuitive physics common sense in machines and infants (Riochet et al., 2019).\\nThe ability to plan is a well-studied feature of human intelligence (Mattar and Lengyel,\\n2022). There is evidence that people construct simpliﬁed representations of the world for'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 41, 'page_label': '42'}, page_content='The ability to plan is a well-studied feature of human intelligence (Mattar and Lengyel,\\n2022). There is evidence that people construct simpliﬁed representations of the world for\\nplanning in which irrelevant details are abstracted away (Ho et al., 2022)\\nConsciousness is a rather speculative topic, owing to the diﬃculty of deﬁning what con-\\nsciousness is. I will not speculate about whether some version of the proposed architecture\\ncould possess a property assimilable to consciousness, but will only mention the work of\\nDehaene and collaborators who have proposed two types of consciousness that they call\\nC1 and C2. C1 is largely related with the modulation of attention, while C2 requires a\\nself-monitoring ability, perhaps assimilable to what the conﬁgurator module needs to do in\\nthe present proposal (Dehaene et al., 2021).\\n42'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 42, 'page_label': '43'}, page_content='8 Discussion, Limitations, Broader Relevance\\nConstructing the cognitive architecture of the present proposal, instantiating all the details,\\nand making the system work for non-trivial tasks will not be an easy task. The path to\\nsuccess is likely riddled with unforeseen obstacles. It will probably take many years to work\\nthem all out.\\n8.1 What is missing from the Proposed Model?\\nA lot of hard work needs to be done to instantiate the proposed architecture and turn it\\ninto a functional system. There may be ﬂaws and pitfalls that may appear to be unsolvable\\nwithin the speciﬁcations of the proposed architecture.\\nThe ﬁrst question is whether a Hierarchical JEPA can be built and trained from videos.\\nCould it learn the type of abstract concept hierarchy mentioned in section 4.1?\\nOne somewhat open question relative to the JEPA is how precisely to regularize the\\nlatent variable so as to minimize its information content. A number of possible mechanisms'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 42, 'page_label': '43'}, page_content='One somewhat open question relative to the JEPA is how precisely to regularize the\\nlatent variable so as to minimize its information content. A number of possible mechanisms\\nare proposed: making the latent variable discrete, low-dimensional, sparse, or stochastic.\\nBut it is not clear which approach will ultimately be the best.\\nThe current proposal does not prescribe a particular way for the actor to infer latent\\nvariable instantiations and optimal action sequences. While the diﬀerentiability of all the\\nmodules makes it possible in principle to use gradient-based optimization to infer optimal\\naction sequences, the optimization problem may be very diﬃcult in practice. In particular,\\nwhen the action space is discrete, or when the function from actions to cost is highly non\\nsmooth, gradient-based method may be ineﬀective, requiring to use other (gradient-free)\\nsearch methods (dynamic programming, belief propagation, MCTS, SAT, etc).'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 42, 'page_label': '43'}, page_content='smooth, gradient-based method may be ineﬀective, requiring to use other (gradient-free)\\nsearch methods (dynamic programming, belief propagation, MCTS, SAT, etc).\\nInstantiating multiple conﬁgurations of latent variables in Mode-2 planning/reasoning\\nmay require additional mechanisms not described in the present proposal. Humans seem\\nto be endowed with an ability to spontaneously cycle through alternative interpretations\\nof a percept, as demonstrated by the Necker cube and other visual illusions that have\\nseveral equally-plausible interpretations. In the context of the present model, diﬀerent\\ninterpretation of an ambiguous percept may be represented by diﬀerent values of a latent\\nvariable. While one could imagine a number of exploratory mechanisms to systematically\\nexplore the space of possible latent variable values, no such mechanism is described here.\\nThe present proposal does not specify the details of the architecture of the various'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 42, 'page_label': '43'}, page_content='explore the space of possible latent variable values, no such mechanism is described here.\\nThe present proposal does not specify the details of the architecture of the various\\nmodules. For example, it is probable that the predictor will require some sort of dynamic\\nrouting and gating circuits in its micro-architecture. Predictors for low-level representation\\nmay have to be specialized to represent the kind of small transformations of the repre-\\nsentation that can occur in the short term. Predictor modules dealing with higher level\\nrepresentations may require more generic architectures that manipulate objects and their\\nrelationships. But none of this is speciﬁed in the present proposal.\\nSimilarly, the precise architecture and function of the short-term memory and how it\\nmay be used to represent beliefs about the state of the world are somewhat fuzzy. The\\noriginal Memory Network system and its successors contained the idea that a neural net'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 42, 'page_label': '43'}, page_content='may be used to represent beliefs about the state of the world are somewhat fuzzy. The\\noriginal Memory Network system and its successors contained the idea that a neural net\\ncould use an associative memory as a working memory to store and retrieve beliefs about\\nthe state of the world between compute cycles (Bordes et al., 2015; Sukhbaatar et al.,\\n43'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 43, 'page_label': '44'}, page_content='2015). But getting such an architecture to work for complex planning and control may\\nprove diﬃcult.\\nOf all the least understood aspects of the current proposal, the conﬁgurator module is the\\nmost mysterious. In particular, while planning a complex task, the conﬁgurator is supposed\\nto identify sequences of subgoals and conﬁgure the agent to successively accomplish those\\nsubgoals. Precisely how to do that is not speciﬁed.\\nThis is merely a list of foreseeable questions, but many questions and problems will\\ninevitably surface as instances of the proposed systems are put together.\\n8.2 Broader Relevance of the Proposed Approach\\nAlthough the proposed architecture is not speciﬁcally designed to model autonomous intel-\\nligence, reasoning, and learning in humans and other animals, one can draw some parallels.\\nThe following is somewhat speculative and provided as a way to connect some concepts\\nin cognitive science and neuroscience that have inspired the present work.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 43, 'page_label': '44'}, page_content='The following is somewhat speculative and provided as a way to connect some concepts\\nin cognitive science and neuroscience that have inspired the present work.\\n8.2.1 Could this Architecture be the Basis of a Model of Animal Intelligence?\\nMany of the modules in the proposed architecture have counterparts in the mammalian\\nbrain that perform similar functions.\\nThe perception module corresponds to the visual, auditory, and other sensory areas\\nof the cortex, as well as some of the association areas. The world model and the critic\\ncorrespond to various part of the prefrontal cortex. The intrinsic cost module corresponds\\nto structures in the basal ganglia involved in rewards, including the amygdala. The trainable\\ncritic may correspond to part of the prefrontal cortex involved in reward prediction. The\\nfunction of the short-term memory overlaps with what is known of the hippocampus. The\\nconﬁgurator may correspond to structures in the prefrontal cortex that perform executive'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 43, 'page_label': '44'}, page_content='function of the short-term memory overlaps with what is known of the hippocampus. The\\nconﬁgurator may correspond to structures in the prefrontal cortex that perform executive\\ncontrol and modulate attention. The actor regroups areas in the pre-motor cortex that\\nelaborate and encode motor plans.\\nThe idea of predictive world model has long been a prominent concept in cognitive\\nscience, and the idea of predictive coding has been a prominent concept in neuroscience. The\\nJEPA architecture and the corresponding non-sample-contrastive self-supervised learning\\nmethod are somewhat consistent with ideas of predictive coding and eﬃcient coding.\\nThe proposed architecture has a single world model engine that can be conﬁgured for\\nthe task at hand by the conﬁgurator. I have argued that this may not only confer a\\ncomputational advantage through hardware reuse, but also allow knowledge to be shared\\nacross multiple tasks. The hypothesis of a single, conﬁgurable world model engine in the'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 43, 'page_label': '44'}, page_content='computational advantage through hardware reuse, but also allow knowledge to be shared\\nacross multiple tasks. The hypothesis of a single, conﬁgurable world model engine in the\\nhuman brain may explain why humans can essentially perform a single “conscious” reasoning\\nand planning task at a time. A highly-speculative idea is that the illusion of consciouness\\nmay be a side-eﬀect of a conﬁgurator-like module in the brain that oversees the function\\nof the rest of brain and conﬁgures it for the task at hand. Perhaps if the brain were large\\nenough to contain many independent, non-conﬁgurable world models, a conﬁgurator would\\nbe unnecessary, and the illusion of consciousness would disappear.\\nWhat is the substrate of emotions in animals and humans? Instantaneous emotions (e.g.\\npain, pleasure, hunger, etc) may be the result of brain structures that play a role similar\\nto the Intrinsic Cost module in the proposed architecture. Other emotions such as fear or\\n44'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 44, 'page_label': '45'}, page_content='elation may be the result of anticipation of outcome by brain structures whose function is\\nsimilar to the Trainable Critic.\\nThe presence of a cost module that drives the behavior of the agent by searching for\\noptimal actions suggests that autonomous intelligent agents of the type proposed here will\\ninevitably possess the equivalent of emotions. In an analogous way to animal and humans,\\nmachine emotions will be the product of an intrinsic cost, or the anticipation of outcomes\\nfrom a trainable critic.\\n8.2.2 Could this be a Path towards Machine Common Sense?\\nIt is a widely-held opinion that none of the current AI systems possess any level of common\\nsense, even at the level that can be observed in a house cat. Animals seem to be able to\\nacquire enough background knowledge about how the world works to exhibit some level\\nof common sense. By contrast, AI systems, even when (pre-)trained with self-supervised\\nmode (e.g. from text) seem to exhibit very limited levels of common sense, making them'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 44, 'page_label': '45'}, page_content='of common sense. By contrast, AI systems, even when (pre-)trained with self-supervised\\nmode (e.g. from text) seem to exhibit very limited levels of common sense, making them\\nsomewhat brittle.\\nFor example, Large language models (LLMs) seem to possess a surprisingly large amount\\nof background knowledge extracted from written text. But much of human common-sense\\nknowledge is not represented in any text and results from our interaction with the physical\\nworld. Because LLMs have no direct experience with an underlying reality, the type of\\ncommon-sense knowledge they exhibit is very shallow and can be disconnected from reality.\\nA possible characterization of common sense is the ability to use models of the world\\nto ﬁll in blanks, for example predicting the future, or more generally ﬁlling in information\\nabout the world that is unavailable from perception or from memory. With this deﬁnition,\\ncommon sense is an ability that emerges from a collection of models of the world or from'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 44, 'page_label': '45'}, page_content='about the world that is unavailable from perception or from memory. With this deﬁnition,\\ncommon sense is an ability that emerges from a collection of models of the world or from\\na single model engine conﬁgurable to handle the situation at hand. This view of common\\nsense sits squarely in the camp of “grounded intelligence”: common sense is a collection of\\nmodels from low-levels of abstraction to high levels, all the way up to knowledge acquired\\nthrough language.\\nCould SSL applied to conﬁgurable H-JEPA constitute the substrate of machine common\\nsense? Could a properly-trained and conﬁgured H-JEPA embed enough predictive knowl-\\nedge and capture enough dependencies about the world to exhibit some level of common\\nsense?\\nI speculate that common sense may emerge from learning world models that capture the\\nself-consistency and mutual dependencies of observations in the world, allowing an agent to\\nﬁll in missing information and detect violations of its world model.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 44, 'page_label': '45'}, page_content='self-consistency and mutual dependencies of observations in the world, allowing an agent to\\nﬁll in missing information and detect violations of its world model.\\n8.3 Is it all about scaling? Is reward really enough?\\nThe section reviews a few potential paths towards human-level intelligence that have been\\nproposed in recent years. The surprising power of large transformer architectures trained\\nto predict text and other modalities have led some to claim that we merely need to scale up\\nthose models (Brown et al., 2020; Brown et al., 2020). The surprising power of reinforcement\\nlearning for games and other simple environments have led other to claim that reward is\\nenough (Silver et al., 2021). ﬁnally, the limitations of current deep-learning systems when it\\n45'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 45, 'page_label': '46'}, page_content='comes to reasoning have led some to claim that deep learning systems need to be augmented\\nby hard-wired circuitry to enable symbol manipulation (Marcus and Davis, 2019)\\n8.3.1 Scaling is not enough\\nLarge Language Models (LLMs), and more generally, large-scale transformer architectures\\ntrained with a form of generative self-supervised learning, have been astonishingly successful\\nat capturing knowledge present in text. This has led to a debate in the AI community as\\nto whether human-level AI can be attained by scaling up these architectures. My position\\nin this debate is that I do not believe that scaling is enough for two main reasons.\\nFirst, current models operate on “tokenized” data and are generative. Every input\\nmodality must be turned into a sequence (or a collection) of “tokens” encoded as vectors.\\nWhile this works well for text, which is already a sequence of discrete tokens, it is less\\nsuitable for continuous, high dimensional signals such as video. The type of SSL training'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 45, 'page_label': '46'}, page_content='While this works well for text, which is already a sequence of discrete tokens, it is less\\nsuitable for continuous, high dimensional signals such as video. The type of SSL training\\nused for LLM-style models can be seen as a particular kind of latent-free generative model\\ntrained with a particular kind of contrastive method called denoising auto-encoder (Vincent\\net al., 2010), or in this case masked auto-encoder (Devlin et al., 2018). Hence, they are\\nsubject to the limitations of generative models, latent-variable free models, and contrastive\\nmethods. Generative models have diﬃculty representing complex uncertainties in contin-\\nuous spaces. LLMs simplify the representation of uncertainty in the prediction by only\\ndealing with discrete objects from a ﬁnite collection (e.g. words from a dictionary). Repre-\\nsenting uncertainty about a word being predicted comes down to producing a vector whose\\ncomponents are scores or probabilities for each word (or discrete token) in the dictionary.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 45, 'page_label': '46'}, page_content='senting uncertainty about a word being predicted comes down to producing a vector whose\\ncomponents are scores or probabilities for each word (or discrete token) in the dictionary.\\nBut this approach doesn’t work for high-dimensional continuous modalities, such as video.\\nTo represent such data, it is necessary to eliminate irrelevant information about the variable\\nto be modeled through an encoder, as in the JEPA. Furthermore, the high-dimensionality\\nof the signal precludes the representation of uncertainty through a normalized distribution.\\nSecond, current models are only capable of very limited forms of reasoning. The absence\\nof abstract latent variables in these models precludes the exploration of multiple interpre-\\ntations of a percept and the search for optimal courses of action to achieve a goal. In fact,\\ndynamically specifying a goal in such models is essentially impossible.\\n8.3.2 Reward is not enough'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 45, 'page_label': '46'}, page_content='tations of a percept and the search for optimal courses of action to achieve a goal. In fact,\\ndynamically specifying a goal in such models is essentially impossible.\\n8.3.2 Reward is not enough\\nThe proposed architecture is designed to minimize the number of actions a system needs\\nto take in the real world to learn a task. It does so by learning a world model that capture\\nas much knowledge about the world as possible without taking actions in the world. It uses\\nintrinsic costs that are diﬀerentiable functions of measured or predicted world states. This\\nmakes the proposal more similar to optimal control than to reinforcement learning. In the\\nproposed model, much of learning takes place at the level of the world model (perceptual\\nencoder and predictor). In this context, what is the role of reinforcement learning (RL)?\\nIn most RL settings the reward (or the cost, which is a negative reward) is fed to the'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 45, 'page_label': '46'}, page_content='encoder and predictor). In this context, what is the role of reinforcement learning (RL)?\\nIn most RL settings the reward (or the cost, which is a negative reward) is fed to the\\nagent by the environment. In other words, Intrinsic Cost module is the environment itself,\\nand is therefore an unknown function. The value of the function can be probed by observing\\nthe state of the world, taking an action, and observing the resulting reward. The gradient\\nof the reward with respect to the action or the state is unknown and must be estimated by\\n46'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 46, 'page_label': '47'}, page_content='multiple action trials as in policy gradient methods. In Actor-Critic methods, the reward\\nfunction is approximated by a critic module that is trained to approximate expected future\\nvalues of the reward. The critic provides a diﬀerentiable approximation of the reward\\nfunction.\\nBut model-free RL is extremely sample-ineﬃcient, at least when compared with human\\nand animal learning, requiring very large numbers of trials to learn a skill. Scalar rewards\\nprovide low-information feedback to a learning system. As a consequence, a pure RL system\\nrequires a very large number of trials to learn even relatively simple tasks. Model-based\\nRL clearly has the potential of being considerably more sample eﬃcient. But the question\\nbecomes how to train the world model: is it trained from taking actions and getting rewards,\\nor is it trained by predicting the world state? In the latter case,reward is clearly not enough:'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 46, 'page_label': '47'}, page_content='becomes how to train the world model: is it trained from taking actions and getting rewards,\\nor is it trained by predicting the world state? In the latter case,reward is clearly not enough:\\nmost of the parameters in the systems are trained to predict large amounts of observations\\nin the world. Contrary to the title of a recent position paper by Silver et al. (Silver et al.,\\n2021), the reward plays a relatively minor role in this scenario.\\n8.3.3 Do We Need Symbols for Reasoning?\\nIn the proposed architecture, reasoning comes down to energy minimization or constraint\\nsatisfaction by the actor using various search methods to ﬁnd a suitable combination of\\nactions and latent variables, as stated in Section 3.1.4.\\nIf the actions and latent variables are continuous, and if the predictor and the cost\\nmodules are diﬀerentiable and relatively well behaved, one can use gradient-based methods\\nto perform the search. But there may be situations where the predictor output changes'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 46, 'page_label': '47'}, page_content='modules are diﬀerentiable and relatively well behaved, one can use gradient-based methods\\nto perform the search. But there may be situations where the predictor output changes\\nquickly as a function of the action, and where the action space is essentially discontinuous.\\nThis is likely to occur at high levels of abstractions where choices are more likely to be\\nqualitative. A high-level decision for a self-driving car may correspond to “turning left or\\nright at the fork”, while the low-level version would be a sequence of wheel angles.\\nIf the action space is discrete with low cardinality, the actor may use exhaustive search\\nmethods. If the action set cardinality, and hence the branching factor, are too large, the\\nactor may have to resort to heuristic search methods, including Monte-Carlo Tree Search,\\nor other gradient-free methods. If the cost function satisﬁed Bellman’s equations, one may\\nuse dynamic programming.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 46, 'page_label': '47'}, page_content='or other gradient-free methods. If the cost function satisﬁed Bellman’s equations, one may\\nuse dynamic programming.\\nBut the eﬃciency advantage of gradient-based search methods over gradient-free search\\nmethods motivates us to ﬁnd ways for the world-model training procedure to ﬁnd hierar-\\nchical representations with which the planning/reasoning problem constitutes a continuous\\nrelaxation of an otherwise discrete problem.\\nA remain question is whether the type of reasoning proposed here can encompass all\\nforms of reasoning that humans and animals are capable of.\\nAcknowledgments\\nIdeas in this paper are a distillation of years of interactions with many people. It is impos-\\nsible to list them all here.\\nI will list some of the more salient ones: L´ eon Bottou, Yoshua Bengio, Geoﬀrey Hinton,\\nRob Fergus, and Jitendra Malick; Emmanuel Dupoux and Stanislas Dehaene; Mikael Henaﬀ,\\n47'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 47, 'page_label': '48'}, page_content='Alfredo Canziani, and Nicolas Carion at NYU; Li Jing, Yubei Chen, Randall Balestriero,\\nand St´ ephane Deny at FAIR; Vlad Sobal, Jiachen Zhu, and Katrina Evtimova at NYU.\\nI am thankful to the following colleagues for their comments on the manuscript: Olivier\\nDelalleau, Gus Xia, Yoshua Bengio, and Emmanuel Dupoux.\\n48'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 48, 'page_label': '49'}, page_content='References\\nAgrawal, P., Nair, A., Abbeel, P., Malik, J., and Levine, S. (2016). Learning to poke by\\npoking: Experiential learning of intuitive physics. CoRR, abs/1606.07419.\\nBabaeizadeh, M., Finn, C., Erhan, D., Campbell, R. H., and Levine, S. (2017). Stochastic\\nvariational video prediction. CoRR, abs/1710.11252.\\nBaevski, A., Zhou, Y., Mohamed, A., and Auli, M. (2020). wav2vec 2.0: A framework for\\nself-supervised learning of speech representations. In Larochelle, H., Ranzato, M., Had-\\nsell, R., Balcan, M., and Lin, H., editors, Advances in Neural Information Processing\\nSystems, volume 33, pages 12449–12460. Curran Associates, Inc.\\nBardes, A., Ponce, J., and LeCun, Y. (2021). Vicreg: Variance-invariance-covariance regu-\\nlarization for self-supervised learning. In International Conference on Learning Repre-\\nsentations (ICLR 2022) . arXiv preprint arXiv:2105.04906.\\nBattaglia, P., Pascanu, R., Lai, M., Jimenez Rezende, D., et al. (2016). Interaction net-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 48, 'page_label': '49'}, page_content='sentations (ICLR 2022) . arXiv preprint arXiv:2105.04906.\\nBattaglia, P., Pascanu, R., Lai, M., Jimenez Rezende, D., et al. (2016). Interaction net-\\nworks for learning about objects, relations and physics. Advances in neural information\\nprocessing systems, 29.\\nBecker, S. and Hinton, G. E. (1992). Self-organizing neural network that discovers surfaces\\nin random-dot stereograms. Nature, 355(6356):161–163.\\nBertsekas, D. (2019). Reinforcement learning and optimal control. Athena Scientiﬁc.\\nBordes, A., Usunier, N., Chopra, S., and Weston, J. (2015). Large-scale simple question\\nanswering with memory networks. arXiv:1506.02075.\\nBromley, J., Guyon, I., LeCun, Y., Sackinger, E., and Shah, R. (1994). Signature veriﬁcation\\nusing a “siamese” time delay neural network. In NeurIPS.\\nBrown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., Neelakantan,\\nA., Shyam, P., Sastry, G., Askell, A., Agarwal, S., Herbert-Voss, A., Krueger, G.,'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 48, 'page_label': '49'}, page_content='Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., Neelakantan,\\nA., Shyam, P., Sastry, G., Askell, A., Agarwal, S., Herbert-Voss, A., Krueger, G.,\\nHenighan, T., Child, R., Ramesh, A., Ziegler, D., Wu, J., Winter, C., Hesse, C., Chen,\\nM., Sigler, E., Litwin, M., Gray, S., Chess, B., Clark, J., Berner, C., McCandlish,\\nS., Radford, A., Sutskever, I., and Amodei, D. (2020). Language models are few-\\nshot learners. In Larochelle, H., Ranzato, M., Hadsell, R., Balcan, M., and Lin, H.,\\neditors, Advances in Neural Information Processing Systems , volume 33, pages 1877–\\n1901. Curran Associates, Inc.\\nBryson, A. and Ho, Y. (1969). Applied optimal control. Blaisdell, Waltham, MA.\\nCarey, S. (2009). The Origin of Concepts . Oxford University Press, New York, New York,\\nUSA.\\nCarion, N., Massa, F., Synnaeve, G., Usunier, N., Kirillov, A., and Zagoruyko, S. (2020).\\nEnd-to-end object detection with transformers. In 16th European Conference, Glasgow,\\nUK (ECCV 2020) , page 213–229.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 48, 'page_label': '49'}, page_content='End-to-end object detection with transformers. In 16th European Conference, Glasgow,\\nUK (ECCV 2020) , page 213–229.\\n49'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 49, 'page_label': '50'}, page_content='Caron, M., Misra, I., Mairal, J., Goyal, P., Bojanowski, P., and Joulin, A. (2020). Unsu-\\npervised learning of visual features by contrasting cluster assignments. In Advances in\\nNeural Information Processing Systems.\\nCarreira-Perpi˜ n´ an, M. A. and Hinton, G. (2005). On contrastive divergence learning. In\\nCowell, R. G. and Ghahramani, Z., editors, Proceedings of the Tenth International\\nWorkshop on Artiﬁcial Intelligence and Statistics, volume R5 ofProceedings of Machine\\nLearning Research, pages 33–40. PMLR. Reissued by PMLR on 30 March 2021.\\nChen, T., Kornblith, S., Swersky, K., Norouzi, M., and Hinton, G. (2020a). Big self-\\nsupervised models are strong semi-supervised learners. In NeurIPS.\\nChen, X., Fan, H., Girshick, R., and He, K. (2020b). Improved baselines with momentum\\ncontrastive learning. arXiv preprint arXiv:2003.04297 .\\nChopra, S., Hadsell, R., and LeCun, Y. (2005). Learning a similarity metric discriminatively,'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 49, 'page_label': '50'}, page_content='contrastive learning. arXiv preprint arXiv:2003.04297 .\\nChopra, S., Hadsell, R., and LeCun, Y. (2005). Learning a similarity metric discriminatively,\\nwith application to face veriﬁcation. In 2005 IEEE Computer Society Conference on\\nComputer Vision and Pattern Recognition (CVPR’05), volume 1, pages 539–546. IEEE.\\nChua, K., Calandra, R., McAllister, R., and Levine, S. (2018). Deep reinforcement learning\\nin a handful of trials using probabilistic dynamics models. CoRR, abs/1805.12114.\\nCraik, K. J. W. (1943). The nature of explanation . University Press, Macmillan.\\nDai, X., Tong, S., Li, M., Wu, Z., Psenka, M., Chan, K. H. R., Zhai, P., Yu, Y., Yuan,\\nX., Shum, H.-Y., and Ma, Y. (2022). Ctrl: Closed-loop transcription to an ldr via\\nminimaxing rate reduction. Entropy, 24(4):456.\\nDehaene, S., Lau, H., and Kouider, S. (2021). What is consciousness, and could machines\\nhave it? Robotics, AI, and Humanity , pages 43–56.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 49, 'page_label': '50'}, page_content='minimaxing rate reduction. Entropy, 24(4):456.\\nDehaene, S., Lau, H., and Kouider, S. (2021). What is consciousness, and could machines\\nhave it? Robotics, AI, and Humanity , pages 43–56.\\nDenton, E. and Fergus, R. (2018). Stochastic video generation with a learned prior. arXiv\\npreprint arXiv 1802.07687 .\\nDevlin, J., Chang, M.-W., Lee, K., and Toutanova, K. (2018). Bert: Pre-training\\nof deep bidirectional transformers for language understanding. arXiv preprint\\narXiv:1810.04805.\\nDoi, E., Balcan, D. C., and Lewicki, M. S. (2007). Robust coding over noisy overcomplete\\nchannels. IEEE Transactions on Image Processing, 16(2):442–452.\\nErmolov, A., Siarohin, A., Sangineto, E., and Sebe, N. (2021). Whitening for self-supervised\\nrepresentation learning.\\nEvtimova, K. and LeCun, Y. (2022). Sparse coding with multi-layer decoders using variance\\nregularization. arXiv:2112.09214.\\nFinn, C., Goodfellow, I. J., and Levine, S. (2016). Unsupervised learning for physical'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 49, 'page_label': '50'}, page_content='regularization. arXiv:2112.09214.\\nFinn, C., Goodfellow, I. J., and Levine, S. (2016). Unsupervised learning for physical\\ninteraction through video prediction. CoRR, abs/1605.07157.\\n50'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 50, 'page_label': '51'}, page_content='Finn, C. and Levine, S. (2017). Deep visual foresight for planning robot motion. In 2017\\nIEEE International Conference on Robotics and Automation (ICRA), pages 2786–2793.\\nIEEE.\\nFragkiadaki, K., Agrawal, P., Levine, S., and Malik, J. (2015). Learning visual predictive\\nmodels of physics for playing billiards. CoRR, abs/1511.07404.\\nGehring, J., Synnaeve, G., Krause, A., and Usunier, N. (2021). Hierarchical skills for eﬃcient\\nexploration. Advances in Neural Information Processing Systems , 34:11553–11564.\\nGoldberger, J., S.Roweis, Hinton, G., and Salakhutdinov, R. (2005). Neighbourhood com-\\nponents analysis. In Saul, L. K., Weiss, Y., and Bottou, L., editors, Advances in Neural\\nInformation Processing Systems 17 , pages 513–520. MIT Press, Cambridge, MA.\\nGoodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville,\\nA., and Bengio, Y. (2014). Generative adversarial nets. In Advances in Neural Infor-\\nmation Processing Systems, pages 2672–2680.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 50, 'page_label': '51'}, page_content='A., and Bengio, Y. (2014). Generative adversarial nets. In Advances in Neural Infor-\\nmation Processing Systems, pages 2672–2680.\\nGopnik, A. and Meltzoﬀ, A. N. (1997). Words, Thoughts, and Theories . MIT Press,\\nCambridge, MA.\\nGopnik, A., Meltzoﬀ, A. N., and Kuhl, P. K. (2001). The Scientist in the Crib: What Early\\nLearning Tells Us About the Mind . Perennial, New York, NY.\\nGoroshin, R., Bruna, J., Tompson, J., Eigen, D., and LeCun, Y. (2015a). Unsupervised\\nfeature learning from temporal data. In International Conference on Computer Vision\\n(ICCV 2015).\\nGoroshin, R., Mathieu, M., and LeCun, Y. (2015b). Learning to linearize under uncertainty.\\nIn Advances in Neural Information Processing Systems (NIPS 2015) , volume 28.\\nGottlieb, J., Oudeyer, P. Y., Lopes, M., and Baranes, A. (2013). Information-seeking,\\ncuriosity, and attention: Computational and neural mechanisms. Trends in Cognitive\\nSciences, 17:585–593.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 50, 'page_label': '51'}, page_content='Gottlieb, J., Oudeyer, P. Y., Lopes, M., and Baranes, A. (2013). Information-seeking,\\ncuriosity, and attention: Computational and neural mechanisms. Trends in Cognitive\\nSciences, 17:585–593.\\nGregor, K. and LeCun, Y. (2010a). Emergence of complex-like cells in a temporal product\\nnetwork with local receptive ﬁelds. arXiv preprint arXiv:1006.0448 .\\nGregor, K. and LeCun, Y. (2010b). Learning fast approximations of sparse coding. In Proc.\\nInternational Conference on Machine learning (ICML’10) .\\nGrill, J.-B., Strub, F., Altch´ e, F., Tallec, C., Richemond, P. H., Buchatskaya, E., Doersch,\\nC., Pires, B. A., Guo, Z. D., Azar, M. G., Piot, B., Kavukcuoglu, K., Munos, R.,\\nand Valko, M. (2020). Bootstrap your own latent: A new approach to self-supervised\\nlearning. In NeurIPS.\\nHa, D. and Schmidhuber, J. (2018a). Recurrent world models facilitate policy evolution. In\\nBengio, S., Wallach, H., Larochelle, H., Grauman, K., Cesa-Bianchi, N., and Garnett,'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 50, 'page_label': '51'}, page_content='learning. In NeurIPS.\\nHa, D. and Schmidhuber, J. (2018a). Recurrent world models facilitate policy evolution. In\\nBengio, S., Wallach, H., Larochelle, H., Grauman, K., Cesa-Bianchi, N., and Garnett,\\nR., editors, Advances in Neural Information Processing Systems , volume 31.\\n51'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 51, 'page_label': '52'}, page_content='Ha, D. and Schmidhuber, J. (2018b). World models. arXiv preprint arXiv:1803.10122 .\\nHadsell, R., Chopra, S., and LeCun, Y. (2006). Dimensionality reduction by learning an\\ninvariant mapping. In CVPR.\\nHafner, D., Lee, K.-H., Fischer, I., and Abbeel, P. (2022). Deep hierarchical planning from\\npixels. arXiv preprint arXiv:2206.04114 .\\nHafner, D., Lillicrap, T., Fischer, I., Villegas, R., Ha, D., Lee, H., and Davidson, J. (2018).\\nLearning latent dynamics for planning from pixels. arXiv 1811.04551.\\nHafner, D., Lillicrap, T., Norouzi, M., and Ba, J. (2020). Mastering atari with discrete\\nworld models. arXiv preprint arXiv:2010.02193 .\\nHe, K., Fan, H., Wu, Y., Xie, S., and Girshick, R. (2020). Momentum contrast for unsu-\\npervised visual representation learning. In CVPR.\\nHenaﬀ, M., Canziani, A., and LeCun, Y. (2019). Model-predictive policy learning with\\nuncertainty regularization for driving in dense traﬃc. In ICLR-19. arXiv:1901.02705.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 51, 'page_label': '52'}, page_content='Henaﬀ, M., Canziani, A., and LeCun, Y. (2019). Model-predictive policy learning with\\nuncertainty regularization for driving in dense traﬃc. In ICLR-19. arXiv:1901.02705.\\nHenaﬀ, M., Weston, J., Szlam, A., Bordes, A., and LeCun, Y. (2017). Tracking the world\\nstate with recurrent entity networks. In International Conference on Learning Repre-\\nsentations (ICLR 2017) .\\nHinton, G. and Sejnowski, T. (1983). Optimal perceptual inference. In Proceedings of\\nthe IEEE Conference on Computer Vision and Pattern Recognition , pages 448–453,\\nWashington 1983. IEEE, New York.\\nHo, M. K., Abel, D., Correa, C. G., Littman, M. L., Cohen, J. D., and Griﬃths, T. L. (2022).\\nPeople construct simpliﬁed mental representations to plan. Nature, 606(7912):129–136.\\nH´ enaﬀ, O. J., Srinivas, A., De Fauw, J., Razavi, A., Doersch, C., Eslami, S. M. A., and\\nvan den Oord, A. (2019). Data-eﬃcient image recognition with contrastive predictive\\ncoding. In ICML.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 51, 'page_label': '52'}, page_content='H´ enaﬀ, O. J., Srinivas, A., De Fauw, J., Razavi, A., Doersch, C., Eslami, S. M. A., and\\nvan den Oord, A. (2019). Data-eﬃcient image recognition with contrastive predictive\\ncoding. In ICML.\\nJanner, M., Li, Q., and Levine, S. (2021). Oﬄine reinforcement learning as one big sequence\\nmodeling problem. In Advances in Neural Information Processing Systems .\\nJing, L., Zbontar, J., et al. (2020). Implicit rank-minimizing autoencoder. Advances in\\nNeural Information Processing Systems, 33:14736–14746.\\nJordan, M. I. and Rumelhart, D. E. (1992). Forward models: Supervised learning with a\\ndistal teacher. Cognitive science, 16(3):307–354.\\nKahneman, D. (2011). Thinking, fast and slow . Macmillan.\\nKingma, D. P. and Welling, M. (2013). Auto-encoding variational bayes. arXiv preprint\\narXiv:1312.6114.\\nLake, B. M., Ullman, T. D., Tenenbaum, J. B., and Gershman, S. J. (2017a). Building\\nmachines that learn and think like people. Behavioral and brain sciences , 40.\\n52'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 52, 'page_label': '53'}, page_content='Lake, B. M., Ullman, T. D., Tenenbaum, J. B., and Gershman, S. J. (2017b). Building\\nmachines that learn and think like people. Behavioral and Brain Sciences , 40:E253.\\nLeCun, Y., Bottou, L., Bengio, Y., and Haﬀner, P. (1998). Gradient-based learning applied\\nto document recognition. Proceedings of the IEEE, 86(11):2278–2324.\\nLeCun, Y., Chopra, S., Hadsell, R., Ranzato, M., and Huang, F. (2006). A tutorial on\\nenergy-based learning. In Bakir, G., Hofman, T., Sch¨ olkopf, B., Smola, A., and Taskar,\\nB., editors, Predicting Structured Data. MIT Press.\\nLerer, A., Gross, S., and Fergus, R. (2016). Learning physical intuition of block towers by\\nexample. In Proceedings of the 33nd International Conference on Machine Learning,\\nICML 2016, New York City, NY, USA, June 19-24, 2016 , pages 430–438.\\nLevine, S. (2021). Understanding the world through action. arXiv:2110.12543. https:\\n//arxiv.org/abs/2110.12543.\\nLuc, P., Clark, A., Dieleman, S., Casas, D. d. L., Doron, Y., Cassirer, A., and Simonyan, K.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 52, 'page_label': '53'}, page_content='//arxiv.org/abs/2110.12543.\\nLuc, P., Clark, A., Dieleman, S., Casas, D. d. L., Doron, Y., Cassirer, A., and Simonyan, K.\\n(2020). Transformation-based adversarial video prediction on large-scale data. arXiv\\npreprint arXiv:2003.04035.\\nLuc, P., Couprie, C., Lecun, Y., and Verbeek, J. (2018). Predicting future instance segmen-\\ntation by forecasting convolutional features. In Proceedings of the european conference\\non computer vision (ECCV) , pages 584–599.\\nLuc, P., Neverova, N., Couprie, C., Verbeek, J., and LeCun, Y. (2017). Predicting deeper\\ninto the future of semantic segmentation. In Proceedings of the IEEE international\\nconference on computer vision, pages 648–657.\\nMarcus, G. and Davis, E. (2019). Rebooting AI: Building artiﬁcial intelligence we can trust .\\nVintage.\\nMathieu, M., Couprie, C., and LeCun, Y. (2015). Deep multi-scale video prediction beyond\\nmean square error. In ICLR 16. arXiv preprint arXiv:1511.05440.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 52, 'page_label': '53'}, page_content='Vintage.\\nMathieu, M., Couprie, C., and LeCun, Y. (2015). Deep multi-scale video prediction beyond\\nmean square error. In ICLR 16. arXiv preprint arXiv:1511.05440.\\nMattar, M. G. and Lengyel, M. (2022). Planning in the brain. Neuron, 110(6):914–934.\\nMercat, J., Gilles, T., El Zoghby, N., Sandou, G., Beauvois, D., and Gil, G. P. (2020). Multi-\\nhead attention for multi-modal joint vehicle motion forecasting. In 2020 IEEE Inter-\\nnational Conference on Robotics and Automation (ICRA) , pages 9638–9644. IEEE.\\nMiller, A. H., Fisch, A., Dodge, J., Karimi, A.-H., Bordes, A., and Weston, J. (2016).\\nKey-value memory networks for directly reading documents. In EMNLP-16.\\nMiller, W. T., Sutton, R. S., and Werbos, P. J. (1995). Neural networks for control . MIT\\npress.\\nMisra, I. and Maaten, L. v. d. (2020). Self-supervised learning of pretext-invariant repre-\\nsentations. In CVPR.\\n53'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 53, 'page_label': '54'}, page_content='Moerland, Thomas, M., Broekens, J., and Jonker, Catholijn, M. (2020). Model-based\\nreinforcement learning: A survey. arXiv:2006.16712. https://arxiv.org/abs/2006.\\n16712.\\nMohamed, A., Lee, H.-y., Borgholt, L., Havtorn, J. D., Edin, J., Igel, C., Kirchhoﬀ, K.,\\nLi, S.-W., Livescu, K., Maaløe, L., et al. (2022). Self-supervised speech representation\\nlearning: A review. arXiv preprint arXiv:2205.10643 .\\nMorari, M. and Lee, J. H. (1997). Model predictive control: Past, present and future.\\nComputers and Chemical Engineering , 23:667–682.\\nMurphy, G. L. (2002). The Big Book of Concepts . MIT Press, Cambridge, MA.\\nNagabandi, A., Kahn, G., Fearing, R. S., and Levine, S. (2017). Neural network dynam-\\nics for model-based deep reinforcement learning with model-free ﬁne-tuning. CoRR,\\nabs/1708.02596.\\nNarendra, K. and Parthasarathy, K. (1990). Identiﬁcation and control of dynamical systems\\nusing neural networks. IEEE Transactions on neural networks , 1(1):4–27.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 53, 'page_label': '54'}, page_content='abs/1708.02596.\\nNarendra, K. and Parthasarathy, K. (1990). Identiﬁcation and control of dynamical systems\\nusing neural networks. IEEE Transactions on neural networks , 1(1):4–27.\\nOh, J., Guo, X., Lee, H., Lewis, R. L., and Singh, S. (2015). Action-conditional video pre-\\ndiction using deep networks in atari games. Advances in neural information processing\\nsystems, 28.\\nOlshausen, B. A. and Field, D. J. (1996). Emergence of simple-cell receptive ﬁeld properties\\nby learning a sparse code for natural images. Nature, 381(6583):607–609.\\nOrhan, E., Gupta, V., and Lake, B. M. (2020). Self-supervised learning through the eyes\\nof a child. Advances in Neural Information Processing Systems , 33:9960–9971.\\nPari, J., Shaﬁullah, N. M., Arunachalam, S. P., and Pinto, L. (2021). The surprising\\neﬀectiveness of representation learning for visual imitation. In Robotics Science and\\nSystems 2022. arXiv preprint arXiv:2112.01511.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 53, 'page_label': '54'}, page_content='eﬀectiveness of representation learning for visual imitation. In Robotics Science and\\nSystems 2022. arXiv preprint arXiv:2112.01511.\\nRichalet, J., Rault, A., Testud, J. L., and Papon, J. (1978). Model predictive heuristic\\ncontrol: Applications to industrial processes. Automatica, 14(5):413–428.\\nRiochet, R., Castro, M. Y., Bernard, M., Lerer, A., Fergus, R., Izard, V., and Dupoux, E.\\n(2019). Intphys: A benchmark for visual intuitive physics reasoning. arXiv:1803.07616.\\nSilver, D., Singh, S., Precup, D., and Sutton, R. S. (2021). Reward is enough. Artiﬁcial\\nIntelligence, 299:103535.\\nSobal, V., Canziani, A., Carion, N., Cho, K., and LeCun, Y. (2022). Separating the world\\nand ego models for self-driving. arXiv:2204.07184.\\nSpelke, E. S. and Kinzler, K. D. (2007). Core knowledge. Developmental Science, 10:89–96.\\nSrinivas, A., Jabri, A., Abbeel, P., Levine, S., and Finn, C. (2018). Universal planning\\nnetworks. CoRR, abs/1804.00645.\\n54'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 54, 'page_label': '55'}, page_content='Srivastava, N., Mansimov, E., and Salakhudinov, R. (2015). Unsupervised learning of video\\nrepresentations using lstms. In Bach, F. and Blei, D., editors, Proceedings of the 32nd\\nInternational Conference on Machine Learning , volume 37 of Proceedings of Machine\\nLearning Research, pages 843–852, Lille, France. PMLR.\\nSukhbaatar, S., Weston, J., Fergus, R., et al. (2015). End-to-end memory networks. Ad-\\nvances in neural information processing systems , 28.\\nSutton, R. S. (1991). Dyna, an integrated architecture for learning, planning, and reacting.\\nACM Sigart Bulletin , 2(4):160–163.\\nTaigman, Y., Yang, M., Ranzato, M., and Wolf, L. (2014). Deepface: Closing the gap to\\nhuman-level performance in face veriﬁcation. In Proceedings of the IEEE conference\\non computer vision and pattern recognition , pages 1701–1708.\\nvan den Oord, A., Li, Y., and Vinyals, O. (2018). Representation learning with contrastive\\npredictive coding. arXiv preprint arXiv:1807.03748 .'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 54, 'page_label': '55'}, page_content='van den Oord, A., Li, Y., and Vinyals, O. (2018). Representation learning with contrastive\\npredictive coding. arXiv preprint arXiv:1807.03748 .\\nvan den Oord, A., Vinyals, O., and Kavukcuoglu, K. (2017). Neural discrete representation\\nlearning. In Guyon, I., Luxburg, U. V., Bengio, S., Wallach, H., Fergus, R., Vish-\\nwanathan, S., and Garnett, R., editors, Advances in Neural Information Processing\\nSystems, volume 30.\\nVaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser,  L.,\\nand Polosukhin, I. (2017). Attention is all you need. Advances in neural information\\nprocessing systems, 30.\\nVincent, P., Larochelle, H., Lajoie, I., Bengio, Y., Manzagol, P.-A., and Bottou, L. (2010).\\nStacked denoising autoencoders: Learning useful representations in a deep network\\nwith a local denoising criterion. Journal of machine learning research , 11(12).\\nWalker, J., Razavi, A., and Oord, A. v. d. (2021). Predicting video with vqvae. arXiv\\npreprint arXiv:2103.01950.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 54, 'page_label': '55'}, page_content='with a local denoising criterion. Journal of machine learning research , 11(12).\\nWalker, J., Razavi, A., and Oord, A. v. d. (2021). Predicting video with vqvae. arXiv\\npreprint arXiv:2103.01950.\\nWayne, G. and Abbott, L. (2014). Hierarchical control using networks trained with higher-\\nlevel forward models. Neural Computation, 26(10):2163–2193.\\nWiskott, L. and Sejnowski, T. J. (2002). Slow feature analysis: Unsupervised learning of\\ninvariances. Neural computation, 14(4):715–770.\\nYarats, D., Kostrikov, I., and Fergus, R. (2021). Image augmentation is all you need:\\nRegularizing deep reinforcement learning from pixels. In ICLR.\\nYu, T., Thomas, G., Yu, L., Ermon, S., Zou, J., Levine, S., Finn, C., and Ma, T. (2020).\\nMopo: Model-based oﬄine policy optimization. arXiv preprint arXiv:2005.13239 .\\nZaadnoordijk, L., Besold, T., and Cusack, R. (2022). Lessons from infant learning for\\nunsupervised machine learning. Nature Machine Intelligence , 4:510–520.\\n55'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 55, 'page_label': '56'}, page_content='Zbontar, J., Jing, L., Misra, I., LeCun, Y., and Deny, S. (2021). Barlow twins: Self-\\nsupervised learning via redundancy reduction. In International Conference on Machine\\nLearning, pages 12310–12320. PMLR.\\n56'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 56, 'page_label': '57'}, page_content='Observed variable\\nUnobserved (latent) variables Deterministic function\\ninput output\\nEnergy term\\n \\n  \\nNon-deterministic function\\nFigure 18: Symbols used in architectural diagrams.\\nArchitectural diagrams use symbols commonly used to draw factor graphs – circles for variables,\\nrectangles for factors – plus rounded rectangles to represent deterministic functions. Filled circles\\nrepresent observed variables, or variables that are outputs of deterministic functions.\\nHollow circles represent latent variables, i.e. variables that must be inferred by minimizing some\\ncost, or sampled from a distribution.\\nRed rectangles represent energy terms. These modules have an implicit scalar output that contributes\\nadditively to the total energy of the system. This is similar to the convention used for factor graphs.\\nRounded rectangles represent deterministic functions, which may have one or several inputs. Given'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 56, 'page_label': '57'}, page_content='Rounded rectangles represent deterministic functions, which may have one or several inputs. Given\\na set of inputs, the output is assumed to be easily computable and unique. The function is generally\\nassumed to be diﬀerentiable. It may contain trainable parameters.\\nNon-deterministic functions are represented as shown on the right. They are composed of a deter-\\nministic function g(x,z) in which one of the inputs is a latent variabl z. The latent variable is seen\\nas varying within a level set of a regularizing energy term R(z). When z varies in the level set\\nZh = {z|R(z) <h}, the output ˜y will vary over the set Yh = {y|y= g(x,z),∀z∈Zh}.\\nIn some cases, the energy term can be transformed into a probability distribution (see text).\\nAppendix: Symbols and Notations\\nArchitectural diagrams in this paper use the symbols shown in Figure 18.\\nWe use symbols that are somewhat similar to the representation of factor graphs: circles'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 56, 'page_label': '57'}, page_content='Appendix: Symbols and Notations\\nArchitectural diagrams in this paper use the symbols shown in Figure 18.\\nWe use symbols that are somewhat similar to the representation of factor graphs: circles\\nfor variables, rectangles for factors. There are two major diﬀerences, however. First, the\\nfactors represent additive energy terms, not multiplicative probability factors. Second, we\\nuse an additional symbol, rounded rectangles, to represent deterministic functions with a\\nclear directionality from inputs to outputs.\\nMore precisely:\\n• Filled circles represent observed variables, or variables that are outputs of determin-\\nistic functions.\\n• Hollow circles represent latent variables, i.e. variables that must be inferred by mini-\\nmizing some cost, varied over a set, or sampled from a distribution.\\n• Red rectangles represent energy terms. These modules have an implicit scalar output\\nthat contributes additively to the total energy of the system.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 56, 'page_label': '57'}, page_content='• Red rectangles represent energy terms. These modules have an implicit scalar output\\nthat contributes additively to the total energy of the system.\\n• Rounded rectangles represent deterministic functions, which may have one or sev-\\neral inputs. Given a set of inputs, the output is assumed to be easily computable\\nand unique. The function is generally assumed to be diﬀerentiable. It may contain\\ntrainable parameters. Such a module is typically implemented as a deep neural net.\\n57'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 57, 'page_label': '58'}, page_content='Non-deterministic functions do not have a dedicated symbol, but must be represented\\nas a combination of deterministic functions, energy modules, and latent variables. An\\nexample is shown on the right of Figure 18. A non-deterministic function is represented\\nby a deterministic function ˜y = g(x,z) whose output depends on a latent variable z. The\\nlatent variable is fed to a regularizing energy term R(z). We ﬁrst deﬁne Zh as the level set\\nof z, i.e. the set of z for which R(z) is less than a threshold h:\\nZh = {z/R(z) <h} (21)\\nAs z varies over Zh, the output will vary over the set:\\nYh = {y|y= g(x,z),∀z∈Zh} (22)\\nIn some cases, this setup may be used to represent probability distributions. Forst,\\nthe energy term is transformed into a probability distribution using a Gibbs-Boltzmann\\nformula:\\nP(z) = exp(−R(z))∫\\nz′ exp(−R(z′)) (23)\\nDrawing the latent variable from this distribution implies a distribution over y:\\nP(y|x) =\\n∫\\nz\\nδ(y−g(x,z))P(z) (24)\\nwhere δ() is the Dirac delta function.\\n58'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 58, 'page_label': '59'}, page_content='Figure 19: Amortized Inference with an EBM. An encoder is trained to produce ˜z = Enc(sx,y)\\nto approximate the value of the latent that minimizes the energy ˇz = argminz∈Z Ew(x,y,z ). The\\nregularizer R(z) plays the essential role of limiting the information that z contains about y. This\\nis particularly important here because the system has access to y and can “cheat” by carrying the\\ncomplete information about y through the encoder.\\nAppendix: Amortized Inference for Latent Variables\\nInference in latent variable models consists in performing the optimization\\nˇz = argmin z∈ZEw(x,y,z ). When z is continuous, this may be best performed through\\na gradient-based optimization that involves backpropagating gradients through the model\\ndowen to z for multiple iterations. In generative architectures, this may be expensive,\\nrequiring to back-propagate through the decoder and the predictor. One way to reduce the'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 58, 'page_label': '59'}, page_content='dowen to z for multiple iterations. In generative architectures, this may be expensive,\\nrequiring to back-propagate through the decoder and the predictor. One way to reduce the\\ncost of inference is to use amortized inference. The idea is to train a neural net to predict\\nan approximate solution to the inference optimization problem.\\nThe architecture is depicted in Figure 20. An encoder ˜ z = Enc( sx,y) is trained to\\nminimize a divergence measure H(ˇz,˜z) between the encoder output and the optimal latent\\nvariable ˇz = argmin z∈ZEw(x,y,z ). Once trained, the prediction ˜ z may be use as an\\nestimate of ˇz or as an initial value for the inference optimization.\\n59'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 59, 'page_label': '60'}, page_content='Figure 20: Amortized Inference with a Regularized Generative Latent-Variable EBM architecture.\\nAn encoder is trained to produce ˜z = Enc( sx,y) to approximate the value ˇz that minimizes the\\nenergy. The regularizer R(z) plays the essential role of limiting the information that z contains\\nabout y. This is particularly important here because the system has access to y and can “cheat” by\\ncarrying the complete information about y through the encoder.\\nThe regularizer R(z) is even more important than in the regular inference case because\\nthe prediction pathway has access toyand can “cheat” by carrying the complete information\\nabout ythrough the encoder. Without an information-limiting regularizer This would cause\\na collapse of the energy function, since it would allow any y to be reconstructed perfectly.\\nThe regularizer is there to minimize the information that ˇz may contains about y.\\nVariational Auto-Encoders, and LISTA-style sparse Auto-Encoders belong to the family'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 59, 'page_label': '60'}, page_content='The regularizer is there to minimize the information that ˇz may contains about y.\\nVariational Auto-Encoders, and LISTA-style sparse Auto-Encoders belong to the family\\nof Regularized GLVEBM with amortized inference. Most of those models are unconditional\\nand do not possess an x nor an Enc(x) module.\\n60'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 60, 'page_label': '61'}, page_content='Appendix: Loss functions for Contrastive Training of EBM\\nMuch can be said about contrastive methods. Table 1 lists a few examples of contrastive\\nmethods, together with their strategy for picking contrastive samples ˆy and their loss func-\\ntional.\\nRows 1-2 in the table are exact maximum likelihood methods. They assume that the\\ngradient of the log partition function can be computed exactly. Rows 2-4 are approxi-\\nmate maximum likelihood methods. Rows 5-10 are not interpretable within a probabilistic\\nframework.\\nRow 1: Maximum Conditional Likelihood for discrete y is used whenever the\\nenergy needs to be turned into a probability distribution. through a Gibbs formulaP(y|x) =\\nexp(−Fw(x,y))/∑\\ny′∈Yexp(−Fw(x,y′). The loss is the negative log conditional likelihood.\\nThis is the prevalent approach when y is a discrete variable within a ﬁnite set (e.g. for\\nclassiﬁcation).\\nRow 2 and 3: Maximum Conditional Likelihood is used for any model that should'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 60, 'page_label': '61'}, page_content='This is the prevalent approach when y is a discrete variable within a ﬁnite set (e.g. for\\nclassiﬁcation).\\nRow 2 and 3: Maximum Conditional Likelihood is used for any model that should\\nproduce probability estimates. Row 2 only applies to tractable models in which the integral\\nin the contrastive term (or its gradient) can be computed analytically. Row 3 applies to\\nsituations where the integral is intractable and its gradient must be approximated by Monte\\nCarlo sampling methods. It then comes down to devising good methods to sample ˆy values\\nfrom the model’s Gibbs distribution: Pw(y|x) = exp(−βFw(x,y)/\\n∫\\ny′ exp(−βFw(x,y′).\\nRow 4: Contrastive Divergence . MCMC sampling methods for Row 3 may take a\\nlong time to mix. One may start from a training sample and let the Markov chain evolve\\nfor a short time, and then accept or reject the resulting sample so as to satisfy detailed\\nbalance (Carreira-Perpi˜ n´ an and Hinton, 2005).'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 60, 'page_label': '61'}, page_content='for a short time, and then accept or reject the resulting sample so as to satisfy detailed\\nbalance (Carreira-Perpi˜ n´ an and Hinton, 2005).\\nRow 5: Pairwise hinge , also known as triplet loss, drives the energy of the correct\\noutput to be lower than the energy of the contrastive output by at least a margin m(y,ˆy)\\nwhich may grow with a measure of divergence between y and ˆy. The diﬃculty is to ﬁnd\\nsuitable contrastive samples whose energy is low and “threatening”, a task sometimes called\\n“hard negative mining”.\\nRows 6-8: Min-hinge, Square-hinge, Square-exp . Assumes that the energy has\\na lower bound. minimizes the energy of the correct output and pushes the energy of con-\\ntrastive outputs above a margin equal to m(y,ˆy) for rows 6 and 7, and inﬁnite for row\\n8.\\nRow 8: Logistic. As with the pairwise hinge, the logistic loss maximizes the diﬀerence\\nbetween the energies of the contrastive output and the correct output. Unlike the pairwise'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 60, 'page_label': '61'}, page_content='8.\\nRow 8: Logistic. As with the pairwise hinge, the logistic loss maximizes the diﬀerence\\nbetween the energies of the contrastive output and the correct output. Unlike the pairwise\\nhinge, the diﬀerence is pushed to inﬁnity, but with a force that decreases quickly.\\nRow 9: GAN . A GAN diﬀers from other contrastive methods in the way contrastive\\nsamples are generated. The contrastive samples are produced by a generator network that\\nis trained preferentially generate samples that have low energy according to the model. In\\nprinciple, any loss function can be used, as long as it increases with the energy of the correct\\noutput, and decreases with the energy of the contrastive sample.\\nRow 10: Denoising Auto-Encoder . A denoising AE produces contrastive samples\\nby corrupting outputs from training samples. The corruption can be performed by adding\\nnoise or by masking parts of the output. The energy function is the reconstruction error,\\n61'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 61, 'page_label': '62'}, page_content='hence the energy is trained to be zero on the data manifold, and to grow with D(y,ˆy) as ˆy\\nmoves away from y on the data manifold.\\nMethod Energy ˆy Generation Loss\\n1 Max Likelihood discrete y exhaustive Fw(x,y) + log∑\\ny′∈Yexp(−Fw(x,y′))\\n2 Max Likelihood tractable exhaustive Fw(x,y) + log\\n∫\\ny′∈Yexp(−Fw(x,y′))\\n3 Max likelihood any MC or MCMC Fw(x,y) −Fw(x,ˆy)\\n4 Contr. Divergence any trunc’d MCMC Fw(x,y) −Fw(x,ˆy)\\n5 Pairwise Hinge any most oﬀending [Fw(x,y) −Fw(x,ˆy) + m(y,ˆy)]+\\n6 Min-Hinge positive most oﬀending Fw(x,y) + [m(y,ˆy) −Fw(x,ˆy)]+\\n6 Square-Hinge divergence most oﬀending Fw(x,y)2 +\\n(\\n[m(y,ˆy) −Fw(x,ˆy)]+)2\\n7 Square-Exp any most oﬀending Fw(x,y)2 + exp(−βFw(x,ˆy))\\n8 Logistic any most oﬀending log(1 + exp(Fw(x,y) −Fw(x,ˆy))\\n9 GAN any ˆy= gu(z) H(Fw(x,y),Fw(x,ˆy),m(y,ˆy))\\n10 Denoising AE D(y,gw(y)) ˆy= N(y) D(y,gw(ˆy)\\nTable 1: A of list of contrastive methods and loss functions to train energy-based models. They'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 61, 'page_label': '62'}, page_content='9 GAN any ˆy= gu(z) H(Fw(x,y),Fw(x,ˆy),m(y,ˆy))\\n10 Denoising AE D(y,gw(y)) ˆy= N(y) D(y,gw(ˆy)\\nTable 1: A of list of contrastive methods and loss functions to train energy-based models. They\\nare all use loss functions with two terms, one that pushes down on the energy of a training sample,\\nand one the pulls up the energies of one or several contrastive samples.\\nThey diﬀer by the strategy they employ to generate contrastive samples, and by the precise form of\\nthe loss function.\\nExact or approximate Maximum Likelihood methods (rows 1-4) are used whenever the model needs to\\nproduce probability estimates. When the second term is intractable, its gradient may be approximated\\nthrough Monte-Carlo methods, which can be seen as particular ways to produce ˆy. Many contrastive\\nself-supervised methods for joint embedding architectures (Siamese nets) use Row 1 (InfoNCE).\\nA number of contrastive methods (Rows 5-8) are based on ﬁnding a ˆy that is “highly oﬀending”,'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 61, 'page_label': '62'}, page_content='self-supervised methods for joint embedding architectures (Siamese nets) use Row 1 (InfoNCE).\\nA number of contrastive methods (Rows 5-8) are based on ﬁnding a ˆy that is “highly oﬀending”,\\nmeaning diﬀerent from the desired y, yet given a low energy by the model. Pairs of energies for y\\nand ˆy are fed to a loss function that pushes the former to low values and the latter to higher values.\\nThis can be done with a variety of losses including hinge loss.\\nGANs (row 9) are contrastive methods in which the contrastive samples are produced by a generator\\nnetwork whose input is a random vector. The generator is trained to produce samples to which the\\nmodel currently attributes a low energy, but should attribute a high energy.\\nDenoising Auto-Encoders (row 10) apply a corruption process to training samples to produce con-\\ntrastive samples ˆy = N(y). The energy function is the reconstruction error Fw(y) = D(y,gw(y))'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 61, 'page_label': '62'}, page_content='Denoising Auto-Encoders (row 10) apply a corruption process to training samples to produce con-\\ntrastive samples ˆy = N(y). The energy function is the reconstruction error Fw(y) = D(y,gw(y))\\nwhere D() is a symmetric divergence measure and gw(y) a parameterized function. By training gw()\\nto map ˆy to y, the energy for ˆy is trained to be equal to D(ˆy,y), while the energy of y is trained to\\nbe zero.\\n62'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 0, 'page_label': '1'}, page_content='Harms from Increasingly Agentic Algorithmic Systems\\nALAN CHAN∗†‡ , Mila, Université de Montréal, Canada\\nREBECCA SALGANIK†, Mila, Université de Montréal, Canada\\nALVA MARKELIUS†, University of Cambridge, UK\\nCHRIS PANG†, University of Cambridge, UK\\nNITARSHAN RAJKUMAR†, University of Cambridge, UK\\nDMITRII KRASHENINNIKOV†, University of Cambridge, UK\\nLAURO LANGOSCO†, University of Cambridge, UK\\nZHONGHAO HE†, University of Cambridge, UK\\nYAWEN DUAN†, University of Cambridge, UK\\nMICAH CARROLL†, University of California, Berkeley, SUA\\nMICHELLE LIN,McGill University, Canada\\nALEX MAYHEW,University of Western Ontario, Canada\\nKATHERINE COLLINS,University of Cambridge, UK\\nMARYAM MOLAMOHAMMADI,Mila, Canada\\nJOHN BURDEN,Center for the Study of Existential Risk, University of Cambridge, UK\\nWANRU ZHAO,University of Cambridge, UK\\nSHALALEH RISMANI,McGill University, Mila, Canada\\nKONSTANTINOS VOUDOURIS,University of Cambridge, UK\\nUMANG BHATT,University of Cambridge, UK'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 0, 'page_label': '1'}, page_content='WANRU ZHAO,University of Cambridge, UK\\nSHALALEH RISMANI,McGill University, Mila, Canada\\nKONSTANTINOS VOUDOURIS,University of Cambridge, UK\\nUMANG BHATT,University of Cambridge, UK\\nADRIAN WELLER,University of Cambridge, UK\\nDAVID KRUEGER∗, University of Cambridge, UK\\nTEGAN MAHARAJ∗† , University of Toronto, Canada\\nResearch in Fairness, Accountability, Transparency, and Ethics (FATE)1 has established many sources and forms of algorithmic harm,\\nin domains as diverse as health care, finance, policing, and recommendations. Much work remains to be done to mitigate the serious\\nharms of these systems, particularly those disproportionately affecting marginalized communities. Despite these ongoing harms, new\\nsystems are being developed and deployed, typically without strong regulatory barriers, threatening the perpetuation of the same\\nharms and the creation of novel ones. In response, the FATE community has emphasized the importance of anticipating harms, rather'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 0, 'page_label': '1'}, page_content='harms and the creation of novel ones. In response, the FATE community has emphasized the importance of anticipating harms, rather\\nthan just responding to them. Anticipation of harms is especially important given the rapid pace of developments in machine learning\\n(ML). Our work focuses on the anticipation of harms from increasingly agentic systems. Rather than providing a definition of agency\\n∗Major contributions to the project direction and framing.\\n†Major contributions to the writing. Authors with only this mark have had their order randomized. Authors without a mark also have their orders\\nrandomized.\\n‡Correspondence to alan.chan@mila.quebec.\\n1We use the term FATEas a shorthand, keeping in mind and valuing the ideological diversity of those who work on FATE and related disciplines not\\ncaptured in this acronym.\\n2023. Manuscript submitted to ACM\\nManuscript submitted to ACM 1\\narXiv:2302.10329v1  [cs.CY]  20 Feb 2023'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 1, 'page_label': '2'}, page_content='2 Chan et al.\\nas a binary property, we identify 4 key characteristics which, particularly in combination, tend to increase the agency of a given\\nalgorithmic system: underspecification, directness of impact, goal-directedness, and long-term planning. We also discuss important\\nharms which arise from increasing agency – notably, these include systemic and/or long-range impacts, often on marginalized or\\nunconsidered stakeholders. We emphasize that recognizing agency of algorithmic systems does not absolve or shift the human\\nresponsibility for algorithmic harms. Rather, we use the term agency to highlight the increasingly evident fact that ML systems are not\\nfully under human control. Our work explores increasingly agentic algorithmic systems in three parts. First, we explain the notion of\\nan increase in agency for algorithmic systems in the context of diverse perspectives on agency across disciplines. Second, we argue for'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 1, 'page_label': '2'}, page_content='an increase in agency for algorithmic systems in the context of diverse perspectives on agency across disciplines. Second, we argue for\\nthe need to anticipate harms from increasingly agentic systems. Third, we discuss important harms from increasingly agentic systems\\nand ways forward for addressing them. We conclude by reflecting on implications of our work for anticipating algorithmic harms\\nfrom emerging systems.\\nAdditional Key Words and Phrases: algorithmic systems, harms, safety, sociotechnical systems, negative externalities, agency, autonomy,\\npower, delayed impacts, ethics, FATE\\nACM Reference Format:\\nAlan Chan, Rebecca Salganik, Alva Markelius, Chris Pang, Nitarshan Rajkumar, Dmitrii Krasheninnikov, Lauro Langosco, Zhonghao\\nHe, Yawen Duan, Micah Carroll, Michelle Lin, Alex Mayhew, Katherine Collins, Maryam Molamohammadi, John Burden, Wanru\\nZhao, Shalaleh Rismani, Konstantinos Voudouris, Umang Bhatt, Adrian Weller, David Krueger, and Tegan Maharaj. 2023. Harms from'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 1, 'page_label': '2'}, page_content='Zhao, Shalaleh Rismani, Konstantinos Voudouris, Umang Bhatt, Adrian Weller, David Krueger, and Tegan Maharaj. 2023. Harms from\\nIncreasingly Agentic Algorithmic Systems. 1, 1 (February 2023), 25 pages. https://doi.org/10.1145/nnnnnnn.nnnnnnn\\n1 INTRODUCTION\\nThe promised benefits of algorithmic systems have not always been borne out, and benefits are often tempered by\\nsignificant negative externalities. Although the deployment of algorithmic systems may result in increased safety or\\nmaterial improvements to human well-being [Abebe and Goldner 2018; Jumper et al . 2021; Li et al . 2017], diverse\\nlines of work in Fairness, Accountability, Transparency, and Ethics (FATE) have established the roles that algorithmic\\nsystems play in causing harm. Examples include the perpetuation of existing, unjust power relations [Barabas et al.\\n2018; Buolamwini and Gebru 2018; Ehsan et al. 2022; Kasy and Abebe 2021; steven t. piantadosi [@spiantado] 2022;'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 1, 'page_label': '2'}, page_content='2018; Buolamwini and Gebru 2018; Ehsan et al. 2022; Kasy and Abebe 2021; steven t. piantadosi [@spiantado] 2022;\\nWolfe and Caliskan 2022], the generation of toxic language [Abid et al. 2021; Gehman et al. 2020], and informational\\nharms [Carroll et al. 2022; Jiang et al. 2019; Li et al. 2022; Weidinger et al. 2022].\\nDespite the clear evidence of harms from existing systems, new types of algorithmic systems are continually being\\ndeveloped and deployed, often without strong regulatory barriers [Gesley et al. 2019]. The pace of development has\\nbeen particularly rapid in the machine learning (ML) community. Just in the last five years, we have witnessed large\\nimprovements in the capabilities of systems to perform a variety of real-world tasks, including search [Nayak 2019],\\ndrug discovery [Jumper et al. 2021; Stokes et al. 2020], and dialogue [OpenAI 2022].\\nResearchers in the FATE community have responded to the rapid pace of ML developments by emphasizing the need'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 1, 'page_label': '2'}, page_content='drug discovery [Jumper et al. 2021; Stokes et al. 2020], and dialogue [OpenAI 2022].\\nResearchers in the FATE community have responded to the rapid pace of ML developments by emphasizing the need\\nto anticipate harms, rather than just react to them. In particular, many have identified the impact of computational\\nmodeling and development in social change [Abebe et al. 2020; Jacobs and Wallach 2021; Selbst et al. 2019] and scoped\\nnumerous taxonomies of risks, harms, and failures of algorithmic systems [Raji et al. 2022; Shelby et al. 2022; Weidinger\\net al. 2022]. While it is crucial not to idealize or over-hype a model’s performance by ignoring model failures [Bender\\net al. 2021; Bender and Koller 2020; Blodgett et al. 2021; Collins et al. 2022; Lin et al. 2022; Raji et al. 2022; Vinsel 2021],\\nit is also important not to understate (and thus fail to anticipate negative consequences of) what these models can do'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 1, 'page_label': '2'}, page_content='it is also important not to understate (and thus fail to anticipate negative consequences of) what these models can do\\nand may be capable of doing in the near future [Bowman 2022; Hoffmann et al. 2022; Kaplan et al. 2020], especially\\ngiven growing investments in the field [Giattino et al. 2022].\\nManuscript submitted to ACM'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 2, 'page_label': '3'}, page_content='Harms from Increasingly Agentic Algorithmic Systems 3\\nIn this paper, we continue the work of anticipating harms by drawing attention to increasingly agentic algorithmic\\nsystems. We use agency and agentic in a narrow sense for our work as applied to algorithmic systems, particularly ML\\nsystems. While recognizing the many meanings of agency, as well as the need not to absolve humans of responsibility\\npertaining to algorithmic harms [Cooper et al . 2022; Nissenbaum 1996; Wieringa 2020], we use the term agency\\nconsciously to counter the somewhat view that the developers of an algorithmic system have full control over its\\nbehaviour. Johnson and Verdicchio [2017] claims that “the behaviour of computational artefacts is in the control of the\\nhumans that design them. ” In a systematic review on algorithmic accountability, Wieringa [2020] defines algorithms\\nas “basically instructions fed to a computer”. While this description is accurate for many purposes, we argue that,'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 2, 'page_label': '3'}, page_content='as “basically instructions fed to a computer”. While this description is accurate for many purposes, we argue that,\\nparticularly for ML-based algorithmic systems, it elides responsive and interactive qualities of these systems which can\\nso easily lead to unforeseen outcomes. Cooper et al. [2022]; Nissenbaum [1996] do identify bugs – including faulty\\nmodeling premises and bad model performance – as one way in which humans may not have total control of the\\noperation of an algorithmic system. However, we view agency as distinct from mistakes or bugs and demonstrate the\\nunique and important harms that can result. We note there are significant economic and military incentives to build\\nincreasingly agentic systems. Indeed, many in the ML community are explicitly building such systems as a research\\ngoal [Chen et al. 2021; Reed et al. 2022; Sutton et al. 2022]. In summary, our contributions are :'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 2, 'page_label': '3'}, page_content='goal [Chen et al. 2021; Reed et al. 2022; Sutton et al. 2022]. In summary, our contributions are :\\n(1) We identify characteristics that tend to increase agency of algorithmic systems, and situate our characterization\\nin the context of diverse perspectives on agency across disciplines. We articulate that even when recognizing\\nagency in algorithmic systems, we can and should emphasize the human responsibility to prevent harms.\\n(2) We argue for the need to anticipate harms from increasingly agentic systems. Increasingly agentic systems are\\nbeing developed and there exist strong incentives for this work to continue.\\n(3) We discuss some harms to be anticipated from increasingly agentic systems. In so doing, we connect to ongoing\\nlines of work in the FATE community, including systemic and delayed effects, an impoverishment of collective\\ndecision-making power, and exacerbation of extreme concentrations of power in the hands of a few. We also'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 2, 'page_label': '3'}, page_content='decision-making power, and exacerbation of extreme concentrations of power in the hands of a few. We also\\ndiscuss the role of increasing agency as a source of harms that are yet to be identified.\\nThis paper is not about the moral agency or consciousness of algorithms or machines. Instead, we focus on identifying\\na property of emerging ML systems, argue for the need to anticipate harms from systems that increasingly satisfy this\\nproperty, and discuss the harms to be anticipated.\\n2 AGENCY\\nIn colloquial use, agency refers to the ability to take actions or affect outcomes. A difficulty of having concrete\\ndiscussions on agency is the variety of perspectives through which such a concept can be defined, making confusion\\nand disagreement common. In recognition of this variety of perspectives, we do not attempt to define agency in a\\nbinary manner, but instead present a set of characteristics we take to be associated with increasing agency, i.e. the more'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 2, 'page_label': '3'}, page_content='binary manner, but instead present a set of characteristics we take to be associated with increasing agency, i.e. the more\\nof these characteristics a system has, particularly in combination, the more agency we can consider it to have. We first\\npresent our characterization, and follow by contextualizing it in some of the most relevant perspectives and related\\nconcepts to our work.\\n2.1 Characteristics that are Associated with Increasing Agency in Algorithmic Systems\\nWe identify 4 key characteristics associated with increasing agency in algorithmic systems, especially in combination:\\nunderspecification, directness of impact, goal-directedness, and long-term planning. When we say that an algorithmic\\nsystem has a degree of agency, we mean that it is to some extent an agent or agentic.Agency is the property, agent\\nManuscript submitted to ACM'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 3, 'page_label': '4'}, page_content='4 Chan et al.\\nis the role, and agentic is the adjective. Our characterization of agency is specific to algorithmic systems and is not\\nmeant to define agency for humans or arbitrary entities. We will sometimes use “agentic system” in place of “agentic\\nalgorithmic system” for brevity.\\n(1) Underspecification: the degree to which the algorithmic system can accomplish a goal provided by operators\\nor designers, without a concrete specification of how the goal is to be accomplished [D’Amour et al. 2020a].\\n(2) Directness of impact: the degree to which the algorithmic system’s actions affect the world without mediation\\nor intervention by a human, i.e. without a human in the loop.\\n(3) Goal-directedness: the degree to which the system is designed/trained to achieve a particular quantifiable\\nobjective.\\n(4) Long-term planning: the degree to which the algorithmic system is designed/trained to make decisions that'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 3, 'page_label': '4'}, page_content='objective.\\n(4) Long-term planning: the degree to which the algorithmic system is designed/trained to make decisions that\\nare temporally dependent upon one another to achieve a goal and/or make predictions over a long time horizon.\\nTo illustrate the notion of increasing agency, consider the task of compiling a literature review on a certain sub-\\nject. With a search engine, the human user must type in queries, click on related works, read papers, look through\\nbibliographies, record relevant information in a document, and edit the text. A system that was more agentic than\\nthe search engine, still for the same task, could simply be queried with the topic of the desired literature review, and\\nwould automatically look through related works on the internet without user intervention, like WebGPT can do to\\nsome extent [Nakano et al. 2022]. The user would not need (or be able to) to specify which papers were relevant nor\\nhave to compile papers manually into a document.\\n2.2 Prior Work on Agency'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 3, 'page_label': '4'}, page_content='some extent [Nakano et al. 2022]. The user would not need (or be able to) to specify which papers were relevant nor\\nhave to compile papers manually into a document.\\n2.2 Prior Work on Agency\\nAgency is a central concept in many fields of academia [Schlosser 2019]. Dennett [1981] provides one of the most\\npopular analyses of when and how to attribute agency, focusing on the notion that agents behave intentionally. Orseau\\net al. [2018] and more recently Kenton et al. [2022] have attempted to formalize this notion of agency in the context\\nof artificial intelligence. In cognitive science and psychology, agency is conceptualized relatively similarly, as having\\nintentions, plans, goals, communication, and reasoning [Lake et al. 2017; Spelke and Kinzler 2007] – entities with agency\\ncan plan, act, memorize, exert self-control, and communicate with others. While these notions of agency focus on'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 3, 'page_label': '4'}, page_content='can plan, act, memorize, exert self-control, and communicate with others. While these notions of agency focus on\\nindividuals making rational choices in pursuit of some goal, in sociology, agency is often thought of as contextualized\\nwithin, constrained by, and/or contrasted with structure [Emirbayer and Mische 1998].\\nPrincipal-agent theory [Eisenhardt 1989; Jensen and Meckling 1976] provides more intuition for how we charac-\\nterize agency. Principal-agent theory concerns itself with aprincipal who delegates tasks to an agent in order to achieve\\ntheir goals. The agent acts (directness of impact) on behalf of the principal to achieve the principal’s goals, which may\\nbe long-horizon (long-term planning). Crucially, the agent and principal have different incentives2 and information: the\\nprincipal does not tell the agent how to complete the tasks (underspecification). In our context, we view the principal'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 3, 'page_label': '4'}, page_content='principal does not tell the agent how to complete the tasks (underspecification). In our context, we view the principal\\nas humans and the agent as algorithmic systems, as done in prior work [Hadfield-Menell and Hadfield 2019]. It is in\\nthis sense that we consider algorithmic systems to have agency.\\nOur notion of increasing agency also takes inspiration from how the term agent is used in AI research. In the\\nmost popular introductory text on artificial intelligence, Russell and Norvig [2021, p. 58] define a rational agent as\\nfollows: “For each possible percept sequence, a rational agent should select an action that is expected to maximize its\\nperformance measure, given the evidence provided by the percept sequence and whatever built-in knowledge the agent\\n2It is coherent to talk about the incentives of algorithmic systems. See Everitt et al. [2021].\\nManuscript submitted to ACM'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 4, 'page_label': '5'}, page_content='Harms from Increasingly Agentic Algorithmic Systems 5\\nhas. ” Russell and Norvig [2021, p. 60] further states that “To the extent that an agent relies on the prior knowledge of its\\ndesigner rather than on its own percepts and learning processes, we say that the agent lacks autonomy. A rational\\nagent should be autonomous—it should learn what it can to compensate for partial or incorrect prior knowledge. ” While\\nour characterization does not consider (ir)rationality, goal-directedness and underspecification are captured in this\\ndefinition.\\nReinforcement learning is a field that concentrates on the construction of agents. In the field’s premier introductory\\ntext, Sutton and Barto [2018, p. 47-8] states that the “learner and decision maker is called the agent. The thing it interacts\\nwith, comprising everything outside the agent, is called the environment. These interact continually, the agent selecting'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 4, 'page_label': '5'}, page_content='with, comprising everything outside the agent, is called the environment. These interact continually, the agent selecting\\nactions and the environment responding to these actions and presenting new situations to the agent. The environment\\nalso gives rise to rewards, special numerical values that the agent seeks to maximize over time through its choice of\\nactions. ” Note that reinforcement learning is not the only way of constructing agents, however. For instance, recent work\\nhas shown that foundation models can perform planning tasks [Huang et al. 2022]. Even simple predictive algorithms,\\ndepending on their training procedure, can follow incentives to affect the world in unexpected ways – for example by\\nshifting user interests rather than improving at their predictive task [Krueger et al. 2020], thus increasing their agency.\\nOne of the difficult discussions surrounding agency is interaction of agency and responsibility, for humans and for'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 4, 'page_label': '5'}, page_content='One of the difficult discussions surrounding agency is interaction of agency and responsibility, for humans and for\\nmachines. Goetze [2022] identifies aresponsibility gap between engineers and the outcomes of their designed systems\\n– people designing autonomous systems are far removed from the consequences of their deployment. The authors\\ncontend that regardless of the system’s autonomy, human designers must be the ones held accountable. [Sullivan and\\nFosso Wamba 2022] investigate attitudes toward agency of fictional AI robots, and find survey respondents do not\\ntypically consider AI systems to be moral agents – they tend to place moral responsibility on developers, not on AI\\nsystems as agents. Similarly, Robinette et al. [2016] examines (over)trust of autonomous systems and find in emergency\\nsituations, people will follow robots into further danger, because they attribute the agency of the robot to the (assumed'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 4, 'page_label': '5'}, page_content='situations, people will follow robots into further danger, because they attribute the agency of the robot to the (assumed\\ncapable and responsible) designers. As people in these situations appear to, we distinguish agency from responsibility,\\nand emphasize that attribution of agency to an autonomous system in no way intends to shift moral responsibility from\\nhumans onto that system.\\nLeufer [2020]; Myths [[n. d.]] examine another aspect of this problem, describing AI agency as a myth which\\nmasks human agency (and therefore responsibility). The authors contend that anthropomorphization of AI systems\\ncontributes to mystification of the underlying technology and sociotechnical blindness [Johnson and Verdicchio 2017],\\nwherein people “believe AI systems got to be the way they are without human intervention”, and obscuring of the\\n(often exploitative) human labour which enables AI systems to exist [Gray and Suri 2019; Pasquinelli and Joler 2021;'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 4, 'page_label': '5'}, page_content='(often exploitative) human labour which enables AI systems to exist [Gray and Suri 2019; Pasquinelli and Joler 2021;\\nPerrigo 2023]. While we strongly agree with all these points, we reach the opposite conclusion – AI agency (in the\\nsense of our work) is not a myth, it is a reality of increasing sociotechnical importance. It is precisely because of the\\nimportance of problems like these (responsibility gap, mystification, sociotechnical blindness, masking human agency\\nand labour, etc.) and their far-ranging implications that we need to carefully examine the agency of AI systems, not\\ndismiss it out of hand. If we think it is categorically impossible for AI systems to have agency, we will never be able to\\naccurately recognize when we are giving up our agency to them.\\nA related concept we wish to distinguish from agency is autonomy. Bekey [2005] defines autonomy as “the ability'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 4, 'page_label': '5'}, page_content='accurately recognize when we are giving up our agency to them.\\nA related concept we wish to distinguish from agency is autonomy. Bekey [2005] defines autonomy as “the ability\\nto operate without a human operator for a protracted period of time. ” Many factory robots are highly autonomous, but\\nthey operate strictly within the confines of a factory, and the actions they take affect only the intended outcome (e.g.\\nthe product they’re making) – they are autonomous but do not have agency. Welsh [2019] presents a series of protocols\\nManuscript submitted to ACM'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 5, 'page_label': '6'}, page_content='6 Chan et al.\\nwhich can be used to govern the use of lethal autonomous weapons, emphasizing the need for human-in-the-loop\\ndecision making – i.e. to ensure all agency rests with human controllers.\\nIn this vein, our focus on agency also shares many commonalities with work from the FATE community on establishing\\nthe harms of automated decision-making (ADM) . ADM involves the use of algorithms to make decisions or enact\\npolicies without human intervention. Given its applications in recommendations [Li et al. 2022; Milano et al. 2020],\\nhealth-care systems [Fogliato et al. 2022; Obermeyer and Mullainathan 2019; Sendak et al. 2020], the judicial sector\\n[Barabas et al. 2020; Green 2020; Zilka et al . 2022], and public services [Black et al . 2022; Loi and Spielkamp 2021;\\nStapleton et al. 2022], ADM can often exhibit similar kinds of diffuse and long-term harms to those we discuss coming'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 5, 'page_label': '6'}, page_content='Stapleton et al. 2022], ADM can often exhibit similar kinds of diffuse and long-term harms to those we discuss coming\\nfrom increased agency. Given the commonalities, many of the harms of ADM also apply to increasingly agentic systems,\\nas we discuss in Section 4. But there are two key differences between the body of work on ADM and our work. First,\\nwith the term agency we emphasize lack of explicit or low-level instructions for behaviour - we might specify a\\ntask, but not how to solve that task. Second, our work explicitly targets systems that are increasingly agentic, such as\\nreinforcement-learning systems that are capable of making decisions in an open-ended environment over long time\\nhorizons without human intervention. Such systems have not been the focus of work in ADM simply because they\\nhave not yet seen widespread public deployment. We thus consider our focus on agency to be a continuation of current\\nwork on ADM.'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 5, 'page_label': '6'}, page_content='have not yet seen widespread public deployment. We thus consider our focus on agency to be a continuation of current\\nwork on ADM.\\nSome philosophical work on agency also focuses on mental states such as, consciousness, emotional states, and\\nsubjective experience [Schlosser 2019]. Entities with these mental states have personalities, and feel things like pleasure,\\ncuriosity, pain, embarrassment, fear and joy. Our work does not address experience or consciousness, only agency.\\n2.3 Potential Objections to our Use of Agency\\nOne objection against framing algorithmic systems as agents is that it distracts from the responsibility of humans. As\\nnoted above, we characterize agency as separate from responsiblity. More attention should be directed towards holding\\ncorporations, regulators, developers, etc (actors for short in this section) accountable [Cooper et al. 2022; Johnson and\\nVerdicchio 2017; Nissenbaum 1996; Wieringa 2020].'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 5, 'page_label': '6'}, page_content='corporations, regulators, developers, etc (actors for short in this section) accountable [Cooper et al. 2022; Johnson and\\nVerdicchio 2017; Nissenbaum 1996; Wieringa 2020].\\nWe strongly agree with the need to hold actors accountable. This claim is not in contention with the idea that\\nalgorithmic systems can be agentic in our narrow sense. Principals can be held responsible on behalf of their agents,\\nsuch as when employers are held liable for negligent hiring when employees cause harm [Hickox 2010].\\nWe should also require more than just individual accountability. In addition to focusing on individual actors, we\\nshould also attend to structural factors that shape their behaviours. A developer is likely blameworthy at least to\\nsome extent when a system causes harm, but structural factors like economic incentives to push forward likely also\\nplay significant roles [van der Loeff et al. 2019; Zwetsloot and Dafoe 2019]. As we will discuss in Section 4, viewing'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 5, 'page_label': '6'}, page_content='play significant roles [van der Loeff et al. 2019; Zwetsloot and Dafoe 2019]. As we will discuss in Section 4, viewing\\nalgorithmic systems as agents can in fact highlight harms and the collective responsibility we have to prevent them.\\n3 THE NEED TO ANTICIPATE HARMS FROM INCREASINGLY AGENTIC SYSTEMS\\nWe argue for the need to anticipate harms from increasingly agentic systems. Anticipation is about two things: (1)\\nthe development of systems with increasing agency and (2) the deployment of systems with more agency than those\\nalready deployed. We touch upon trends in ML development and deployment as well as some reasons to expect these\\ntrends to continue. In Section 3.3 we respond to some potential objections.\\nManuscript submitted to ACM'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 6, 'page_label': '7'}, page_content='Harms from Increasingly Agentic Algorithmic Systems 7\\n3.1 Trends in Development and Deployment\\nWe aim to show two things in this section. First, the development of increasingly agentic systems has proceeded by\\nconsistently overcoming technical challenges. Second, the deployment of increasingly agentic systems has occurred\\nbecause these systems have increasingly practical skills that are useful for real-world applications.\\n3.1.1 Overcoming Technical Challenges to Build Increasingly Agentic Systems. Reinforcement learning (RL), as one of\\nthe major paradigms of machine learning, has a major focus on the construction of agents [Sutton and Barto 2018;\\nSutton et al. 2022]. In particular, RL is about designing systems to learn, without human intervention, to achieve a goal\\nencoded in a reward function. Prior to 2013, RL systems were developed mainly for a restricted set of simple domains'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 6, 'page_label': '7'}, page_content='encoded in a reward function. Prior to 2013, RL systems were developed mainly for a restricted set of simple domains\\n[Coulom 2002]. The introduction of deep learning to RL systems produced superhuman performance on a wider variety\\nof narrow tasks with limited to no human supervision, including but not limited to increasingly complex board games\\n[Brown and Sandholm 2019; Perolat et al. 2022; Silver et al. 2016, 2017] and video games [Mnih et al. 2013; Schrittwieser\\net al. 2020; Ye et al. 2021]. Subsequent work has greatly improved the performance of RL systems on more complex,\\nopen-ended environments. For instance, DreamerV3 [Hafner et al . 2023] collected diamonds from scratch without\\nhuman data or curricula in MineCraft, which has been a longstanding challenge because the task is extremely complex\\nand open-ended. Another striking example comes from Diplomacy, a complex, multiplayer board game involving'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 6, 'page_label': '7'}, page_content='and open-ended. Another striking example comes from Diplomacy, a complex, multiplayer board game involving\\ntactical coordination and natural language negotiation. The recent Cicero [Bakhtin et al. 2022], integrating a language\\nmodel with planning and RL algorithms, is the first AI to achieve human-level performance in Diplomacy. Such systems\\nhave demonstrated strong capabilities to interact with complex environments and humans to accomplish their goals\\nthat require long-horizon planning.\\nWe emphasize that for all the systems we have mentioned in this section so far, designers do not specify how the tasks\\nwere to be completed. In the current scientific paradigm of large-scale deep-learning, one instead provides high-level\\nlearning algorithms that tend to be task-agnostic or adapt to new tasks efficiently [Beck et al. 2023; Dong et al. 2022].\\nOne particular example to highlight is AdA [Team et al . 2023], which adapts to open-ended, novel, embodied 3D'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 6, 'page_label': '7'}, page_content='One particular example to highlight is AdA [Team et al . 2023], which adapts to open-ended, novel, embodied 3D\\nproblems as quickly as humans, without human specification of how to solve problems.\\n3.1.2 The Increasing Deployment of Increasingly Agentic Systems. The practicality of systems has increased along\\nwith their agency. Increasing practicality means that increasingly agentic systems are more likely to be found making\\ndecisions in the real world. Major companies have been deploying increasingly agentic systems to control parts of their\\noperation. For example, DeepMind and Google use RL for controlling commercial cooling systems and data centers\\n[Evans and Gao 2016; Kava 2014]. Amazon has applied RL to supply chain optimization problems [Schmelzer 2019].\\nAdditionally, there has been an increasing amount of research in recommender systems to optimize long-term metrics\\nsuch as engagement via reinforcement learning [Afsar et al. 2022]. Major recommendation companies such as Meta'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 6, 'page_label': '7'}, page_content='such as engagement via reinforcement learning [Afsar et al. 2022]. Major recommendation companies such as Meta\\n[Gauci et al. 2019], YouTube [Association for Computing Machinery (ACM) 2019], and Spotify [Engineering 2021] have\\nalready deployed RL-based recommender systems on their live products.\\nSystems that can competently operate across different data modalities and tasks are plausibly more useful than\\nmore narrow systems, regardless of how agentic they are. Before the current era of large language models (LLMs)\\n[Bommasani et al. 2022; Brown et al. 2020; Rae et al. 2022; Srivastava et al. 2022], few systems competently performed\\nout-of-the-box on a range of natural language tasks [Brown et al. 2020]. Recent models [Alayrac et al. 2022; Reed et al.\\n2022; Zeng et al. 2022] can even handle multiple data modalities simultaneously. GATO [Reed et al. 2022] can complete\\ntasks using the same model and weights in vastly different domains, such as Atari, image captioning, dialogue, and'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 6, 'page_label': '7'}, page_content='tasks using the same model and weights in vastly different domains, such as Atari, image captioning, dialogue, and\\nManuscript submitted to ACM'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 7, 'page_label': '8'}, page_content='8 Chan et al.\\nrobotics. As systems become increasingly agentic, the systems that are increasingly domain general seem likely to see\\nmore practical application.\\nIncreasingly agentic systems are also becoming more available to the general public. Although language models are\\nonly trained on next-token prediction, they can be leveraged to interact with APIs and accomplish a wide variety of\\nmulti-step digital tasks with increasingly less explicit human intervention [Chase 2022; Menick et al. 2022; Nakano et al.\\n2022]. Adept’s ACT-1 [Adept 2022] is a system in development which purportedly can perform an arbitrary task on\\nyour computer, such as searching for and buying an item online, through a single text command.\\nDespite the progress so far, systems still have limitations and there are still barriers to the deployment of more\\nagentic systems. For example, the raw task performance of generalist systems [Reed et al. 2022; Zeng et al. 2022] is still'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 7, 'page_label': '8'}, page_content='agentic systems. For example, the raw task performance of generalist systems [Reed et al. 2022; Zeng et al. 2022] is still\\nlimited to tasks where expert data is available and has not achieved human level on all tasks. In the realm of language\\nmodels, recent studies [Ji et al. 2022; Valmeekam et al. 2022] have shown that large language models can perform poorly\\non planning and reasoning tasks, and such systems are prone to hallucinate unintended text, which fails to meet users’\\nintents on many real-world scenarios.\\n3.2 Factors in the Continued Development and Deployment of Increasingly Agentic Systems\\nFor current AI models, there are strong incentives for continued investment and development despite uncertainty\\naround how their future capabilities will emerge [Ganguli et al . 2022]. Similarly, a number of reasons suggest the\\npotential for development and deployment of increasingly agentic algorithmic systems. These factors are the economic'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 7, 'page_label': '8'}, page_content='potential for development and deployment of increasingly agentic algorithmic systems. These factors are the economic\\nand military advantages afforded by increasingly agentic systems, scientific curiosity and prestige, a lack of regulatory\\nbarriers, and emergent agency. The first three reasons are sociopolitical, while the last reason concerns potentially\\nsurprising technical properties of ML systems. Taken together, these increase our subjective likelihood that systems\\nwill become increasingly agentic.\\n3.2.1 Economic Incentives. Actors who deploy more agentic systems than their competitors would likely generate more\\nprofit because of increased automation. First, more agentic systems might be able to perform tasks much more cheaply\\nthan a less agentic systems. A less agentic system by definition would require more human intervention, whether to\\nmake decisions or specify explicit procedures for task completion. Second, more agentic systems will often be more'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 7, 'page_label': '8'}, page_content='make decisions or specify explicit procedures for task completion. Second, more agentic systems will often be more\\neffective at performing tasks than less agentic systems. Part of an increase of agency is the degree to which a system\\nachieves a goal without operators or designers to specify how. The upshot is that the search space of solutions to a\\nproblem is larger for a more agentic system, which could result in solutions that would be much more efficient than\\nthose a human could have found. That AlphaGo [Silver et al. 2016] beat Lee Sedol, the world Go champion, with the\\napparently confusing move 37 is evidence of this possibility.\\n3.2.2 Military Incentives. Militaries may perceive that increasingly agentic systems could provide capability advantages\\nto over adversaries that are constrained by human decision-making. The introduction by any one military of a more\\nagentic system could upset a balance of power and force others to pursue similar developments in an unsafe race to the'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 7, 'page_label': '8'}, page_content='agentic system could upset a balance of power and force others to pursue similar developments in an unsafe race to the\\nbottom, mirroring other races for technologies such as nuclear weapons, and ballistic and hypersonic missiles [Dafoe\\n2018]. The UK’s defence AI strategy [noa 2022a] frames advances in AI as being an area of “geostrategic competition”\\nand “a battleground for competing ideologies”, but also imposes no governance or oversight mechanisms on increasingly\\nagentic systems, focusing such efforts “on effects rather than the nature of any particular technology. ” Total bans on\\ndevelopments for such highly autonomous systems may be difficult to introduce and maintain, and it may be easier to\\npursue nonproliferation of such advances beyond a small set of technologically advanced users [Trager 2022].\\nManuscript submitted to ACM'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 8, 'page_label': '9'}, page_content='Harms from Increasingly Agentic Algorithmic Systems 9\\n3.2.3 Scientific Curiosity and Prestige. Developing increasingly agentic systems is an object of scientific curiosity and\\nalso confers status, a motivation that contributes to a prestige race at varying levels between actors in the AI research\\nsystem. For individual researchers this emerges through standard metrics such as paper publications and grant awards\\nthat support climbing the academic career ladder, but for many leading figures the ambitions transcend these: Geoffrey\\nHinton – a pioneer deep learning research – has stated that “the prospect of discovery is too sweet” in spite of his\\nbeliefs that “political systems will use [AI] to terrorize people” [Khatchadourian 2015], and Rich Sutton – a pioneer\\nin reinforcement learning – has stated that creating “beings of far greater intelligence than current humans” (that'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 8, 'page_label': '9'}, page_content='in reinforcement learning – has stated that creating “beings of far greater intelligence than current humans” (that\\nwould necessarily be agentic) will be “the greatest intellectual achievement of all time” and “a great and glorious goal”\\n[Sutton 2022]. For companies, developing increasingly agentic systems could drive the most impactful research and\\ndevelopment outputs, increasing attractiveness to the best scientific talent in a competitive hiring pool. For nations,\\nhighly visible scientific demonstrations may act as demonstrations of broader state capacity, and prestige may be as\\nmotivating a force as security for competitive races with peers and adversaries [Barnhart 2022]\\n3.2.4 Lack of Regulatory Barriers. Regulatory efforts for AI have focused largely on salient risks, rather than on\\nanticipatory governance mechanisms that are proactive to future advances in AI capabilities [Gesley et al. 2019]. For'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 8, 'page_label': '9'}, page_content='anticipatory governance mechanisms that are proactive to future advances in AI capabilities [Gesley et al. 2019]. For\\nexample, the EU AI act currently proposes to target regulation according to tiers of risk determined by type of data\\nuse and deployment setting, and efforts in the UK take a sectoral focus on regulating only the applications of AI, but\\nneither covers development of agentic AI systems that could both be intrinsically high-risk and could underlie progress\\nand use across a variety of sectors and domains [noa 2022b; Edwards 2022]. Accordingly, development and deployment\\nin this space is effectively unregulated and without any clear possibility of regulation in the near future.\\n3.2.5 Emergent Agency. Even if designers do not explicitly build more agency into their systems, it may emerge from\\ngeneral capability improvements. Recent works discuss emergent behaviors of large language models. Bommasani et al.'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 8, 'page_label': '9'}, page_content='general capability improvements. Recent works discuss emergent behaviors of large language models. Bommasani et al.\\n[2022] introduce emergence as a “behavior of a system [that] is implicitly induced rather than explicitly constructed; it\\nis both the source of scientific excitement and anxiety about unintended consequences. ” For example, LLMs are trained\\nto model a distribution of internet text; this training leads toemergent behavior such as learning from very few examples\\n[Olsson et al. 2022], or arithmetic [Brown et al. 2020], or even the ability itself to perform sequential reasoning [Wei\\net al. 2023]. Many of these abilities only emerge at a certain scale, or after a certain point in the training process [Wei\\net al. 2022].\\nWhen emergent behavior increases the agency of a system we can speak ofemergent agency. One particularly striking\\nexample is the ability of LLMs to simulate the human agents who are the sources of the training data. For example,'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 8, 'page_label': '9'}, page_content='example is the ability of LLMs to simulate the human agents who are the sources of the training data. For example,\\nmaraoz [2021] uses GPT-3 to write a transcript of a conversation between themselves and Albert Einstein, and others\\nhave used LLMs to retroactively simulate user studies from psychology and economics [Aher et al. 2022]. The seeming\\nfidelity of such texts has motivated some to argue that LLMs have a general ability to simulate human agents [Andreas\\n2022].\\nSome emergent capabilities relate directly to our characterization of agency. Wei et al . [2023] show that adding\\n“let’s think step-by-step” vastly improves sequential reasoning capabilities in LLMs, a capability which is useful for\\nperforming tasks over long time horizons. Team et al. [2023] show that scaling up a particular approach leads to RL\\nsystems that capably adapt to open-ended, novel 3D problems as well as humans can, without human intervention on\\nhow to solve the problem.\\nManuscript submitted to ACM'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 9, 'page_label': '10'}, page_content='10 Chan et al.\\n3.3 Potential Objections to our Characterization of ML Progress\\n3.3.1 The Need for Anticipation of Increasingly Agentic Systems is Small. Earlier, we distinguished between two things\\nto anticipate: (1) the increasing agency of developed systems and (2) the deployment of systems with more agency\\nthan those already deployed. We respond to objections against both points.\\nOne could accept the need for attention to (1), but maintain that the need is small given that technical improvements\\nto increase agency occur much more slowly than we have characterized. Indeed, past beliefs in rapid pace of artificial\\nintelligence research have been overoptimistic [Dreyfus 1965]. Barriers to increasing agency include acting capably\\nover long time horizons [Valmeekam et al. 2022] and with an accurate understanding of the world [Bender and Koller\\n2020]. These challenges are real and there is by no means any certainty that the ML research community will overcome'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 9, 'page_label': '10'}, page_content='2020]. These challenges are real and there is by no means any certainty that the ML research community will overcome\\nthem. Even the perceived agency of algorithmic systems depends heavily on (sometimes exploitative) human labor\\nand data extraction [Gray and Suri 2019; Pasquinelli and Joler 2021]. Moreover, it can be difficult to measure the rate\\nof progress towards agentic systems. Dehghani et al. [2021] provide evidence that factors other than “fundamental\\nalgorithmic superiority” may lead to the perception that a particular method is superior. Raji et al. [2021] discuss several\\nissues with benchmarking, including construct invalidity and limitations in scope.\\nWe have no disagreements on the technical challenges of developing systems of increased agency. We are also not\\nclaiming that systems of significantly greater agency than those in development already (e.g., compared to ACT-1'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 9, 'page_label': '10'}, page_content='claiming that systems of significantly greater agency than those in development already (e.g., compared to ACT-1\\n[Adept 2022], GATO [Reed et al. 2022]) will be coming soon. Rather, our view is that even absent significant technical\\nbreakthroughs, continued work within the current scientific paradigm [Kuhn and Hacking 2012] of scaling deep-\\nlearning seems likely to generate systems that are appreciably more agentic than current systems. Scaling laws provide\\npredictable relationships between the amount of compute and data used to train model of a given size, and the\\nperformance of a model on some metric. Of particular interest for increasing agency is that scaling laws have been\\nderived for reinforcement learning [Gao et al . 2022; Hilton et al . 2023; Team et al. 2023] and generative modeling\\n[Hoffmann et al. 2022; Kaplan et al. 2020]. There is also initial work into developing scaling laws for robotics [Caballero'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 9, 'page_label': '10'}, page_content='[Hoffmann et al. 2022; Kaplan et al. 2020]. There is also initial work into developing scaling laws for robotics [Caballero\\net al. 2023]. The upshot is that continued training of larger models with more compute and data seems likely to increase\\nthe ability of systems to act in environments of increasing scope, over longer time horizons, to achieve goals without\\nsignificant designer/operator intervention.\\nOne could also object to the need for attention to (2). Even if a system that is more agentic than those currently\\ndeployed has been developed, there might still be strong reasons against deployment, despite the incentives in Sec-\\ntion 3.2.1. Raji et al. [2022] argues that deployed AI systems often simply do not work, suffering from issues such as\\nrobustness failures, missing safety features, or being set to perform impossible tasks (such as inferring criminality\\nfrom appearance). Given that increasingly agentic systems would be more capable of achieving goals without human'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 9, 'page_label': '10'}, page_content='from appearance). Given that increasingly agentic systems would be more capable of achieving goals without human\\nspecification of how, the failures that Raji et al. [2022] highlight could disincentivize adoption of increasingly agentic\\nsystems, even if they were developed.\\nThe likely failures of a more agentic system (relative to what has been deployed already) are certainly a barrier to\\ndeployment – given the disproportionate impact of these failures on already marginalized groups, we would hope and\\nadvocate for restrictions on deployment [Brundage et al. 2020]. However, we think that this barrier is unfortunately\\nweak relative to countervailing forces. Hype around the (claimed) functionalities of ML systems is strong [Broussard\\net al. 2019; Natale and Ballatore 2020; Schulz et al. 2019], which is unsurprising given massive financial investments\\n[Giattino et al. 2022]. Continued cycles of deployment and failure [Barabas et al. 2020; Buolamwini and Gebru 2018;'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 9, 'page_label': '10'}, page_content='[Giattino et al. 2022]. Continued cycles of deployment and failure [Barabas et al. 2020; Buolamwini and Gebru 2018;\\nObermeyer and Mullainathan 2019; Piantadosi and Hill 2022; Ribeiro et al. 2020; Wallace et al. 2019; Wolfe and Caliskan\\nManuscript submitted to ACM'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 10, 'page_label': '11'}, page_content='Harms from Increasingly Agentic Algorithmic Systems 11\\n2022] suggest that increasingly agentic systems will likely be deployed according to industry interests, and not the\\ninterest of those most likely to be harmed.\\n3.3.2 Techno-Determinism. An objection against our characterization of increasingly agentic systems is that it is\\ntechno-deterministic – it assumes that AI development is inevitable and determines the direction of sociocultural\\ndevelopment [Wyatt 2008]. This objection comes in two parts. Firstly, the perceived inevitability of ML progress nullifies\\naccountability of those developing the systems and removes reason to regulate or stop development. Secondly, techno-\\ndeterminism neglects social and cultural structures and implies a reductionist view of the harms caused by ML systems.\\nRelated to this is the adoption of discourse around ML systems that their capabilities are both scientifically impossible'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 10, 'page_label': '11'}, page_content='Related to this is the adoption of discourse around ML systems that their capabilities are both scientifically impossible\\nto explain, and yet deterministic in their societal impact [Campolo and Crawford 2020]. Some who study the harms of\\nmore agentic systems have also been accused of techno-optimism – optimism about the potential of technology to solve\\nmajor social problems – and techno-determinism [Cremer and Kemp 2021]. The problems include a disproportionately\\nhigh reliance on technological solutions and neglect of insights from structural aspects of risk-analysis.\\nWe do not dispute the dangers of techno-determinism or techno-optimism. However, careful work on identifying\\nand mitigating harms of increasingly agentic systems need not rely on or contribute to either. For example, one can\\nbe engaged in activism to ban specific uses or developments of increasingly agentic AI, while concurrently pursuing'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 10, 'page_label': '11'}, page_content='be engaged in activism to ban specific uses or developments of increasingly agentic AI, while concurrently pursuing\\nsociotechnical research to mitigate those systems’ potential harms. In this framing, the sociotechnical work can be\\nseen as an attempt to reduce harm in the case that one’s broader attempts to change the field’s course of action are not\\nsuccessful. While it can be argued that working on such harm reduction contributes to perceptions of inevitability or\\ndeployment incentives, being thoughtful in the framing of one’s work can significantly contribute to avoiding this issue.\\n4 ANTICIPATED HARMS FROM INCREASINGLY AGENTIC SYSTEMS\\nThe previous section argued for the need to anticipate the harms of increasingly agentic systems. We now delve into\\nsome of these harms and why they are of especial importance for the FATE community.\\n4.1 Systemic, Delayed Harms\\nA systemic harm is a harm that is pervasively embedded in society. A delayed harm is a harm whose cause has a'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 10, 'page_label': '11'}, page_content='4.1 Systemic, Delayed Harms\\nA systemic harm is a harm that is pervasively embedded in society. A delayed harm is a harm whose cause has a\\nnon-immediate impact. Systemic, delayed harms from algorithmic systems negatively influence groups of people in\\nnon-immediate ways. While harder to analyze than immediate harms, systemic and delayed harms might also be more\\ninsidious, as they can be caused even by low-stakes decision making systems. Each action might not seem consequential\\non its own, but, in aggregate, the outcomes can be destructive, long-lasting, and hard to fix. For example, there has\\nrecently been evidence that a single rent-setting algorithm might have significantly contributed to an increase in\\nhousing rental costs across the US [Vogell et al. 2022].\\nThe FATE community has studied systemic and delayed harms in the past, such as environmental risks [Bender\\net al. 2021], concentration of power [Abdalla and Abdalla 2021; Pratyusha 2020], unfair algorithmic hiring decisions'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 10, 'page_label': '11'}, page_content='et al. 2021], concentration of power [Abdalla and Abdalla 2021; Pratyusha 2020], unfair algorithmic hiring decisions\\n[Sühr et al. 2021], and privacy infringements [Ekstrand et al. 2018]. Another line of work focusing on the long-term\\nfairness implications of decisions [Bird et al. 2016; D’Amour et al. 2020b; Jabbari et al. 2017; Joseph et al. 2016; Liu et al.\\n2018; Zhang and Liu 2020]. More broadly, many have identified the systemic nature of general classes of harms, such as\\nfinancial risk [Armour and Gordon 2014], racism [Braveman et al. 2022], and misogyny [Manne 2017].\\nSocial media is speculated to be a contributing factor to many systemic and delayed harms, including mental health\\nissues [Hou et al. 2019; Yoon et al. 2019], the amplification of political polarisation [Whittaker et al . 2021], and the\\nManuscript submitted to ACM'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 11, 'page_label': '12'}, page_content='12 Chan et al.\\nspread of fake news [Allcott and Gentzkow 2017]. There is evidence on both sides for many of these issues [Boxell et al.\\n2017; Keles et al. 2020; Lewis-Kraus 2022], but caution seems warranted due to the sheer scale of these platforms (e.g.,\\nFacebook has almost three-billion users [Meta 2023]).\\nWhile many of these harms do not involve the use of algorithms that are trained to act over long time horizons\\n[Jiang et al. 2019], the application of reinforcement-learning based recommendation systems (RLRS) in today’s social\\nmedia platforms warrant additional reason for concern. In particular, Carroll et al. [2022]; Evans and Kasirzadeh [2022];\\nKrueger et al. [2020] show that long time-horizon systems, such as RLRS, will have incentives to change or manipulate\\nusers’ internal states (e.g. preferences, beliefs, and psychology) for the purposes of increasing the metrics the RLRS'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 11, 'page_label': '12'}, page_content='users’ internal states (e.g. preferences, beliefs, and psychology) for the purposes of increasing the metrics the RLRS\\nsystems are optimizing. While some work has also investigated potential solutions [Carroll et al. 2022; Farquhar et al.\\n2022], how to practically measure and address these issues in real-world RLRS remains an open problem. Notably, such\\nsystems are not speculative: RLRS are now increasingly applied by major social media providers (such as YouTube or\\nFacebook), as discussed in Section 3.1.2.\\n4.2 Collective Disempowerment\\nWe take collective self-governance to be the capacity and ongoing act of deciding collectively how to govern one’s\\ncommunity, whether it be a small, local community, a state, or human societies at large [Christiano and Bajaj 2022].\\nCollective self-governance is about power, which is a core theme in FATE work [Abdalla and Abdalla 2021; Barabas et al.'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 11, 'page_label': '12'}, page_content='Collective self-governance is about power, which is a core theme in FATE work [Abdalla and Abdalla 2021; Barabas et al.\\n2020; Birhane et al. 2022; Boag et al. 2022; Kasy and Abebe 2021; Young et al. 2022]. Indeed, the FATE community has\\nextensively studied the ways in which automated decision-making can disempower individuals, by impairing human\\ndecision-making [Green and Chen 2019; Green 2021] or subjecting individuals to oppressive institutions [Barabas\\net al. 2020, 2018; Green 2020; Zilka et al. 2022]. We extend this ongoing discussion by pointing to some ways in which\\nincreasingly agentic systems can result in collective disempowerment. A key underlying point will be that increasingly\\nagentic systems will likely seem more capable of handling more important societal functions without significant\\noperator or designer intervention, as we discussed in Section 3.2.1. We discuss two possibilities: a situation in which'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 11, 'page_label': '12'}, page_content='operator or designer intervention, as we discussed in Section 3.2.1. We discuss two possibilities: a situation in which\\npower diffuses away from all humans, and a situation in which power concentrates in the hands of a few.\\n4.2.1 Diffusion of Power Away from Humans. As systems become increasingly agentic, they have increasing control of\\nsocietal functions in many ways. At one end, humans in a particular social structure may decide to cede decision-making\\npower to an particular system, such as one that decides taxation policy [Zheng et al. 2021]. At the other end, power\\nmay gradually be ceded, as separate groups are incentivized to delegate more central functions to increasingly agentic\\nsystems per Section 3.2.1. Cooper et al. [2022]; Nissenbaum [1996] examine the erosion of accountability that externalizes\\nalgorithmic harms. Even if collective disempowerment is a risk, it might not be a large enough risk for a single party to'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 11, 'page_label': '12'}, page_content='algorithmic harms. Even if collective disempowerment is a risk, it might not be a large enough risk for a single party to\\nbe concerned. In either case, ceding decision-making power to such systems is not inevitable; it would be a result of\\ncollective human decisions.\\nRegardless of how power is ceded, any group might have increasing difficulty in controlling increasingly agentic\\nsystems. Specifying a correct objective function is quite difficult [Krakovna et al. 2020; Skalse et al. 2022]. Even a system\\nsuccessfully trained under a correctly specified objective function may do something completely different in a different\\nenvironment [Langosco et al. 2022; Shah et al. 2022]. Additional problems remain in understanding how to manage the\\ninterests of multiple stakeholders [Dafoe et al. 2020]. As well, it would likely be extremely difficult to understand the\\ndecisions of the controlling system(s). Analysis of a single decision is likely insufficient for understanding the reasons'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 11, 'page_label': '12'}, page_content='decisions of the controlling system(s). Analysis of a single decision is likely insufficient for understanding the reasons\\nfor a series of long-term decisions (i.e., the overall plan). Collective self-governance requires not just having decisions\\nbe made, but understanding why those decisions are made, which Lazar [2022] terms the publicity requirement. Lazar\\nManuscript submitted to ACM'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 12, 'page_label': '13'}, page_content='Harms from Increasingly Agentic Algorithmic Systems 13\\n[2022] argues that failure to satisfy this requirement delegitimizes the exercise of political authority, by nullifying the\\nmoral effectiveness of consent.\\n4.2.2 Exacerbating the Extreme Concentration of Power Amongst the “Coding Elite”. The FATE community has highlighted\\nthe concerning ways in which the deployment of algorithmic systems has concentrated power in the hands of designers\\nand/or operators. Kasy and Abebe [2021] argues that common notions of fairness legitimize hierarchies that are the\\nresult of historical injustice. They also provide a framework to reason about the impact of algorithmic decisions on the\\ndistribution of power. Burrell and Fourcade [2021, p. 217] identifies the coding elite – a nebula of software developers,\\ntech CEOs, investors, and computer science and engineering professors, among others, often circulating effortlessly'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 12, 'page_label': '13'}, page_content='tech CEOs, investors, and computer science and engineering professors, among others, often circulating effortlessly\\nbetween these influential roles – as a main beneficiary of the concentration of power. According to Burrell and Fourcade\\n[2021], the coding elite concentrates power by controlling the algorithms underlying the modern digital world, using\\nthat power to affect politics for their own gains. The amount of control exerted is already substantial with existing\\nalgorithmic systems, considering the centrality of the products of a handful of tech companies in our daily lives.\\nIncreasingly agentic systems threaten to exacerbate an already extreme concentration of power. First, Ganguli et al.\\n[2022, p. 11] show that the proportion of large-scale ML results from industry has dominated in the past few years. The\\nimportance of large-scale results for increasing agency is that, as we discussed in Section 3, scaling up the compute,'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 12, 'page_label': '13'}, page_content='importance of large-scale results for increasing agency is that, as we discussed in Section 3, scaling up the compute,\\ndata, and parameters of a system provides a significant way to increase its agency, and is in some sense easier than\\nderiving fundamental algorithmic insights. It therefore seems plausible that large industrial labs will continue to be the\\nones who deploy and profit the most from increasingly agentic systems. Second, increasingly agentic systems would\\nlikely enable the coding elite to integrate algorithms into more of society. There are many tasks now that are yet outside\\nthe reach of algorithmic systems, such as deciding national economic policy or running a business. Increasingly agentic\\nsystems seem more likely to be able to assume many of those tasks than current systems.\\n4.3 Harms that have yet to be Identified\\nIn Section 3.2.5, we identified emergent behaviours as a possible cause of increasingly agentic algorithmic systems.'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 12, 'page_label': '13'}, page_content='4.3 Harms that have yet to be Identified\\nIn Section 3.2.5, we identified emergent behaviours as a possible cause of increasingly agentic algorithmic systems.\\nHere, we explain some emergent behaviours that could be the source of harms that have yet to be identified and the\\nlink of those behaviours with increasing agency.\\n4.3.1 Reward Hacking. An RL system trained to maximize its score in the video game CoastRunners will drive off-track\\nand keep turning in circles forever, thus achieving a high score despite not completing the race-track as intended by the\\nprogrammers [Clark and Amodei 2016]. This kind of failure is called reward hacking [Krakovna et al. 2020; Skalse\\net al. 2022], which is when a system exploits a reward signal to achieve a goal in an unforeseen, perhaps undesirable\\nway. As an instance of Goodhart’s law [Goodhart 1975], reward hacking is a common problem in ML systems that'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 12, 'page_label': '13'}, page_content='way. As an instance of Goodhart’s law [Goodhart 1975], reward hacking is a common problem in ML systems that\\ninvolve elements associated with increasing agency, in particular goal-directedness.3 Increased model size or training\\ntime can result in abrupt increases in reward hacking, because a more capable model is better able find unforeseen\\nmaxima of its reward function [Pan et al. 2022].\\nIf increasingly agentic systems are deployed in consequential domains like finance, health care, and law, reward\\nhacking could result in extremely negative outcomes. Even with knowledge of the possibility of reward hacking,\\ndesigners might still deploy systems anyway if the harms from their systems are externalized, or if they judge the\\nimmediate likelihood of reward hacking to be low.\\n4.3.2 Instrumental Goals. An instrumental goal is a goal that is useful as a subobjective in pursuit of a specified'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 12, 'page_label': '13'}, page_content='immediate likelihood of reward hacking to be low.\\n4.3.2 Instrumental Goals. An instrumental goal is a goal that is useful as a subobjective in pursuit of a specified\\ngoal. A convergent instrumental goal is a goal that would be useful in pursuit of a wide range of possible goals. For\\n3A large number of examples of reward hacking are compiled in this online spreadsheet.\\nManuscript submitted to ACM'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 13, 'page_label': '14'}, page_content='14 Chan et al.\\nexample, acquiring money is a convergent instrumental goal since money increases economic power and optionality.\\nMany convergent instrumental goals involve gaining some sort of power over the environment and other actors within\\nit [Omohundro 2008].\\nAn algorithmic system that sought to gain power over other actors, such as through manipulation or threats [Kenton\\net al. 2021], would be concerning. An additional concern would be if the same thing were to happen without explicit,\\nmalicious instructions from their designer(s) or operator(s) to perform such behaviour. While this possibility remains\\nuncertain, some initial evidence does not dismiss it. Perez et al . [2022] show that increased training of a LLM with\\nRL techniques can increase the proportion of the time that the LLM expresses the pursuit of convergent instrumental\\ngoals, such as gaining wealth and persuading the operator not to shut it off, without any apparent designer or operator'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 13, 'page_label': '14'}, page_content='goals, such as gaining wealth and persuading the operator not to shut it off, without any apparent designer or operator\\ninstruction to do so. To recall, RL is about the construction of agents, by training systems to act over long time horizons\\nto achieve goals without explicit human intervention. Training LLMs with RL techniques plausibly increases their\\nagency; therefore, Perez et al. [2022] provides some evidence that increasing the agency of LLMs can be associated with\\nan increase in the expression of convergent instrumental goals. It is important not to overstate this early evidence;\\nexpressing a desire to pursue a goal is different from actually pursuing the goal in the world. Yet, this evidence should\\nbe taken as an additional reason for caution regarding increasingly agentic systems.\\n5 POSSIBILITIES FOR FUTURE WORK\\nMuch work remains in figuring out how to address the present need we have highlighted throughout our piece. We'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 13, 'page_label': '14'}, page_content='5 POSSIBILITIES FOR FUTURE WORK\\nMuch work remains in figuring out how to address the present need we have highlighted throughout our piece. We\\nprovide a preliminary discussion of some directions and tie them to existing work from the FATE community.\\n5.1 Investigating the Sociotechnical Attributes of Increasingly Agentic Systems\\nSeveral landmark works in the FATE community have involved audits [Raji et al. 2020] of algorithmic systems [Black\\net al. 2022; Buolamwini and Gebru 2018; Obermeyer and Mullainathan 2019; Ribeiro et al. 2020]. Audits have motivated\\naction from designers to reduce the harms of their systems [Raji and Buolamwini 2019].\\nSince one typically audits a deployed system, it will be difficult to perform thorough audits of increasingly agentic\\nsystems before they are widely deployed. Nevertheless, there are a variety of ways to reason about the potential impacts'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 13, 'page_label': '14'}, page_content='systems before they are widely deployed. Nevertheless, there are a variety of ways to reason about the potential impacts\\nof a system’s deployment. Assuming either that we have the system in question or that we can simulate it faithfully\\n[Aher et al. 2022; Elzayn and Fish 2020; Park et al. 2022], we can formulate and test hypotheses in simple experiments\\nor simulation. More broadly, it might be possible to take inspiration from policymaking techniques such as scenario\\nplanning [Volkery and Ribeiro 2009], which involve thinking ahead about how to make effective policy decisions when\\nuncertain about what the world will look like in the future. The emerging science of forecasting [Tetlock and Gardner\\n2016] may also provide insights into anticipating the impacts of emerging systems.\\nOther tools from the FATE community may be helpful for characterizing the sociotechnical attributes of increasingly'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 13, 'page_label': '14'}, page_content='2016] may also provide insights into anticipating the impacts of emerging systems.\\nOther tools from the FATE community may be helpful for characterizing the sociotechnical attributes of increasingly\\nagentic systems, even before widespread deployment. For example, datasheets [Gebru et al . 2021] and model cards\\n[Mitchell et al. 2019] can highlight sources of harm, such as accountability gaps [Nissenbaum 1996], in a way that\\ndoes not depend upon a particular application. In the same vein, Gilbert et al . [2022] introduces reward reports to\\ndocument what it appears that systems are optimizing for, which may help to reduce the likelihood of unintended\\nnegative consequences from system operation.\\nManuscript submitted to ACM'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 14, 'page_label': '15'}, page_content='Harms from Increasingly Agentic Algorithmic Systems 15\\n5.2 Stronger Regulations\\nStronger regulations could prevent some harms of increasingly agentic systems from occurring. Compute limits enforced\\nby compute usage tracking [Brundage et al. 2020], while a source of serious privacy risks, could help to control the pace\\nat which systems become increasngly agentic and permit more time to develop mitigations. Along this line, it might be\\ncollectively beneficial to decide upon a level of agency as a deployment bar. If a system surpassed this level of agency, it\\nwould be forbidden from application in certain consequential sectors, like energy, the military, finance, health care,\\nand criminal justice. The FATE community has previously rallied around deeming certain applications off-limits for\\nparticular technologies, such as the use of deep learning to predict criminality [for Critical Technology 2020]. Such an'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 14, 'page_label': '15'}, page_content='particular technologies, such as the use of deep learning to predict criminality [for Critical Technology 2020]. Such an\\nidea could be implemented in what Tutt [2017] calls an “FDA for algorithms”, which would scrutinize each algorithmic\\nsystem before permitting its deployment, just as drugs are regulated in the United States.\\n6 CONCLUSION\\nOur work focused on the increasing prevalence of agency in machine-learning systems and associated harms. We\\nsituated our characterization of increasing agency in the context of diverse work on the meaning of agency. We\\nargued that there is a need to anticipate the harms from increasingly agentic systems, given a strong track record\\nof, and incentives for, technical developments and increasing deployment. We described some anticipated harms\\nfrom increasingly agentic systems, namely that they could cause systemic and delayed harms, disempower human'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 14, 'page_label': '15'}, page_content='from increasingly agentic systems, namely that they could cause systemic and delayed harms, disempower human\\ndecision-making, exacerbate extreme concentrations of power, and be a source of additional unknown threats through\\nemergent capabilities.\\nAddressing the harms of increasingly agentic systems shares commonalities with central lines of work in the FATE\\ncommunity on anticipating the harms of algorithmic decision-making systems. Future work, such as investigations into\\nthe sociotechnical attributes of increasingly agentic systems and interventions upon the structural factors underlying\\ntheir harms, readily follows from ongoing efforts. Immense pressure to develop and deploy emerging technologies\\nshould be met with similarly strong attempts to guide and constrain their impact.\\nACKNOWLEDGMENTS\\nIn no particular order, we would like to thank Robert Harling, Max Kaufmann, Fernando Diaz, Seth Lazar, Janarthan'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 14, 'page_label': '15'}, page_content='ACKNOWLEDGMENTS\\nIn no particular order, we would like to thank Robert Harling, Max Kaufmann, Fernando Diaz, Seth Lazar, Janarthan\\nRajendran, Nicolas Le Roux, Shahar Avin, Kayla Matteucci, Thomas Gilbert, Herbie Bradley, and Usman Anwar for\\ninsightful comments about the direction of the project and parts of the paper. All mistakes remain our own.\\nREFERENCES\\n2022a. Defence Artificial Intelligence Strategy . Technical Report. Ministry of Defence. https://www.gov.uk/government/publications/defence-artificial-\\nintelligence-strategy/defence-artificial-intelligence-strategy\\n2022b. Establishing a pro-innovation approach to regulating AI . Technical Report. Office for Artificial Intelligence. https://www.gov.uk/government/\\npublications/establishing-a-pro-innovation-approach-to-regulating-ai/establishing-a-pro-innovation-approach-to-regulating-ai-policy-statement'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 14, 'page_label': '15'}, page_content='publications/establishing-a-pro-innovation-approach-to-regulating-ai/establishing-a-pro-innovation-approach-to-regulating-ai-policy-statement\\nMohamed Abdalla and Moustafa Abdalla. 2021. The Grey Hoodie Project: Big Tobacco, Big Tech, and the Threat on Academic Integrity. In Proceedings of\\nthe 2021 AAAI/ACM Conference on AI, Ethics, and Society . ACM. https://doi.org/10.1145/3461702.3462563\\nRediet Abebe, Solon Barocas, Jon Kleinberg, Karen Levy, Manish Raghavan, and David G. Robinson. 2020. Roles for computing in social change. In\\nProceedings of the 2020 Conference on Fairness, Accountability, and Transparency . ACM. https://doi.org/10.1145/3351095.3372871\\nRediet Abebe and Kira Goldner. 2018. Mechanism design for social good. AI Matters 4, 3 (Oct. 2018), 27–34. https://doi.org/10.1145/3284751.3284761\\nAbubakar Abid, Maheen Farooqi, and James Zou. 2021. Persistent Anti-Muslim Bias in Large Language Models. In Proceedings of the 2021 AAAI/ACM'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 14, 'page_label': '15'}, page_content='Abubakar Abid, Maheen Farooqi, and James Zou. 2021. Persistent Anti-Muslim Bias in Large Language Models. In Proceedings of the 2021 AAAI/ACM\\nConference on AI, Ethics, and Society . ACM. https://doi.org/10.1145/3461702.3462624\\nAdept. 2022. ACT-1: Transformer for Actions. https://www.adept.ai/act\\nManuscript submitted to ACM'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 15, 'page_label': '16'}, page_content='16 Chan et al.\\nM. Mehdi Afsar, Trafford Crump, and Behrouz Far. 2022. Reinforcement learning based recommender systems: A survey. https://doi.org/10.48550/arXiv.\\n2101.06286 arXiv:2101.06286 [cs].\\nGati Aher, Rosa I Arriaga, and Adam Tauman Kalai. 2022. Using Large Language Models to Simulate Multiple Humans. arXiv preprint arXiv:2208.10264\\n(2022).\\nJean-Baptiste Alayrac, Jeff Donahue, Pauline Luc, Antoine Miech, Iain Barr, Yana Hasson, Karel Lenc, Arthur Mensch, Katie Millican, Malcolm Reynolds,\\nRoman Ring, Eliza Rutherford, Serkan Cabi, Tengda Han, Zhitao Gong, Sina Samangooei, Marianne Monteiro, Jacob Menick, Sebastian Borgeaud,\\nAndrew Brock, Aida Nematzadeh, Sahand Sharifzadeh, Mikolaj Binkowski, Ricardo Barreira, Oriol Vinyals, Andrew Zisserman, and Karen Simonyan.\\n2022. Flamingo: a Visual Language Model for Few-Shot Learning. https://doi.org/10.48550/arXiv.2204.14198 arXiv:2204.14198 [cs].'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 15, 'page_label': '16'}, page_content='2022. Flamingo: a Visual Language Model for Few-Shot Learning. https://doi.org/10.48550/arXiv.2204.14198 arXiv:2204.14198 [cs].\\nHunt Allcott and Matthew Gentzkow. 2017. Social Media and Fake News in the 2016 Election. Journal of Economic Perspectives 31, 2 (May 2017), 211–236.\\nhttps://doi.org/10.1257/jep.31.2.211\\nJacob Andreas. 2022. Language Models as Agent Models. https://doi.org/10.48550/arXiv.2212.01681 arXiv:2212.01681 [cs].\\nJohn Armour and Jeffrey N. Gordon. 2014. Systemic Harms and Shareholder Value. Journal of Legal Analysis 6, 1 (Oct. 2014), 35–85. https://doi.org/10.\\n1093/jla/lau004\\nAssociation for Computing Machinery (ACM). 2019. \"Reinforcement Learning for Recommender Systems: A Case Study on Youtube, \" by Minmin Chen.\\nhttps://www.youtube.com/watch?v=HEqQ2_1XRTs\\nAnton Bakhtin, Noam Brown, Emily Dinan, Gabriele Farina, Colin Flaherty, Daniel Fried, Andrew Goff, Jonathan Gray, Hengyuan Hu, Athul Paul Jacob,'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 15, 'page_label': '16'}, page_content='https://www.youtube.com/watch?v=HEqQ2_1XRTs\\nAnton Bakhtin, Noam Brown, Emily Dinan, Gabriele Farina, Colin Flaherty, Daniel Fried, Andrew Goff, Jonathan Gray, Hengyuan Hu, Athul Paul Jacob,\\nMojtaba Komeili, Karthik Konath, Minae Kwon, Adam Lerer, Mike Lewis, Alexander H. Miller, Sasha Mitts, Adithya Renduchintala, Stephen Roller,\\nDirk Rowe, Weiyan Shi, Joe Spisak, Alexander Wei, David Wu, Hugh Zhang, and Markus Zijlstra. 2022. Human-level play in the game of Diplomacy\\nby combining language models with strategic reasoning. Science 378, 6624 (Dec. 2022), 1067–1074. https://doi.org/10.1126/science.ade9097 Publisher:\\nAmerican Association for the Advancement of Science.\\nChelsea Barabas, Colin Doyle, J. B. Rubinovitz, and Karthik Dinakar. 2020. Studying up. In Proceedings of the 2020 Conference on Fairness, Accountability,\\nand Transparency. ACM. https://doi.org/10.1145/3351095.3372859'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 15, 'page_label': '16'}, page_content='and Transparency. ACM. https://doi.org/10.1145/3351095.3372859\\nChelsea Barabas, Madars Virza, Karthik Dinakar, Joichi Ito, and Jonathan Zittrain. 2018. Interventions over Predictions: Reframing the Ethical Debate for\\nActuarial Risk Assessment. In Proceedings of the 1st Conference on Fairness, Accountability and Transparency (Proceedings of Machine Learning Research,\\nVol. 81), Sorelle A. Friedler and Christo Wilson (Eds.). PMLR, 62–76. https://proceedings.mlr.press/v81/barabas18a.html\\nJoslyn Barnhart. 2022. Emerging Technologies, Prestige Motivations and the Dynamics of International Competition. (Jan. 2022). https://www.governance.\\nai/research-paper/emerging-technologies-prestige-motivations-and-the-dynamics-of-international-competition\\nJacob Beck, Risto Vuorio, Evan Zheran Liu, Zheng Xiong, Luisa Zintgraf, Chelsea Finn, and Shimon Whiteson. 2023. A Survey of Meta-Reinforcement\\nLearning. https://doi.org/10.48550/arXiv.2301.08028 arXiv:2301.08028 [cs].'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 15, 'page_label': '16'}, page_content='Learning. https://doi.org/10.48550/arXiv.2301.08028 arXiv:2301.08028 [cs].\\nG.A. Bekey. 2005. Autonomous Robots: From Biological Inspiration to Implementation and Control . MIT Press. https://books.google.ca/books?id=\\n3xwfia2DpmoC\\nEmily M. Bender, Timnit Gebru, Angelina McMillan-Major, and Shmargaret Shmitchell. 2021. On the Dangers of Stochastic Parrots: Can Language\\nModels Be Too Big?. In Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency (FAccT ’21) . Association for Computing\\nMachinery, New York, NY, USA, 610–623. https://doi.org/10.1145/3442188.3445922 event-place: Virtual Event, Canada.\\nEmily M. Bender and Alexander Koller. 2020. Climbing towards NLU: On Meaning, Form, and Understanding in the Age of Data. In Proceedings of\\nthe 58th Annual Meeting of the Association for Computational Linguistics . Association for Computational Linguistics, Online, 5185–5198. https:\\n//doi.org/10.18653/v1/2020.acl-main.463'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 15, 'page_label': '16'}, page_content='the 58th Annual Meeting of the Association for Computational Linguistics . Association for Computational Linguistics, Online, 5185–5198. https:\\n//doi.org/10.18653/v1/2020.acl-main.463\\nSarah Bird, Solon Barocas, Kate Crawford, Fernando Diaz, and Hanna Wallach. 2016. Exploring or Exploiting? Social and Ethical Implications of\\nAutonomous Experimentation in AI. https://papers.ssrn.com/abstract=2846909\\nAbeba Birhane, Elayne Ruane, Thomas Laurent, Matthew S. Brown, Johnathan Flowers, Anthony Ventresque, and Christopher L. Dancy. 2022. The\\nForgotten Margins of AI Ethics. In 2022 ACM Conference on Fairness, Accountability, and Transparency . ACM. https://doi.org/10.1145/3531146.3533157\\nEmily Black, Hadi Elzayn, Alexandra Chouldechova, Jacob Goldin, and Daniel Ho. 2022. Algorithmic Fairness and Vertical Equity: Income Fairness with\\nIRS Tax Audit Models. In 2022 ACM Conference on Fairness, Accountability, and Transparency . ACM. https://doi.org/10.1145/3531146.3533204'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 15, 'page_label': '16'}, page_content='IRS Tax Audit Models. In 2022 ACM Conference on Fairness, Accountability, and Transparency . ACM. https://doi.org/10.1145/3531146.3533204\\nSu Lin Blodgett, Gilsinia Lopez, Alexandra Olteanu, Robert Sim, and Hanna Wallach. 2021. Stereotyping Norwegian Salmon: An Inventory of Pitfalls in\\nFairness Benchmark Datasets. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International\\nJoint Conference on Natural Language Processing (Volume 1: Long Papers) . Association for Computational Linguistics, Online, 1004–1015. https:\\n//doi.org/10.18653/v1/2021.acl-long.81\\nWilliam Boag, Harini Suresh, Bianca Lepe, and Catherine D’Ignazio. 2022. Tech Worker Organizing for Power and Accountability. In2022 ACM Conference\\non Fairness, Accountability, and Transparency . ACM. https://doi.org/10.1145/3531146.3533111'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 15, 'page_label': '16'}, page_content='on Fairness, Accountability, and Transparency . ACM. https://doi.org/10.1145/3531146.3533111\\nRishi Bommasani, Drew A. Hudson, Ehsan Adeli, Russ Altman, Simran Arora, Sydney von Arx, Michael S. Bernstein, Jeannette Bohg, Antoine Bosselut,\\nEmma Brunskill, Erik Brynjolfsson, Shyamal Buch, Dallas Card, Rodrigo Castellon, Niladri Chatterji, Annie Chen, Kathleen Creel, Jared Quincy\\nDavis, Dora Demszky, Chris Donahue, Moussa Doumbouya, Esin Durmus, Stefano Ermon, John Etchemendy, Kawin Ethayarajh, Li Fei-Fei, Chelsea\\nFinn, Trevor Gale, Lauren Gillespie, Karan Goel, Noah Goodman, Shelby Grossman, Neel Guha, Tatsunori Hashimoto, Peter Henderson, John Hewitt,\\nDaniel E. Ho, Jenny Hong, Kyle Hsu, Jing Huang, Thomas Icard, Saahil Jain, Dan Jurafsky, Pratyusha Kalluri, Siddharth Karamcheti, Geoff Keeling,\\nFereshte Khani, Omar Khattab, Pang Wei Koh, Mark Krass, Ranjay Krishna, Rohith Kuditipudi, Ananya Kumar, Faisal Ladhak, Mina Lee, Tony Lee,'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 15, 'page_label': '16'}, page_content='Fereshte Khani, Omar Khattab, Pang Wei Koh, Mark Krass, Ranjay Krishna, Rohith Kuditipudi, Ananya Kumar, Faisal Ladhak, Mina Lee, Tony Lee,\\nJure Leskovec, Isabelle Levent, Xiang Lisa Li, Xuechen Li, Tengyu Ma, Ali Malik, Christopher D. Manning, Suvir Mirchandani, Eric Mitchell, Zanele\\nManuscript submitted to ACM'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 16, 'page_label': '17'}, page_content='Harms from Increasingly Agentic Algorithmic Systems 17\\nMunyikwa, Suraj Nair, Avanika Narayan, Deepak Narayanan, Ben Newman, Allen Nie, Juan Carlos Niebles, Hamed Nilforoshan, Julian Nyarko, Giray\\nOgut, Laurel Orr, Isabel Papadimitriou, Joon Sung Park, Chris Piech, Eva Portelance, Christopher Potts, Aditi Raghunathan, Rob Reich, Hongyu Ren,\\nFrieda Rong, Yusuf Roohani, Camilo Ruiz, Jack Ryan, Christopher Ré, Dorsa Sadigh, Shiori Sagawa, Keshav Santhanam, Andy Shih, Krishnan Srinivasan,\\nAlex Tamkin, Rohan Taori, Armin W. Thomas, Florian Tramèr, Rose E. Wang, William Wang, Bohan Wu, Jiajun Wu, Yuhuai Wu, Sang Michael Xie,\\nMichihiro Yasunaga, Jiaxuan You, Matei Zaharia, Michael Zhang, Tianyi Zhang, Xikun Zhang, Yuhui Zhang, Lucia Zheng, Kaitlyn Zhou, and Percy\\nLiang. 2022. On the Opportunities and Risks of Foundation Models. https://doi.org/10.48550/arXiv.2108.07258 arXiv:2108.07258 [cs].'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 16, 'page_label': '17'}, page_content='Liang. 2022. On the Opportunities and Risks of Foundation Models. https://doi.org/10.48550/arXiv.2108.07258 arXiv:2108.07258 [cs].\\nSamuel Bowman. 2022. The Dangers of Underclaiming: Reasons for Caution When Reporting How NLP Systems Fail. In Proceedings of the 60th Annual\\nMeeting of the Association for Computational Linguistics (Volume 1: Long Papers) . Association for Computational Linguistics, Dublin, Ireland, 7484–7499.\\nhttps://doi.org/10.18653/v1/2022.acl-long.516\\nLevi Boxell, Matthew Gentzkow, and Jesse M Shapiro. 2017. Greater Internet use is not associated with faster growth in political polarization among US\\ndemographic groups. Proceedings of the National Academy of Sciences 114, 40 (2017), 10612–10617. Publisher: National Acad Sciences.\\nPaula A. Braveman, Elaine Arkin, Dwayne Proctor, Tina Kauh, and Nicole Holm. 2022. Systemic And Structural Racism: Definitions, Examples, Health'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 16, 'page_label': '17'}, page_content='Paula A. Braveman, Elaine Arkin, Dwayne Proctor, Tina Kauh, and Nicole Holm. 2022. Systemic And Structural Racism: Definitions, Examples, Health\\nDamages, And Approaches To Dismantling. Health Affairs 41, 2 (Feb. 2022), 171–178. https://doi.org/10.1377/hlthaff.2021.01394 Publisher: Health\\nAffairs.\\nMeredith Broussard, Nicholas Diakopoulos, Andrea L Guzman, Rediet Abebe, Michel Dupagne, and Ching-Hua Chuan. 2019. Artificial intelligence and\\njournalism. Journalism & Mass Communication Quarterly 96, 3 (2019), 673–695. Publisher: SAGE Publications Sage CA: Los Angeles, CA.\\nNoam Brown and Tuomas Sandholm. 2019. Superhuman AI for multiplayer poker. Science 365, 6456 (Aug. 2019), 885–890. https://doi.org/10.1126/science.\\naay2400 Publisher: American Association for the Advancement of Science.\\nTom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 16, 'page_label': '17'}, page_content='Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda\\nAskell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens\\nWinter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec\\nRadford, Ilya Sutskever, and Dario Amodei. 2020. Language Models are Few-Shot Learners. In Advances in Neural Information Processing Systems ,\\nVol. 33. Curran Associates, Inc., 1877–1901. https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html\\nMiles Brundage, Shahar Avin, Jasmine Wang, Haydn Belfield, Gretchen Krueger, Gillian Hadfield, Heidy Khlaaf, Jingying Yang, Helen Toner, Ruth\\nFong, Tegan Maharaj, Pang Wei Koh, Sara Hooker, Jade Leung, Andrew Trask, Emma Bluemke, Jonathan Lebensold, Cullen O’Keefe, Mark Koren,'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 16, 'page_label': '17'}, page_content='Fong, Tegan Maharaj, Pang Wei Koh, Sara Hooker, Jade Leung, Andrew Trask, Emma Bluemke, Jonathan Lebensold, Cullen O’Keefe, Mark Koren,\\nThéo Ryffel, J. B. Rubinovitz, Tamay Besiroglu, Federica Carugati, Jack Clark, Peter Eckersley, Sarah de Haas, Maritza Johnson, Ben Laurie, Alex\\nIngerman, Igor Krawczuk, Amanda Askell, Rosario Cammarota, Andrew Lohn, David Krueger, Charlotte Stix, Peter Henderson, Logan Graham, Carina\\nPrunkl, Bianca Martin, Elizabeth Seger, Noa Zilberman, Seán Ó hÉigeartaigh, Frens Kroeger, Girish Sastry, Rebecca Kagan, Adrian Weller, Brian\\nTse, Elizabeth Barnes, Allan Dafoe, Paul Scharre, Ariel Herbert-Voss, Martijn Rasser, Shagun Sodhani, Carrick Flynn, Thomas Krendl Gilbert, Lisa\\nDyer, Saif Khan, Yoshua Bengio, and Markus Anderljung. 2020. Toward Trustworthy AI Development: Mechanisms for Supporting Verifiable Claims.\\nhttps://doi.org/10.48550/arXiv.2004.07213 arXiv:2004.07213 [cs].'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 16, 'page_label': '17'}, page_content='https://doi.org/10.48550/arXiv.2004.07213 arXiv:2004.07213 [cs].\\nJoy Buolamwini and Timnit Gebru. 2018. Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification. In Proceedings of the\\n1st Conference on Fairness, Accountability and Transparency (Proceedings of Machine Learning Research, Vol. 81) , Sorelle A. Friedler and Christo Wilson\\n(Eds.). PMLR, 77–91. https://proceedings.mlr.press/v81/buolamwini18a.html\\nJenna Burrell and Marion Fourcade. 2021. The Society of Algorithms. Annual Review of Sociology 47, 1 (2021), 213–237. https://doi.org/10.1146/annurev-\\nsoc-090820-020800 _eprint: https://doi.org/10.1146/annurev-soc-090820-020800.\\nEthan Caballero, Kshitij Gupta, Irina Rish, and David Krueger. 2023. Broken Neural Scaling Laws. https://doi.org/10.48550/arXiv.2210.14891\\narXiv:2210.14891 [cs].\\nAlexander Campolo and Kate Crawford. 2020. Enchanted Determinism: Power without Responsibility in Artificial Intelligence. Engaging Science,'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 16, 'page_label': '17'}, page_content='arXiv:2210.14891 [cs].\\nAlexander Campolo and Kate Crawford. 2020. Enchanted Determinism: Power without Responsibility in Artificial Intelligence. Engaging Science,\\nTechnology, and Society 6 (Jan. 2020), 1–19. https://doi.org/10.17351/ests2020.277\\nMicah D. Carroll, Anca Dragan, Stuart Russell, and Dylan Hadfield-Menell. 2022. Estimating and Penalizing Induced Preference Shifts in Recommender\\nSystems. In Proceedings of the 39th International Conference on Machine Learning . PMLR, 2686–2708. https://proceedings.mlr.press/v162/carroll22a.html\\nISSN: 2640-3498.\\nHarrison Chase. 2022. LangChain 0.0.77 Docs. https://langchain.readthedocs.io/en/latest/modules/agents/getting_started.html\\nLili Chen, Kevin Lu, Aravind Rajeswaran, Kimin Lee, Aditya Grover, Misha Laskin, Pieter Abbeel, Aravind Srinivas, and Igor Mordatch. 2021. Decision\\nTransformer: Reinforcement Learning via Sequence Modeling. In Advances in Neural Information Processing Systems , Vol. 34. Curran Associates, Inc.,'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 16, 'page_label': '17'}, page_content='Transformer: Reinforcement Learning via Sequence Modeling. In Advances in Neural Information Processing Systems , Vol. 34. Curran Associates, Inc.,\\n15084–15097. https://proceedings.neurips.cc/paper/2021/hash/7f489f642a0ddb10272b5c31057f0663-Abstract.html\\nTom Christiano and Sameer Bajaj. 2022. Democracy. In The Stanford Encyclopedia of Philosophy (spring 2022 ed.), Edward N. Zalta (Ed.). Metaphysics\\nResearch Lab, Stanford University. https://plato.stanford.edu/archives/spr2022/entries/democracy/\\nJack Clark and Dario Amodei. 2016. Faulty Reward Functions in the Wild. https://openai.com/blog/faulty-reward-functions/\\nKatherine M. Collins, Catherine Wong, Jiahai Feng, Megan Wei, and Joshua B. Tenenbaum. 2022. Structured, flexible, and robust: benchmarking and\\nimproving large language models towards more human-like behavior in out-of-distribution reasoning tasks. (May 2022). https://doi.org/10.48550/\\narXiv.2205.05718'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 16, 'page_label': '17'}, page_content='improving large language models towards more human-like behavior in out-of-distribution reasoning tasks. (May 2022). https://doi.org/10.48550/\\narXiv.2205.05718\\nA. Feder Cooper, Emanuel Moss, Benjamin Laufer, and Helen Nissenbaum. 2022. Accountability in an Algorithmic Society: Relationality, Responsibility, and\\nRobustness in Machine Learning. In2022 ACM Conference on Fairness, Accountability, and Transparency . ACM. https://doi.org/10.1145/3531146.3533150\\nRémi Coulom. 2002. Reinforcement Learning Using Neural Networks, with Applications to Motor Control. (June 2002).\\nManuscript submitted to ACM'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 17, 'page_label': '18'}, page_content='18 Chan et al.\\nCarla Zoe Cremer and Luke Kemp. 2021. Democratising Risk: In Search of a Methodology to Study Existential Risk. https://papers.ssrn.com/abstract=\\n3995225\\nAllan Dafoe. 2018. AI Governance: A Research Agenda. (Aug. 2018). https://www.fhi.ox.ac.uk/wp-content/uploads/GovAI-Agenda.pdf\\nAllan Dafoe, Edward Hughes, Yoram Bachrach, Tantum Collins, Kevin R. McKee, Joel Z. Leibo, Kate Larson, and Thore Graepel. 2020. Open Problems in\\nCooperative AI. https://doi.org/10.48550/arXiv.2012.08630 arXiv:2012.08630 [cs].\\nAlexander D’Amour, Katherine Heller, Dan Moldovan, Ben Adlam, Babak Alipanahi, Alex Beutel, Christina Chen, Jonathan Deaton, Jacob Eisenstein,\\nMatthew D. Hoffman, Farhad Hormozdiari, Neil Houlsby, Shaobo Hou, Ghassen Jerfel, Alan Karthikesalingam, Mario Lucic, Yian Ma, Cory McLean,\\nDiana Mincu, Akinori Mitani, Andrea Montanari, Zachary Nado, Vivek Natarajan, Christopher Nielson, Thomas F. Osborne, Rajiv Raman, Kim'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 17, 'page_label': '18'}, page_content='Diana Mincu, Akinori Mitani, Andrea Montanari, Zachary Nado, Vivek Natarajan, Christopher Nielson, Thomas F. Osborne, Rajiv Raman, Kim\\nRamasamy, Rory Sayres, Jessica Schrouff, Martin Seneviratne, Shannon Sequeira, Harini Suresh, Victor Veitch, Max Vladymyrov, Xuezhi Wang, Kellie\\nWebster, Steve Yadlowsky, Taedong Yun, Xiaohua Zhai, and D. Sculley. 2020a. Underspecification Presents Challenges for Credibility in Modern\\nMachine Learning. https://doi.org/10.48550/arXiv.2011.03395 arXiv:2011.03395 [cs, stat].\\nAlexander D’Amour, Hansa Srinivasan, James Atwood, Pallavi Baljekar, D. Sculley, and Yoni Halpern. 2020b. Fairness is not static. InProceedings of the\\n2020 Conference on Fairness, Accountability, and Transparency . ACM. https://doi.org/10.1145/3351095.3372878\\nMostafa Dehghani, Yi Tay, Alexey A. Gritsenko, Zhe Zhao, Neil Houlsby, Fernando Diaz, Donald Metzler, and Oriol Vinyals. 2021. The Benchmark\\nLottery. https://doi.org/10.48550/arXiv.2107.07002 arXiv:2107.07002 [cs].'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 17, 'page_label': '18'}, page_content='Lottery. https://doi.org/10.48550/arXiv.2107.07002 arXiv:2107.07002 [cs].\\nDaniel Clement Dennett. 1981. The Intentional Stance . MIT Press.\\nQingxiu Dong, Lei Li, Damai Dai, Ce Zheng, Zhiyong Wu, Baobao Chang, Xu Sun, Jingjing Xu, Lei Li, and Zhifang Sui. 2022. A Survey for In-context\\nLearning. https://doi.org/10.48550/arXiv.2301.00234 arXiv:2301.00234 [cs].\\nHubert L Dreyfus. 1965. Alchemy and artificial intelligence . Technical Report. RAND CORP SANTA MONICA CA.\\nLilian Edwards. 2022. The EU AI Act: a summary of its significance and scope . Technical Report. https://www.adalovelaceinstitute.org/wp-content/\\nuploads/2022/04/Expert-explainer-The-EU-AI-Act-11-April-2022.pdf\\nUpol Ehsan, Ranjit Singh, Jacob Metcalf, and Mark Riedl. 2022. The Algorithmic Imprint. In 2022 ACM Conference on Fairness, Accountability, and\\nTransparency. ACM. https://doi.org/10.1145/3531146.3533186'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 17, 'page_label': '18'}, page_content='Transparency. ACM. https://doi.org/10.1145/3531146.3533186\\nKathleen M. Eisenhardt. 1989. Agency Theory: An Assessment and Review. The Academy of Management Review 14, 1 (1989), 57–74. https://doi.org/10.\\n2307/258191 Publisher: Academy of Management.\\nMichael D. Ekstrand, Mucun Tian, Ion Madrazo Azpiazu, Jennifer D. Ekstrand, Oghenemaro Anuyah, David McNeill, and Maria Soledad Pera. 2018. All\\nThe Cool Kids, How Do They Fit In?: Popularity and Demographic Biases in Recommender Evaluation and Effectiveness. In Proceedings of the 1st\\nConference on Fairness, Accountability and Transparency (Proceedings of Machine Learning Research, Vol. 81) , Sorelle A. Friedler and Christo Wilson\\n(Eds.). PMLR, 172–186. https://proceedings.mlr.press/v81/ekstrand18b.html\\nHadi Elzayn and Benjamin Fish. 2020. The effects of competition and regulation on error inequality in data-driven markets. In Proceedings of the 2020'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 17, 'page_label': '18'}, page_content='Hadi Elzayn and Benjamin Fish. 2020. The effects of competition and regulation on error inequality in data-driven markets. In Proceedings of the 2020\\nConference on Fairness, Accountability, and Transparency . ACM. https://doi.org/10.1145/3351095.3372842\\nMustafa Emirbayer and Ann Mische. 1998. What is Agency? American journal of sociology 103, 4 (1998), 962–1023. Publisher: The University of Chicago\\nPress.\\nSpotify Engineering. 2021. Shifting Consumption towards Diverse content via Reinforcement Learning. https://research.atspotify.com/2021/03/shifting-\\nconsumption-towards-diverse-content-via-reinforcement-learning/ Section: Algorithmic Responsibility.\\nCharles Evans and Atoosa Kasirzadeh. 2022. User Tampering in Reinforcement Learning Recommender Systems. https://doi.org/10.48550/arXiv.2109.04083\\narXiv:2109.04083 [cs].\\nRichard Evans and Jim Gao. 2016. DeepMind AI Reduces Google Data Centre Cooling Bill by 40%. https://www.deepmind.com/blog/deepmind-ai-'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 17, 'page_label': '18'}, page_content='arXiv:2109.04083 [cs].\\nRichard Evans and Jim Gao. 2016. DeepMind AI Reduces Google Data Centre Cooling Bill by 40%. https://www.deepmind.com/blog/deepmind-ai-\\nreduces-google-data-centre-cooling-bill-by-40\\nTom Everitt, Ryan Carey, Eric D. Langlois, Pedro A. Ortega, and Shane Legg. 2021. Agent Incentives: A Causal Perspective. Proceedings of the AAAI\\nConference on Artificial Intelligence 35, 13 (May 2021), 11487–11495. https://doi.org/10.1609/aaai.v35i13.17368 Number: 13.\\nSebastian Farquhar, Ryan Carey, and Tom Everitt. 2022. Path-Specific Objectives for Safer Agent Incentives. https://doi.org/10.48550/arXiv.2204.10018\\narXiv:2204.10018 [cs, stat].\\nRiccardo Fogliato, Shreya Chappidi, Matthew Lungren, Paul Fisher, Diane Wilson, Michael Fitzke, Mark Parkinson, Eric Horvitz, Kori Inkpen, and Besmira\\nNushi. 2022. Who Goes First? Influences of Human-AI Workflow on Decision Making in Clinical Imaging. In 2022 ACM Conference on Fairness,'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 17, 'page_label': '18'}, page_content='Nushi. 2022. Who Goes First? Influences of Human-AI Workflow on Decision Making in Clinical Imaging. In 2022 ACM Conference on Fairness,\\nAccountability, and Transparency . ACM. https://doi.org/10.1145/3531146.3533193\\nCoalition for Critical Technology. 2020. Abolish the #TechToPrisonPipeline. https://medium.com/@CoalitionForCriticalTechnology/abolish-the-\\ntechtoprisonpipeline-9b5b14366b16\\nDeep Ganguli, Danny Hernandez, Liane Lovitt, Amanda Askell, Yuntao Bai, Anna Chen, Tom Conerly, Nova Dassarma, Dawn Drain, Nelson Elhage,\\nSheer El Showk, Stanislav Fort, Zac Hatfield-Dodds, Tom Henighan, Scott Johnston, Andy Jones, Nicholas Joseph, Jackson Kernian, Shauna Kravec,\\nBen Mann, Neel Nanda, Kamal Ndousse, Catherine Olsson, Daniela Amodei, Tom Brown, Jared Kaplan, Sam McCandlish, Christopher Olah, Dario\\nAmodei, and Jack Clark. 2022. Predictability and Surprise in Large Generative Models. In 2022 ACM Conference on Fairness, Accountability, and'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 17, 'page_label': '18'}, page_content='Amodei, and Jack Clark. 2022. Predictability and Surprise in Large Generative Models. In 2022 ACM Conference on Fairness, Accountability, and\\nTransparency. ACM. https://doi.org/10.1145/3531146.3533229\\nLeo Gao, John Schulman, and Jacob Hilton. 2022. Scaling Laws for Reward Model Overoptimization. https://doi.org/10.48550/arXiv.2210.10760\\narXiv:2210.10760 [cs, stat].\\nManuscript submitted to ACM'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 18, 'page_label': '19'}, page_content='Harms from Increasingly Agentic Algorithmic Systems 19\\nJason Gauci, Edoardo Conti, Yitao Liang, Kittipat Virochsiri, Yuchen He, Zachary Kaden, Vivek Narayanan, Xiaohui Ye, Zhengxing Chen, and Scott Fujimoto.\\n2019. Horizon: Facebook’s Open Source Applied Reinforcement Learning Platform. https://doi.org/10.48550/arXiv.1811.00260 arXiv:1811.00260 [cs,\\nstat].\\nTimnit Gebru, Jamie Morgenstern, Briana Vecchione, Jennifer Wortman Vaughan, Hanna Wallach, Hal Daumé Iii, and Kate Crawford. 2021. Datasheets\\nfor datasets. Commun. ACM 64, 12 (Dec. 2021), 86–92. https://doi.org/10.1145/3458723\\nSamuel Gehman, Suchin Gururangan, Maarten Sap, Yejin Choi, and Noah A. Smith. 2020. RealToxicityPrompts: Evaluating Neural Toxic Degeneration\\nin Language Models. In Findings of the Association for Computational Linguistics: EMNLP 2020 . Association for Computational Linguistics, Online,\\n3356–3369. https://doi.org/10.18653/v1/2020.findings-emnlp.301'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 18, 'page_label': '19'}, page_content='3356–3369. https://doi.org/10.18653/v1/2020.findings-emnlp.301\\nJenny Gesley, Tariq Ahmad, Edouardo Soares, Ruth Levush, Gustavo Guerra, James Martin, Kelly Buchanan, Laney Zhang, Sayuri Umeda, Astghik Grigoryan,\\nNicolas Boring, Elin Hofverberg, Clare Feikhert-Ahalt, Graciela Rodriguez-Ferrand, George Sadek, and Hanibal Goitom. 2019. Regulation of Artificial\\nIntelligence in Selected Jurisdictions. Copyright, Fair Use, Scholarly Communication, etc. (Jan. 2019). https://digitalcommons.unl.edu/scholcom/177\\nCharlie Giattino, Edouard Mathieu, Julia Broden, and Max Roser. 2022. Artificial Intelligence. Our World in Data (2022).\\nThomas Krendl Gilbert, Sarah Dean, Nathan Lambert, Tom Zick, and Aaron Snoswell. 2022. Reward Reports for Reinforcement Learning. https:\\n//doi.org/10.48550/arXiv.2204.10817 arXiv:2204.10817 [cs].\\nTrystan S. Goetze. 2022. Mind the Gap: Autonomous Systems, the Responsibility Gap, and Moral Entanglement. In 2022 ACM Conference on Fairness,'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 18, 'page_label': '19'}, page_content='Trystan S. Goetze. 2022. Mind the Gap: Autonomous Systems, the Responsibility Gap, and Moral Entanglement. In 2022 ACM Conference on Fairness,\\nAccountability, and Transparency . ACM. https://doi.org/10.1145/3531146.3533106\\nCharles Goodhart. 1975. Problems of monetary management: the UK experience in papers in monetary economics. Monetary Economics 1 (1975).\\nMary L. Gray and Siddharth Suri. 2019. Ghost work: how to stop Silicon Valley from building a new global underclass . Houghton Mifflin Harcourt, Boston.\\nBen Green. 2020. The false promise of risk assessments. In Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency . ACM.\\nhttps://doi.org/10.1145/3351095.3372869\\nBen Green and Yiling Chen. 2019. Disparate Interactions. In Proceedings of the Conference on Fairness, Accountability, and Transparency . ACM. https:\\n//doi.org/10.1145/3287560.3287563'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 18, 'page_label': '19'}, page_content='Ben Green and Yiling Chen. 2019. Disparate Interactions. In Proceedings of the Conference on Fairness, Accountability, and Transparency . ACM. https:\\n//doi.org/10.1145/3287560.3287563\\nNancy Green. 2021. An AI Ethics Course Highlighting Explicit Ethical Agents. In Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society .\\nACM. https://doi.org/10.1145/3461702.3462552\\nDylan Hadfield-Menell and Gillian K. Hadfield. 2019. Incomplete Contracting and AI Alignment. In Proceedings of the 2019 AAAI/ACM Conference on AI,\\nEthics, and Society . ACM. https://doi.org/10.1145/3306618.3314250\\nDanijar Hafner, Jurgis Pasukonis, Jimmy Ba, and Timothy Lillicrap. 2023. Mastering Diverse Domains through World Models. https://doi.org/10.48550/\\narXiv.2301.04104 arXiv:2301.04104 [cs, stat].\\nStacy A. Hickox. 2010. Employer Liability of Negligent Hiring of Ex-Offenders. Saint Louis University Law Journal 55, 3 (2010), 1001–1046. https:\\n//heinonline.org/HOL/P?h=hein.journals/stlulj55&i=1029'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 18, 'page_label': '19'}, page_content='//heinonline.org/HOL/P?h=hein.journals/stlulj55&i=1029\\nJacob Hilton, Jie Tang, and John Schulman. 2023. Scaling laws for single-agent reinforcement learning. https://doi.org/10.48550/arXiv.2301.13442\\narXiv:2301.13442 [cs, stat].\\nJordan Hoffmann, Sebastian Borgeaud, Arthur Mensch, Elena Buchatskaya, Trevor Cai, Eliza Rutherford, Diego de las Casas, Lisa Anne Hendricks,\\nJohannes Welbl, Aidan Clark, Tom Hennigan, Eric Noland, Katherine Millican, George van den Driessche, Bogdan Damoc, Aurelia Guy, Simon\\nOsindero, Karen Simonyan, Erich Elsen, Oriol Vinyals, Jack William Rae, and Laurent Sifre. 2022. An empirical analysis of compute-optimal large\\nlanguage model training. In Advances in Neural Information Processing Systems , Alice H. Oh, Alekh Agarwal, Danielle Belgrave, and Kyunghyun Cho\\n(Eds.). https://openreview.net/forum?id=iBBcRUlOAPR\\nYubo Hou, Dan Xiong, Tonglin Jiang, Lily Song, and Qi Wang. 2019. Social media addiction: Its impact, mediation, and intervention. Cyberpsychology:'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 18, 'page_label': '19'}, page_content='(Eds.). https://openreview.net/forum?id=iBBcRUlOAPR\\nYubo Hou, Dan Xiong, Tonglin Jiang, Lily Song, and Qi Wang. 2019. Social media addiction: Its impact, mediation, and intervention. Cyberpsychology:\\nJournal of Psychosocial Research on Cyberspace 13, 1 (Feb. 2019). https://doi.org/10.5817/CP2019-1-4 Number: 1.\\nWenlong Huang, Fei Xia, Ted Xiao, Harris Chan, Jacky Liang, Pete Florence, Andy Zeng, Jonathan Tompson, Igor Mordatch, Yevgen Chebotar, Pierre\\nSermanet, Noah Brown, Tomas Jackson, Linda Luu, Sergey Levine, Karol Hausman, and Brian Ichter. 2022. Inner Monologue: Embodied Reasoning\\nthrough Planning with Language Models. https://doi.org/10.48550/arXiv.2207.05608 arXiv:2207.05608 [cs].\\nShahin Jabbari, Matthew Joseph, Michael Kearns, Jamie Morgenstern, and Aaron Roth. 2017. Fairness in Reinforcement Learning. In Proceedings of the\\n34th International Conference on Machine Learning . PMLR, 1617–1626. https://proceedings.mlr.press/v70/jabbari17a.html ISSN: 2640-3498.'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 18, 'page_label': '19'}, page_content='34th International Conference on Machine Learning . PMLR, 1617–1626. https://proceedings.mlr.press/v70/jabbari17a.html ISSN: 2640-3498.\\nAbigail Z. Jacobs and Hanna Wallach. 2021. Measurement and Fairness. In Proceedings of the 2021 ACM Conference on Fairness, Accountability, and\\nTransparency (FAccT ’21) . Association for Computing Machinery, New York, NY, USA, 375–385. https://doi.org/10.1145/3442188.3445901 event-place:\\nVirtual Event, Canada.\\nMichael C. Jensen and William H. Meckling. 1976. Theory of the firm: Managerial behavior, agency costs and ownership structure. Journal of Financial\\nEconomics 3, 4 (Oct. 1976), 305–360. https://doi.org/10.1016/0304-405X(76)90026-X\\nZiwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan Su, Yan Xu, Etsuko Ishii, Yejin Bang, Wenliang Dai, Andrea Madotto, and Pascale Fung. 2022. Survey\\nof Hallucination in Natural Language Generation. Comput. Surveys (Nov. 2022), 3571730. https://doi.org/10.1145/3571730 arXiv:2202.03629 [cs].'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 18, 'page_label': '19'}, page_content='of Hallucination in Natural Language Generation. Comput. Surveys (Nov. 2022), 3571730. https://doi.org/10.1145/3571730 arXiv:2202.03629 [cs].\\nRay Jiang, Silvia Chiappa, Tor Lattimore, András György, and Pushmeet Kohli. 2019. Degenerate Feedback Loops in Recommender Systems. InProceedings\\nof the 2019 AAAI/ACM Conference on AI, Ethics, and Society . ACM. https://doi.org/10.1145/3306618.3314288\\nDeborah G. Johnson and Mario Verdicchio. 2017. Reframing AI Discourse. Minds and Machines 27, 4 (Dec. 2017), 575–590. https://doi.org/10.1007/s11023-\\n017-9417-6\\nManuscript submitted to ACM'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 19, 'page_label': '20'}, page_content='20 Chan et al.\\nMatthew Joseph, Michael Kearns, Jamie H Morgenstern, and Aaron Roth. 2016. Fairness in Learning: Classic and Contextual Bandits. In Advances in\\nNeural Information Processing Systems , Vol. 29. Curran Associates, Inc. https://papers.nips.cc/paper/2016/hash/eb163727917cbba1eea208541a643e74-\\nAbstract.html\\nJohn Jumper, Richard Evans, Alexander Pritzel, Tim Green, Michael Figurnov, Olaf Ronneberger, Kathryn Tunyasuvunakool, Russ Bates, Augustin Žídek,\\nAnna Potapenko, Alex Bridgland, Clemens Meyer, Simon A. A. Kohl, Andrew J. Ballard, Andrew Cowie, Bernardino Romera-Paredes, Stanislav Nikolov,\\nRishub Jain, Jonas Adler, Trevor Back, Stig Petersen, David Reiman, Ellen Clancy, Michal Zielinski, Martin Steinegger, Michalina Pacholska, Tamas\\nBerghammer, Sebastian Bodenstein, David Silver, Oriol Vinyals, Andrew W. Senior, Koray Kavukcuoglu, Pushmeet Kohli, and Demis Hassabis. 2021.'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 19, 'page_label': '20'}, page_content='Berghammer, Sebastian Bodenstein, David Silver, Oriol Vinyals, Andrew W. Senior, Koray Kavukcuoglu, Pushmeet Kohli, and Demis Hassabis. 2021.\\nHighly accurate protein structure prediction with AlphaFold. Nature 596, 7873 (Aug. 2021), 583–589. https://doi.org/10.1038/s41586-021-03819-2\\nNumber: 7873 Publisher: Nature Publishing Group.\\nJared Kaplan, Sam McCandlish, Tom Henighan, Tom B. Brown, Benjamin Chess, Rewon Child, Scott Gray, Alec Radford, Jeffrey Wu, and Dario Amodei.\\n2020. Scaling Laws for Neural Language Models. https://doi.org/10.48550/arXiv.2001.08361 arXiv:2001.08361 [cs, stat].\\nMaximilian Kasy and Rediet Abebe. 2021. Fairness, Equality, and Power in Algorithmic Decision-Making. In Proceedings of the 2021 ACM Conference on\\nFairness, Accountability, and Transparency (FAccT ’21) . Association for Computing Machinery, New York, NY, USA, 576–586. https://doi.org/10.1145/\\n3442188.3445919 event-place: Virtual Event, Canada.'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 19, 'page_label': '20'}, page_content='Fairness, Accountability, and Transparency (FAccT ’21) . Association for Computing Machinery, New York, NY, USA, 576–586. https://doi.org/10.1145/\\n3442188.3445919 event-place: Virtual Event, Canada.\\nJoe Kava. 2014. Better data centers through machine learning. https://blog.google/inside-google/infrastructure/better-data-centers-through-machine/\\nBetul Keles, Niall McCrae, and Annmarie Grealish. 2020. A systematic review: the influence of social media on depression, anxiety and psychological\\ndistress in adolescents. International Journal of Adolescence and Youth 25, 1 (Dec. 2020), 79–93. https://doi.org/10.1080/02673843.2019.1590851\\nPublisher: Routledge _eprint: https://doi.org/10.1080/02673843.2019.1590851.\\nZachary Kenton, Tom Everitt, Laura Weidinger, Iason Gabriel, Vladimir Mikulik, and Geoffrey Irving. 2021. Alignment of Language Agents.arXiv:2103.14659\\n[cs] (March 2021). http://arxiv.org/abs/2103.14659 arXiv: 2103.14659.'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 19, 'page_label': '20'}, page_content='[cs] (March 2021). http://arxiv.org/abs/2103.14659 arXiv: 2103.14659.\\nZachary Kenton, Ramana Kumar, Sebastian Farquhar, Jonathan Richens, Matt MacDermott, and Tom Everitt. 2022. Discovering Agents. https:\\n//doi.org/10.48550/arXiv.2208.08345 arXiv:2208.08345 [cs].\\nRaffi Khatchadourian. 2015. The Doomsday Invention. The New Yorker (Nov. 2015). https://www.newyorker.com/magazine/2015/11/23/doomsday-\\ninvention-artificial-intelligence-nick-bostrom\\nVictoria Krakovna, Jonathan Uesato, Vladimir Mikulik, Matthew Rahtz, Tom Everitt, Ramana Kumar, Zac Kenton, Jan Leike, and Shane Legg. 2020.\\nSpecification gaming: the flip side of AI ingenuity. DeepMind Blog (2020).\\nDavid Krueger, Tegan Maharaj, and Jan Leike. 2020. Hidden Incentives for Auto-Induced Distributional Shift. https://doi.org/10.48550/arXiv.2009.09153\\narXiv:2009.09153 [cs, stat].\\nT.S. Kuhn and I. Hacking. 2012. The Structure of Scientific Revolutions . University of Chicago Press. https://books.google.co.uk/books?id=3eP5Y_OOuzwC'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 19, 'page_label': '20'}, page_content='arXiv:2009.09153 [cs, stat].\\nT.S. Kuhn and I. Hacking. 2012. The Structure of Scientific Revolutions . University of Chicago Press. https://books.google.co.uk/books?id=3eP5Y_OOuzwC\\nBrenden M. Lake, Tomer D. Ullman, Joshua B. Tenenbaum, and Samuel J. Gershman. 2017. Building machines that learn and think like people. Behavioral\\nand Brain Sciences 40 (2017), e253. https://doi.org/10.1017/S0140525X16001837 Publisher: Cambridge University Press.\\nLauro Langosco Di Langosco, Jack Koch, Lee D Sharkey, Jacob Pfau, and David Krueger. 2022. Goal Misgeneralization in Deep Reinforcement Learning. In\\nProceedings of the 39th International Conference on Machine Learning (Proceedings of Machine Learning Research, Vol. 162) , Kamalika Chaudhuri, Stefanie\\nJegelka, Le Song, Csaba Szepesvari, Gang Niu, and Sivan Sabato (Eds.). PMLR, 12004–12019. https://proceedings.mlr.press/v162/langosco22a.html'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 19, 'page_label': '20'}, page_content='Jegelka, Le Song, Csaba Szepesvari, Gang Niu, and Sivan Sabato (Eds.). PMLR, 12004–12019. https://proceedings.mlr.press/v162/langosco22a.html\\nSeth Lazar. 2022. Legitimacy, Authority, and the Political Value of Explanations. https://doi.org/10.48550/arXiv.2208.08628 arXiv:2208.08628 [cs].\\nDaniel Leufer. 2020. Why We Need to Bust Some Myths about AI. Patterns 1, 7 (Oct. 2020), 100124. https://doi.org/10.1016/j.patter.2020.100124\\nGideon Lewis-Kraus. 2022. How harmful is social media? https://www.newyorker.com/culture/annals-of-inquiry/we-know-less-about-social-media-\\nthan-we-think Publication Title: The New Yorker.\\nBo-hu Li, Bao-cun Hou, Wen-tao Yu, Xiao-bing Lu, and Chun-wei Yang. 2017. Applications of artificial intelligence in intelligent manufacturing: a review.\\nFrontiers of Information Technology & Electronic Engineering 18, 1 (Jan. 2017), 86–96. https://doi.org/10.1631/FITEE.1601885'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 19, 'page_label': '20'}, page_content='Frontiers of Information Technology & Electronic Engineering 18, 1 (Jan. 2017), 86–96. https://doi.org/10.1631/FITEE.1601885\\nYunqi Li, Hanxiong Chen, Shuyuan Xu, Yingqiang Ge, Juntao Tan, Shuchang Liu, and Yongfeng Zhang. 2022. Fairness in Recommendation: A Survey.\\nhttps://doi.org/10.48550/arXiv.2205.13619 arXiv:2205.13619 [cs].\\nStephanie Lin, Jacob Hilton, and Owain Evans. 2022. TruthfulQA: Measuring How Models Mimic Human Falsehoods. In Proceedings of the 60th Annual\\nMeeting of the Association for Computational Linguistics (Volume 1: Long Papers) . Association for Computational Linguistics, Dublin, Ireland, 3214–3252.\\nhttps://doi.org/10.18653/v1/2022.acl-long.229\\nLydia T Liu, Sarah Dean, Esther Rolf, Max Simchowitz, and Moritz Hardt. 2018. Delayed impact of fair machine learning. In International Conference on\\nMachine Learning . PMLR, 3150–3158.'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 19, 'page_label': '20'}, page_content='Lydia T Liu, Sarah Dean, Esther Rolf, Max Simchowitz, and Moritz Hardt. 2018. Delayed impact of fair machine learning. In International Conference on\\nMachine Learning . PMLR, 3150–3158.\\nMichele Loi and Matthias Spielkamp. 2021. Towards Accountability in the Use of Artificial Intelligence for Public Administrations. In Proceedings of the\\n2021 AAAI/ACM Conference on AI, Ethics, and Society . ACM. https://doi.org/10.1145/3461702.3462631\\nKate Manne. 2017. Down Girl: The Logic of Misogyny . Oxford University Press.\\nmaraoz. 2021. Interviewing Albert Einstein via GPT-3. https://maraoz.substack.com/embed\\nJacob Menick, Maja Trebacz, Vladimir Mikulik, John Aslanides, Francis Song, Martin Chadwick, Mia Glaese, Susannah Young, Lucy Campbell-Gillingham,\\nGeoffrey Irving, and Nat McAleese. 2022. Teaching language models to support answers with verified quotes. https://doi.org/10.48550/arXiv.2203.11147\\narXiv:2203.11147 [cs].'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 19, 'page_label': '20'}, page_content='Geoffrey Irving, and Nat McAleese. 2022. Teaching language models to support answers with verified quotes. https://doi.org/10.48550/arXiv.2203.11147\\narXiv:2203.11147 [cs].\\nMeta. 2023. Meta Reports Fourth Quarter and Full Year 2022 Results. https://investor.fb.com/investor-news/press-release-details/2023/Meta-Reports-\\nFourth-Quarter-and-Full-Year-2022-Results/default.aspx\\nManuscript submitted to ACM'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 20, 'page_label': '21'}, page_content='Harms from Increasingly Agentic Algorithmic Systems 21\\nSilvia Milano, Mariarosaria Taddeo, and Luciano Floridi. 2020. Recommender systems and their ethical challenges. AI & SOCIETY 35, 4 (Dec. 2020),\\n957–967. https://doi.org/10.1007/s00146-020-00950-y\\nMargaret Mitchell, Simone Wu, Andrew Zaldivar, Parker Barnes, Lucy Vasserman, Ben Hutchinson, Elena Spitzer, Inioluwa Deborah Raji, and Timnit\\nGebru. 2019. Model Cards for Model Reporting. In Proceedings of the Conference on Fairness, Accountability, and Transparency . ACM. https:\\n//doi.org/10.1145/3287560.3287596\\nVolodymyr Mnih, Koray Kavukcuoglu, David Silver, Alex Graves, Ioannis Antonoglou, Daan Wierstra, and Martin Riedmiller. 2013. Playing Atari with\\nDeep Reinforcement Learning. https://doi.org/10.48550/arXiv.1312.5602 arXiv:1312.5602 [cs].\\nAI Myths. [n. d.]. Myth: AI has agency. https://www.aimyths.org/ai-has-agency'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 20, 'page_label': '21'}, page_content='Deep Reinforcement Learning. https://doi.org/10.48550/arXiv.1312.5602 arXiv:1312.5602 [cs].\\nAI Myths. [n. d.]. Myth: AI has agency. https://www.aimyths.org/ai-has-agency\\nReiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu, Long Ouyang, Christina Kim, Christopher Hesse, Shantanu Jain, Vineet Kosaraju, William Saunders,\\nXu Jiang, Karl Cobbe, Tyna Eloundou, Gretchen Krueger, Kevin Button, Matthew Knight, Benjamin Chess, and John Schulman. 2022. WebGPT:\\nBrowser-assisted question-answering with human feedback. https://doi.org/10.48550/arXiv.2112.09332 arXiv:2112.09332 [cs].\\nSimone Natale and Andrea Ballatore. 2020. Imagining the thinking machine: Technological myths and the rise of artificial intelligence. Convergence 26, 1\\n(2020), 3–18. Publisher: SAGE Publications Sage UK: London, England.\\nPandu Nayak. 2019. Understanding searches better than ever before. https://blog.google/products/search/search-language-understanding-bert/'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 20, 'page_label': '21'}, page_content='Pandu Nayak. 2019. Understanding searches better than ever before. https://blog.google/products/search/search-language-understanding-bert/\\nHelen Nissenbaum. 1996. Accountability in a computerized society. Science and Engineering Ethics 2, 1 (March 1996), 25–42. https://doi.org/10.1007/\\nBF02639315\\nZiad Obermeyer and Sendhil Mullainathan. 2019. Dissecting Racial Bias in an Algorithm that Guides Health Decisions for 70 Million People. InProceedings\\nof the Conference on Fairness, Accountability, and Transparency . ACM. https://doi.org/10.1145/3287560.3287593\\nCatherine Olsson, Nelson Elhage, Neel Nanda, Nicholas Joseph, Nova DasSarma, Tom Henighan, Ben Mann, Amanda Askell, Yuntao Bai, Anna Chen,\\nTom Conerly, Dawn Drain, Deep Ganguli, Zac Hatfield-Dodds, Danny Hernandez, Scott Johnston, Andy Jones, Jackson Kernion, Liane Lovitt, Kamal\\nNdousse, Dario Amodei, Tom Brown, Jack Clark, Jared Kaplan, Sam McCandlish, and Chris Olah. 2022. In-context Learning and Induction Heads.'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 20, 'page_label': '21'}, page_content='Ndousse, Dario Amodei, Tom Brown, Jack Clark, Jared Kaplan, Sam McCandlish, and Chris Olah. 2022. In-context Learning and Induction Heads.\\nTransformer Circuits Thread (2022).\\nStephen M Omohundro. 2008. The Basic AI Drives. In AGI, Vol. 171. 483–492.\\nOpenAI. 2022. ChatGPT: Optimizing Language Models for Dialogue. https://openai.com/blog/chatgpt/\\nLaurent Orseau, Simon McGregor McGill, and Shane Legg. 2018. Agents and Devices: A Relative Definition of Agency. https://doi.org/10.48550/arXiv.\\n1805.12387 arXiv:1805.12387 [cs, stat].\\nAlexander Pan, Kush Bhatia, and Jacob Steinhardt. 2022. The Effects of Reward Misspecification: Mapping and Mitigating Misaligned Models. In\\nInternational Conference on Learning Representations . https://openreview.net/forum?id=JYtwGwIL7ye\\nJoon Sung Park, Lindsay Popowski, Carrie Cai, Meredith Ringel Morris, Percy Liang, and Michael S. Bernstein. 2022. Social Simulacra: Creating Populated'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 20, 'page_label': '21'}, page_content='Joon Sung Park, Lindsay Popowski, Carrie Cai, Meredith Ringel Morris, Percy Liang, and Michael S. Bernstein. 2022. Social Simulacra: Creating Populated\\nPrototypes for Social Computing Systems. In Proceedings of the 35th Annual ACM Symposium on User Interface Software and Technology (UIST ’22) .\\nAssociation for Computing Machinery, New York, NY, USA, 1–18. https://doi.org/10.1145/3526113.3545616\\nMatteo Pasquinelli and Vladan Joler. 2021. The Nooscope manifested: AI as instrument of knowledge extractivism. AI & SOCIETY 36, 4 (Dec. 2021),\\n1263–1280. https://doi.org/10.1007/s00146-020-01097-6\\nEthan Perez, Sam Ringer, Kamil˙e Lukoši¯ut˙e, Karina Nguyen, Edwin Chen, Scott Heiner, Craig Pettit, Catherine Olsson, Sandipan Kundu, Saurav Kadavath,\\nAndy Jones, Anna Chen, Ben Mann, Brian Israel, Bryan Seethor, Cameron McKinnon, Christopher Olah, Da Yan, Daniela Amodei, Dario Amodei,'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 20, 'page_label': '21'}, page_content='Andy Jones, Anna Chen, Ben Mann, Brian Israel, Bryan Seethor, Cameron McKinnon, Christopher Olah, Da Yan, Daniela Amodei, Dario Amodei,\\nDawn Drain, Dustin Li, Eli Tran-Johnson, Guro Khundadze, Jackson Kernion, James Landis, Jamie Kerr, Jared Mueller, Jeeyoon Hyun, Joshua Landau,\\nKamal Ndousse, Landon Goldberg, Liane Lovitt, Martin Lucas, Michael Sellitto, Miranda Zhang, Neerav Kingsland, Nelson Elhage, Nicholas Joseph,\\nNoemí Mercado, Nova DasSarma, Oliver Rausch, Robin Larson, Sam McCandlish, Scott Johnston, Shauna Kravec, Sheer El Showk, Tamera Lanham,\\nTimothy Telleen-Lawton, Tom Brown, Tom Henighan, Tristan Hume, Yuntao Bai, Zac Hatfield-Dodds, Jack Clark, Samuel R. Bowman, Amanda Askell,\\nRoger Grosse, Danny Hernandez, Deep Ganguli, Evan Hubinger, Nicholas Schiefer, and Jared Kaplan. 2022. Discovering Language Model Behaviors\\nwith Model-Written Evaluations. https://doi.org/10.48550/arXiv.2212.09251 arXiv:2212.09251 [cs].'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 20, 'page_label': '21'}, page_content='with Model-Written Evaluations. https://doi.org/10.48550/arXiv.2212.09251 arXiv:2212.09251 [cs].\\nJulien Perolat, Bart De Vylder, Daniel Hennes, Eugene Tarassov, Florian Strub, Vincent de Boer, Paul Muller, Jerome T. Connor, Neil Burch, Thomas\\nAnthony, Stephen McAleer, Romuald Elie, Sarah H. Cen, Zhe Wang, Audrunas Gruslys, Aleksandra Malysheva, Mina Khan, Sherjil Ozair, Finbarr\\nTimbers, Toby Pohlen, Tom Eccles, Mark Rowland, Marc Lanctot, Jean-Baptiste Lespiau, Bilal Piot, Shayegan Omidshafiei, Edward Lockhart, Laurent\\nSifre, Nathalie Beauguerlange, Remi Munos, David Silver, Satinder Singh, Demis Hassabis, and Karl Tuyls. 2022. Mastering the game of Stratego with\\nmodel-free multiagent reinforcement learning. Science 378, 6623 (Dec. 2022), 990–996. https://doi.org/10.1126/science.add4679 Publisher: American\\nAssociation for the Advancement of Science.'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 20, 'page_label': '21'}, page_content='model-free multiagent reinforcement learning. Science 378, 6623 (Dec. 2022), 990–996. https://doi.org/10.1126/science.add4679 Publisher: American\\nAssociation for the Advancement of Science.\\nBilly Perrigo. 2023. Exclusive: The $2 Per Hour Workers Who Made ChatGPT Safer. Time (Jan. 2023). https://time.com/6247678/openai-chatgpt-kenya-\\nworkers/\\nSteven T. Piantadosi and Felix Hill. 2022. Meaning without reference in large language models. https://doi.org/10.48550/arXiv.2208.02957 arXiv:2208.02957\\n[cs].\\nBy Pratyusha. 2020. World view. Nature 583 (2020), 169.\\nJack W. Rae, Sebastian Borgeaud, Trevor Cai, Katie Millican, Jordan Hoffmann, Francis Song, John Aslanides, Sarah Henderson, Roman Ring, Susannah\\nYoung, Eliza Rutherford, Tom Hennigan, Jacob Menick, Albin Cassirer, Richard Powell, George van den Driessche, Lisa Anne Hendricks, Maribeth\\nRauh, Po-Sen Huang, Amelia Glaese, Johannes Welbl, Sumanth Dathathri, Saffron Huang, Jonathan Uesato, John Mellor, Irina Higgins, Antonia'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 20, 'page_label': '21'}, page_content='Rauh, Po-Sen Huang, Amelia Glaese, Johannes Welbl, Sumanth Dathathri, Saffron Huang, Jonathan Uesato, John Mellor, Irina Higgins, Antonia\\nCreswell, Nat McAleese, Amy Wu, Erich Elsen, Siddhant Jayakumar, Elena Buchatskaya, David Budden, Esme Sutherland, Karen Simonyan, Michela\\nManuscript submitted to ACM'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 21, 'page_label': '22'}, page_content='22 Chan et al.\\nPaganini, Laurent Sifre, Lena Martens, Xiang Lorraine Li, Adhiguna Kuncoro, Aida Nematzadeh, Elena Gribovskaya, Domenic Donato, Angeliki\\nLazaridou, Arthur Mensch, Jean-Baptiste Lespiau, Maria Tsimpoukelli, Nikolai Grigorev, Doug Fritz, Thibault Sottiaux, Mantas Pajarskas, Toby Pohlen,\\nZhitao Gong, Daniel Toyama, Cyprien de Masson d’Autume, Yujia Li, Tayfun Terzi, Vladimir Mikulik, Igor Babuschkin, Aidan Clark, Diego de Las\\nCasas, Aurelia Guy, Chris Jones, James Bradbury, Matthew Johnson, Blake Hechtman, Laura Weidinger, Iason Gabriel, William Isaac, Ed Lockhart,\\nSimon Osindero, Laura Rimell, Chris Dyer, Oriol Vinyals, Kareem Ayoub, Jeff Stanway, Lorrayne Bennett, Demis Hassabis, Koray Kavukcuoglu, and\\nGeoffrey Irving. 2022. Scaling Language Models: Methods, Analysis & Insights from Training Gopher. https://doi.org/10.48550/arXiv.2112.11446\\narXiv:2112.11446 [cs].'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 21, 'page_label': '22'}, page_content='Geoffrey Irving. 2022. Scaling Language Models: Methods, Analysis & Insights from Training Gopher. https://doi.org/10.48550/arXiv.2112.11446\\narXiv:2112.11446 [cs].\\nDeborah Raji, Emily Denton, Emily M. Bender, Alex Hanna, and Amandalynne Paullada. 2021. AI and the Everything in the Whole Wide World\\nBenchmark. Proceedings of the Neural Information Processing Systems Track on Datasets and Benchmarks 1 (Dec. 2021). https://datasets-benchmarks-\\nproceedings.neurips.cc/paper/2021/hash/084b6fbb10729ed4da8c3d3f5a3ae7c9-Abstract-round2.html\\nInioluwa Deborah Raji and Joy Buolamwini. 2019. Actionable Auditing. In Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and Society . ACM.\\nhttps://doi.org/10.1145/3306618.3314244\\nInioluwa Deborah Raji, I. Elizabeth Kumar, Aaron Horowitz, and Andrew Selbst. 2022. The Fallacy of AI Functionality. In2022 ACM Conference on Fairness,\\nAccountability, and Transparency . ACM. https://doi.org/10.1145/3531146.3533158'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 21, 'page_label': '22'}, page_content='Accountability, and Transparency . ACM. https://doi.org/10.1145/3531146.3533158\\nInioluwa Deborah Raji, Andrew Smart, Rebecca N. White, Margaret Mitchell, Timnit Gebru, Ben Hutchinson, Jamila Smith-Loud, Daniel Theron, and\\nParker Barnes. 2020. Closing the AI accountability gap. In Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency . ACM.\\nhttps://doi.org/10.1145/3351095.3372873\\nScott Reed, Konrad Zolna, Emilio Parisotto, Sergio Gómez Colmenarejo, Alexander Novikov, Gabriel Barth-maron, Mai Giménez, Yury Sulsky, Jackie Kay,\\nJost Tobias Springenberg, Tom Eccles, Jake Bruce, Ali Razavi, Ashley Edwards, Nicolas Heess, Yutian Chen, Raia Hadsell, Oriol Vinyals, Mahyar Bordbar,\\nand Nando de Freitas. 2022. A Generalist Agent. Transactions on Machine Learning Research (2022). https://openreview.net/forum?id=1ikK0kHjvj\\nManoel Horta Ribeiro, Raphael Ottoni, Robert West, Virgílio A. F. Almeida, and Wagner Meira. 2020. Auditing radicalization pathways on YouTube. In'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 21, 'page_label': '22'}, page_content='Manoel Horta Ribeiro, Raphael Ottoni, Robert West, Virgílio A. F. Almeida, and Wagner Meira. 2020. Auditing radicalization pathways on YouTube. In\\nProceedings of the 2020 Conference on Fairness, Accountability, and Transparency . ACM. https://doi.org/10.1145/3351095.3372879\\nPaul Robinette, Wenchen Li, Robert Allen, Ayanna M Howard, and Alan R Wagner. 2016. Overtrust of robots in emergency evacuation scenarios. In 2016\\n11th ACM/IEEE international conference on human-robot interaction (HRI) . IEEE, 101–108.\\nStuart J. Russell and Peter Norvig. 2021. Artificial Intelligence: A Modern Approach (4 ed.).\\nMarkus Schlosser. 2019. Agency. In The Stanford Encyclopedia of Philosophy (winter 2019 ed.), Edward N. Zalta (Ed.). Metaphysics Research Lab, Stanford\\nUniversity. https://plato.stanford.edu/archives/win2019/entries/agency/\\nRon Schmelzer. 2019. Amazon Dives Deep into Reinforcement Learning. Forbes (June 2019). https://www.forbes.com/sites/cognitiveworld/2019/06/14/'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 21, 'page_label': '22'}, page_content='Ron Schmelzer. 2019. Amazon Dives Deep into Reinforcement Learning. Forbes (June 2019). https://www.forbes.com/sites/cognitiveworld/2019/06/14/\\namazon-dives-deep-into-reinforcement-learning/ Section: AI & Big Data.\\nJulian Schrittwieser, Ioannis Antonoglou, Thomas Hubert, Karen Simonyan, Laurent Sifre, Simon Schmitt, Arthur Guez, Edward Lockhart, Demis Hassabis,\\nThore Graepel, Timothy Lillicrap, and David Silver. 2020. Mastering Atari, Go, chess and shogi by planning with a learned model. Nature 588, 7839\\n(Dec. 2020), 604–609. https://doi.org/10.1038/s41586-020-03051-4 Number: 7839 Publisher: Nature Publishing Group.\\nAnne Schulz, P Howard, and R Nielsen. 2019. Industry, Experts, or Industry Experts? Academic Sourcing in News Coverage of AI. (2019). Publisher:\\nReuters Institute for the Study of Journalism.\\nAndrew D. Selbst, Danah Boyd, Sorelle A. Friedler, Suresh Venkatasubramanian, and Janet Vertesi. 2019. Fairness and Abstraction in Sociotechnical'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 21, 'page_label': '22'}, page_content='Reuters Institute for the Study of Journalism.\\nAndrew D. Selbst, Danah Boyd, Sorelle A. Friedler, Suresh Venkatasubramanian, and Janet Vertesi. 2019. Fairness and Abstraction in Sociotechnical\\nSystems. In Proceedings of the Conference on Fairness, Accountability, and Transparency . ACM. https://doi.org/10.1145/3287560.3287598\\nMark Sendak, Madeleine Clare Elish, Michael Gao, Joseph Futoma, William Ratliff, Marshall Nichols, Armando Bedoya, Suresh Balu, and Cara O’Brien.\\n2020. \"The human body is a black box\". In Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency . ACM. https://doi.org/10.\\n1145/3351095.3372827\\nRohin Shah, Vikrant Varma, Ramana Kumar, Mary Phuong, Victoria Krakovna, Jonathan Uesato, and Zac Kenton. 2022. Goal Misgeneralization: Why\\nCorrect Specifications Aren’t Enough For Correct Goals. https://doi.org/10.48550/arXiv.2210.01790 arXiv:2210.01790 [cs].'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 21, 'page_label': '22'}, page_content='Correct Specifications Aren’t Enough For Correct Goals. https://doi.org/10.48550/arXiv.2210.01790 arXiv:2210.01790 [cs].\\nRenee Shelby, Shalaleh Rismani, Kathryn Henne, AJung Moon, Negar Rostamzadeh, Paul Nicholas, N’Mah Yilla, Jess Gallegos, Andrew Smart, Emilio\\nGarcia, and Gurleen Virk. 2022. Sociotechnical Harms: Scoping a Taxonomy for Harm Reduction. https://doi.org/10.48550/arXiv.2210.05791\\narXiv:2210.05791 [cs].\\nDavid Silver, Aja Huang, Chris J. Maddison, Arthur Guez, Laurent Sifre, George van den Driessche, Julian Schrittwieser, Ioannis Antonoglou, Veda\\nPanneershelvam, Marc Lanctot, Sander Dieleman, Dominik Grewe, John Nham, Nal Kalchbrenner, Ilya Sutskever, Timothy Lillicrap, Madeleine Leach,\\nKoray Kavukcuoglu, Thore Graepel, and Demis Hassabis. 2016. Mastering the game of Go with deep neural networks and tree search. Nature 529,\\n7587 (Jan. 2016), 484–489. https://doi.org/10.1038/nature16961 Number: 7587 Publisher: Nature Publishing Group.'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 21, 'page_label': '22'}, page_content='7587 (Jan. 2016), 484–489. https://doi.org/10.1038/nature16961 Number: 7587 Publisher: Nature Publishing Group.\\nDavid Silver, Thomas Hubert, Julian Schrittwieser, Ioannis Antonoglou, Matthew Lai, Arthur Guez, Marc Lanctot, Laurent Sifre, Dharshan Kumaran,\\nThore Graepel, Timothy Lillicrap, Karen Simonyan, and Demis Hassabis. 2017. Mastering Chess and Shogi by Self-Play with a General Reinforcement\\nLearning Algorithm. https://doi.org/10.48550/arXiv.1712.01815 arXiv:1712.01815 [cs].\\nJoar Max Viktor Skalse, Nikolaus H. R. Howe, Dmitrii Krasheninnikov, and David Krueger. 2022. Defining and Characterizing Reward Hacking. InAdvances\\nin Neural Information Processing Systems , Alice H. Oh, Alekh Agarwal, Danielle Belgrave, and Kyunghyun Cho (Eds.). https://arxiv.org/abs/2209.13085\\nElizabeth S Spelke and Katherine D Kinzler. 2007. Core knowledge. Developmental science 10, 1 (2007), 89–96. Publisher: Wiley Online Library.'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 21, 'page_label': '22'}, page_content='Elizabeth S Spelke and Katherine D Kinzler. 2007. Core knowledge. Developmental science 10, 1 (2007), 89–96. Publisher: Wiley Online Library.\\nAarohi Srivastava, Abhinav Rastogi, Abhishek Rao, Abu Awal Md Shoeb, Abubakar Abid, Adam Fisch, Adam R. Brown, Adam Santoro, Aditya Gupta, Adrià\\nGarriga-Alonso, Agnieszka Kluska, Aitor Lewkowycz, Akshat Agarwal, Alethea Power, Alex Ray, Alex Warstadt, Alexander W. Kocurek, Ali Safaya,\\nManuscript submitted to ACM'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 22, 'page_label': '23'}, page_content='Harms from Increasingly Agentic Algorithmic Systems 23\\nAli Tazarv, Alice Xiang, Alicia Parrish, Allen Nie, Aman Hussain, Amanda Askell, Amanda Dsouza, Ambrose Slone, Ameet Rahane, Anantharaman S.\\nIyer, Anders Andreassen, Andrea Madotto, Andrea Santilli, Andreas Stuhlmüller, Andrew Dai, Andrew La, Andrew Lampinen, Andy Zou, Angela Jiang,\\nAngelica Chen, Anh Vuong, Animesh Gupta, Anna Gottardi, Antonio Norelli, Anu Venkatesh, Arash Gholamidavoodi, Arfa Tabassum, Arul Menezes,\\nArun Kirubarajan, Asher Mullokandov, Ashish Sabharwal, Austin Herrick, Avia Efrat, Aykut Erdem, Ayla Karakaş, B. Ryan Roberts, Bao Sheng\\nLoe, Barret Zoph, Bartłomiej Bojanowski, Batuhan Özyurt, Behnam Hedayatnia, Behnam Neyshabur, Benjamin Inden, Benno Stein, Berk Ekmekci,\\nBill Yuchen Lin, Blake Howald, Cameron Diao, Cameron Dour, Catherine Stinson, Cedrick Argueta, César Ferri Ramírez, Chandan Singh, Charles'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 22, 'page_label': '23'}, page_content='Bill Yuchen Lin, Blake Howald, Cameron Diao, Cameron Dour, Catherine Stinson, Cedrick Argueta, César Ferri Ramírez, Chandan Singh, Charles\\nRathkopf, Chenlin Meng, Chitta Baral, Chiyu Wu, Chris Callison-Burch, Chris Waites, Christian Voigt, Christopher D. Manning, Christopher Potts,\\nCindy Ramirez, Clara E. Rivera, Clemencia Siro, Colin Raffel, Courtney Ashcraft, Cristina Garbacea, Damien Sileo, Dan Garrette, Dan Hendrycks, Dan\\nKilman, Dan Roth, Daniel Freeman, Daniel Khashabi, Daniel Levy, Daniel Moseguí González, Danielle Perszyk, Danny Hernandez, Danqi Chen, Daphne\\nIppolito, Dar Gilboa, David Dohan, David Drakard, David Jurgens, Debajyoti Datta, Deep Ganguli, Denis Emelin, Denis Kleyko, Deniz Yuret, Derek\\nChen, Derek Tam, Dieuwke Hupkes, Diganta Misra, Dilyar Buzan, Dimitri Coelho Mollo, Diyi Yang, Dong-Ho Lee, Ekaterina Shutova, Ekin Dogus\\nCubuk, Elad Segal, Eleanor Hagerman, Elizabeth Barnes, Elizabeth Donoway, Ellie Pavlick, Emanuele Rodola, Emma Lam, Eric Chu, Eric Tang, Erkut'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 22, 'page_label': '23'}, page_content='Cubuk, Elad Segal, Eleanor Hagerman, Elizabeth Barnes, Elizabeth Donoway, Ellie Pavlick, Emanuele Rodola, Emma Lam, Eric Chu, Eric Tang, Erkut\\nErdem, Ernie Chang, Ethan A. Chi, Ethan Dyer, Ethan Jerzak, Ethan Kim, Eunice Engefu Manyasi, Evgenii Zheltonozhskii, Fanyue Xia, Fatemeh\\nSiar, Fernando Martínez-Plumed, Francesca Happé, Francois Chollet, Frieda Rong, Gaurav Mishra, Genta Indra Winata, Gerard de Melo, Germán\\nKruszewski, Giambattista Parascandolo, Giorgio Mariani, Gloria Wang, Gonzalo Jaimovitch-López, Gregor Betz, Guy Gur-Ari, Hana Galijasevic,\\nHannah Kim, Hannah Rashkin, Hannaneh Hajishirzi, Harsh Mehta, Hayden Bogar, Henry Shevlin, Hinrich Schütze, Hiromu Yakura, Hongming Zhang,\\nHugh Mee Wong, Ian Ng, Isaac Noble, Jaap Jumelet, Jack Geissinger, Jackson Kernion, Jacob Hilton, Jaehoon Lee, Jaime Fernández Fisac, James B.\\nSimon, James Koppel, James Zheng, James Zou, Jan Kocoń, Jana Thompson, Jared Kaplan, Jarema Radom, Jascha Sohl-Dickstein, Jason Phang, Jason'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 22, 'page_label': '23'}, page_content='Simon, James Koppel, James Zheng, James Zou, Jan Kocoń, Jana Thompson, Jared Kaplan, Jarema Radom, Jascha Sohl-Dickstein, Jason Phang, Jason\\nWei, Jason Yosinski, Jekaterina Novikova, Jelle Bosscher, Jennifer Marsh, Jeremy Kim, Jeroen Taal, Jesse Engel, Jesujoba Alabi, Jiacheng Xu, Jiaming\\nSong, Jillian Tang, Joan Waweru, John Burden, John Miller, John U. Balis, Jonathan Berant, Jörg Frohberg, Jos Rozen, Jose Hernandez-Orallo, Joseph\\nBoudeman, Joseph Jones, Joshua B. Tenenbaum, Joshua S. Rule, Joyce Chua, Kamil Kanclerz, Karen Livescu, Karl Krauth, Karthik Gopalakrishnan,\\nKaterina Ignatyeva, Katja Markert, Kaustubh D. Dhole, Kevin Gimpel, Kevin Omondi, Kory Mathewson, Kristen Chiafullo, Ksenia Shkaruta, Kumar\\nShridhar, Kyle McDonell, Kyle Richardson, Laria Reynolds, Leo Gao, Li Zhang, Liam Dugan, Lianhui Qin, Lidia Contreras-Ochando, Louis-Philippe'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 22, 'page_label': '23'}, page_content='Shridhar, Kyle McDonell, Kyle Richardson, Laria Reynolds, Leo Gao, Li Zhang, Liam Dugan, Lianhui Qin, Lidia Contreras-Ochando, Louis-Philippe\\nMorency, Luca Moschella, Lucas Lam, Lucy Noble, Ludwig Schmidt, Luheng He, Luis Oliveros Colón, Luke Metz, Lütfi Kerem Şenel, Maarten Bosma,\\nMaarten Sap, Maartje ter Hoeve, Maheen Farooqi, Manaal Faruqui, Mantas Mazeika, Marco Baturan, Marco Marelli, Marco Maru, Maria Jose Ramírez\\nQuintana, Marie Tolkiehn, Mario Giulianelli, Martha Lewis, Martin Potthast, Matthew L. Leavitt, Matthias Hagen, Mátyás Schubert, Medina Orduna\\nBaitemirova, Melody Arnaud, Melvin McElrath, Michael A. Yee, Michael Cohen, Michael Gu, Michael Ivanitskiy, Michael Starritt, Michael Strube,\\nMichał Swędrowski, Michele Bevilacqua, Michihiro Yasunaga, Mihir Kale, Mike Cain, Mimee Xu, Mirac Suzgun, Mo Tiwari, Mohit Bansal, Moin\\nAminnaseri, Mor Geva, Mozhdeh Gheini, Mukund Varma T, Nanyun Peng, Nathan Chi, Nayeon Lee, Neta Gur-Ari Krakover, Nicholas Cameron,'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 22, 'page_label': '23'}, page_content='Aminnaseri, Mor Geva, Mozhdeh Gheini, Mukund Varma T, Nanyun Peng, Nathan Chi, Nayeon Lee, Neta Gur-Ari Krakover, Nicholas Cameron,\\nNicholas Roberts, Nick Doiron, Nikita Nangia, Niklas Deckers, Niklas Muennighoff, Nitish Shirish Keskar, Niveditha S. Iyer, Noah Constant, Noah\\nFiedel, Nuan Wen, Oliver Zhang, Omar Agha, Omar Elbaghdadi, Omer Levy, Owain Evans, Pablo Antonio Moreno Casares, Parth Doshi, Pascale Fung,\\nPaul Pu Liang, Paul Vicol, Pegah Alipoormolabashi, Peiyuan Liao, Percy Liang, Peter Chang, Peter Eckersley, Phu Mon Htut, Pinyu Hwang, Piotr\\nMiłkowski, Piyush Patil, Pouya Pezeshkpour, Priti Oli, Qiaozhu Mei, Qing Lyu, Qinlang Chen, Rabin Banjade, Rachel Etta Rudolph, Raefer Gabriel,\\nRahel Habacker, Ramón Risco Delgado, Raphaël Millière, Rhythm Garg, Richard Barnes, Rif A. Saurous, Riku Arakawa, Robbe Raymaekers, Robert\\nFrank, Rohan Sikand, Roman Novak, Roman Sitelew, Ronan LeBras, Rosanne Liu, Rowan Jacobs, Rui Zhang, Ruslan Salakhutdinov, Ryan Chi, Ryan'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 22, 'page_label': '23'}, page_content='Frank, Rohan Sikand, Roman Novak, Roman Sitelew, Ronan LeBras, Rosanne Liu, Rowan Jacobs, Rui Zhang, Ruslan Salakhutdinov, Ryan Chi, Ryan\\nLee, Ryan Stovall, Ryan Teehan, Rylan Yang, Sahib Singh, Saif M. Mohammad, Sajant Anand, Sam Dillavou, Sam Shleifer, Sam Wiseman, Samuel\\nGruetter, Samuel R. Bowman, Samuel S. Schoenholz, Sanghyun Han, Sanjeev Kwatra, Sarah A. Rous, Sarik Ghazarian, Sayan Ghosh, Sean Casey,\\nSebastian Bischoff, Sebastian Gehrmann, Sebastian Schuster, Sepideh Sadeghi, Shadi Hamdan, Sharon Zhou, Shashank Srivastava, Sherry Shi, Shikhar\\nSingh, Shima Asaadi, Shixiang Shane Gu, Shubh Pachchigar, Shubham Toshniwal, Shyam Upadhyay, Shyamolima, Debnath, Siamak Shakeri, Simon\\nThormeyer, Simone Melzi, Siva Reddy, Sneha Priscilla Makini, Soo-Hwan Lee, Spencer Torene, Sriharsha Hatwar, Stanislas Dehaene, Stefan Divic,\\nStefano Ermon, Stella Biderman, Stephanie Lin, Stephen Prasad, Steven T. Piantadosi, Stuart M. Shieber, Summer Misherghi, Svetlana Kiritchenko,'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 22, 'page_label': '23'}, page_content='Stefano Ermon, Stella Biderman, Stephanie Lin, Stephen Prasad, Steven T. Piantadosi, Stuart M. Shieber, Summer Misherghi, Svetlana Kiritchenko,\\nSwaroop Mishra, Tal Linzen, Tal Schuster, Tao Li, Tao Yu, Tariq Ali, Tatsu Hashimoto, Te-Lin Wu, Théo Desbordes, Theodore Rothschild, Thomas\\nPhan, Tianle Wang, Tiberius Nkinyili, Timo Schick, Timofei Kornev, Timothy Telleen-Lawton, Titus Tunduny, Tobias Gerstenberg, Trenton Chang,\\nTrishala Neeraj, Tushar Khot, Tyler Shultz, Uri Shaham, Vedant Misra, Vera Demberg, Victoria Nyamai, Vikas Raunak, Vinay Ramasesh, Vinay Uday\\nPrabhu, Vishakh Padmakumar, Vivek Srikumar, William Fedus, William Saunders, William Zhang, Wout Vossen, Xiang Ren, Xiaoyu Tong, Xinran\\nZhao, Xinyi Wu, Xudong Shen, Yadollah Yaghoobzadeh, Yair Lakretz, Yangqiu Song, Yasaman Bahri, Yejin Choi, Yichi Yang, Yiding Hao, Yifu Chen,\\nYonatan Belinkov, Yu Hou, Yufang Hou, Yuntao Bai, Zachary Seid, Zhuoye Zhao, Zijian Wang, Zijie J. Wang, Zirui Wang, and Ziyi Wu. 2022. Beyond'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 22, 'page_label': '23'}, page_content='Yonatan Belinkov, Yu Hou, Yufang Hou, Yuntao Bai, Zachary Seid, Zhuoye Zhao, Zijian Wang, Zijie J. Wang, Zirui Wang, and Ziyi Wu. 2022. Beyond\\nthe Imitation Game: Quantifying and extrapolating the capabilities of language models. https://doi.org/10.48550/arXiv.2206.04615 arXiv:2206.04615\\n[cs, stat].\\nLogan Stapleton, Min Hun Lee, Diana Qing, Marya Wright, Alexandra Chouldechova, Ken Holstein, Zhiwei Steven Wu, and Haiyi Zhu. 2022. Imagining\\nnew futures beyond predictive systems in child welfare: A qualitative study with impacted stakeholders. In 2022 ACM Conference on Fairness,\\nAccountability, and Transparency . ACM. https://doi.org/10.1145/3531146.3533177\\nsteven t. piantadosi [@spiantado]. 2022. Yes, ChatGPT is amazing and impressive. No, @OpenAI has not come close to addressing the problem of bias.\\nFilters appear to be bypassed with simple tricks, and superficially masked. And what is lurking inside is egregious. @Abebab @sama tw racism,'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 22, 'page_label': '23'}, page_content='Filters appear to be bypassed with simple tricks, and superficially masked. And what is lurking inside is egregious. @Abebab @sama tw racism,\\nsexism. https://t.co/V4fw1fY9dY. https://twitter.com/spiantado/status/1599462375887114240\\nManuscript submitted to ACM'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 23, 'page_label': '24'}, page_content='24 Chan et al.\\nJonathan M. Stokes, Kevin Yang, Kyle Swanson, Wengong Jin, Andres Cubillos-Ruiz, Nina M. Donghia, Craig R. MacNair, Shawn French, Lindsey A.\\nCarfrae, Zohar Bloom-Ackermann, Victoria M. Tran, Anush Chiappino-Pepe, Ahmed H. Badran, Ian W. Andrews, Emma J. Chory, George M. Church,\\nEric D. Brown, Tommi S. Jaakkola, Regina Barzilay, and James J. Collins. 2020. A Deep Learning Approach to Antibiotic Discovery. Cell 180, 4 (Feb.\\n2020), 688–702.e13. https://doi.org/10.1016/j.cell.2020.01.021\\nYulia W. Sullivan and Samuel Fosso Wamba. 2022. Moral Judgments in the Age of Artificial Intelligence. Journal of Business Ethics 178, 4 (July 2022),\\n917–943. https://doi.org/10.1007/s10551-022-05053-w\\nRichard Sutton. 2022. https://twitter.com/richardssutton/status/1575619651563708418\\nRichard S Sutton and Andrew G Barto. 2018. Reinforcement learning: An introduction . MIT press.'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 23, 'page_label': '24'}, page_content='Richard Sutton. 2022. https://twitter.com/richardssutton/status/1575619651563708418\\nRichard S Sutton and Andrew G Barto. 2018. Reinforcement learning: An introduction . MIT press.\\nRichard S. Sutton, Michael Bowling, and Patrick M. Pilarski. 2022. The Alberta Plan for AI Research. https://doi.org/10.48550/arXiv.2208.11173\\narXiv:2208.11173 [cs].\\nTom Sühr, Sophie Hilgard, and Himabindu Lakkaraju. 2021. Does Fair Ranking Improve Minority Outcomes? Understanding the Interplay of Human and\\nAlgorithmic Biases in Online Hiring. In Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society . ACM. https://doi.org/10.1145/3461702.\\n3462602\\nAdaptive Agent Team, Jakob Bauer, Kate Baumli, Satinder Baveja, Feryal Behbahani, Avishkar Bhoopchand, Nathalie Bradley-Schmieg, Michael\\nChang, Natalie Clay, Adrian Collister, Vibhavari Dasagi, Lucy Gonzalez, Karol Gregor, Edward Hughes, Sheleem Kashem, Maria Loks-Thompson,'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 23, 'page_label': '24'}, page_content='Chang, Natalie Clay, Adrian Collister, Vibhavari Dasagi, Lucy Gonzalez, Karol Gregor, Edward Hughes, Sheleem Kashem, Maria Loks-Thompson,\\nHannah Openshaw, Jack Parker-Holder, Shreya Pathak, Nicolas Perez-Nieves, Nemanja Rakicevic, Tim Rocktäschel, Yannick Schroecker, Jakub\\nSygnowski, Karl Tuyls, Sarah York, Alexander Zacherl, and Lei Zhang. 2023. Human-Timescale Adaptation in an Open-Ended Task Space. https:\\n//doi.org/10.48550/arXiv.2301.07608 arXiv:2301.07608 [cs].\\nPhilip E Tetlock and Dan Gardner. 2016. Superforecasting: The Art and Science of Prediction . Random House.\\nRobert Trager. 2022. Deliberating Autonomous Weapons. Issues in Science and Technology XXXVIII, 4 (2022). https://issues.org/autonomous-weapons-\\nrussell-forum/\\nAndrew Tutt. 2017. An FDA for Algorithms.Administrative Law Review 69, 1 (2017), 83–124. https://heinonline.org/HOL/P?h=hein.journals/admin69&i=95'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 23, 'page_label': '24'}, page_content='russell-forum/\\nAndrew Tutt. 2017. An FDA for Algorithms.Administrative Law Review 69, 1 (2017), 83–124. https://heinonline.org/HOL/P?h=hein.journals/admin69&i=95\\nKarthik Valmeekam, Alberto Olmo, Sarath Sreedharan, and Subbarao Kambhampati. 2022. Large Language Models Still Can’t Plan (A Benchmark for\\nLLMs on Planning and Reasoning about Change). https://doi.org/10.48550/arXiv.2206.10498 arXiv:2206.10498 [cs].\\nAgnes Schim van der Loeff, Iggy Bassi, Sachin Kapila, and Jevgenij Gamper. 2019. AI Ethics for Systemic Issues: A Structural Approach. https:\\n//doi.org/10.48550/arXiv.1911.03216 arXiv:1911.03216 [cs].\\nLee Vinsel. 2021. You’re Doing It Wrong: Notes on Criticism and Technology Hype. https://sts-news.medium.com/youre-doing-it-wrong-notes-on-\\ncriticism-and-technology-hype-18b08b4307e5\\nHeather Vogell, Haru Coryne, and Ryan Little. 2022. How a secret rent algorithm pushes rents higher. https://www.propublica.org/article/yieldstar-rent-'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 23, 'page_label': '24'}, page_content='criticism-and-technology-hype-18b08b4307e5\\nHeather Vogell, Haru Coryne, and Ryan Little. 2022. How a secret rent algorithm pushes rents higher. https://www.propublica.org/article/yieldstar-rent-\\nincrease-realpage-rent Publication Title: ProPublica.\\nAxel Volkery and Teresa Ribeiro. 2009. Scenario planning in public policy: Understanding use, impacts and the role of institutional context factors.\\nTechnological forecasting and social change 76, 9 (2009), 1198–1207. Publisher: Elsevier.\\nEric Wallace, Shi Feng, Nikhil Kandpal, Matt Gardner, and Sameer Singh. 2019. Universal Adversarial Triggers for Attacking and Analyzing NLP. In\\nProceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language\\nProcessing (EMNLP-IJCNLP) . Association for Computational Linguistics, Hong Kong, China, 2153–2162. https://doi.org/10.18653/v1/D19-1221'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 23, 'page_label': '24'}, page_content='Processing (EMNLP-IJCNLP) . Association for Computational Linguistics, Hong Kong, China, 2153–2162. https://doi.org/10.18653/v1/D19-1221\\nJason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, Ed H.\\nChi, Tatsunori Hashimoto, Oriol Vinyals, Percy Liang, Jeff Dean, and William Fedus. 2022. Emergent Abilities of Large Language Models. Transactions\\non Machine Learning Research (2022). https://openreview.net/forum?id=yzkSU5zdwD\\nJason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed Chi, Quoc Le, and Denny Zhou. 2023. Chain-of-Thought Prompting\\nElicits Reasoning in Large Language Models. https://doi.org/10.48550/arXiv.2201.11903 arXiv:2201.11903 [cs].\\nLaura Weidinger, Jonathan Uesato, Maribeth Rauh, Conor Griffin, Po-Sen Huang, John Mellor, Amelia Glaese, Myra Cheng, Borja Balle, Atoosa Kasirzadeh,'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 23, 'page_label': '24'}, page_content='Laura Weidinger, Jonathan Uesato, Maribeth Rauh, Conor Griffin, Po-Sen Huang, John Mellor, Amelia Glaese, Myra Cheng, Borja Balle, Atoosa Kasirzadeh,\\nCourtney Biles, Sasha Brown, Zac Kenton, Will Hawkins, Tom Stepleton, Abeba Birhane, Lisa Anne Hendricks, Laura Rimell, William Isaac, Julia\\nHaas, Sean Legassick, Geoffrey Irving, and Iason Gabriel. 2022. Taxonomy of Risks posed by Language Models. In 2022 ACM Conference on Fairness,\\nAccountability, and Transparency . ACM. https://doi.org/10.1145/3531146.3533088\\nSean Welsh. 2019. Regulating Lethal and Harmful Autonomy. In Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and Society . ACM.\\nhttps://doi.org/10.1145/3306618.3314295\\nJoe Whittaker, Seán Looney, Alastair Reed, and Fabio Votta. 2021. Recommender systems and the amplification of extremist content. Internet Policy\\nReview 10, 2 (June 2021). https://policyreview.info/articles/analysis/recommender-systems-and-amplification-extremist-content'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 23, 'page_label': '24'}, page_content='Review 10, 2 (June 2021). https://policyreview.info/articles/analysis/recommender-systems-and-amplification-extremist-content\\nMaranke Wieringa. 2020. What to account for when accounting for algorithms. In Proceedings of the 2020 Conference on Fairness, Accountability, and\\nTransparency. ACM. https://doi.org/10.1145/3351095.3372833\\nRobert Wolfe and Aylin Caliskan. 2022. American == White in Multimodal Language-and-Image AI. In Proceedings of the 2022 AAAI/ACM Conference on\\nAI, Ethics, and Society . ACM. https://doi.org/10.1145/3514094.3534136\\nS. Wyatt. 2008. Technological determinism is dead; Long live technological determinism. In Handbook of Science and Technology Studies , E. Hackett,\\nO. Amsterdamska, M. Lynch, and J. Wajcman (Eds.). MIT Press, Cambridge, 165–180.\\nWeirui Ye, Shaohuai Liu, Thanard Kurutach, Pieter Abbeel, and Yang Gao. 2021. Mastering Atari Games with Limited Data. InAdvances in Neural Information'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 23, 'page_label': '24'}, page_content='Weirui Ye, Shaohuai Liu, Thanard Kurutach, Pieter Abbeel, and Yang Gao. 2021. Mastering Atari Games with Limited Data. InAdvances in Neural Information\\nProcessing Systems, Vol. 34. Curran Associates, Inc., 25476–25488. https://proceedings.neurips.cc/paper/2021/hash/d5eca8dc3820cad9fe56a3bafda65ca1-\\nManuscript submitted to ACM'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 24, 'page_label': '25'}, page_content='Harms from Increasingly Agentic Algorithmic Systems 25\\nAbstract.html\\nSunkyung Yoon, Mary Kleinman, Jessica Mertz, and Michael Brannick. 2019. Is social network site usage related to depression? A meta-analysis of\\nFacebook–depression relations. Journal of Affective Disorders 248 (April 2019), 65–72. https://doi.org/10.1016/j.jad.2019.01.026\\nMeg Young, Michael Katell, and P. M. Krafft. 2022. Confronting Power and Corporate Capture at the FAccT Conference. In 2022 ACM Conference on\\nFairness, Accountability, and Transparency . ACM. https://doi.org/10.1145/3531146.3533194\\nAndy Zeng, Maria Attarian, Brian Ichter, Krzysztof Choromanski, Adrian Wong, Stefan Welker, Federico Tombari, Aveek Purohit, Michael Ryoo, Vikas\\nSindhwani, Johnny Lee, Vincent Vanhoucke, and Pete Florence. 2022. Socratic Models: Composing Zero-Shot Multimodal Reasoning with Language.\\nhttps://doi.org/10.48550/arXiv.2204.00598 arXiv:2204.00598 [cs].'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 24, 'page_label': '25'}, page_content='https://doi.org/10.48550/arXiv.2204.00598 arXiv:2204.00598 [cs].\\nXueru Zhang and M. Liu. 2020. Fairness in Learning-Based Sequential Decision Algorithms: A Survey. ArXiv abs/2001.04861 (2020).\\nStephan Zheng, Alexander Trott, Sunil Srinivasa, David C. Parkes, and Richard Socher. 2021. The AI Economist: Optimal Economic Policy Design via\\nTwo-level Deep Reinforcement Learning. https://doi.org/10.48550/arXiv.2108.02755 arXiv:2108.02755 [cs, econ, q-fin].\\nMiri Zilka, Holli Sargeant, and Adrian Weller. 2022. Transparency, Governance and Regulation of Algorithmic Tools Deployed in the Criminal Justice\\nSystem: a UK Case Study. In Proceedings of the 2022 AAAI/ACM Conference on AI, Ethics, and Society . ACM. https://doi.org/10.1145/3514094.3534200\\nRemco Zwetsloot and Allan Dafoe. 2019. Thinking about risks from AI: Accidents, misuse and structure. Lawfare. February 11 (2019), 2019.\\nManuscript submitted to ACM')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "565\n"
     ]
    }
   ],
   "source": [
    "doc_splitter = RecursiveCharacterTextSplitter(chunk_size=1024, chunk_overlap=64)\n",
    "split_texts = doc_splitter.split_documents(texts)\n",
    "print(len(split_texts))  # Prints the number of chunks the PDF has been split into\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 0, 'page_label': '1'}, page_content='Chain-of-Thought Prompting Elicits Reasoning\\nin Large Language Models\\nJason Wei Xuezhi Wang Dale Schuurmans Maarten Bosma\\nBrian Ichter Fei Xia Ed H. Chi Quoc V . Le Denny Zhou\\nGoogle Research, Brain Team\\n{jasonwei,dennyzhou}@google.com\\nAbstract\\nWe explore how generating a chain of thought—a series of intermediate reasoning\\nsteps—signiﬁcantly improves the ability of large language models to perform\\ncomplex reasoning. In particular, we show how such reasoning abilities emerge\\nnaturally in sufﬁciently large language models via a simple method called chain-of-\\nthought prompting, where a few chain of thought demonstrations are provided as\\nexemplars in prompting.\\nExperiments on three large language models show that chain-of-thought prompting\\nimproves performance on a range of arithmetic, commonsense, and symbolic\\nreasoning tasks. The empirical gains can be striking. For instance, prompting a\\nPaLM 540B with just eight chain-of-thought exemplars achieves state-of-the-art'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 0, 'page_label': '1'}, page_content='reasoning tasks. The empirical gains can be striking. For instance, prompting a\\nPaLM 540B with just eight chain-of-thought exemplars achieves state-of-the-art\\naccuracy on the GSM8K benchmark of math word problems, surpassing even\\nﬁnetuned GPT-3 with a veriﬁer.\\nA: The cafeteria had 23 apples originally. They used \\n20 to make lunch. So they had 23 - 20 = 3. They \\nbought 6 more apples, so they have 3 + 6 = 9. The \\nanswer is 9.\\nChain-of-Thought Prompting\\nQ: Roger has 5 tennis balls. He buys 2 more cans of \\ntennis balls. Each can has 3 tennis balls. How many \\ntennis balls does he have now? \\nA: The answer is 11. \\nQ: The cafeteria had 23 apples. If they used 20 to \\nmake lunch and bought 6 more, how many apples \\ndo they have?\\nA: The answer is 27.\\nStandard Prompting\\nQ: Roger has 5 tennis balls. He buys 2 more cans of \\ntennis balls. Each can has 3 tennis balls. How many \\ntennis balls does he have now? \\nA: Roger started with 5 balls. 2 cans of 3 tennis balls'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 0, 'page_label': '1'}, page_content='Q: Roger has 5 tennis balls. He buys 2 more cans of \\ntennis balls. Each can has 3 tennis balls. How many \\ntennis balls does he have now? \\nA: Roger started with 5 balls. 2 cans of 3 tennis balls \\neach is 6 tennis balls. 5 + 6 = 11. The answer is 11. \\nQ: The cafeteria had 23 apples. If they used 20 to \\nmake lunch and bought 6 more, how many apples \\ndo they have?\\nModel Input\\nModel Output Model Output\\nModel Input\\nFigure 1: Chain-of-thought prompting enables large language models to tackle complex arithmetic,\\ncommonsense, and symbolic reasoning tasks. Chain-of-thought reasoning processes are highlighted.\\n36th Conference on Neural Information Processing Systems (NeurIPS 2022).\\narXiv:2201.11903v6  [cs.CL]  10 Jan 2023'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 1, 'page_label': '2'}, page_content='1 Introduction\\nMath Word Problems (GSM8K)\\n0\\n20\\n40\\n60\\n80\\n100\\n33\\n55\\n18\\n57\\nSolve rate (%)\\nFinetuned GPT-3 175B\\nPrior best\\nPaLM 540B: standard prompting\\nPaLM 540B: chain-of-thought prompting\\nFigure 2: PaLM 540B uses chain-of-\\nthought prompting to achieve new state-\\nof-the-art performance on the GSM8K\\nbenchmark of math word problems.\\nFinetuned GPT-3 and prior best are from\\nCobbe et al. (2021).\\nThe NLP landscape has recently been revolutionized by\\nlanguage models (Peters et al., 2018; Devlin et al., 2019;\\nBrown et al., 2020, inter alia). Scaling up the size of lan-\\nguage models has been shown to confer a range of beneﬁts,\\nsuch as improved performance and sample efﬁciency (Ka-\\nplan et al., 2020; Brown et al., 2020, inter alia). However,\\nscaling up model size alone has not proved sufﬁcient for\\nachieving high performance on challenging tasks such as\\narithmetic, commonsense, and symbolic reasoning (Rae\\net al., 2021).\\nThis work explores how the reasoning ability of large'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 1, 'page_label': '2'}, page_content='achieving high performance on challenging tasks such as\\narithmetic, commonsense, and symbolic reasoning (Rae\\net al., 2021).\\nThis work explores how the reasoning ability of large\\nlanguage models can be unlocked by a simple method\\nmotivated by two ideas. First, techniques for arithmetic\\nreasoning can beneﬁt from generating natural language\\nrationales that lead to the ﬁnal answer. Prior work has\\ngiven models the ability to generate natural language inter-\\nmediate steps by training from scratch (Ling et al., 2017)\\nor ﬁnetuning a pretrained model (Cobbe et al., 2021), in\\naddition to neuro-symbolic methods that use formal lan-\\nguages instead of natural language (Roy and Roth, 2015;\\nChiang and Chen, 2019; Amini et al., 2019; Chen et al.,\\n2019). Second, large language models offer the exciting\\nprospect of in-context few-shot learning via prompting. That is, instead of ﬁnetuning a separate\\nlanguage model checkpoint for each new task, one can simply “prompt” the model with a few'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 1, 'page_label': '2'}, page_content='prospect of in-context few-shot learning via prompting. That is, instead of ﬁnetuning a separate\\nlanguage model checkpoint for each new task, one can simply “prompt” the model with a few\\ninput–output exemplars demonstrating the task. Remarkably, this has been successful for a range of\\nsimple question-answering tasks (Brown et al., 2020).\\nBoth of the above ideas, however, have key limitations. For rationale-augmented training and\\nﬁnetuning methods, it is costly to create a large set of high quality rationales, which is much more\\ncomplicated than simple input–output pairs used in normal machine learning. For the traditional few-\\nshot prompting method used in Brown et al. (2020), it works poorly on tasks that require reasoning\\nabilities, and often does not improve substantially with increasing language model scale (Rae et al.,\\n2021). In this paper, we combine the strengths of these two ideas in a way that avoids their limitations.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 1, 'page_label': '2'}, page_content='2021). In this paper, we combine the strengths of these two ideas in a way that avoids their limitations.\\nSpeciﬁcally, we explore the ability of language models to perform few-shot prompting for reasoning\\ntasks, given a prompt that consists of triples: ⟨input, chain of thought, output⟩. A chain of thought is\\na series of intermediate natural language reasoning steps that lead to the ﬁnal output, and we refer to\\nthis approach as chain-of-thought prompting. An example prompt is shown in Figure 1.\\nWe present empirical evaluations on arithmetic, commonsense, and symbolic reasoning benchmarks,\\nshowing that chain-of-thought prompting outperforms standard prompting, sometimes to a striking\\ndegree. Figure 2 illustrates one such result—on the GSM8K benchmark of math word problems\\n(Cobbe et al., 2021), chain-of-thought prompting with PaLM 540B outperforms standard prompting\\nby a large margin and achieves new state-of-the-art performance. A prompting only approach is'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 1, 'page_label': '2'}, page_content='(Cobbe et al., 2021), chain-of-thought prompting with PaLM 540B outperforms standard prompting\\nby a large margin and achieves new state-of-the-art performance. A prompting only approach is\\nimportant because it does not require a large training dataset and because a single model checkpoint\\ncan perform many tasks without loss of generality. This work underscores how large language models\\ncan learn via a few examples with natural language data about the task (c.f. automatically learning\\nthe patterns underlying inputs and outputs via a large training dataset).\\n2 Chain-of-Thought Prompting\\nConsider one’s own thought process when solving a complicated reasoning task such as a multi-step\\nmath word problem. It is typical to decompose the problem into intermediate steps and solve each\\nbefore giving the ﬁnal answer: “After Jane gives 2 ﬂowers to her mom she has 10 ... then after she\\ngives 3 to her dad she will have 7 ... so the answer is 7. ”The goal of this paper is to endow language'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 1, 'page_label': '2'}, page_content='gives 3 to her dad she will have 7 ... so the answer is 7. ”The goal of this paper is to endow language\\nmodels with the ability to generate a similar chain of thought—a coherent series of intermediate\\nreasoning steps that lead to the ﬁnal answer for a problem. We will show that sufﬁciently large\\n2'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 2, 'page_label': '3'}, page_content='language models can generate chains of thought if demonstrations of chain-of-thought reasoning are\\nprovided in the exemplars for few-shot prompting.\\nFigure 1 shows an example of a model producing a chain of thought to solve a math word problem\\nthat it would have otherwise gotten incorrect. The chain of thought in this case resembles a solution\\nand can interpreted as one, but we still opt to call it a chain of thought to better capture the idea that it\\nmimics a step-by-step thought process for arriving at the answer (and also, solutions/explanations\\ntypically come after the ﬁnal answer (Narang et al., 2020; Wiegreffe et al., 2022; Lampinen et al.,\\n2022, inter alia)).\\nChain-of-thought prompting has several attractive properties as an approach for facilitating reasoning\\nin language models.\\n1. First, chain of thought, in principle, allows models to decompose multi-step problems into\\nintermediate steps, which means that additional computation can be allocated to problems'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 2, 'page_label': '3'}, page_content='1. First, chain of thought, in principle, allows models to decompose multi-step problems into\\nintermediate steps, which means that additional computation can be allocated to problems\\nthat require more reasoning steps.\\n2. Second, a chain of thought provides an interpretable window into the behavior of the model,\\nsuggesting how it might have arrived at a particular answer and providing opportunities\\nto debug where the reasoning path went wrong (although fully characterizing a model’s\\ncomputations that support an answer remains an open question).\\n3. Third, chain-of-thought reasoning can be used for tasks such as math word problems,\\ncommonsense reasoning, and symbolic manipulation, and is potentially applicable (at least\\nin principle) to any task that humans can solve via language.\\n4. Finally, chain-of-thought reasoning can be readily elicited in sufﬁciently large off-the-shelf\\nlanguage models simply by including examples of chain of thought sequences into the'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 2, 'page_label': '3'}, page_content='4. Finally, chain-of-thought reasoning can be readily elicited in sufﬁciently large off-the-shelf\\nlanguage models simply by including examples of chain of thought sequences into the\\nexemplars of few-shot prompting.\\nIn empirical experiments, we will observe the utility of chain-of-thought prompting for arithmetic\\nreasoning (Section 3), commonsense reasoning (Section 4), and symbolic reasoning (Section 5).\\n3 Arithmetic Reasoning\\nWe begin by considering math word problems of the form in Figure 1, which measure the arithmetic\\nreasoning ability of language models. Though simple for humans, arithmetic reasoning is a task where\\nlanguage models often struggle (Hendrycks et al., 2021; Patel et al., 2021,inter alia). Strikingly, chain-\\nof-thought prompting when used with the 540B parameter language model performs comparably with\\ntask-speciﬁc ﬁnetuned models on several tasks, even achieving new state of the art on the challenging\\nGSM8K benchmark (Cobbe et al., 2021).\\n3.1 Experimental Setup'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 2, 'page_label': '3'}, page_content='task-speciﬁc ﬁnetuned models on several tasks, even achieving new state of the art on the challenging\\nGSM8K benchmark (Cobbe et al., 2021).\\n3.1 Experimental Setup\\nWe explore chain-of-thought prompting for various language models on multiple benchmarks.\\nBenchmarks. We consider the following ﬁve math word problem benchmarks: (1) the GSM8K\\nbenchmark of math word problems (Cobbe et al., 2021), (2) the SV AMPdataset of math word\\nproblems with varying structures (Patel et al., 2021), (3) the ASDiv dataset of diverse math word\\nproblems (Miao et al., 2020), (4) the AQuA dataset of algebraic word problems, and (5) the MA WPS\\nbenchmark (Koncel-Kedziorski et al., 2016). Example problems are given in Appendix Table 12.\\nStandard prompting. For the baseline, we consider standard few-shot prompting, popularized by\\nBrown et al. (2020), in which a language model is given in-context exemplars of input–output pairs'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 2, 'page_label': '3'}, page_content='Standard prompting. For the baseline, we consider standard few-shot prompting, popularized by\\nBrown et al. (2020), in which a language model is given in-context exemplars of input–output pairs\\nbefore outputting a prediction for a test-time example. Exemplars are formatted as questions and\\nanswers. The model gives the answer directly, as shown in Figure 1 (left).\\nChain-of-thought prompting. Our proposed approach is to augment each exemplar in few-shot\\nprompting with a chain of thought for an associated answer, as illustrated in Figure 1 (right). As most\\nof the datasets only have an evaluation split, we manually composed a set of eight few-shot exemplars\\nwith chains of thought for prompting—Figure 1 (right) shows one chain of thought exemplar, and the\\nfull set of exemplars is given in Appendix Table 20. (These particular exemplars did not undergo\\nprompt engineering; robustness is studied in Section 3.4 and Appendix A.2.) To investigate whether'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 2, 'page_label': '3'}, page_content='full set of exemplars is given in Appendix Table 20. (These particular exemplars did not undergo\\nprompt engineering; robustness is studied in Section 3.4 and Appendix A.2.) To investigate whether\\nchain-of-thought prompting in this form can successfully elicit successful reasoning across a range of\\n3'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 3, 'page_label': '4'}, page_content=\"Q: Roger has 5 tennis balls. He buys \\n2 more cans of tennis balls. Each can \\nhas 3 tennis balls. How many tennis \\nballs does he have now? \\nA: Roger started with 5 balls. 2 cans \\nof 3 tennis balls each is 6 tennis \\nballs. 5 + 6 = 11. The answer is 11.\\nQ: Sammy wanted to go to where the \\npeople were. Where might he go? \\nOptions: (a) race track (b) populated areas \\n(c) desert (d) apartment (e) roadblock \\nA: The answer must be a place with a \\nlot of people. Race tracks, desert, \\napartments, and roadblocks don't \\nhave a lot of people, but populated \\nareas do. So the answer is (b). \\nQ: Yes or no: Would a pear sink in \\nwater? \\nA: The density of a pear is about 0.6 \\ng/cm^3, which is less than water. \\nThus, a pear would float. So the \\nanswer is no.\\nQ: The concert was scheduled to be \\non 06/01/1943, but was delayed by \\none day to today. What is the date 10 \\ndays ago in MM/DD/YYYY?  \\nA: One day after 06/01/1943 is \\n06/02/1943, so today is 06/02/1943. \\n10 days before today is 05/23/1943.\"),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 3, 'page_label': '4'}, page_content='one day to today. What is the date 10 \\ndays ago in MM/DD/YYYY?  \\nA: One day after 06/01/1943 is \\n06/02/1943, so today is 06/02/1943. \\n10 days before today is 05/23/1943. \\nSo the answer is 05/23/1943. \\nQ: Is the following sentence \\nplausible? \"Joao Moutinho caught the \\nscreen pass in the NFC \\nchampionship.\"  \\nA: Joao Moutinho is a soccer player. \\nThe NFC championship is part of \\nAmerican football, not soccer. So the \\nanswer is no.\\nQ: Take the last letters of the words \\nin “Lady Gaga” and concatenate \\nthem. \\nA: The last letter of “Lady” is “y”. The \\nlast letter of “Gaga” is “a”. \\nConcatenating them is “ya”. So the \\nanswer is ya.\\nQ: A coin is heads up. Maybelle flips \\nthe coin. Shalonda does not flip the \\ncoin. Is the coin still heads up? \\nA: The coin was flipped by Maybelle. \\nSo the coin was flipped 1 time, which \\nis an odd number. The coin started \\nheads up, so after an odd number of \\nflips, it will be tails up. So the answer \\nis no.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 3, 'page_label': '4'}, page_content='A: The coin was flipped by Maybelle. \\nSo the coin was flipped 1 time, which \\nis an odd number. The coin started \\nheads up, so after an odd number of \\nflips, it will be tails up. So the answer \\nis no.\\nMath Word Problems (free response) Math Word Problems (multiple choice) CSQA (commonsense)\\nStrategyQA Date Understanding Sports Understanding\\nLast Letter Concatenation Coin Flip (state tracking)\\nQ: How many keystrokes are needed \\nto type the numbers from 1 to 500?\\nAnswer Choices: (a) 1156 (b) 1392 (c) 1480 \\n(d) 1562 (e) 1788 \\nA: There are 9 one-digit numbers \\nfrom 1 to 9. There are 90 two-digit \\nnumbers from 10 to 99. There are \\n401 three-digit numbers from 100 to \\n500. 9 + 90(2) + 401(3) = 1392. The \\nanswer is (b).\\nSayCan (Instructing a robot)\\nHuman: How would you bring me \\nsomething that isn’t a fruit? \\nExplanation: the user wants \\nsomething to eat that isn’t a fruit. An \\nenergy bar is not a fruit, so I will bring \\nthe user an energy bar.  \\nPlan: 1. find(energy bar) 2.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 3, 'page_label': '4'}, page_content='Explanation: the user wants \\nsomething to eat that isn’t a fruit. An \\nenergy bar is not a fruit, so I will bring \\nthe user an energy bar.  \\nPlan: 1. find(energy bar) 2. \\npick(energy bar) 3. find(user) 4. \\nput(energy bar) 5. done().\\nFigure 3: Examples of ⟨input, chain of thought, output⟩triples for arithmetic, commonsense, and\\nsymbolic reasoning benchmarks. Chains of thought are highlighted. Full prompts in Appendix G.\\nmath word problems, we used this single set of eight chain of thought exemplars for all benchmarks\\nexcept AQuA, which is multiple choice instead of free response. For AQuA, we used four exemplars\\nand solutions from the training set, as given in Appendix Table 21.\\nLanguage models. We evaluate ﬁve large language models. The ﬁrst is GPT-3 (Brown et al.,\\n2020), for which we use text-ada-001, text-babbage-001, text-curie-001, and text-davinci-002, which\\npresumably correspond to InstructGPT models of 350M, 1.3B, 6.7B, and 175B parameters (Ouyang'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 3, 'page_label': '4'}, page_content='2020), for which we use text-ada-001, text-babbage-001, text-curie-001, and text-davinci-002, which\\npresumably correspond to InstructGPT models of 350M, 1.3B, 6.7B, and 175B parameters (Ouyang\\net al., 2022).The second is LaMDA (Thoppilan et al., 2022), which has models of 422M, 2B, 8B,\\n68B, and 137B parameters. The third is PaLM, which has models of 8B, 62B, and 540B parameters.\\nThe fourth is UL2 20B (Tay et al., 2022), and the ﬁfth is Codex (Chen et al., 2021, code-davinci-002\\nin the OpenAI API). We sample from the models via greedy decoding (though follow-up work shows\\nchain-of-thought prompting can be improved by taking the majority ﬁnal answer over many sampled\\ngenerations (Wang et al., 2022a)). For LaMDA, we report averaged results over ﬁve random seeds,\\nwhere each seed had a different randomly shufﬂed order of exemplars. As LaMDA experiments\\ndid not show large variance among different seeds, to save compute we report results for a single\\nexemplar order for all other models.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 3, 'page_label': '4'}, page_content='did not show large variance among different seeds, to save compute we report results for a single\\nexemplar order for all other models.\\n3.2 Results\\nThe strongest results of chain-of-thought prompting are summarized in Figure 4, with all experimental\\noutputs for each model collection, model size, and benchmark shown in Table 2 in the Appendix.\\nThere are three key takeaways. First, Figure 4 shows that chain-of-thought prompting is an emergent\\nability of model scale (Wei et al., 2022b). That is, chain-of-thought prompting does not positively\\nimpact performance for small models, and only yields performance gains when used with models of\\n∼100B parameters. We qualitatively found that models of smaller scale produced ﬂuent but illogical\\nchains of thought, leading to lower performance than standard prompting.\\n4'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 4, 'page_label': '5'}, page_content='0\\n20\\n40\\n60\\nGSM8K\\nsolve rate (%)\\nLaMDA GPT PaLM\\nStandard prompting\\nChain-of-thought prompting\\nPrior supervised best\\n0\\n20\\n40\\n60\\n80\\nSV AMP\\nsolve rate (%)\\n0.4 8 137\\n0\\n25\\n50\\n75\\n100\\nMAWPS\\nsolve rate (%)\\n0.4 7 175 8 62 540\\nModel scale (# parameters in billions)\\nFigure 4: Chain-of-thought prompting enables\\nlarge language models to solve challenging math\\nproblems. Notably, chain-of-thought reasoning\\nis an emergent ability of increasing model scale.\\nPrior best numbers are from Cobbe et al. (2021)\\nfor GSM8K, Jie et al. (2022) for SV AMP, and Lan\\net al. (2021) for MAWPS.\\nSecond, chain-of-thought prompting has larger\\nperformance gains for more-complicated prob-\\nlems. For instance, for GSM8K (the dataset\\nwith the lowest baseline performance), perfor-\\nmance more than doubled for the largest GPT\\nand PaLM models. On the other hand, for Sin-\\ngleOp, the easiest subset of MAWPS which only\\nrequires a single step to solve, performance im-\\nprovements were either negative or very small\\n(see Appendix Table 3).'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 4, 'page_label': '5'}, page_content='gleOp, the easiest subset of MAWPS which only\\nrequires a single step to solve, performance im-\\nprovements were either negative or very small\\n(see Appendix Table 3).\\nThird, chain-of-thought prompting via GPT-3\\n175B and PaLM 540B compares favorably to\\nprior state of the art, which typically ﬁnetunes a\\ntask-speciﬁc model on a labeled training dataset.\\nFigure 4 shows how PaLM 540B uses chain-of-\\nthought prompting to achieve new state of the art\\non GSM8K, SV AMP, and MAWPS (though note\\nthat standard prompting already passed the prior\\nbest for SV AMP). On the other two datasets,\\nAQuA and ASDiv, PaLM with chain-of-thought\\nprompting reaches within 2% of the state of the\\nart (Appendix Table 2).\\nTo better understand why chain-of-thought\\nprompting works, we manually examined model-\\ngenerated chains of thought by LaMDA 137B\\nfor GSM8K. Of 50 random examples where the\\nmodel returned the correct ﬁnal answer, all of\\nthe generated chains of thought were also log-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 4, 'page_label': '5'}, page_content='generated chains of thought by LaMDA 137B\\nfor GSM8K. Of 50 random examples where the\\nmodel returned the correct ﬁnal answer, all of\\nthe generated chains of thought were also log-\\nically and mathematically correct except two\\nthat coincidentally arrived at the correct answer\\n(see Appendix D.1, and Table 8 for examples\\nof correct model-generated chains of thought).\\nWe also randomly examined 50 random sam-\\nples for which the model gave the wrong answer.\\nThe summary of this analysis is that 46% of the\\nchains of thought were almost correct, barring\\nminor mistakes (calculator error, symbol map-\\nping error, or one reasoning step missing), and that the other 54% of the chains of thought had major\\nerrors in semantic understanding or coherence (see Appendix D.2). To provide a small insight into\\nwhy scaling improves chain-of-thought reasoning ability, we performed a similar analysis of errors\\nmade by PaLM 62B and whether those errors were ﬁxed by scaling to PaLM 540B. The summary'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 4, 'page_label': '5'}, page_content='why scaling improves chain-of-thought reasoning ability, we performed a similar analysis of errors\\nmade by PaLM 62B and whether those errors were ﬁxed by scaling to PaLM 540B. The summary\\nis that scaling PaLM to 540B ﬁxes a large portion of one-step missing and semantic understanding\\nerrors in the 62B model (see Appendix A.1).\\n3.3 Ablation Study\\nThe observed beneﬁts of using chain-of-thought prompting raises the natural question of whether the\\nsame performance improvements can be conferred via other types of prompting. Figure 5 shows an\\nablation study with three variations of chain of thought described below.\\nEquation only. One reason for why chain-of-thought prompting might help is that it produces the\\nmathematical equation to be evaluated, and so we test a variation where the model is prompted\\nto output only a mathematical equation before giving the answer. Figure 5 shows that equation\\nonly prompting does not help much for GSM8K, which implies that the semantics of the questions'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 4, 'page_label': '5'}, page_content='to output only a mathematical equation before giving the answer. Figure 5 shows that equation\\nonly prompting does not help much for GSM8K, which implies that the semantics of the questions\\nin GSM8K are too challenging to directly translate into an equation without the natural language\\nreasoning steps in chain of thought. For datasets of one-step or two-step problems, however, we ﬁnd\\nthat equation only prompting does improve performance, since the equation can be easily derived\\nfrom the question (see Appendix Table 6).\\n5'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 5, 'page_label': '6'}, page_content='LaMDA PaLM\\n0\\n20\\n40\\n60\\nGSM8K solve rate (%)\\nStandard prompting\\nEquation only\\nVariable compute only\\nReasoning after answer\\nChain-of-thought prompting\\nFigure 5: Ablation study for dif-\\nferent variations of prompting us-\\ning LaMDA 137B and PaLM 540B.\\nResults for other datasets are given\\nin Appendix Table 6 and Table 7.\\nVariable compute only. Another intuition is that chain of\\nthought allows the model to spend more computation (i.e.,\\nintermediate tokens) on harder problems. To isolate the effect\\nof variable computation from chain-of-thought reasoning, we\\ntest a conﬁguration where the model is prompted to output a\\nonly sequence of dots (... ) equal to the number of characters in\\nthe equation needed to solve the problem. This variant performs\\nabout the same as the baseline, which suggests that variable\\ncomputation by itself is not the reason for the success of chain-\\nof-thought prompting, and that there appears to be utility from\\nexpressing intermediate steps via natural language.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 5, 'page_label': '6'}, page_content='computation by itself is not the reason for the success of chain-\\nof-thought prompting, and that there appears to be utility from\\nexpressing intermediate steps via natural language.\\nChain of thought after answer. Another potential beneﬁt of\\nchain-of-thought prompting could simply be that such prompts\\nallow the model to better access relevant knowledge acquired\\nduring pretraining. Therefore, we test an alternative conﬁgura-\\ntion where the chain of thought prompt is only given after the\\nanswer, isolating whether the model actually depends on the\\nproduced chain of thought to give the ﬁnal answer. This variant\\nperforms about the same as the baseline, which suggests that\\nthe sequential reasoning embodied in the chain of thought is\\nuseful for reasons beyond just activating knowledge.\\n3.4 Robustness of Chain of Thought\\nGSM8K\\n0\\n5\\n10\\n15\\n20Solve rate (%)\\nStandard prompting\\nChain-of-thought prompting\\n·different annotator (B)\\n·different annotator (C)\\n·intentionally concise style'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 5, 'page_label': '6'}, page_content='3.4 Robustness of Chain of Thought\\nGSM8K\\n0\\n5\\n10\\n15\\n20Solve rate (%)\\nStandard prompting\\nChain-of-thought prompting\\n·different annotator (B)\\n·different annotator (C)\\n·intentionally concise style\\n·exemplars from GSM8K (α)\\n·exemplars from GSM8K (β)\\n·exemplars from GSM8K (γ)\\nMAWPS\\n0\\n20\\n40\\n60\\nFigure 6: Chain-of-thought prompting\\nhas variance for different prompt exam-\\nples (as expected) but outperforms stan-\\ndard prompting for various annotators as\\nwell as for different exemplars.\\nSensitivity to exemplars is a key consideration of prompt-\\ning approaches—for instance, varying the permutation of\\nfew-shot exemplars can cause the accuracy of GPT-3 on\\nSST-2 to range from near chance (54.3%) to near state of\\nthe art (93.4%) (Zhao et al., 2021). In this ﬁnal subsec-\\ntion, we evaluate robustness to chains of thought written\\nby different annotators. In addition to the results above,\\nwhich used chains of thought written by an Annotator\\nA, two other co-authors of this paper (Annotators B and'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 5, 'page_label': '6'}, page_content='by different annotators. In addition to the results above,\\nwhich used chains of thought written by an Annotator\\nA, two other co-authors of this paper (Annotators B and\\nC) independently wrote chains of thought for the same\\nfew-shot exemplars (shown in Appendix H). Annotator A\\nalso wrote another chain of thought that was more concise\\nthan the original, following the style of solutions given in\\nCobbe et al. (2021).1\\nFigure 6 shows these results for LaMDA 137B on GSM8K\\nand MAWPS (ablation results for other datasets are given\\nin Appendix Table 6 / Table 7). Although there is variance\\namong different chain of thought annotations, as would be\\nexpected when using exemplar-based prompting (Le Scao\\nand Rush, 2021; Reynolds and McDonell, 2021; Zhao\\net al., 2021), all sets of chain of thought prompts outper-\\nform the standard baseline by a large margin. This result\\nimplies that successful use of chain of thought does not\\ndepend on a particular linguistic style.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 5, 'page_label': '6'}, page_content='form the standard baseline by a large margin. This result\\nimplies that successful use of chain of thought does not\\ndepend on a particular linguistic style.\\nTo conﬁrm that successful chain-of-thought prompting\\nworks for other sets of exemplars, we also run experiments\\nwith three sets of eight exemplars randomly sampled from the GSM8K training set, an independent\\n1For instance, whereas original chain of thought uses several short sentences ( “’There were originally 9\\ncomputers. For each of 4 days, 5 more computers were added. So 5 * 4 = 20 computers were added. 9 + 20 is\\n29. ”), the concise chain of thought would read “5 * 4 = 20 new computers were added. So there are 9 + 20 = 29\\nnew computers in the server room now”.\\n6'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 6, 'page_label': '7'}, page_content='source (examples in this dataset already included reasoning steps like a chain of thought). 2 Fig-\\nure 6 shows that these prompts performed comparably with our manually written exemplars, also\\nsubstantially outperforming standard prompting.\\nIn addition to robustness to annotators, independently-written chains of thought, different exemplars,\\nand various language models, we also ﬁnd that chain-of-thought prompting for arithmetic reasoning\\nis robust to different exemplar orders and varying numbers of exemplars (see Appendix A.2).\\n4 Commonsense Reasoning\\nAlthough chain of thought is particularly suitable for math word problems, the language-based nature\\nof chain of thought actually makes it applicable to a broad class of commonsense reasoning problems,\\nwhich involve reasoning about physical and human interactions under the presumption of general\\nbackground knowledge. Commonsense reasoning is key for interacting with the world and is still'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 6, 'page_label': '7'}, page_content='which involve reasoning about physical and human interactions under the presumption of general\\nbackground knowledge. Commonsense reasoning is key for interacting with the world and is still\\nbeyond the reach of current natural language understanding systems (Talmor et al., 2021).\\nBenchmarks. We consider ﬁve datasets covering a diverse range of commonsense reasoning types.\\nThe popular CSQA (Talmor et al., 2019) asks commonsense questions about the world involving\\ncomplex semantics that often require prior knowledge. StrategyQA (Geva et al., 2021) requires\\nmodels to infer a multi-hop strategy to answer questions. We choose two specialized evaluation sets\\nfrom the BIG-bench effort (BIG-bench collaboration, 2021): Date Understanding, which involves\\ninferring a date from a given context, andSports Understanding, which involves determining whether\\na sentence relating to sports is plausible or implausible. Finally, the SayCan dataset (Ahn et al.,'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 6, 'page_label': '7'}, page_content='inferring a date from a given context, andSports Understanding, which involves determining whether\\na sentence relating to sports is plausible or implausible. Finally, the SayCan dataset (Ahn et al.,\\n2022) involves mapping a natural language instruction to a sequence of robot actions from a discrete\\nset. Figure 3 shows examples with chain of thought annotations for all datasets.\\nPrompts. We follow the same experimental setup as the prior section. For CSQA and StrategyQA,\\nwe randomly selected examples from the training set and manually composed chains of thought for\\nthem to use as few-shot exemplars. The two BIG-bench tasks do not have training sets, so we selected\\nthe ﬁrst ten examples as exemplars in the evaluation set as few-shot exemplars and report numbers on\\nthe rest of the evaluation set. For SayCan, we use six examples from the training set used in Ahn et al.\\n(2022) and also manually composed chains of thought.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 6, 'page_label': '7'}, page_content='the rest of the evaluation set. For SayCan, we use six examples from the training set used in Ahn et al.\\n(2022) and also manually composed chains of thought.\\nResults. Figure 7 highlights these results for PaLM (full results for LaMDA, GPT-3, and different\\nmodel scales are shown in Table 4). For all tasks, scaling up model size improved the performance\\nof standard prompting; chain-of-thought prompting led to further gains, with improvements appear-\\ning to be largest for PaLM 540B. With chain-of-thought prompting, PaLM 540B achieved strong\\nperformance relative to baselines, outperforming the prior state of the art on StrategyQA (75.6% vs\\n69.4%) and outperforming an unaided sports enthusiast on sports understanding (95.4% vs 84%).\\nThese results demonstrate that chain-of-thought prompting can also improve performance on tasks\\nrequiring a range of commonsense reasoning abilities (though note that gain was minimal on CSQA).\\n8 62 540\\n20\\n40\\n60\\n80\\n100Solve rate (%)\\nCSQA\\n8 62 540\\n50\\n60\\n70\\n80\\n90'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 6, 'page_label': '7'}, page_content='requiring a range of commonsense reasoning abilities (though note that gain was minimal on CSQA).\\n8 62 540\\n20\\n40\\n60\\n80\\n100Solve rate (%)\\nCSQA\\n8 62 540\\n50\\n60\\n70\\n80\\n90\\nStrategyQA\\nStandard prompting\\nChain of thought\\nPrior supervised best\\nHuman\\n8 62 540\\n0\\n20\\n40\\n60\\n80\\nModel scale (# parameters in billions)\\nDate\\n8 62 540\\n40\\n60\\n80\\n100\\nSports\\n8 62 540\\n20\\n40\\n60\\n80\\n100\\nSayCan\\nFigure 7: Chain-of-thought prompting also improves the commonsense reasoning abilities of\\nlanguage models. The language model shown here is PaLM. Prior best numbers are from the\\nleaderboards of CSQA (Talmor et al., 2019) and StrategyQA (Geva et al., 2021) (single-model only,\\nas of May 5, 2022). Additional results using various sizes of LaMDA, GPT-3, and PaLM are shown\\nin Table 4.\\n2We sample examples ≤60 tokens to ﬁt into our input context window, and also limit the examples to ≤2\\nsteps to solve for a fair comparison with the eight exemplars that we composed.\\n7'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 7, 'page_label': '8'}, page_content='5 Symbolic Reasoning\\n0\\n25\\n50\\n75\\n100Solve rate (%)\\nLetter Concat: 2\\n(in domain)\\nLetter Concat: 4\\n(OOD)\\nStandard prompting\\nChain-of-thought prompting\\n8 62 540\\n40\\n60\\n80\\n100Solve rate (%)\\nCoin Flip: 2\\n(in domain)\\n8 62 540\\nModel scale (# parameters in billions)\\nCoin Flip: 4\\n(OOD)\\nFigure 8: Using chain-of-thought\\nprompting facilitates generalization to\\nlonger sequences in two symbolic rea-\\nsoning tasks.\\nOur ﬁnal experimental evaluation considers symbolic rea-\\nsoning, which is simple for humans but potentially chal-\\nlenging for language models. We show that chain-of-\\nthought prompting not only enables language models to\\nperform symbolic reasoning tasks that are challenging in\\nthe standard prompting setting, but also facilitates length\\ngeneralization to inference-time inputs longer than those\\nseen in the few-shot exemplars.\\nTasks. We use the following two toy tasks.\\n• Last letter concatenation. This task asks the model\\nto concatenate the last letters of words in a name (e.g.,'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 7, 'page_label': '8'}, page_content='seen in the few-shot exemplars.\\nTasks. We use the following two toy tasks.\\n• Last letter concatenation. This task asks the model\\nto concatenate the last letters of words in a name (e.g.,\\n“Amy Brown” →“yn”). It is a more challenging version\\nof ﬁrst letter concatenation, which language models can\\nalready perform without chain of thought.3 We generate\\nfull names by randomly concatenating names from the\\ntop one-thousand ﬁrst and last names from name census\\ndata (https://namecensus.com/).\\n• Coin ﬂip. This task asks the model to answer whether a\\ncoin is still heads up after people either ﬂip or don’t ﬂip\\nthe coin (e.g., “A coin is heads up. Phoebe ﬂips the coin.\\nOsvaldo does not ﬂip the coin. Is the coin still heads up?”\\n→“no”).\\nAs the construction of these symbolic reasoning tasks is\\nwell-deﬁned, for each task we consider an in-domain test\\nset for which examples had the same number of steps as\\nthe training/few-shot exemplars, as well as an out-of-domain (OOD) test set, for which evaluation'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 7, 'page_label': '8'}, page_content='set for which examples had the same number of steps as\\nthe training/few-shot exemplars, as well as an out-of-domain (OOD) test set, for which evaluation\\nexamples had more steps than those in the exemplars. For last letter concatenation, the model only\\nsees exemplars of names with two words, and then performs last letter concatenation on names with 3\\nand 4 words.4 We do the same for the number of potential ﬂips in the coin ﬂip task. Our experimental\\nsetup uses the same methods and models as in the prior two sections. We again manually compose\\nchains of thought for the few-shot exemplars for each task, which are given in Figure 3.\\nResults. The results of these in-domain and OOD evaluations are shown in Figure 8 for PaLM,\\nwith results for LaMDA shown in Appendix Table 5. With PaLM 540B, chain-of-thought prompting\\nleads to almost 100% solve rates (note that standard prompting already solves coin ﬂip with PaLM'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 7, 'page_label': '8'}, page_content='with results for LaMDA shown in Appendix Table 5. With PaLM 540B, chain-of-thought prompting\\nleads to almost 100% solve rates (note that standard prompting already solves coin ﬂip with PaLM\\n540, though not for LaMDA 137B). Note that these in-domain evaluations are “toy tasks” in the\\nsense that perfect solution structures are already provided by the chains of thought in the few-shot\\nexemplars; all the model has to do is repeat the same steps with the new symbols in the test-time\\nexample. And yet, small models still fail—the ability to perform abstract manipulations on unseen\\nsymbols for these three tasks only arises at the scale of 100B model parameters.\\nAs for the OOD evaluations, standard prompting fails for both tasks. With chain-of-thought prompting,\\nlanguage models achieve upward scaling curves (though performance is lower than in the in-domain\\nsetting). Hence, chain-of-thought prompting facilitates length generalization beyond seen chains of'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 7, 'page_label': '8'}, page_content='language models achieve upward scaling curves (though performance is lower than in the in-domain\\nsetting). Hence, chain-of-thought prompting facilitates length generalization beyond seen chains of\\nthought for language models of sufﬁcient scale.\\n6 Discussion\\nWe have explored chain-of-thought prompting as a simple mechanism for eliciting multi-step rea-\\nsoning behavior in large language models. We ﬁrst saw that chain-of-thought prompting improves\\nperformance by a large margin on arithmetic reasoning, yielding improvements that are much stronger\\nthan ablations and robust to different annotators, exemplars, and language models (Section 3). Next,\\n3We tested 10 common names using GPT-3davinci and it got all but one correct.\\n4For names of length longer than 2 words, we concatenate multiple ﬁrst and last names together.\\n8'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 8, 'page_label': '9'}, page_content='experiments on commonsense reasoning underscored how the linguistic nature of chain-of-thought\\nreasoning makes it generally applicable (Section 4). Finally, we showed that for symbolic reasoning,\\nchain-of-thought prompting facilitates OOD generalization to longer sequence lengths (Section 5). In\\nall experiments, chain-of-thought reasoning is elicited simply by prompting an off-the-shelf language\\nmodel. No language models were ﬁnetuned in the process of writing this paper.\\nThe emergence of chain-of-thought reasoning as a result of model scale has been a prevailing theme\\n(Wei et al., 2022b). For many reasoning tasks where standard prompting has a ﬂat scaling curve, chain-\\nof-thought prompting leads to dramatically increasing scaling curves. Chain-of-thought prompting\\nappears to expand the set of tasks that large language models can perform successfully—in other\\nwords, our work underscores that standard prompting only provides a lower bound on the capabilities'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 8, 'page_label': '9'}, page_content='appears to expand the set of tasks that large language models can perform successfully—in other\\nwords, our work underscores that standard prompting only provides a lower bound on the capabilities\\nof large language models. This observation likely raises more questions than it answers—for instance,\\nhow much more can we expect reasoning ability to improve with a further increase in model scale?\\nWhat other prompting methods might expand the range of tasks that language models can solve?\\nAs for limitations, we ﬁrst qualify that although chain of thought emulates the thought processes of\\nhuman reasoners, this does not answer whether the neural network is actually “reasoning,” which\\nwe leave as an open question. Second, although the cost of manually augmenting exemplars with\\nchains of thought is minimal in the few-shot setting, such annotation costs could be prohibitive for\\nﬁnetuning (though this could potentially be surmounted with synthetic data generation, or zero-shot'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 8, 'page_label': '9'}, page_content='ﬁnetuning (though this could potentially be surmounted with synthetic data generation, or zero-shot\\ngeneralization). Third, there is no guarantee of correct reasoning paths, which can lead to both correct\\nand incorrect answers; improving factual generations of language models is an open direction for\\nfuture work (Rashkin et al., 2021; Ye and Durrett, 2022; Wiegreffe et al., 2022,inter alia). Finally,\\nthe emergence of chain-of-thought reasoning only at large model scales makes it costly to serve in\\nreal-world applications; further research could explore how to induce reasoning in smaller models.\\n7 Related Work\\nThis work is inspired by many research areas, which we detail in an extended related work section\\n(Appendix C). Here we describe two directions and associated papers that are perhaps most relevant.\\nThe ﬁrst relevant direction is using intermediate steps to solve reasoning problems. Ling et al. (2017)'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 8, 'page_label': '9'}, page_content='The ﬁrst relevant direction is using intermediate steps to solve reasoning problems. Ling et al. (2017)\\npioneer the idea of using natural language rationales to solve math word problems through a series\\nof intermediate steps. Their work is a remarkable contrast to the literature using formal languages\\nto reason (Roy et al., 2015; Chiang and Chen, 2019; Amini et al., 2019; Chen et al., 2019). Cobbe\\net al. (2021) extend Ling et al. (2017) by creating a larger dataset and using it to ﬁnetune a pretrained\\nlanguage model rather than training a model from scratch. In the domain of program synthesis,\\nNye et al. (2021) leverage language models to predict the ﬁnal outputs of Python programs via\\nﬁrst line-to-line predicting the intermediate computational results, and show that their step-by-step\\nprediction method performs better than directly predicting the ﬁnal outputs.\\nNaturally, this paper also relates closely to the large body of recent work on prompting. Since the'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 8, 'page_label': '9'}, page_content='prediction method performs better than directly predicting the ﬁnal outputs.\\nNaturally, this paper also relates closely to the large body of recent work on prompting. Since the\\npopularization of few-shot prompting as given by Brown et al. (2020), several general approaches\\nhave improved the prompting ability of models, such as automatically learning prompts (Lester et al.,\\n2021) or giving models instructions describing a task (Wei et al., 2022a; Sanh et al., 2022; Ouyang\\net al., 2022). Whereas these approaches improve or augment the input part of the prompt (e.g.,\\ninstructions that are prepended to inputs), our work takes the orthogonal direction of augmenting the\\noutputs of language models with a chain of thought.\\n8 Conclusions\\nWe have explored chain-of-thought prompting as a simple and broadly applicable method for enhanc-\\ning reasoning in language models. Through experiments on arithmetic, symbolic, and commonsense'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 8, 'page_label': '9'}, page_content='We have explored chain-of-thought prompting as a simple and broadly applicable method for enhanc-\\ning reasoning in language models. Through experiments on arithmetic, symbolic, and commonsense\\nreasoning, we ﬁnd that chain-of-thought reasoning is an emergent property of model scale that allows\\nsufﬁciently large language models to perform reasoning tasks that otherwise have ﬂat scaling curves.\\nBroadening the range of reasoning tasks that language models can perform will hopefully inspire\\nfurther work on language-based approaches to reasoning.\\n9'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 9, 'page_label': '10'}, page_content='Acknowledgements\\nWe thank Jacob Devlin, Claire Cui, Andrew Dai, and Ellie Pavlick for providing feedback on the\\npaper. We thank Jacob Austin, Yuhuai Wu, Henryk Michalewski, Aitor Lewkowycz, Charles Sutton,\\nand Aakanksha Chowdhery for helpful discussions. We thank Sid Maxwell for notifying us about a\\nmistake in the manual error analysis in the original manuscript.\\nReferences\\nMichael Ahn, Anthony Brohan, Noah Brown, Yevgen Chebotar, Omar Cortes, Byron David, Chelsea\\nFinn, Keerthana Gopalakrishnan, Karol Hausman, Alex Herzog, et al. 2022. Do as I can, not as I\\nsay: Grounding language in robotic affordances. arXiv preprint arXiv:2204.01691.\\nAida Amini, Saadia Gabriel, Shanchuan Lin, Rik Koncel-Kedziorski, Yejin Choi, and Hannaneh\\nHajishirzi. 2019. MathQA: Towards interpretable math word problem solving with operation-\\nbased formalisms. In Proceedings of the 2019 Conference of the North American Chapter of the'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 9, 'page_label': '10'}, page_content='Hajishirzi. 2019. MathQA: Towards interpretable math word problem solving with operation-\\nbased formalisms. In Proceedings of the 2019 Conference of the North American Chapter of the\\nAssociation for Computational Linguistics: Human Language Technologies, Volume 1 (Long and\\nShort Papers), Minneapolis, Minnesota. Association for Computational Linguistics.\\nDaniel Andor, Luheng He, Kenton Lee, and Emily Pitler. 2019. Giving BERT a calculator: Finding\\noperations and arguments with reading comprehension. EMNLP.\\nJacob Andreas, Dan Klein, and Sergey Levine. 2018. Learning with latent language. NAACL.\\nJacob Austin, Augustus Odena, Maxwell Nye, Maarten Bosma, Henryk Michalewski, David Dohan,\\nEllen Jiang, Carrie Cai, Michael Terry, Quoc Le, et al. 2021. Program synthesis with large language\\nmodels. arXiv preprint arXiv:2108.07732.\\nBIG-bench collaboration. 2021. Beyond the imitation game: Measuring and extrapolating the\\ncapabilities of language models. In preparation.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 9, 'page_label': '10'}, page_content='models. arXiv preprint arXiv:2108.07732.\\nBIG-bench collaboration. 2021. Beyond the imitation game: Measuring and extrapolating the\\ncapabilities of language models. In preparation.\\nKaj Bostrom, Xinyu Zhao, Swarat Chaudhuri, and Greg Durrett. 2021. Flexible generation of natural\\nlanguage deductions. EMNLP.\\nTom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal,\\nArvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel\\nHerbert-V oss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler,\\nJeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray,\\nBenjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever,\\nand Dario Amodei. 2020. Language models are few-shot learners. NeurIPS.\\nJonathon Cai, Richard Shin, and Dawn Song. 2017. Making neural programming architectures\\ngeneralize via recursion. ICLR.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 9, 'page_label': '10'}, page_content='and Dario Amodei. 2020. Language models are few-shot learners. NeurIPS.\\nJonathon Cai, Richard Shin, and Dawn Song. 2017. Making neural programming architectures\\ngeneralize via recursion. ICLR.\\nOana-Maria Camburu, Tim Rocktäschel, Thomas Lukasiewicz, and Phil Blunsom. 2018. e-SNLI:\\nNatural language inference with natural language explanations. NeurIPS.\\nHoward Chen, Jacqueline He, Karthik Narasimhan, and Danqi Chen. 2022. Can rationalization\\nimprove robustness? NAACL.\\nMark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared\\nKaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, et al. 2021. Evaluating\\nlarge language models trained on code. arXiv preprint arXiv:2107.03374.\\nXinyun Chen, Chen Liang, Adams Wei Yu, Denny Zhou, Dawn Song, and Quoc V . Le. 2019. Neural\\nsymbolic reader: Scalable integration of distributed and symbolic representations for reading\\ncomprehension. ICLR.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 9, 'page_label': '10'}, page_content='symbolic reader: Scalable integration of distributed and symbolic representations for reading\\ncomprehension. ICLR.\\nTing-Rui Chiang and Yun-Nung Chen. 2019. Semantically-aligned equation generation for solving\\nand reasoning math word problems. In Proceedings of the 2019 Conference of the North Ameri-\\ncan Chapter of the Association for Computational Linguistics: Human Language Technologies,\\nVolume 1 (Long and Short Papers), pages 2656–2668, Minneapolis, Minnesota. Association for\\nComputational Linguistics.\\n10'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 10, 'page_label': '11'}, page_content='Peter Clark, Oyvind Tafjord, and Kyle Richardson. 2020. Transformers as soft reasoners over\\nlanguage. IJCAI.\\nKarl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Jacob Hilton, Reiichiro Nakano, Christopher\\nHesse, and John Schulman. 2021. Training veriﬁers to solve math word problems. arXiv preprint\\narXiv:2110.14168.\\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of\\ndeep bidirectional transformers for language understanding. NAACL.\\nHonghua Dong, Jiayuan Mao, Tian Lin, Chong Wang, Lihong Li, and Denny Zhou. 2019. Neural\\nlogic machines. ICLR.\\nDheeru Dua, Sameer Singh, and Matt Gardner. 2020. Beneﬁts of intermediate annotations in reading\\ncomprehension. ACL.\\nMor Geva, Daniel Khashabi, Elad Segal, Tushar Khot, Dan Roth, and Jonathan Berant. 2021. Did\\naristotle use a laptop? A question answering benchmark with implicit reasoning strategies. TACL.\\nYuling Gu, Bhavana Dalvi Mishra, and Peter Clark. 2022. DREAM: Uncovering mental models'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 10, 'page_label': '11'}, page_content='aristotle use a laptop? A question answering benchmark with implicit reasoning strategies. TACL.\\nYuling Gu, Bhavana Dalvi Mishra, and Peter Clark. 2022. DREAM: Uncovering mental models\\nbehind language models. NAACL.\\nBraden Hancock, Paroma Varma, Stephanie Wang, Martin Bringmann, Percy Liang, and Christopher\\nRé. 2018. Training classiﬁers with natural language explanations. ACL.\\nPeter Hase and Mohit Bansal. 2022. When can models learn from explanations? a formal framework\\nfor understanding the roles of explanation data. ACL.\\nDan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang, Dawn Song,\\nand Jacob Steinhardt. 2021. Measuring mathematical problem solving with the math dataset. arXiv\\npreprint arXiv:2103.03874.\\nMohammad Javad Hosseini, Hannaneh Hajishirzi, Oren Etzioni, and Nate Kushman. 2014. Learning\\nto solve arithmetic word problems with verb categorization. EMNLP.\\nZhanming Jie, Jierui Li, and Wei Lu. 2022. Learning to reason deductively: Math word problem'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 10, 'page_label': '11'}, page_content='to solve arithmetic word problems with verb categorization. EMNLP.\\nZhanming Jie, Jierui Li, and Wei Lu. 2022. Learning to reason deductively: Math word problem\\nsolving as complex relation extraction. arXiv preprint arXiv:2203.10316.\\nJared Kaplan, Sam McCandlish, Tom Henighan, Tom B Brown, Benjamin Chess, Rewon Child,\\nScott Gray, Alec Radford, Jeffrey Wu, and Dario Amodei. 2020. Scaling laws for neural language\\nmodels. arXiv preprint arXiv:2001.08361.\\nRik Koncel-Kedziorski, Subhro Roy, Aida Amini, Nate Kushman, and Hannaneh Hajishirzi. 2016.\\nMAWPS: A math word problem repository. NAACL.\\nAndrew K. Lampinen, Ishita Dasgupta, Stephanie C.Y . Chan, Kory Matthewson, Michael Henry\\nTessler, Antonia Creswell, James L. McClelland, Jane X. Wang, and Felix Hill. 2022. Can language\\nmodels learn from explanations in context? arXiv preprint arXiv:2204.02329.\\nYihuai Lan, Lei Wang, Qiyuan Zhang, Yunshi Lan, Bing Tian Dai, Yan Wang, Dongxiang Zhang,'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 10, 'page_label': '11'}, page_content='models learn from explanations in context? arXiv preprint arXiv:2204.02329.\\nYihuai Lan, Lei Wang, Qiyuan Zhang, Yunshi Lan, Bing Tian Dai, Yan Wang, Dongxiang Zhang,\\nand Ee-Peng Lim. 2021. MWPToolkit: An open-source framework for deep learning-based math\\nword problem solvers. arXiv preprint arXiv:2109.00799.\\nTeven Le Scao and Alexander Rush. 2021. How many data points is a prompt worth? NAACL.\\nBrian Lester, Rami Al-Rfou, and Noah Constant. 2021. The power of scale for parameter-efﬁcient\\nprompt tuning. EMNLP.\\nIddo Lev, Bill MacCartney, Christopher Manning, and Roger Levy. 2004. Solving logic puzzles:\\nFrom robust processing to precise semantics. Proceedings of the 2nd Workshop on Text Meaning\\nand Interpretation.\\nXiang Lisa Li and Percy Liang. 2021. Preﬁx-tuning: Optimizing continuous prompts for generation.\\nACL.\\n11'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 11, 'page_label': '12'}, page_content='Zhengzhong Liang, Steven Bethard, and Mihai Surdeanu. 2021. Explainable multi-hop verbal\\nreasoning through internal monologue. NAACL.\\nWang Ling, Dani Yogatama, Chris Dyer, and Phil Blunsom. 2017. Program induction by rationale\\ngeneration: Learning to solve and explain algebraic word problems. ACL.\\nPengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki Hayashi, and Graham Neubig. 2021.\\nPre-train, prompt, and predict: A systematic survey of prompting methods in natural language\\nprocessing. arXiv preprint arXiv:2107.13586.\\nBodhisattwa Prasad Majumder, Oana-Maria Camburu, Thomas Lukasiewicz, and Julian McAuley.\\n2021. Rationale-inspired natural language explanations with commonsense. arXiv preprint\\narXiv:2106.13876.\\nAna Marasovi´c, Iz Beltagy, Doug Downey, and Matthew E Peters. 2022. Few-shot self-rationalization\\nwith natural language prompts. NAACL Findings.\\nJoshua Maynez, Shashi Narayan, Bernd Bohnet, and Ryan McDonald. 2020. On faithfulness and'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 11, 'page_label': '12'}, page_content='with natural language prompts. NAACL Findings.\\nJoshua Maynez, Shashi Narayan, Bernd Bohnet, and Ryan McDonald. 2020. On faithfulness and\\nfactuality in abstractive summarization. In ACL.\\nShen Yun Miao, Chao Chun Liang, and Keh Yih Su. 2020. A diverse corpus for evaluating and\\ndeveloping English math word problem solvers. ACL.\\nSewon Min, Xinxi Lyu, Ari Holtzman, Mikel Artetxe, Mike Lewis, Hannaneh Hajishirzi, and Luke\\nZettlemoyer. 2022. Rethinking the role of demonstrations: What makes in-context learning work?\\narXiv preprint arXiv:2202.12837.\\nSharan Narang, Colin Raffel, Katherine Lee, Adam Roberts, Noah Fiedel, and Karishma Malkan.\\n2020. WT5?! Training text-to-text models to explain their predictions. arXiv preprint\\narXiv:2004.14546.\\nMaxwell Nye, Anders Johan Andreassen, Guy Gur-Ari, Henryk Michalewski, Jacob Austin, David\\nBieber, David Dohan, Aitor Lewkowycz, Maarten Bosma, David Luan, et al. 2021. Show your work:'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 11, 'page_label': '12'}, page_content='Maxwell Nye, Anders Johan Andreassen, Guy Gur-Ari, Henryk Michalewski, Jacob Austin, David\\nBieber, David Dohan, Aitor Lewkowycz, Maarten Bosma, David Luan, et al. 2021. Show your work:\\nScratchpads for intermediate computation with language models. arXiv preprint arXiv:2112.00114.\\nLong Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela Mishkin, Chong\\nZhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. 2022. Training language models to\\nfollow instructions with human feedback. arXiv preprint arXiv:2203.02155.\\nArkil Patel, Satwik Bhattamishra, and Navin Goyal. 2021. Are NLP models really able to solve\\nsimple math word problems? NAACL.\\nMatthew E. Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark, Kenton Lee, and\\nLuke Zettlemoyer. 2018. Deep contextualized word representations. NAACL.\\nXinyu Pi, Qian Liu, Bei Chen, Morteza Ziyadi, Zeqi Lin, Yan Gao, Qiang Fu, Jian-Guang Lou, and'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 11, 'page_label': '12'}, page_content='Luke Zettlemoyer. 2018. Deep contextualized word representations. NAACL.\\nXinyu Pi, Qian Liu, Bei Chen, Morteza Ziyadi, Zeqi Lin, Yan Gao, Qiang Fu, Jian-Guang Lou, and\\nWeizhu Chen. 2022. Reasoning like program executors. arXiv preprint arXiv:2201.11473.\\nPiotr Pi˛ ekos, Mateusz Malinowski, and Henryk Michalewski. 2021. Measuring and improving\\nBERT’s mathematical abilities by predicting the order of reasoning.ACL.\\nJack W. Rae, Sebastian Borgeaud, Trevor Cai, Katie Millican, Jordan Hoffmann, Francis Song, John\\nAslanides, Sarah Henderson, Roman Ring, Susannah Young, et al. 2021. Scaling language models:\\nMethods, analysis & insights from training Gopher. arXiv preprint arXiv:2112.11446.\\nColin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi\\nZhou, Wei Li, and Peter J Liu. 2020. Exploring the limits of transfer learning with a uniﬁed\\ntext-to-text transformer. Journal of Machine Learning Research, 21:1–67.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 11, 'page_label': '12'}, page_content='Zhou, Wei Li, and Peter J Liu. 2020. Exploring the limits of transfer learning with a uniﬁed\\ntext-to-text transformer. Journal of Machine Learning Research, 21:1–67.\\nDheeraj Rajagopal, Vidhisha Balachandran, Eduard H. Hovy, and Yulia Tsvetkov. 2021. SelfExplain:\\nA self-explaining architecture for neural text classiﬁers. EMNLP.\\nNazneen Fatema Rajani, Bryan McCann, Caiming Xiong, and Richard Socher. 2019. Explain\\nyourself! Leveraging language models for commonsense reasoning. ACL.\\n12'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 12, 'page_label': '13'}, page_content='Qiu Ran, Yankai Lin, Peng Li, Jie Zhou, and Zhiyuan Liu. 2019. NumNet: Machine reading\\ncomprehension with numerical reasoning. EMNLP.\\nHannah Rashkin, Vitaly Nikolaev, Matthew Lamm, Michael Collins, Dipanjan Das, Slav Petrov,\\nGaurav Singh Tomar, Iulia Turc, and David Reitter. 2021. Measuring attribution in natural language\\ngeneration models. arXiv preprint arXiv:2112.12870.\\nGabriel Recchia. 2021. Teaching autoregressive language models complex tasks by demonstration.\\narXiv preprint arXiv:2109.02102.\\nEmily Reif, Daphne Ippolito, Ann Yuan, Andy Coenen, Chris Callison-Burch, and Jason Wei. 2022.\\nA recipe for arbitrary text style transfer with large language models. ACL.\\nLaria Reynolds and Kyle McDonell. 2021. Prompt programming for large language models: Beyond\\nthe few-shot paradigm. Extended Abstracts of the 2021 CHI Conference on Human Factors in\\nComputing Systems.\\nSubhro Roy and Dan Roth. 2015. Solving general arithmetic word problems. EMNLP.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 12, 'page_label': '13'}, page_content='the few-shot paradigm. Extended Abstracts of the 2021 CHI Conference on Human Factors in\\nComputing Systems.\\nSubhro Roy and Dan Roth. 2015. Solving general arithmetic word problems. EMNLP.\\nSubhro Roy, Tim Vieira, and Dan Roth. 2015. Reasoning about Quantities in Natural Language.\\nTACL.\\nMohammed Saeed, Naser Ahmadi, Preslav Nakov, and Paolo Papotti. 2021. RuleBERT: Teaching\\nsoft rules to pre-trained language models. EMNLP.\\nVictor Sanh, Albert Webson, Colin Raffel, Stephen H. Bach, Lintang Sutawika, Zaid Alyafeai,\\nAntoine Chafﬁn, Arnaud Stiegler, Teven Le Scao, Arun Raja, et al. 2022. Multitask prompted\\ntraining enables zero-shot task generalization. ICLR.\\nJianhao Shen, Yichun Yin, Lin Li, Lifeng Shang, Xin Jiang, Ming Zhang, and Qun Liu. 2021.\\nGenerate & rank: A multi-task framework for math word problems. In Findings of the Association\\nfor Computational Linguistics: EMNLP 2021.\\nAlon Talmor, Jonathan Herzig, Nicholas Lourie, and Jonathan Berant. 2019. CommonsenseQA: A'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 12, 'page_label': '13'}, page_content='for Computational Linguistics: EMNLP 2021.\\nAlon Talmor, Jonathan Herzig, Nicholas Lourie, and Jonathan Berant. 2019. CommonsenseQA: A\\nquestion answering challenge targeting commonsense knowledge. NAACL.\\nAlon Talmor, Oyvind Tafjord, Peter Clark, Yoav Goldberg, and Jonathan Berant. 2020. Leap-of-\\nthought: Teaching pre-trained models to systematically reason over implicit knowledge. NeurIPS.\\nAlon Talmor, Ori Yoran, Ronan Le Bras, Chandra Bhagavatula, Yoav Goldberg, Yejin Choi, and\\nJonathan Berant. 2021. CommonsenseQA 2.0: Exposing the limits of ai through gamiﬁcation.\\nNeurIPS Track on Datasets and Benchmarks.\\nYi Tay, Mostafa Dehghani, Vinh Q Tran, Xavier Garcia, Dara Bahri, Tal Schuster, Huaixiu Steven\\nZheng, Neil Houlsby, and Donald Metzler. 2022. Unifying language learning paradigms. arXiv\\npreprint arXiv:2205.05131.\\nRomal Thoppilan, Daniel De Freitas, Jamie Hall, Noam Shazeer, Apoorv Kulshreshtha, Heng-Tze'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 12, 'page_label': '13'}, page_content='preprint arXiv:2205.05131.\\nRomal Thoppilan, Daniel De Freitas, Jamie Hall, Noam Shazeer, Apoorv Kulshreshtha, Heng-Tze\\nCheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu Du, et al. 2022. LaMDA: Language models for\\ndialog applications. arXiv preprint arXiv:2201.08239.\\nXuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, and Denny Zhou. 2022a.\\nSelf-consistency improves chain of thought reasoning in language models. arXiv preprint\\narXiv:2203.11171.\\nYizhong Wang, Swaroop Mishra, Pegah Alipoormolabashi, Yeganeh Kordi, Amirreza Mirzaei, Anjana\\nArunkumar, Arjun Ashok, Arut Selvan Dhanasekaran, Atharva Naik, David Stap, et al. 2022b.\\nBenchmarking generalization via in-context instructions on 1,600+ language tasks. arXiv preprint\\narXiv:2204.07705.\\nJason Wei, Maarten Bosma, Vincent Y . Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du,\\nAndrew M. Dai, and Quoc V . Le. 2022a. Finetuned language models are zero-shot learners.ICLR.\\n13'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 13, 'page_label': '14'}, page_content='Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama,\\nMaarten Bosma, Denny Zhou, Donald Metzler, et al. 2022b. Emergent abilities of large language\\nmodels. Transactions on Machine Learning Research.\\nSarah Wiegreffe, Jack Hessel, Swabha Swayamdipta, Mark Riedl, and Yejin Choi. 2022. Reframing\\nhuman-AI collaboration for generating free-text explanations. NAACL.\\nSarah Wiegreffe and Ana Marasovi´c. 2021. Teach me to explain: A review of datasets for explainable\\nNLP. NeurIPS.\\nSarah Wiegreffe, Ana Marasovi´c, and Noah A. Smith. 2021. Measuring association between labels\\nand free-text rationales. EMNLP.\\nTongshuang Wu, Ellen Jiang, Aaron Donsbach, Jeff Gray, Alejandra Molina, Michael Terry, and\\nCarrie J Cai. 2022a. PromptChainer: Chaining large language model prompts through visual\\nprogramming. CHI Extended Abstracts.\\nTongshuang Wu, Michael Terry, and Carrie Jun Cai. 2022b. AI chains: Transparent and controllable'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 13, 'page_label': '14'}, page_content='programming. CHI Extended Abstracts.\\nTongshuang Wu, Michael Terry, and Carrie Jun Cai. 2022b. AI chains: Transparent and controllable\\nhuman-AI interaction by chaining large language model prompts. CHI.\\nYujun Yan, Kevin Swersky, Danai Koutra, Parthasarathy Ranganathan, and Milad Hashemi. 2020.\\nNeural execution engines: Learning to execute subroutines. NeurIPS.\\nHuihan Yao, Ying Chen, Qinyuan Ye, Xisen Jin, and Xiang Ren. 2021. Reﬁning language models\\nwith compositional explanations. NeurIPS.\\nXi Ye and Greg Durrett. 2022. The unreliability of explanations in few-shot in-context learning.\\narXiv preprint arXiv:2205.03401.\\nYordan Yordanov, Vid Kocijan, Thomas Lukasiewicz, and Oana-Maria Camburu. 2021. Few-shot\\nout-of-domain transfer learning of natural language explanations.arXiv preprint arXiv:2112.06204.\\nOmar Zaidan, Jason Eisner, and Christine Piatko. 2007. Using “annotator rationales” to improve\\nmachine learning for text categorization. NAACL.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 13, 'page_label': '14'}, page_content='Omar Zaidan, Jason Eisner, and Christine Piatko. 2007. Using “annotator rationales” to improve\\nmachine learning for text categorization. NAACL.\\nWojciech Zaremba and Ilya Sutskever. 2014. Learning to execute. arXiv preprint arXiv:1410.4615.\\nEric Zelikman, Yuhuai Wu, and Noah D. Goodman. 2022. STaR: Bootstrapping reasoning with\\nreasoning. arXiv preprint arXiv:2203.14465.\\nTony Z. Zhao, Eric Wallace, Shi Feng, Dan Klein, and Sameer Singh. 2021. Calibrate before use:\\nImproving few-shot performance of language models. ICML.\\nWangchunshu Zhou, Jinyi Hu, Hanlin Zhang, Xiaodan Liang, Maosong Sun, Chenyan Xiong, and\\nJian Tang. 2020. Towards interpretable natural language understanding with explanations as latent\\nvariables. NeurIPS.\\n14'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 14, 'page_label': '15'}, page_content='Checklist\\n1. For all authors...\\n(a) Do the main claims made in the abstract and introduction accurately reﬂect the paper’s\\ncontributions and scope? [Yes]\\n(b) Did you describe the limitations of your work? [Yes] See Section 6 and Appendix A.2.\\n(c) Did you discuss any potential negative societal impacts of your work? [Yes] We don’t\\nexpect negative societal impacts as a direct result of the contributions in our paper. One\\nconsideration, however, is that generated chain of thought is not always factual, which\\nis noted as a limitation in Appendix D.1 (and note that we do not suggest using such\\nchains of thought in a factual manner or in any real-world scenario).\\n(d) Have you read the ethics review guidelines and ensured that your paper conforms to\\nthem? [Yes]\\n2. If you are including theoretical results...\\n(a) Did you state the full set of assumptions of all theoretical results? [N/A]\\n(b) Did you include complete proofs of all theoretical results? [N/A]\\n3. If you ran experiments...'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 14, 'page_label': '15'}, page_content='(a) Did you state the full set of assumptions of all theoretical results? [N/A]\\n(b) Did you include complete proofs of all theoretical results? [N/A]\\n3. If you ran experiments...\\n(a) Did you include the code, data, and instructions needed to reproduce the main experi-\\nmental results (either in the supplemental material or as a URL)? [Yes] We included\\ninputs, outputs, and targets for LaMDA and GPT-3 in the supplementary material.\\nAlthough we use proprietary models, we GPT-3 results are fully reproducible. Repro-\\nducibility is further discussed in Appendix E.1.\\n(b) Did you specify all the training details (e.g., data splits, hyperparameters, how they\\nwere chosen)? [Yes] Data splits were speciﬁed, N/A for hyperparams.\\n(c) Did you report error bars (e.g., with respect to the random seed after running exper-\\niments multiple times)? [Yes] Standard deviation for multiple seeds using LaMDA\\n137B, where each seed is a different random order of exemplars, is given in Table 6\\nand Table 7.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 14, 'page_label': '15'}, page_content='iments multiple times)? [Yes] Standard deviation for multiple seeds using LaMDA\\n137B, where each seed is a different random order of exemplars, is given in Table 6\\nand Table 7.\\n(d) Did you include the total amount of compute and the type of resources used (e.g., type\\nof GPUs, internal cluster, or cloud provider)? [Yes] Type of resources are described in\\nAppendix E.2, though we did not estimate the total amount of compute.\\n4. If you are using existing assets (e.g., code, data, models) or curating/releasing new assets...\\n(a) If your work uses existing assets, did you cite the creators? [Yes] We used two models\\nthat we anonymized based on the recommendation of the NeurIPS chairs. These models\\nwill be cited in the camera-ready version of the paper.\\n(b) Did you mention the license of the assets? [Yes] See Appendix E.3.\\n(c) Did you include any new assets either in the supplemental material or as a URL? [Yes]'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 14, 'page_label': '15'}, page_content='(b) Did you mention the license of the assets? [Yes] See Appendix E.3.\\n(c) Did you include any new assets either in the supplemental material or as a URL? [Yes]\\nThe coinﬂip and last letter concatenation datasets are the only new assets, and they are\\ngiven in the Supplementary Materials.\\n(d) Did you discuss whether and how consent was obtained from people whose data you’re\\nusing/curating? [N/A] No human data collected.\\n(e) Did you discuss whether the data you are using/curating contains personally identiﬁable\\ninformation or offensive content? [N/A] No human data collected.\\n5. If you used crowdsourcing or conducted research with human subjects...\\n(a) Did you include the full text of instructions given to participants and screenshots, if\\napplicable? [N/A]\\n(b) Did you describe any potential participant risks, with links to Institutional Review\\nBoard (IRB) approvals, if applicable? [N/A]\\n(c) Did you include the estimated hourly wage paid to participants and the total amount'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 14, 'page_label': '15'}, page_content='Board (IRB) approvals, if applicable? [N/A]\\n(c) Did you include the estimated hourly wage paid to participants and the total amount\\nspent on participant compensation? [N/A]\\n15'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 15, 'page_label': '16'}, page_content='A Frequently Asked Questions\\nA.1 Why does increasing model scale improve chain-of-thought prompting?\\nThe ﬁnding that successful chain-of-thought reasoning predictably emerges only at certain model\\nscales is intriguing. Scaling up language models has been shown to confer beneﬁts such as improved\\nperformance and sample efﬁciency (Kaplan et al., 2020), but chain-of-thought reasoning is emergent\\nin the sense that its success cannot be predicted only by extrapolating the performance of small scale\\nmodels, as chain of thought actually hurts performance for most models smaller than 10B parameters.\\nThe question of why model scale improves chain-of-thought prompting is certainly multi-faceted, and\\nwe made a preliminary attempt to shed insight into it via error analysis. This small analysis involved\\nmanually reading 45 errors made by PaLM 62B and categorizing them into semantic understanding\\n(20 errors), one step missing (18 errors), and other errors (7 errors). The “other category” included'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 15, 'page_label': '16'}, page_content='manually reading 45 errors made by PaLM 62B and categorizing them into semantic understanding\\n(20 errors), one step missing (18 errors), and other errors (7 errors). The “other category” included\\nhallucinations, repetitive outputs, and symbol mapping errors. This categorization is a coarse one\\nborrowed from the initial error analysis done on LaMDA in Appendix D.2, for which categories were\\nconceived based on what improvements were needed to make the chain of thought correct.\\nAs shown in Figure 9, scaling PaLM to 540B parameters ﬁxed a substantial portion of errors in all\\nthree categories. Examples of semantic understanding and one-step missing errors that were ﬁxed by\\nscaling PaLM to 540B are given in Figure 10. This result appears consistent with a hypothesis that\\nlanguage models acquire a range of semantic understanding and logical reasoning skills as a function\\nof model scale (though note that model scale is often conﬂated with other factors, such as amount of\\ntraining compute).'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 15, 'page_label': '16'}, page_content='of model scale (though note that model scale is often conﬂated with other factors, such as amount of\\ntraining compute).\\nSemantic understanding\\n(62B made 20 errors of this type, \\n540B ﬁxes 6 of them)\\nOne step missing\\n(62B made 18 errors of this type, \\n540B ﬁxes 12 of them)\\nOther\\n(62B made 7 errors of this type, \\n540B ﬁxes 4 of them)\\nTypes of errors made by \\na 62B language model:\\nErrors ﬁxed by \\nscaling from \\n62B to 540B\\nFigure 9: Error analysis of 45 problems that PaLM 62B got incorrect. These errors were categorized\\nthat semantic understanding, one step missing, and other. The other category includes hallucinations,\\nrepetitive outputs, and symbol mapping errors. Scaling PaLM to 540B ﬁxed a substantial portion of\\nerrors in all categories.\\nThere are also three notable points regarding why small language models fail. The ﬁrst observation\\nis that small language models fail at even relatively easy symbol mapping tasks. As demonstrated'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 15, 'page_label': '16'}, page_content='There are also three notable points regarding why small language models fail. The ﬁrst observation\\nis that small language models fail at even relatively easy symbol mapping tasks. As demonstrated\\nin Section 5, for even symbolic reasoning tasks that only require generalization to new examples\\nusing the same chain of thought logical structure that was given in the few-shot exemplars, small\\nlanguage models still failed. The second observation is that small language models seem to have\\ninherently weaker arithmetic abilities, as shown by Brown et al. (2020), the ability to do simple\\narithmetic operations (without semantic understanding) requires sufﬁcient model scale. Finally, we\\nnoticed qualitatively that small language models often did not generate a ﬁnal answer that could be\\nparsed, due to either repetitions or logic that never arrived at a ﬁnal answer.\\nIn summary, the success of chain-of-thought reasoning as a result of model scale is a complicated'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 15, 'page_label': '16'}, page_content='parsed, due to either repetitions or logic that never arrived at a ﬁnal answer.\\nIn summary, the success of chain-of-thought reasoning as a result of model scale is a complicated\\nphenomena that likely involves a variety of emergent abilities (semantic understanding, symbol\\nmapping, staying on topic, arithmetic ability, faithfulness, etc). Future work could more thoroughly\\ninvestigate what properties of pretraining data, model architecture, and optimization objective causally\\nenable such reasoning capabilities.\\n16'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 16, 'page_label': '17'}, page_content=\"Tracy used a piece of wire 4 \\nfeet long to support tomato \\nplants in the garden. The \\nwire was cut into pieces 6 \\ninches long. How many \\npieces did she obtain?\\nShe cut the wire into 6 inch pieces. \\nThis means she got 4 * 6 = 24 \\npieces. The answer is 24. \\n(Incorrect: semantic \\nunderstanding error)\\n62B Model OutputQuestion 540B Model Output\\nThe wire was 4 feet long. This \\nmeans it was 4 * 12 = 48 inches \\nlong. It was cut into pieces 6 inches \\nlong. This means she obtained 48 / \\n6 = 8 pieces. The answer is 8. \\n(Correct)\\nTom's ship can travel at 10 \\nmiles per hour. He is sailing \\nfrom 1 to 4 PM. He then \\ntravels back at a rate of 6 \\nmph. How long does it take \\nhim to get back?\\nHe travels from 1 to 4 PM. That \\nmeans he travels for 3 hours. He \\ntravels back at 6 mph. That means \\nhe travels for 3 * 6 = 18 miles. The \\nanswer is 18. (Incorrect: semantic \\nunderstanding error)\\nHe travels at 10 mph from 1 to 4 \\nPM. This means he travels 3 hours. \\n3 hours at 10 mph means he travels\"),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 16, 'page_label': '17'}, page_content=\"answer is 18. (Incorrect: semantic \\nunderstanding error)\\nHe travels at 10 mph from 1 to 4 \\nPM. This means he travels 3 hours. \\n3 hours at 10 mph means he travels \\n3 * 10 = 30 miles. He then travels \\nback at 6 mph. This means he \\ntravels 6 miles per hour. He has to \\ntravel 30 miles, so it takes him 30 / 6 \\n= 5 hours. The answer is 5. \\n(Correct)\\nStephen placed an online \\norder for groceries. His final \\nbill came to $40.00. \\nBecause this was through a \\ndelivery vendor, they tacked \\non a 25% fee to his final \\ntotal and charged him $3.00 \\nin delivery fees. Stephen \\nalso added a $4.00 tip. After \\nthe extra fees, what was the \\nfinal price of Stephen's \\ngroceries?\\nThe final price of Stephen's \\ngroceries was $40.00. The delivery \\nvendor added 25% to the final total, \\nso the final total was 125% of \\n$40.00. This means the final total \\nwas 125% * $40.00 = $50.00. The \\ndelivery vendor also charged $3.00 \\nin delivery fees. So the final price of \\nStephen's groceries was $50.00 +\"),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 16, 'page_label': '17'}, page_content=\"$40.00. This means the final total \\nwas 125% * $40.00 = $50.00. The \\ndelivery vendor also charged $3.00 \\nin delivery fees. So the final price of \\nStephen's groceries was $50.00 + \\n$3.00 = $53.00. The answer is \\n$53.00. (Incorrect: one step \\nmissing error)\\nStephen's bill was $40.00. The \\ndelivery vendor added 25% to the \\nbill. This means the bill was \\nincreased by 25% of $40.00. This is \\n0.25 * $40.00 = $10.00. The delivery \\nfee was $3.00. The tip was $4.00. \\nSo the total bill was $40.00 + $10.00 \\n+ $3.00 + 540b model $4.00 = \\n$57.00. The answer is 57. (Correct)\\nThere are four schools \\ncompeting at a basketball \\ntournament. Each school \\nhas sent a girls’ basketball \\nteam and a boys’ basketball \\nteam and each team has 5 \\nplayers each. Each school \\nhas also sent a coach for \\neach team. In total, how \\nmany people have all of the \\nschools sent?\\nThere are 4 schools. Each school \\nhas sent a girls’ basketball team and \\na boys’ basketball team. Each team \\nhas 5 players each. That means\"),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 16, 'page_label': '17'}, page_content='many people have all of the \\nschools sent?\\nThere are 4 schools. Each school \\nhas sent a girls’ basketball team and \\na boys’ basketball team. Each team \\nhas 5 players each. That means \\nthere are 4 * 2 * 5 = 40 players. \\nEach team has a coach. That \\nmeans there are 40 + 4 = 44 \\ncoaches. The answer is 44. \\n(Incorrect: one step missing \\nerror)\\nEach school has sent 2 teams, each \\nwith 5 players. This means each \\nschool has sent 2 * 5 = 10 players. \\nEach school has also sent 2 \\ncoaches. This means each school \\nhas sent 10 + 2 = 12 people. There \\nare 4 schools, so in total all of the \\nschools have sent 4 * 12 = 48 \\npeople. The answer is 48. (Correct)\\n62B Model Output\\n62B Model Output\\n62B Model Output\\n540B Model Output\\n540B Model Output\\n540B Model Output\\nQuestion\\nQuestion\\nQuestion\\nFigure 10: Examples of semantic understanding and one-step missing errors that were ﬁxed by\\nscaling PaLM from 62B to 540B.\\nA.2 What is the role of prompt engineering?'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 16, 'page_label': '17'}, page_content='Question\\nQuestion\\nQuestion\\nFigure 10: Examples of semantic understanding and one-step missing errors that were ﬁxed by\\nscaling PaLM from 62B to 540B.\\nA.2 What is the role of prompt engineering?\\nOne of the key considerations of prompting is sensitivity to the exact prompt. There is no shortage\\nof work showing that prompts affect language models in unexpected ways (Min et al., 2022). The\\ngeneral way that we created chain of thought annotations was by taking eight exemplars from the\\ntraining set and decomposing the reasoning process into multiple steps leading to the ﬁnal answer.\\nExamples of chain of thought annotations are provided in Figure 3, with full prompts given in\\nAppendix G. To analyze how sensitive chain of thought is to prompt engineering, we performed\\nrobustness experiments with respect to various factors.\\n• Different annotators. We ﬁrst analyze robustness to three different annotators (Section 3.4 and'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 16, 'page_label': '17'}, page_content='robustness experiments with respect to various factors.\\n• Different annotators. We ﬁrst analyze robustness to three different annotators (Section 3.4 and\\nFigure 6). Although there is notable variance in performance (which we will discuss later), chain\\nof thought performed better than the baseline by a large margin for all three annotators on eight\\ndatasets in arithmetic, commonsense, and symbolic reasoning (Table 6 and Table 7). Similar to the\\nannotation process in Cobbe et al. (2021), annotators were not given speciﬁc instructions about\\n17'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 17, 'page_label': '18'}, page_content='how to write the chain of thought annotations other than to simply write the step-by-step reasoning\\nprocess that led to the ﬁnal answer. Thus, the annotations were written in each annotator’s own\\nlinguistic “chain of thought” writing style.\\n• Annotators without machine learning background. The GSM8K dataset (Cobbe et al., 2021)\\nconveniently provides a training set with reasoning chains written by crowd compute workers,\\nwhich enables us to investigate whether chain of thought still works with reasoning chains from an\\nindependent source without a background in machine learning. So we randomly sampled three sets\\nof eight exemplars with chains of thought from GSM8K. These chain of thought annotations also\\noutperformed the baseline by a large margin for all four arithmetic datasets (Table 6), indicating\\nthat chain of thought is not dependent on a particular set of annotators.\\n• Different exemplars. The different GSM8K exemplars experiment above (Table 6) also shows'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 17, 'page_label': '18'}, page_content='that chain of thought is not dependent on a particular set of annotators.\\n• Different exemplars. The different GSM8K exemplars experiment above (Table 6) also shows\\nthat chain-of-thought prompting works for different sets of exemplars. Notably, we test every set of\\nexemplars on all four arithmetic datasets (instead of picking exemplars from the training set for\\neach dataset), which suggests that the exemplars do not necessarily have to come from the same\\ndataset distribution as the test examples.\\n• Different order of exemplars. Prior work has shown that in some cases (e.g., classiﬁcation) even\\nthe order of prompts matter—varying the permutation of few-shot exemplars can cause the accuracy\\nof GPT-3 on SST-2 to range from near chance (54.3%) to near SOTA (93.4%) (Zhao et al., 2021).\\nWe show the standard deviation of performance from different exemplars in Table 6 and Table 7.\\nStandard deviations with respect to prompt order are relatively minimal in almost all cases. The'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 17, 'page_label': '18'}, page_content='We show the standard deviation of performance from different exemplars in Table 6 and Table 7.\\nStandard deviations with respect to prompt order are relatively minimal in almost all cases. The\\none exception is the coin ﬂip task, for which exemplar orders have high standard deviation, likely\\nfor the reason cited in Zhao et al. (2021)—for classiﬁcation, many exemplars of the same category\\nin a row biases the model outputs).\\n• Different number of exemplars. We also found that gains from chain-of-thought prompting\\ngenerally still held when there was a varying number of few-shot exemplars. This is shown for ﬁve\\ndatasets in Figure 11 (we did not have the compute to run this for all datasets). We also found in\\npreliminary experiments that further increasing the number of exemplars in standard prompting\\ndid not lead to signiﬁcant gains (e.g., increasing from 8 to 16 exemplars did not improve the\\nperformance of standard prompting enough to catch up with chain-of-thought prompting).'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 17, 'page_label': '18'}, page_content='did not lead to signiﬁcant gains (e.g., increasing from 8 to 16 exemplars did not improve the\\nperformance of standard prompting enough to catch up with chain-of-thought prompting).\\n• Different language models. Another interesting question is whether certain prompts that work\\nbetter for one model work better for other large language models. We ﬁnd that with the same\\nprompts, chain-of-thought prompting improves performance across all three models (LaMDA,\\nGPT-3, and PaLM) for all datasets except CSQA and StrategyQA for GPT-3 (Table 1, Table 4,\\nTable 5). The fact that gains from chain of thought did not transfer perfectly among models is\\na limitation; further work could investigate why how different pre-training datasets and model\\narchitectures affect the performance gain from chain-of-thought prompting.\\nPrompt engineering still matters, though. Although the results are relatively robust to the prompt'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 17, 'page_label': '18'}, page_content='architectures affect the performance gain from chain-of-thought prompting.\\nPrompt engineering still matters, though. Although the results are relatively robust to the prompt\\nfor arithmetic reasoning, we want to be clear that prompt engineering still does matter, and can\\nimprove performance signiﬁcantly in many cases. Though most chain of thought annotations\\noutperform standard prompting, there is large variation in many cases. For instance, for the coin\\nﬂip task, the performance varied from 99.6% for Annotator A to 71.4% for Annotator C, though\\nboth were above standard prompting = 50.0% (see Table 7). There are even tasks where prompt\\nengineering is a requirement for good performance. In preliminary experiments, we tried using chain\\nof thought to enable language models to reverse the order of a list of 5 items. While two co-authors\\nwere not able to write chain of thought prompts that solved the task despite their best attempts, a third'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 17, 'page_label': '18'}, page_content='were not able to write chain of thought prompts that solved the task despite their best attempts, a third\\nco-author was able to write a chain of thought that perfectly solved the task.\\nHow to generate chain of thought annotations in a robust fashion could be an interesting direction\\nfor future work. For instance, an idea here could be to use a large language model to automatically\\ngenerate chains of thought via prompting (and potentially optimize this over a validation set).\\nA.3 Will chain-of-thought prompting improve performance for my task of interest?\\nWhile chain-of-thought prompting is in principle applicable for any text-to-text task, it is more\\nhelpful for some tasks than others. Based on the experiments in this paper, our intuition is that chain\\nof thought helps the most when three conditions are met: (1) the task is challenging and requires\\n18'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 18, 'page_label': '19'}, page_content='multi-step reasoning, (2) a large language model is used, and (3) the scaling curve is relatively ﬂat.\\nConversely, the beneﬁts are smaller when one or more of these conditions are not met.\\nThese intuitions are perhaps supported by the arithmetic reasoning results. The performance gain\\nfrom chain-of-thought prompting is largest for PaLM 540B on GSM8K (challenging multi-step\\nproblems, ﬂat scaling curve), which meets these conditions. The performance gain is small for the\\nsubsets of MAWPS that only require one or two steps (SingleOP, SingleEq, and AddSub), for which\\nPaLM 540B already achieves performance of 90% or higher (and it is also generally true that there is\\nless headroom for improvement when performance is already strong).\\nAlthough in this paper we focused on multi-step reasoning tasks (arithmetic, commonsense, and\\nsymbolic), chain-of-thought prompting can potentially be applied to any task for which humans use a'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 18, 'page_label': '19'}, page_content='Although in this paper we focused on multi-step reasoning tasks (arithmetic, commonsense, and\\nsymbolic), chain-of-thought prompting can potentially be applied to any task for which humans use a\\n“chain of thought” to solve (at least in principle). We leave the empirical evaluation of chain-of-thought\\nprompting on such diverse tasks (e.g., machine translation, etc.) to future work.\\nA.4 Why is prompting with the equation only not enough for some arithmetic reasoning\\ndatasets?\\nPrompting with the equation only as an intermediate step does help on many datasets, especially when\\nthe datasets only require a few reasoning steps (SV AMP, ASDiv, MAWPS). For GSM8K, however,\\nusing the equation only did not improve performance substantially. Based on qualitative analysis, we\\nbelieve that these questions are too semantically challenging for the model to directly translate them\\ninto a math equation. Consider this example from LaMDA 137B:'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 18, 'page_label': '19'}, page_content='believe that these questions are too semantically challenging for the model to directly translate them\\ninto a math equation. Consider this example from LaMDA 137B:\\nQUESTION : Mike plays ping pong for 40 minutes. In the ﬁrst 20 minutes, he scores 4\\npoints. In the second 20 minutes, he scores 25% more points. How many total points did he\\nscore?\\nEQUATION ONLY (WRONG ANSWER ): (4 + 20 * 0.25) = 6. The answer is 6.\\nCHAIN OF THOUGHT (CORRECT ): Mike played ping pong for 40 minutes. In the ﬁrst\\n20 minutes, he scored 4 points. In the second 20 minutes, he scored 25% more points. So\\nhe scored 25% more in the second 20 minutes. 4 x 1.25 = 5. So he scored 5 points in the\\nsecond 20 minutes. So he scored 9 points in total. The answer is 9.\\nIt is hard for the model to directly translate all of the semantics into a single equation, but chain of\\nthought allows it to better reason about each part of the question via intermediate steps in natural\\nlanguage.\\n19'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 19, 'page_label': '20'}, page_content='B All Experimental Results\\nThis section contains tables for experimental results for varying models and model sizes, on all\\nbenchmarks, for standard prompting vs. chain-of-thought prompting.\\nFor the arithmetic reasoning benchmarks, some chains of thought (along with the equations produced)\\nwere correct, except the model performed an arithmetic operation incorrectly. A similar observation\\nwas made in Cobbe et al. (2021). Hence, we can further add a Python program as an external\\ncalculator (using the Python eval function) to all the equations in the generated chain of thought.\\nWhen there are multiple equations in a chain of thought, we propagate the external calculator results\\nfrom one equation to the following equations via string matching. As shown in Table 1, we see that\\nadding a calculator signiﬁcantly boosts performance of chain-of-thought prompting on most tasks.\\nTable 1: Chain of thought prompting outperforms standard prompting for various large language'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 19, 'page_label': '20'}, page_content='adding a calculator signiﬁcantly boosts performance of chain-of-thought prompting on most tasks.\\nTable 1: Chain of thought prompting outperforms standard prompting for various large language\\nmodels on ﬁve arithmetic reasoning benchmarks. All metrics are accuracy (%). Ext. calc.: post-hoc\\nexternal calculator for arithmetic computations only. Prior best numbers are from the following. a:\\nCobbe et al. (2021). b& e: Pi et al. (2022), c: Lan et al. (2021), d: Pi˛ ekos et al. (2021).\\nPrompting GSM8K SV AMP ASDiv AQuA MAWPS\\nPrior best N/A (ﬁnetuning) 55 a 57.4b 75.3c 37.9d 88.4e\\nUL2 20B Standard 4.1 10.1 16.0 20.5 16.6\\nChain of thought 4.4 (+0.3) 12.5 (+2.4) 16.9 (+0.9) 23.6 (+3.1) 19.1 (+2.5)\\n+ ext. calc 6.9 28.3 34.3 23.6 42.7\\nLaMDA 137B Standard 6.5 29.5 40.1 25.5 43.2\\nChain of thought 14.3 (+7.8) 37.5 (+8.0) 46.6 (+6.5) 20.6 (-4.9) 57.9 (+14.7)\\n+ ext. calc 17.8 42.1 53.4 20.6 69.3\\nGPT-3 175B Standard 15.6 65.7 70.3 24.8 72.7'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 19, 'page_label': '20'}, page_content='Chain of thought 14.3 (+7.8) 37.5 (+8.0) 46.6 (+6.5) 20.6 (-4.9) 57.9 (+14.7)\\n+ ext. calc 17.8 42.1 53.4 20.6 69.3\\nGPT-3 175B Standard 15.6 65.7 70.3 24.8 72.7\\n(text-davinci-002) Chain of thought 46.9 (+31.3) 68.9 (+3.2) 71.3 (+1.0) 35.8 (+11.0) 87.1 (+14.4)\\n+ ext. calc 49.6 70.3 71.1 35.8 87.5\\nCodex Standard 19.7 69.9 74.0 29.5 78.7\\n(code-davinci-002) Chain of thought 63.1 (+43.4) 76.4 (+6.5) 80.4 (+6.4) 45.3 (+15.8) 92.6 (+13.9)\\n+ ext. calc 65.4 77.0 80.0 45.3 93.3\\nPaLM 540B Standard 17.9 69.4 72.1 25.2 79.2\\nChain of thought 56.9 (+39.0) 79.0 (+9.6) 73.9 (+1.8) 35.8 (+10.6) 93.3 (+14.2)\\n+ ext. calc 58.6 79.8 72.6 35.8 93.5\\n20'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 20, 'page_label': '21'}, page_content='Table 2: Standard prompting versus chain of thought prompting on ﬁve arithmetic reasoning bench-\\nmarks. Note that chain of thought prompting is an emergent ability of model scale—it does not\\npositively impact performance until used with a model of sufﬁcient scale.\\nGSM8K SV AMP ASDiv AQuA MAWPS\\nModel standard CoT standard CoT standard CoT standard CoT standard CoT\\nUL2 20B 4.1 4.4 10.1 12.5 16.0 16.9 20.5 23.6 16.6 19.1\\nLaMDA 420M 2.6 0.4 2.5 1.6 3.2 0.8 23.5 8.3 3.2 0.9\\n2B 3.6 1.9 3.3 2.4 4.1 3.8 22.9 17.7 3.9 3.1\\n8B 3.2 1.6 4.3 3.4 5.9 5.0 22.8 18.6 5.3 4.8\\n68B 5.7 8.2 13.6 18.8 21.8 23.1 22.3 20.2 21.6 30.6\\n137B 6.5 14.3 29.5 37.5 40.1 46.6 25.5 20.6 43.2 57.9\\nGPT 350M 2.2 0.5 1.4 0.8 2.1 0.8 18.1 8.7 2.4 1.1\\n1.3B 2.4 0.5 1.5 1.7 2.6 1.4 12.6 4.3 3.1 1.7\\n6.7B 4.0 2.4 6.1 3.1 8.6 3.6 15.4 13.4 8.8 3.5\\n175B 15.6 46.9 65.7 68.9 70.3 71.3 24.8 35.8 72.7 87.1\\nCodex - 19.7 63.1 69.9 76.4 74.0 80.4 29.5 45.3 78.7 92.6\\nPaLM 8B 4.9 4.1 15.1 16.8 23.7 25.2 19.3 21.7 26.2 30.5'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 20, 'page_label': '21'}, page_content='175B 15.6 46.9 65.7 68.9 70.3 71.3 24.8 35.8 72.7 87.1\\nCodex - 19.7 63.1 69.9 76.4 74.0 80.4 29.5 45.3 78.7 92.6\\nPaLM 8B 4.9 4.1 15.1 16.8 23.7 25.2 19.3 21.7 26.2 30.5\\n62B 9.6 29.9 48.2 46.7 58.7 61.9 25.6 22.4 61.8 80.3\\n540B 17.9 56.9 69.4 79.0 72.1 73.9 25.2 35.8 79.2 93.3\\nTable 3: Standard prompting versus chain of thought prompting on the four subsets of the MAWPS\\nbenchmark. The point of stratifying the MAWPS benchmark is to show that performance gains are\\nminimal on easy one-step or two-step problems where large language models already achieve high\\nperformance (e.g., SingleOp, SingleEq, and AddSub).\\nSingleOp SingleEq AddSub MultiArith\\nModel standard CoT standard CoT standard CoT standard CoT\\nUL2 20B 24.9 27.2 18.0 20.2 18.5 18.2 5.0 10.7\\nLaMDA 420M 2.8 1.0 2.4 0.4 1.9 0.7 5.8 1.5\\n2B 4.6 4.1 2.4 3.3 2.7 3.2 5.8 1.8\\n8B 8.0 7.0 4.5 4.4 3.4 5.2 5.2 2.4\\n68B 36.5 40.8 23.9 26.0 17.3 23.2 8.7 32.4\\n137B 73.2 76.2 48.8 58.7 43.0 51.9 7.6 44.9\\nGPT 350M 3.2 1.8 2.0 0.2 2.0 1.5 2.3 0.8'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 20, 'page_label': '21'}, page_content='2B 4.6 4.1 2.4 3.3 2.7 3.2 5.8 1.8\\n8B 8.0 7.0 4.5 4.4 3.4 5.2 5.2 2.4\\n68B 36.5 40.8 23.9 26.0 17.3 23.2 8.7 32.4\\n137B 73.2 76.2 48.8 58.7 43.0 51.9 7.6 44.9\\nGPT 350M 3.2 1.8 2.0 0.2 2.0 1.5 2.3 0.8\\n1.3B 5.3 3.0 2.4 1.6 2.3 1.5 2.2 0.5\\n6.7B 13.5 3.9 8.7 4.9 8.6 2.5 4.5 2.8\\n175B 90.9 88.8 82.7 86.6 83.3 81.3 33.8 91.7\\nCodex - 93.1 91.8 86.8 93.1 90.9 89.1 44.0 96.2\\nPaLM 8B 41.8 46.6 29.5 28.2 29.4 31.4 4.2 15.8\\n62B 87.9 85.6 77.2 83.5 74.7 78.2 7.3 73.7\\n540B 94.1 94.1 86.5 92.3 93.9 91.9 42.2 94.7\\n21'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 21, 'page_label': '22'}, page_content='Table 4: Standard prompting versus chain of thought prompting on ﬁve commonsense reasoning\\nbenchmarks. Chain of thought prompting is an emergent ability of model scale—it does not positively\\nimpact performance until used with a model of sufﬁcient scale.\\nCSQA StrategyQA Date Sports SayCan\\nModel standard CoT standard CoT standard CoT standard CoT standard CoT\\nUL2 20B 34.2 51.4 59.0 53.3 13.5 14.0 57.9 65.3 20.0 41.7\\nLaMDA 420M 20.1 19.2 46.4 24.9 1.9 1.6 50.0 49.7 7.5 7.5\\n2B 20.2 19.6 52.6 45.2 8.0 6.8 49.3 57.5 8.3 8.3\\n8B 19.0 20.3 54.1 46.8 9.5 5.4 50.0 52.1 28.3 33.3\\n68B 37.0 44.1 59.6 62.2 15.5 18.6 55.2 77.5 35.0 42.5\\n137B 53.6 57.9 62.4 65.4 21.5 26.8 59.5 85.8 43.3 46.6\\nGPT 350M 14.7 15.2 20.6 0.9 4.3 0.9 33.8 41.6 12.5 0.8\\n1.3B 12.0 19.2 45.8 35.7 4.0 1.4 0.0 26.9 20.8 9.2\\n6.7B 19.0 24.0 53.6 50.0 8.9 4.9 0.0 4.4 17.5 35.0\\n175B 79.5 73.5 65.9 65.4 43.8 52.1 69.6 82.4 81.7 87.5\\nCodex - 82.3 77.9 67.1 73.2 49.0 64.8 71.7 98.5 85.8 88.3'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 21, 'page_label': '22'}, page_content='6.7B 19.0 24.0 53.6 50.0 8.9 4.9 0.0 4.4 17.5 35.0\\n175B 79.5 73.5 65.9 65.4 43.8 52.1 69.6 82.4 81.7 87.5\\nCodex - 82.3 77.9 67.1 73.2 49.0 64.8 71.7 98.5 85.8 88.3\\nPaLM 8B 19.8 24.9 55.6 53.5 12.9 13.1 55.1 75.2 34.2 40.0\\n62B 65.4 68.1 58.4 63.4 29.8 44.7 72.1 93.6 65.8 70.0\\n540B 78.1 79.9 68.6 77.8 49.0 65.3 80.5 95.4 80.8 91.7\\nTable 5: Standard prompting versus chain of thought prompting enables length generalization to\\nlonger inference examples on two symbolic manipulation tasks.\\nLast Letter Concatenation Coin Flip (state tracking)\\n2 OOD: 3 OOD: 4 2 OOD: 3 OOD: 4\\nModel standard CoT standard CoT standard CoT standard CoT standard CoT standard CoT\\nUL2 20B 0.6 18.8 0.0 0.2 0.0 0.0 70.4 67.1 51.6 52.2 48.7 50.4\\nLaMDA 420M 0.3 1.6 0.0 0.0 0.0 0.0 52.9 49.6 50.0 50.5 49.5 49.1\\n2B 2.3 6.0 0.0 0.0 0.0 0.0 54.9 55.3 47.4 48.7 49.8 50.2\\n8B 1.5 11.5 0.0 0.0 0.0 0.0 52.9 55.5 48.2 49.6 51.2 50.6\\n68B 4.4 52.0 0.0 0.8 0.0 2.5 56.2 83.2 50.4 69.1 50.9 59.6'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 21, 'page_label': '22'}, page_content='2B 2.3 6.0 0.0 0.0 0.0 0.0 54.9 55.3 47.4 48.7 49.8 50.2\\n8B 1.5 11.5 0.0 0.0 0.0 0.0 52.9 55.5 48.2 49.6 51.2 50.6\\n68B 4.4 52.0 0.0 0.8 0.0 2.5 56.2 83.2 50.4 69.1 50.9 59.6\\n137B 5.8 77.5 0.0 34.4 0.0 13.5 49.0 99.6 50.7 91.0 49.1 74.5\\nPaLM 8B 2.6 18.8 0.0 0.0 0.0 0.2 60.0 74.4 47.3 57.1 50.9 51.8\\n62B 6.8 85.0 0.0 59.6 0.0 13.4 91.4 96.8 43.9 91.0 38.3 72.4\\n540B 7.6 99.4 0.2 94.8 0.0 63.0 98.1 100.0 49.3 98.6 54.8 90.2\\n22'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 22, 'page_label': '23'}, page_content='Table 6: Ablation and robustness results for arithmetic reasoning datasets. Chain of thought generally\\noutperforms ablations by a large amount. “Equation only” performs in between standard prompting\\nand chain of thought prompting, as it allows for intermediate reasoning steps via equations but does\\nnot leverage natural language. Chain of thought prompting has variance (as expected) when used\\nwith prompts written by different annotators or when using other exemplars, but still outperforms\\nstandard prompting by a large margin. Standard deviation shown is for different order of few-shot\\nprompting exemplars, with ﬁve different random seeds. Results here are shown for LaMDA 137B, as\\nadditional queries for GPT-3 and PaLM are both limited and expensive.\\nGSM8K SV AMP ASDiv MAWPS\\nStandard prompting 6.5 ±0.4 29.5 ±0.6 40.1 ±0.6 43.2 ±0.9\\nChain of thought prompting 14.3 ±0.4 36.7 ±0.4 46.6 ±0.7 57.9 ±1.5\\nAblations\\n·equation only 5.4 ±0.2 35.1 ±0.4 45.9 ±0.6 50.1 ±1.0'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 22, 'page_label': '23'}, page_content='Standard prompting 6.5 ±0.4 29.5 ±0.6 40.1 ±0.6 43.2 ±0.9\\nChain of thought prompting 14.3 ±0.4 36.7 ±0.4 46.6 ±0.7 57.9 ±1.5\\nAblations\\n·equation only 5.4 ±0.2 35.1 ±0.4 45.9 ±0.6 50.1 ±1.0\\n·variable compute only 6.4 ±0.3 28.0 ±0.6 39.4 ±0.4 41.3 ±1.1\\n·reasoning after answer 6.1 ±0.4 30.7 ±0.9 38.6 ±0.6 43.6 ±1.0\\nRobustness\\n·different annotator (B) 15.5 ±0.6 35.2 ±0.4 46.5 ±0.4 58.2 ±1.0\\n·different annotator (C) 17.6 ±1.0 37.5 ±2.0 48.7 ±0.7 60.1 ±2.0\\n·intentionally concise style 11.1 ±0.3 38.7 ±0.8 48.0 ±0.3 59.6 ±0.7\\n·exemplars from GSM8K (α) 12.6 ±0.6 32.8 ±1.1 44.1 ±0.9 53.9 ±1.1\\n·exemplars from GSM8K (β) 12.7 ±0.5 34.8 ±1.1 46.9 ±0.6 60.9 ±0.8\\n·exemplars from GSM8K (γ) 12.6 ±0.7 35.6 ±0.5 44.4 ±2.6 54.2 ±4.7\\nTable 7: Ablation and robustness results for four datasets in commonsense and symbolic reasoning.\\nChain of thought generally outperforms ablations by a large amount. Chain of thought prompting has'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 22, 'page_label': '23'}, page_content='Table 7: Ablation and robustness results for four datasets in commonsense and symbolic reasoning.\\nChain of thought generally outperforms ablations by a large amount. Chain of thought prompting has\\nvariance (as expected) when used with prompts written by different annotators or when using other\\nexemplars, but still outperforms standard prompting by a large margin. Standard deviation shown\\nis for different order of few-shot prompting exemplars, with ﬁve different random seeds. Results\\nhere are shown for LaMDA 137B, as additional queries for GPT-3 and PaLM are both limited and\\nexpensive. The exception is that we run SayCan using PaLM here, as the SayCan evaluation set is\\nonly 120 examples and therefore less expensive to run multiple times.\\nCommonsense Symbolic\\nDate Sports SayCan Concat Coin\\nStandard prompting 21.5 ±0.6 59.5 ±3.0 80.8 ±1.8 5.8 ±0.6 49.0 ±2.1\\nChain of thought prompting 26.8 ±2.1 85.8 ±1.8 91.7 ±1.4 77.5 ±3.8 99.6 ±0.3\\nAblations'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 22, 'page_label': '23'}, page_content='Date Sports SayCan Concat Coin\\nStandard prompting 21.5 ±0.6 59.5 ±3.0 80.8 ±1.8 5.8 ±0.6 49.0 ±2.1\\nChain of thought prompting 26.8 ±2.1 85.8 ±1.8 91.7 ±1.4 77.5 ±3.8 99.6 ±0.3\\nAblations\\n·variable compute only 21.3 ±0.7 61.6 ±2.2 74.2 ±2.3 7.2 ±1.6 50.7 ±0.7\\n·reasoning after answer 20.9 ±1.0 63.0 ±2.0 83.3 ±0.6 0.0 ±0.0 50.2 ±0.5\\nRobustness\\n·different annotator (B) 27.4 ±1.7 75.4 ±2.7 88.3 ±1.4 76.0 ±1.9 77.5 ±7.9\\n·different annotator (C) 25.5 ±2.5 81.1 ±3.6 85.0 ±1.8 68.1 ±2.2 71.4 ±11.1\\n23'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 23, 'page_label': '24'}, page_content='C Extended Related Work\\nChain-of-thought prompting is a general approach that is inspired by several prior directions: prompt-\\ning, natural language explanations, program synthesis/execution, numeric and logical reasoning, and\\nintermediate language steps.\\nC.1 Prompting\\nThe recent success of large-scale language models has led to growing interest in improving their\\ncapability to perform tasks via prompting (Brown et al. (2020), and see Liu et al. (2021) for a\\nsurvey). This paper falls in the category of general prompting approaches, whereby input prompts are\\noptimized to allow a single large language model to better perform a variety of tasks (Li and Liang,\\n2021; Lester et al., 2021; Reif et al., 2022, inter alia).\\nOne recent line of work aims to improve the ability of language models to perform a task by providing\\ninstructions that describe the task (Raffel et al., 2020; Wei et al., 2022a; Ouyang et al., 2022; Sanh'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 23, 'page_label': '24'}, page_content='instructions that describe the task (Raffel et al., 2020; Wei et al., 2022a; Ouyang et al., 2022; Sanh\\net al., 2022; Wang et al., 2022b). This line of work is related because it also augments input–output\\npairs with meta-data. But whereas an instruction augments the input to a task (instructions are typically\\nprepended to the inputs), chain-of-thought prompting augments the outputs of language models.\\nAnother related direction is sequentially combining the outputs of language models; human–computer\\ninteraction (HCI) work (Wu et al., 2022a,b) has shown that combining sequential generations of\\nlanguage models improves task outcomes in a 20-person user study.\\nC.2 Natural language explanations\\nAnother closely related direction uses natural language explanations (NLEs), often with the goal of\\nimproving model interpretability (Zhou et al., 2020; Wiegreffe and Marasovi´c, 2021, inter alia). That'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 23, 'page_label': '24'}, page_content='improving model interpretability (Zhou et al., 2020; Wiegreffe and Marasovi´c, 2021, inter alia). That\\nline of work typically focuses on natural language inference (Camburu et al., 2018; Yordanov et al.,\\n2021; Bostrom et al., 2021), and produces explanations either simultaneously to or after the ﬁnal\\nprediction (Narang et al., 2020; Majumder et al., 2021; Wiegreffe et al., 2021, 2022). By contrast,\\nthe chain of thought processing considered in this paper occurs before the ﬁnal answer. And while\\nNLE aims mostly to improve neural network interpretability (Rajagopal et al., 2021), the goal of\\nchain-of-thought prompting is to allow models to decompose multi-hop reasoning tasks into multiple\\nsteps—interpretability is just a side effect. Marasovi ´c et al. (2022) show that prompt-based ﬁnetuning\\nwith NLE improves NLI and classiﬁcation performance, though they largely focus on evaluating\\nexplanation plausibility. In comparison, our work focuses on a range of arithmetic, commonsense,'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 23, 'page_label': '24'}, page_content='with NLE improves NLI and classiﬁcation performance, though they largely focus on evaluating\\nexplanation plausibility. In comparison, our work focuses on a range of arithmetic, commonsense,\\nand symbolic tasks that require multi-hop reasoning.\\nC.3 Program synthesis and execution\\nUsing intermediate reasoning steps has a long history in program synthesis and execution (Zaremba\\nand Sutskever, 2014, inter alia). Recent work along in this direction has included a number of\\narchitectural innovations (Cai et al., 2017; Dong et al., 2019; Yan et al., 2020), as well as the use of\\nlarge language models (Chen et al., 2021; Austin et al., 2021). The program execution work closest to\\nours is perhaps Nye et al. (2021), which show that large language models can perform up to 10-digit\\naddition, evaluate polynomials, and execute python programs. Whereas generating a program and\\nthen executing it can be viewed as a type of reasoning, our work generalizes such domain-speciﬁc'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 23, 'page_label': '24'}, page_content='addition, evaluate polynomials, and execute python programs. Whereas generating a program and\\nthen executing it can be viewed as a type of reasoning, our work generalizes such domain-speciﬁc\\nprimitives to natural language, which is open-domain and relevant to any text-to-text NLP task in\\nprinciple.\\nC.4 Numeric and logical reasoning\\nNumeric and logical reasoning has been a long-studied task in machine learning and natural language\\nprocessing (Lev et al., 2004, inter alia). Recent work has also aimed to inject numeric reasoning\\nabilities in language models in various ways, such as augmenting BERT with a predeﬁned set of\\nexecutable operations (Andor et al., 2019), including a graph neural network (Ran et al., 2019), and\\nusing specialized training procedures (Pi˛ ekos et al., 2021). Another line of work aims to enable\\nlanguage models to perform logical or formal reasoning, often by verablizing the rules in natural'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 23, 'page_label': '24'}, page_content='using specialized training procedures (Pi˛ ekos et al., 2021). Another line of work aims to enable\\nlanguage models to perform logical or formal reasoning, often by verablizing the rules in natural\\nlanguage formal rules using language (Clark et al., 2020; Saeed et al., 2021; Liang et al., 2021).\\n24'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 24, 'page_label': '25'}, page_content='Perhaps the most-related work here is Recchia (2021), which shows that ﬁnetuning enables longhand\\nmodule operations, which has previously been difﬁcult for performers. Whereas work in this direction\\nis often task-speciﬁc and uses ﬁnetuning, we show that chain-of-thought prompting works for a broad\\nrange of tasks without any ﬁnetuning.\\nC.5 Intermediate language steps\\nExtensive prior work has shown the beneﬁts of endowing neural networks with the ability to produce\\nintermediate steps via training or ﬁnetuning confers various beneﬁts in a range of scenarios. As\\nexamples, it has been shown that natural language intermediate steps can improve performance\\n(Zaidan et al., 2007; Yao et al., 2021; Hase and Bansal, 2022; Gu et al., 2022), improve robustness\\n(Chen et al., 2022), speed up training (Hancock et al., 2018), mitigate bias (Dua et al., 2020), and\\neven help in image and reinforcement learning settings (Andreas et al., 2018). To endow models with'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 24, 'page_label': '25'}, page_content='even help in image and reinforcement learning settings (Andreas et al., 2018). To endow models with\\nthe ability to produce intermediate steps, prior work typically ﬁnetunes models on either manually\\nannotated training datasets (Camburu et al., 2018; Rajani et al., 2019,inter alia) or generates synthetic\\ndatasets (Talmor et al., 2020; Zelikman et al., 2022). Compared with these training or ﬁnetuning\\nmethods, our work shows that various natural language reasoning abilities can be elicited in off-the-\\nshelf language models of sufﬁcient scale simply via prompting. This prompting setup is important\\nbecause it allows for intermediate step reasoning without a large number of labeled annotations, and\\nbecause a single model can perform a range of reasoning tasks without any gradient updates.\\nD Appendix: Additional Analysis\\nD.1 Correct Chain of Thought Analysis\\nAs mentioned in the main text, we analyze 50 chains of thought from LaMDA 137B that led to'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 24, 'page_label': '25'}, page_content='D Appendix: Additional Analysis\\nD.1 Correct Chain of Thought Analysis\\nAs mentioned in the main text, we analyze 50 chains of thought from LaMDA 137B that led to\\ncorrect answers in the GSM8K dataset. Of these 50, only one arrived at the correct answer through\\nincorrect reasoning (shown in Table 9: “correct by chance”). The other 49 had correct logic and\\nmath, with examples shown in Table 8. Five had minor imperfections while maintaining coherent and\\nunderstandable logic:\\n• One had underspeciﬁed statements (shown in Table 9: “correct but underspeciﬁed statements”).\\n• One made an unrelated but correct statement (shown in Table 9: “correct but unrelated statement”).\\n• Two had the correct logic but omitted speciﬁc steps in the equation, though it was still understand-\\nable (shown in Table 9: “correct but imperfect equation”).\\n• One had the correct math but inverted the semantics (shown in Table 9: “correct but inverted\\nsemantics”)'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 24, 'page_label': '25'}, page_content='able (shown in Table 9: “correct but imperfect equation”).\\n• One had the correct math but inverted the semantics (shown in Table 9: “correct but inverted\\nsemantics”)\\nTable 8: Example of correct chains of thought produced by the model for the GSM8K dataset.\\nQUESTION : James decides to run 3 sprints 3 times a week. He runs 60 meters each sprint. How many total\\nmeters does he run a week?\\nMODEL ANSWER (CORRECT): James decides to run 3 sprints 3 times a week. He runs 60 meters each\\nsprint. So he runs 60 meters x 3 sprints x 3 times a week. That is 60 meters x 9. The answer is 540. ✓\\nQUESTION : Brandon’s iPhone is four times as old as Ben’s iPhone. Ben’s iPhone is two times older than Suzy’s\\niPhone. If Suzy’s iPhone is 1 year old, how old is Brandon’s iPhone?\\nMODEL ANSWER (CORRECT): Brandon’s iPhone is 4 times as old as Ben’s iPhone. Ben’s iPhone is 2\\ntimes older than Suzy’s iPhone. So Brandon’s iPhone is 4 x 2 = 8 times older than Suzy’s iPhone. Suzy’s iPhone'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 24, 'page_label': '25'}, page_content='times older than Suzy’s iPhone. So Brandon’s iPhone is 4 x 2 = 8 times older than Suzy’s iPhone. Suzy’s iPhone\\nis 1 year old. So Brandon’s iPhone is 8 x 1 = 8 years old. The answer is 8. ✓\\nQUESTION : Jean has 30 lollipops. Jean eats 2 of the lollipops. With the remaining lollipops, Jean wants to\\npackage 2 lollipops in one bag. How many bags can Jean ﬁll?\\nMODEL ANSWER (CORRECT): Jean started with 30 lollipops. She ate 2 of them. So she has 28 lollipops\\nleft. She wants to package 2 lollipops in one bag. So she can package 28 / 2 = 14 bags. The answer is 14. ✓\\nAlthough we ﬁnd that chain-of-thought reasoning is mostly correct for math questions where the ﬁnal\\nanswer was correct, this is likely because it is hard to arrive at the correct ﬁnal answer by coincidence\\nfor free response questions. For multiple choice or binary classiﬁcation problems, it was much more\\n25'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 25, 'page_label': '26'}, page_content='likely that models could arrive at the correct answer via an incorrect reasoning path (e.g., all the\\ncommmonsense reasoning datasets we evaluate). This is a limitation, and future work should perform\\nan analysis of the factuality of such chains of thought.\\nTable 9: Of 50 examples that the model got correct, there were 7 salient cases where the chain of\\nthought the model generated was imperfect. We found the other 43 to be equivalent to what a human\\nwould potentially generate as a ground truth.\\nQUESTION : There are 36 penguins sunbathing in the snow. One-third of them jump in and swim in the ocean.\\nAnother one-third go inside the cave to eat their dinner. How many penguins are still left sunbathing?\\nMODEL ANSWER (CORRECT BY CHANCE ): There are 36 penguins. One-third of them jump in and swim in\\nthe ocean. So that is 12 penguins. Another one-third go inside the cave to eat their dinner. So that is 12 penguins.\\nThe answer is 12.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 25, 'page_label': '26'}, page_content='the ocean. So that is 12 penguins. Another one-third go inside the cave to eat their dinner. So that is 12 penguins.\\nThe answer is 12.\\nQUESTION : John has 2 houses with 3 bedrooms each. Each bedroom has 2 windows each. There are an\\nadditional 4 windows in each house not connected to bedrooms. How many total windows are there between the\\nhouses?\\nMODEL ANSWER (CORRECT BUT UNDERSPECIFIED STATEMENTS ): There are 2 houses with 3 bedrooms\\neach. Each bedroom has 2 windows each. So there are 2 x 3 = 6 windows in each house. There are an additional\\n4 windows in each house not connected to bedrooms. So there are 4 + 4 = 8 windows in each house. So there are\\n6 x 2 = 12 windows in each house. So there are 12 + 8 = 20 windows in both houses. The answer is 20.\\nQUESTION : If Ann is 9 years old and her brother is twice her age, how old will her brother be in 3 years?\\nMODEL ANSWER (CORRECT BUT UNRELATED STATEMENT ): Ann is 9 years old. Her brother is twice her'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 25, 'page_label': '26'}, page_content='MODEL ANSWER (CORRECT BUT UNRELATED STATEMENT ): Ann is 9 years old. Her brother is twice her\\nage. So her brother is 18 years old. In 3 years, she will be 12. So her brother will be 18 + 3 = 21 years old. The\\nanswer is 21.\\nQUESTION : A local gas station is selling gas for $3.00 a gallon. An app company is offering $.20 cashback per\\ngallon if you ﬁll up at this station. If someone buys 10 gallons of gas, how much with their gas be, after the\\ncashback rewards?\\nMODEL ANSWER (CORRECT BUT IMPERFECT EQUATION ): The gas is originally 3 dollars per gallon. If\\nyou buy 10 gallons, that is 3 x 10 = 30 dollars. If you get 20 cents off per gallon, that is 20 x 10 = 2 dollars. So\\nthe total is 30 - 2 = 28 dollars. The answer is 28 dollars.\\nQUESTION : Nissa hires 60 seasonal workers to play elves in her department store’s Santa village. A third of\\nthe elves quit after children vomit on them, then 10 of the remaining elves quit after kids kick their shins. How\\nmany elves are left?'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 25, 'page_label': '26'}, page_content='the elves quit after children vomit on them, then 10 of the remaining elves quit after kids kick their shins. How\\nmany elves are left?\\nMODEL ANSWER (CORRECT BUT IMPERFECT EQUATION ): Nissa hires 60 seasonal workers. A third of\\nthem quit. So 60 - 1/3 = 40 elves are left. Then 10 elves quit. So 40 - 10 = 30 elves are left. The answer is 30\\nelves.\\nQUESTION : Grandma Jones baked 5 apple pies for the ﬁreman’s luncheon. She cut each pie into 8 pieces and\\nset the ﬁve pies out on the buffet table for the guests to serve themselves. At the end of the evening, after the\\nguests had taken and eaten their pieces of pie, there were 14 pieces of pie remaining. How many pieces were\\ntaken by the guests?\\nMODEL ANSWER (CORRECT BUT INVERTED SEMANTICS ): 5 pies were baked and cut into 8 pieces each.\\nThe 5 pies were then served to the guests. 8 x 5 = 40 pieces of pie. The guests ate 14 pieces of pie. 40 - 14 = 26\\npieces of pie were left. The answer is 26. ✓\\n26'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 26, 'page_label': '27'}, page_content='D.2 Incorrect Chain of Thought Analysis\\nWe also manually analyze 50 randomly sampled outputs of the model that were incorrect on GSM8K\\nfor LaMDA 137B. There are many ways that a chain of thought can be incorrect, making the design\\nof error categorization non-trivial. We decided to categorize errors into what changes are needed to\\nmake the chain of thought correct, with the goal of elucidating how the model can be improved in the\\nfuture.\\nWe found that many chains of thought can be made correct with one of the following three classes of\\nmodiﬁcation.\\n• Calculator error only. We found that 8% of the chains of thought were completely correct except\\nfor a calculator error—in other words, applying an external calculator to equations, as done in\\nCobbe et al. (2021), would make the chain of thought correct. An example of this type of error is\\nshown in Table 10: “calculator error only”. Indeed, the solve rate of chain-of-thought prompting'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 26, 'page_label': '27'}, page_content='Cobbe et al. (2021), would make the chain of thought correct. An example of this type of error is\\nshown in Table 10: “calculator error only”. Indeed, the solve rate of chain-of-thought prompting\\non for LaMDA 137B GSM8K went up from 14.3% to 17.3% when we added a Python program\\nas an external calculator, as shown in Table 2. Also, 34% of the examples contained calculator\\nerrors in addition to other types of errors. However, we perform the rest of the error categorization\\nindependently of calculator errors.\\n• Symbol mapping error. We next found that 16% percent of the chains of thought were correct\\nexcept for what we call symbol mapping errors. We deﬁne a symbol mapping error as when the\\nchain of thought is correct except for the number symbols, and it could be made totally correct by\\nmodifying only the equations and not the words. As one might argue that they could simply place\\nthe correct ﬁnal equation in any chain of thought, we constrain this category to chains of thought'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 26, 'page_label': '27'}, page_content='modifying only the equations and not the words. As one might argue that they could simply place\\nthe correct ﬁnal equation in any chain of thought, we constrain this category to chains of thought\\nwhere the chain of thought can be modiﬁed to be a completely correct reasoning process (not just\\nﬁnal answer). An example of this error category is shown in Table 10: “symbol mapping error”.\\n• One step missing error. Our next category of error is chains of thought which were correct except\\nthat they were missing a single step. In other words, these chains of thoughts could be rewritten to\\nbe correct by adding in an additional reasoning step that was missed by the model. An example of\\nthis error category is shown in Table 10: “one step missing error”. We found that 22% percent of\\nthe errors fell into this category.\\nTable 10: Example of incorrect chains of thought, categorized as described in Appendix D.2.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 26, 'page_label': '27'}, page_content='the errors fell into this category.\\nTable 10: Example of incorrect chains of thought, categorized as described in Appendix D.2.\\nQUESTION : Dan plants 3 rose bushes. Each rose bush has 25 roses. Each rose has 8 thorns. How many thorns\\nare there total?\\nMODEL ANSWER (INCORRECT ; CALCULATOR ERROR ONLY ): Dan plants 3 rose bushes. Each rose bush\\nhas 25 roses. Each rose has 8 thorns. So 3 x 25 x 8 = 300. The answer is 300. \\x17\\nEXPLANATION FOR ERROR CATEGORY : The produced chain of thought could be made correct just by\\nrunning the equation through an external calculator, instead of asking the model to do the computation.\\nQUESTION : Jill gets paid $20 per hour to teach and $30 to be a cheerleading coach. If she works 50 weeks a\\nyear, 35 hours a week as a teacher and 15 hours a week as a coach, what’s her annual salary?\\nMODEL ANSWER (INCORRECT ; SYMBOL MAPPING ERROR ): Jill gets paid 20 dollars per hour to teach'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 26, 'page_label': '27'}, page_content='year, 35 hours a week as a teacher and 15 hours a week as a coach, what’s her annual salary?\\nMODEL ANSWER (INCORRECT ; SYMBOL MAPPING ERROR ): Jill gets paid 20 dollars per hour to teach\\nand 30 dollars per hour to be a cheerleading coach. If she works 50 weeks a year, 35 hours a week as a teacher\\nand 15 hours a week as a coach, then she works 50 x 35 = 1750 hours as a teacher and 15 x 30 = 450 hours as a\\ncoach. So she works 1750 + 450 = 2200 hours. She gets paid 20 dollars per hour for 1750 hours and 30 dollars\\nper hour for 450 hours. So her annual salary is 20 x 1750 + 30 x 450 = $36,500. The answer is $36,500. \\x17\\nEXPLANATION FOR ERROR CATEGORY : The model incorrectly mapped “15 x 30” instead of “15 x 50”, and\\nthe chain of thought would be made correct by ﬁxing just that one change (with an external calculator).\\nQUESTION : Kelian has two recipes for preparing dishes, one having 20 instructions and the second one having'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 26, 'page_label': '27'}, page_content='QUESTION : Kelian has two recipes for preparing dishes, one having 20 instructions and the second one having\\ntwice as many instructions as the ﬁrst one. How many instructions does Kelian have to read to prepare the two\\ndishes?\\nMODEL ANSWER (INCORRECT ; ONE STEP MISSING ERROR ): Kelian has two recipes. One has 20 instruc-\\ntions. The other has twice as many instructions as the ﬁrst one. So the second one has 40 instructions. So Kelian\\nhas to read 40 instructions to prepare the two dishes. The answer is 40. \\x17\\nEXPLANATION FOR ERROR CATEGORY : The model answer could be made correct just adding one additional\\nstep (in this case, adding 20 and 40).\\n27'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 27, 'page_label': '28'}, page_content='We found that the remaining chains of thought (27 of 50; 54%) would require substantial edits to make\\ninto a correct chain of thought. Almost all cases here involved some error in semantic understanding\\n(see Table 11: “semantic understanding error”), and 8 of the 27 also had incoherent chain of thoughts,\\nmeaning that some statements in the generated chain of thought did not follow from prior ones or\\nviolated basic world knowledge (see Table 11: “incoherent chain of thought error”).\\nTable 11: Example of incorrect chains of thought, categorized as described in Appendix D.2. These\\nchains of thought had multiple mistakes that could not be ﬁxed with minor edits.\\nQUESTION : Gretchen has 110 coins. There are 30 more gold coins than silver coins. How many gold coins\\ndoes Gretchen have?\\nMODEL ANSWER (INCORRECT ; SEMANTIC UNDERSTANDING ERROR ): Gretchen has 110 coins. There\\nare 30 more gold coins than silver coins. So there are 110 - 30 = 80 silver coins. So there are 80 silver coins and'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 27, 'page_label': '28'}, page_content='are 30 more gold coins than silver coins. So there are 110 - 30 = 80 silver coins. So there are 80 silver coins and\\n110 - 80 = 30 gold coins. The answer is 30. \\x17\\nEXPLANATION FOR ERROR CATEGORY : The model does not understand that 110 coins are in total and that\\nit must solve an equation to get the number of gold and silver coins.\\nQUESTION : In a dance class of 20 students, 20% enrolled in contemporary dance, 25% of the remaining\\nenrolled in jazz dance, and the rest enrolled in hip-hop dance. What percentage of the entire students enrolled in\\nhip-hop dance?\\nMODEL ANSWER (INCORRECT ; INCOHERENT CHAIN OF THOUGHT ERROR ): 20% of the students en-\\nrolled in contemporary dance. 25% of the remaining students enrolled in jazz dance. The rest enrolled in hip-hop\\ndance. So the percentage of the entire students enrolled in hip-hop dance is the percentage of the students\\nenrolled in hip-hop dance, minus the percentage of the students enrolled in contemporary dance, minus the'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 27, 'page_label': '28'}, page_content='enrolled in hip-hop dance, minus the percentage of the students enrolled in contemporary dance, minus the\\npercentage of the students enrolled in jazz dance. So the percentage of the entire students enrolled in hip-hop\\ndance is (25 + 20) - (25 + 20) = 100%. The answer is 100%. \\x17\\nEXPLANATION FOR ERROR CATEGORY : This chain of thought is incoherent in that the percent of entire\\nstudents enrolled in hip-hope dance cannot be the percent of student enrolled in hip-hop dance minus another\\nterm.\\nOverall, there are no guarantees that the reasoning processes generated by large language models\\nare coherent or factually correct, as underscored by the recent work evaluating the factuality of\\nlanguage model generations and explanations (Maynez et al., 2020; Rashkin et al., 2021; Ye and\\nDurrett, 2022; Marasovi´c et al., 2022; Wiegreffe et al., 2022). Incorrect reasoning processes can lead\\nto both incorrect ﬁnal answers as well as accidentally correct ﬁnal answers (with accidentally correct'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 27, 'page_label': '28'}, page_content='to both incorrect ﬁnal answers as well as accidentally correct ﬁnal answers (with accidentally correct\\nﬁnal answers being more likely for tasks such as binary classiﬁcation as opposed to free response).\\nImproving the factuality of language model generations with respect to context and world knowledge\\nis an important direction open problems in language model research and could also be expected to\\npotentially improve multi-step reasoning abilities of language models. One potential method for\\nimproving the quality of decoding could involve generating multiple reasoning paths and scoring\\neach of them with a veriﬁer, though this requires training the veriﬁer (Cobbe et al., 2021; Shen et al.,\\n2021; Thoppilan et al., 2022).\\nD.3 Additional Robustness Analysis\\nAs the experiments in the main paper use a ﬁxed number of few-shot exemplars (8; as constrained by\\nthe input length of 1024 tokens), we verify that the chain-of-thought prompting is robust to various'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 27, 'page_label': '28'}, page_content='As the experiments in the main paper use a ﬁxed number of few-shot exemplars (8; as constrained by\\nthe input length of 1024 tokens), we verify that the chain-of-thought prompting is robust to various\\nnumbers of few-shot exemplars. We run experiments for LaMDA 137B, comparing chain-of-thought\\nprompting with standard prompting for the ﬁve datasets where standard prompting had a mostly ﬂat\\nscaling curve (the largest model did not achieve high performance). As shown in Figure 11, the\\nimprovement of chain-of-thought prompting over standard prompting remains robust to varying the\\nnumber of few-shot exemplars in the prompt.\\n28'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 28, 'page_label': '29'}, page_content='1 2 4 6 80\\n5\\n10\\n15Solve rate (%)\\nGSM8K\\n1 2 4 6 80\\n20\\n40\\n60\\nMultiArith\\n(MAWPS)\\n1 2 4 6 80\\n25\\n50\\n75\\n100\\nNumber of few-shot exemplars\\nSports\\nUnderstanding\\nStandard prompting\\nChain of thought prompting\\n1 2 4 6 80\\n25\\n50\\n75\\n100\\nCoin Flip\\n1 2 3 40\\n25\\n50\\n75\\n100\\nLast Letter\\nConcatenation\\nFigure 11: The improvement of chain of thought prompting over standard prompting appears robust\\nto varying the number of few-shot exemplars in the prompt.\\nTable 12: Summary of math word problem benchmarks we use in this paper with examples. N:\\nnumber of evaluation examples.\\nDataset N Example problem\\nGSM8K 1,319 Josh decides to try ﬂipping a house. He buys a house for $80,000 and then puts\\nin $50,000 in repairs. This increased the value of the house by 150%. How\\nmuch proﬁt did he make?\\nSV AMP 1,000 Each pack of dvds costs 76 dollars. If there is a discount of 25 dollars on each\\npack. How much do you have to pay to buy each pack?'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 28, 'page_label': '29'}, page_content='much proﬁt did he make?\\nSV AMP 1,000 Each pack of dvds costs 76 dollars. If there is a discount of 25 dollars on each\\npack. How much do you have to pay to buy each pack?\\nASDiv 2,096 Ellen has six more balls than Marin. Marin has nine balls. How many balls does\\nEllen have?\\nAQuA 254 A car is being driven, in a straight line and at a uniform speed, towards the base\\nof a vertical tower. The top of the tower is observed from the car and, in the\\nprocess, it takes 10 minutes for the angle of elevation to change from 45◦ to 60◦.\\nAfter how much more time will this car reach the base of the tower? Answer\\nChoices: (a) 5\\n√\\n3 + 1 (b) 6\\n√\\n3 +\\n√\\n2 (c) 7\\n√\\n3 - 1 (d) 8\\n√\\n3 - 2 (e) None of these\\nMAWPS: SingleOp 562 If there are 7 bottle caps in a box and Linda puts 7 more bottle caps inside, how\\nmany bottle caps are in the box?\\nMAWPS: SingleEq 508 Benny bought a soft drink for 2 dollars and 5 candy bars. He spent a total of 27\\ndollars. How much did each candy bar cost?'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 28, 'page_label': '29'}, page_content='many bottle caps are in the box?\\nMAWPS: SingleEq 508 Benny bought a soft drink for 2 dollars and 5 candy bars. He spent a total of 27\\ndollars. How much did each candy bar cost?\\nMAWPS: AddSub 395 There were 6 roses in the vase. Mary cut some roses from her ﬂower garden.\\nThere are now 16 roses in the vase. How many roses did she cut?\\nMAWPS: MultiArith 600 The school cafeteria ordered 42 red apples and 7 green apples for students\\nlunches. But, if only 9 students wanted fruit, how many extra did the cafeteria\\nend up with?\\n29'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 29, 'page_label': '30'}, page_content='E Additional Details\\nVersion Control\\nV5 →V6. Fixed minor typo in Figure 3.\\nV4 →V5. Added Codex and UL2 results. Small changes to writing and style of paper.\\nV3 →V4. Fixed typo in Figure 3 and added a couple citations.\\nV2 →V3. Added GPT-3 results. Added SV AMP and AQuA eval datasets for math. Added SayCan\\neval for commonsense. Added Extended Related Work section (Appendix C). Added ablations for\\nCommonsense and Symbolic Reasoning (Table 7). Added FAQ section (Appendix A). Added raw\\nresults in Appendix B.\\nV1 →V2. Added PaLM results (V1 only had LaMDA).\\nE.1 Reproducibility Statement\\nAs our results make use of two sets of large language models that is not publicly available, we take\\nthe following actions to facilitate reproducibility. First, we provide the exact input prompts for all\\ntasks in Table 20–Table 27 in Appendix G (and emphasize that we do not perform any ﬁnetuning and\\nonly apply prompting to off-the-shelf language models). Second, we conduct experiments using the'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 29, 'page_label': '30'}, page_content='tasks in Table 20–Table 27 in Appendix G (and emphasize that we do not perform any ﬁnetuning and\\nonly apply prompting to off-the-shelf language models). Second, we conduct experiments using the\\npublicly available GPT-3 API for four model scales text-ada-001, text-babbage-001, text-curie-001,\\ntext-davinci-002). Finally, we make exact inputs, targets, and predictions for LaMDA 137B for each\\ntask available as a zip ﬁle in the supplementary material.\\nE.2 Computational Resources\\nFor all three language models we evaluated, we did prompting-based inference only. No ﬁnetuning\\nwas done for this paper. For inference on LaMDA 137B we use TPU v3 (8x8 conﬁguration, 64 chips\\n/ 128 cores), and for inference on PaLM 540B we use TPU v4 (4x4x12 conﬁguration, 192 chips / 384\\ncores). GPT-3 experiments were done using the public API.5\\nE.3 Dataset Details and Licenses\\nWe list the details and licenses for all arithmetic and commonsense datasets used in this paper. The'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 29, 'page_label': '30'}, page_content='cores). GPT-3 experiments were done using the public API.5\\nE.3 Dataset Details and Licenses\\nWe list the details and licenses for all arithmetic and commonsense datasets used in this paper. The\\nsymbolic reasoning datasets were created synthetically, as described in Section 4.\\nArithmetic reasoning\\n• Math Word Problem Repository (Koncel-Kedziorski et al., 2016): AddSub (Hosseini\\net al., 2014): https://www.cs.washington.edu/nlp/arithmetic; MultiArith (Roy\\nand Roth, 2015), license: CC BY 4.0.\\n• ASDiv (Miao et al., 2020): https://github.com/chaochun/nlu-asdiv-dataset.\\n• AQuA (Ling et al., 2017): https://github.com/deepmind/AQuA, license: https://\\ngithub.com/deepmind/AQuA/blob/master/LICENSE.\\n• GSM8K (Cobbe et al., 2021): https://github.com/openai/grade-school-math,\\nMIT license: https://github.com/openai/grade-school-math/blob/master/\\nLICENSE.\\n• SV AMP (Patel et al., 2021): https://github.com/arkilpatel/SVAMP, MIT license:\\nhttps://github.com/arkilpatel/SVAMP/blob/main/LICENSE.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 29, 'page_label': '30'}, page_content='LICENSE.\\n• SV AMP (Patel et al., 2021): https://github.com/arkilpatel/SVAMP, MIT license:\\nhttps://github.com/arkilpatel/SVAMP/blob/main/LICENSE.\\nCommonsense reasoning\\n• CSQA (Talmor et al., 2019): https://www.tau-nlp.org/commonsenseqa, https://\\ngithub.com/jonathanherzig/commonsenseqa.\\n5https://beta.openai.com/docs/api-reference/making-requests\\n30'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 30, 'page_label': '31'}, page_content='• StrategyQA (Geva et al., 2021): we use the open-domain setting (question-only set)\\nfrom BIG-bench collaboration (2021): https://github.com/google/BIG-bench/\\ntree/main/bigbench/benchmark_tasks/strategyqa. The original dataset is from\\nhttps://github.com/eladsegal/strategyqa, MIT license: https://github.com/\\neladsegal/strategyqa/blob/main/LICENSE.\\n• Date understanding and sports understanding from BIG-Bench (BIG-bench collaboration,\\n2021): Apache License v.2: https://github.com/google/BIG-bench/blob/main/\\nLICENSE.\\n• SayCan (Ahn et al., 2022): SayCan dataset can be accessed at https://say-can.github.\\nio/ under CC BY 4.0 license.\\n31'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 31, 'page_label': '32'}, page_content='F Appendix: Input/Output Examples\\nTable 13: Examples of correct and incorrect chains of thought produced by LaMDA 137B on the\\nletter concatenation task.\\nQUESTION : Take the last letters of the words in “Waldo Schmidt” and concatenate them.\\nMODEL ANSWER (CORRECT): The last letter of “Waldo” is “o”. The last letter of “Schmidt” is “t”.\\nConcatenating them is “ot”. So the answer is ot. ✓\\nQUESTION : Take the last letters of the words in “Daniel Friedman” and concatenate them.\\nMODEL ANSWER (INCORRECT): The last letter of “Daniel” is “l”. The last letter of “Friedman” is “m”.\\nConcatenating them is “lm”. So the answer is lm. \\x17\\nTable 14: Examples of correct and incorrect chains of thought produced by LaMDA 137B on the\\ncoinﬂip task.\\nQUESTION : A coin is heads up. Andree ﬂips the coin. Audrie does not ﬂip the coin. Is the coin still heads up?\\nMODEL ANSWER (CORRECT): The coin was ﬂipped by Andree. So the coin was ﬂipped 1 time, which is'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 31, 'page_label': '32'}, page_content='MODEL ANSWER (CORRECT): The coin was ﬂipped by Andree. So the coin was ﬂipped 1 time, which is\\nan odd number. The coin started heads up, so after an odd number of ﬂips, it will be tails up. So the answer is no.\\n✓\\nQUESTION : A coin is heads up. Kristian does not ﬂip the coin. Dallas does not ﬂip the coin. Is the coin still\\nheads up?\\nMODEL ANSWER (INCORRECT): The coin was ﬂipped by Kristian. So the coin was ﬂipped 1 time, which\\nis an odd number. The coin started heads up, so after an odd number of ﬂips, it will be tails up. So the answer is\\nno. \\x17\\nTable 15: Examples of correct and incorrect chains of thought produced by LaMDA 137B on CSQA.\\nQUESTION : When a person is beginning work, what are they building?\\nAnswer Choices: (a) time (b) accomplishing (c) working (d) momentum (e) tiredness\\nMODEL ANSWER (CORRECT): The answer must be something that is built. Of the above choices, only\\nmomentum is built. So the answer is (d). ✓\\nQUESTION : Where are you likely to ﬁnd a hamburger?'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 31, 'page_label': '32'}, page_content='MODEL ANSWER (CORRECT): The answer must be something that is built. Of the above choices, only\\nmomentum is built. So the answer is (d). ✓\\nQUESTION : Where are you likely to ﬁnd a hamburger?\\nAnswer Choices: (a) fast food restaurant (b) pizza (c) ground up dead cows (d) mouth (e) cow carcus\\nMODEL ANSWER (CORRECT): The answer must be a place where hamburgers are found. Of the above\\nchoices, only fast food restaurants serve hamburgers. So the answer is (a). ✓\\nQUESTION : Aside from water and nourishment what does your dog need?\\nAnswer Choices: (a) bone (b) charm (c) petted (d) lots of attention (e) walked\\nMODEL ANSWER (INCORRECT): The answer must be something that a dog needs. Of the above choices,\\nonly bone is something that a dog needs. So the answer is (a). \\x17 (Ground truth is (d).)\\nQUESTION : What are you waiting alongside with when you’re in a reception area?\\nAnswer Choices: (a) motel (b) chair (c) hospital (d) people (e) hotels'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 31, 'page_label': '32'}, page_content='QUESTION : What are you waiting alongside with when you’re in a reception area?\\nAnswer Choices: (a) motel (b) chair (c) hospital (d) people (e) hotels\\nMODEL ANSWER (INCORRECT): The answer must be something that is waiting with you in a reception\\narea. Of the above choices, only people are waiting with you in a reception area. So the answer is (e). \\x17 (Ground\\ntruth is (d).)\\n32'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 32, 'page_label': '33'}, page_content='Table 16: Examples of correct and incorrect chains of thought produced by LaMDA 137B on\\nStrategyQA.\\nQUESTION : Will The Exorcist stimulate limbic system?\\nMODEL ANSWER (CORRECT): The Exorcist is a horror movie. Horror movies are scary. The limbic system\\nis involved in fear. Thus, The Exorcist will stimulate the limbic system. So the answer is yes. ✓\\nQUESTION : Was Jackson Pollock trained by Leonardo da Vinci?\\nMODEL ANSWER (CORRECT): Leonardo da Vinci lived in the 15th century. Jackson Pollock lived in the\\n20th century. Thus, Jackson Pollock could not have been trained by Leonardo da Vinci. So the answer is no. ✓\\nQUESTION : Can Harry Potter book a ﬂight on Asiana Airlines?\\nMODEL ANSWER (INCORRECT): Harry Potter is a ﬁctional character. Thus, Harry Potter can do anything.\\nSo the answer is yes. \\x17 (Ground truth is “no”.)\\nQUESTION : Would a sophist use an épée?\\nMODEL ANSWER (INCORRECT): A sophist is a person who is skilled in the art of persuasion. An épée is'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 32, 'page_label': '33'}, page_content='So the answer is yes. \\x17 (Ground truth is “no”.)\\nQUESTION : Would a sophist use an épée?\\nMODEL ANSWER (INCORRECT): A sophist is a person who is skilled in the art of persuasion. An épée is\\na type of sword. Thus, a sophist could use an épée. So the answer is yes. \\x17 (Ground truth is “no”.)\\nTable 17: Examples of correct and incorrect chains of thought produced by LaMDA 137B on Date\\nUnderstanding.\\nQUESTION : May 6, 1992 is like yesterday to Jane, but that is actually ten years ago. What is the date a month\\nago in MM/DD/YYYY?\\nMODEL ANSWER (CORRECT): May 6, 1992 is ten years ago, so today is May 6, 2002. So a month ago will\\nbe April 6, 2002. So the answer is 04/06/2002. ✓\\nQUESTION : This is the last day of 1899. What is the date 24 hours later in MM/DD/YYYY?\\nMODEL ANSWER (CORRECT): Today is 12/31/1899. 24 hours later will be 01/01/1900. So the answer is\\n01/01/1900. ✓\\nQUESTION : Jane scheduled 3 apointments with 5 poeple for tomorrow (Tue, 7/9/1972). What is the date one'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 32, 'page_label': '33'}, page_content='01/01/1900. ✓\\nQUESTION : Jane scheduled 3 apointments with 5 poeple for tomorrow (Tue, 7/9/1972). What is the date one\\nweek ago from today in MM/DD/YYYY?\\nMODEL ANSWER (INCORRECT): Tomorrow is 7/9/1972. One week ago from today is 7/2/1972. So the\\nanswer is 7/2/1972. \\x17 (Ground truth is 07/01/1972.)\\nQUESTION : Today is the palindrome day of 2020, because the MMDDYYYY format of the date is the same\\nbackwards as forwards. What is the date tomorrow in MM/DD/YYYY?\\nMODEL ANSWER (INCORRECT): Today is 02/29/2020. Tomorrow will be 03/01/2020. So the answer is\\n03/01/2020. \\x17 (Ground truth is “02/03/2020”.)\\nTable 18: Examples of correct and incorrect chains of thought produced by LaMDA 137B on Sports\\nUnderstanding.\\nQUESTION : Is the following sentence plausible? “Joao Moutinho was out at third.”\\nMODEL ANSWER (CORRECT): Joao Moutinho is a soccer player. Being out at third is part of baseball, not\\nsoccer. So the answer is no. ✓'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 32, 'page_label': '33'}, page_content='MODEL ANSWER (CORRECT): Joao Moutinho is a soccer player. Being out at third is part of baseball, not\\nsoccer. So the answer is no. ✓\\nQUESTION : Is the following sentence plausible? “Malcolm Brogdon eurostepped to the basket in the NBA\\nChampionship.”\\nMODEL ANSWER (CORRECT): Malcolm Brogdon is a basketball player. Eurostepping to the basket is part\\nof basketball. So the answer is yes. ✓\\nQUESTION : Is the following sentence plausible? “Derrick White backhanded a shot.”\\nMODEL ANSWER (INCORRECT): Derrick White is a basketball player. Backhanding a shot is part of\\nbasketball. So the answer is yes. \\x17 (Ground truth is “no”, backhanding a shot is part of hockey.)\\nQUESTION : Is the following sentence plausible? “Nazem Kadri was out at home.”\\nMODEL ANSWER (INCORRECT): Nazem Kadri is a hockey player. Being out at home is part of hockey.\\nSo the answer is yes. \\x17 (Ground truth is “no”, being out at home is part of baseball.)\\n33'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 33, 'page_label': '34'}, page_content='Table 19: Examples of correct and incorrect chains of thought produced by PaLM 540B on SayCan\\nrobot planning tasks.\\nQUESTION : I spilled my coke on the table, could you throw it away and then bring me something to help clean?\\nMODEL ANSWER (CORRECT): Explanation: The user has spilled their coke on the table. I will throw away\\nthe coke and then bring the user a sponge. Plan: ﬁnd(coke), pick(coke), ﬁnd(trash), put(coke), ﬁnd(sponge),\\npick(sponge), ﬁnd(table), put(sponge). ✓\\nQUESTION : Could you compost that apple for me?\\nMODEL ANSWER (CORRECT): Explanation: The user would like me to compost the apple. I will move the\\napple to the compost. Plan: ﬁnd(apple), pick(apple), ﬁnd(trash), put(apple). ✓\\nQUESTION : Can you bring me a drink that is not coke?\\nMODEL ANSWER (INCORRECT): Explanation: The user asked me to bring a drink that is not coke, I will\\nbring a sprite. Plan: ﬁnd(sprite), pick(sprite), ﬁnd(user), put(sprite). \\x17 (Feasible answers including ﬁnding lime'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 33, 'page_label': '34'}, page_content='bring a sprite. Plan: ﬁnd(sprite), pick(sprite), ﬁnd(user), put(sprite). \\x17 (Feasible answers including ﬁnding lime\\nsoda, pepsi, grapefruit soda or water, because there is no sprite in the scene as deﬁned in Table 28.)\\nQUESTION : Can you bring me something salty?\\nMODEL ANSWER (INCORRECT): Explanation: The user would like something salty. There are several\\noptions in the objects list, so I will bring the user a lime soda. Plan: ﬁnd(lime soda), pick(lime soda), ﬁnd(user),\\nput(lime soda). \\x17 (Feasible answers including ﬁnding chips. The model misidentify lime soda as salty.)\\n34'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 34, 'page_label': '35'}, page_content='G Appendix: Full Prompts\\nTable 20: Few-shot exemplars for full chain of thought prompt for math word problems. This set of\\nexemplars was used for all math word problem datasets except AQuA.\\nPROMPT FOR MATH WORD PROBLEMS\\nQ: There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there\\nwill be 21 trees. How many trees did the grove workers plant today?\\nA: There are 15 trees originally. Then there were 21 trees after some more were planted. So there must have\\nbeen 21 - 15 = 6. The answer is 6.\\nQ: If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\\nA: There are originally 3 cars. 2 more cars arrive. 3 + 2 = 5. The answer is 5.\\nQ: Leah had 32 chocolates and her sister had 42. If they ate 35, how many pieces do they have left in total?\\nA: Originally, Leah had 32 chocolates. Her sister had 42. So in total they had 32 + 42 = 74. After eating 35, they\\nhad 74 - 35 = 39. The answer is 39.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 34, 'page_label': '35'}, page_content='A: Originally, Leah had 32 chocolates. Her sister had 42. So in total they had 32 + 42 = 74. After eating 35, they\\nhad 74 - 35 = 39. The answer is 39.\\nQ: Jason had 20 lollipops. He gave Denny some lollipops. Now Jason has 12 lollipops. How many lollipops did\\nJason give to Denny?\\nA: Jason started with 20 lollipops. Then he had 12 after giving some to Denny. So he gave Denny 20 - 12 = 8.\\nThe answer is 8.\\nQ: Shawn has ﬁve toys. For Christmas, he got two toys each from his mom and dad. How many toys does he\\nhave now?\\nA: Shawn started with 5 toys. If he got 2 toys each from his mom and dad, then that is 4 more toys. 5 + 4 = 9.\\nThe answer is 9.\\nQ: There were nine computers in the server room. Five more computers were installed each day, from monday\\nto thursday. How many computers are now in the server room?\\nA: There were originally 9 computers. For each of 4 days, 5 more computers were added. So 5 * 4 = 20\\ncomputers were added. 9 + 20 is 29. The answer is 29.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 34, 'page_label': '35'}, page_content='A: There were originally 9 computers. For each of 4 days, 5 more computers were added. So 5 * 4 = 20\\ncomputers were added. 9 + 20 is 29. The answer is 29.\\nQ: Michael had 58 golf balls. On tuesday, he lost 23 golf balls. On wednesday, he lost 2 more. How many golf\\nballs did he have at the end of wednesday?\\nA: Michael started with 58 golf balls. After losing 23 on tuesday, he had 58 - 23 = 35. After losing 2 more, he\\nhad 35 - 2 = 33 golf balls. The answer is 33.\\nQ: Olivia has $23. She bought ﬁve bagels for $3 each. How much money does she have left?\\nA: Olivia had 23 dollars. 5 bagels for 3 dollars each will be 5 x 3 = 15 dollars. So she has 23 - 15 dollars left. 23\\n- 15 is 8. The answer is 8.\\n35'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 35, 'page_label': '36'}, page_content='Table 21: Few-shot exemplars for full chain of thought prompt for AQuA.\\nPROMPT FOR AQUA ALGEBRAIC WORD PROBLEMS\\nQ: John found that the average of 15 numbers is 40. If 10 is added to each number then the mean of the numbers\\nis?\\nAnswer Choices: (a) 50 (b) 45 (c) 65 (d) 78 (e) 64\\nA: If 10 is added to each number, then the mean of the numbers also increases by 10. So the new mean would be\\n50. The answer is (a).\\nQ: If a / b = 3/4 and 8a + 5b = 22,then ﬁnd the value of a.\\nAnswer Choices: (a) 1/2 (b) 3/2 (c) 5/2 (d) 4/2 (e) 7/2\\nA: If a / b = 3/4, then b = 4a / 3. So 8a + 5(4a / 3) = 22. This simpliﬁes to 8a + 20a / 3 = 22, which means 44a / 3\\n= 22. So a is equal to 3/2. The answer is (b).\\nQ: A person is traveling at 20 km/hr and reached his destiny in 2.5 hr then ﬁnd the distance?\\nAnswer Choices: (a) 53 km (b) 55 km (c) 52 km (d) 60 km (e) 50 km\\nA: The distance that the person traveled would have been 20 km/hr * 2.5 hrs = 50 km. The answer is (e).'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 35, 'page_label': '36'}, page_content='Answer Choices: (a) 53 km (b) 55 km (c) 52 km (d) 60 km (e) 50 km\\nA: The distance that the person traveled would have been 20 km/hr * 2.5 hrs = 50 km. The answer is (e).\\nQ: How many keystrokes are needed to type the numbers from 1 to 500?\\nAnswer Choices: (a) 1156 (b) 1392 (c) 1480 (d) 1562 (e) 1788\\nA: There are 9 one-digit numbers from 1 to 9. There are 90 two-digit numbers from 10 to 99. There are 401\\nthree-digit numbers from 100 to 500. 9 + 90(2) + 401(3) = 1392. The answer is (b).\\nTable 22: Few-shot exemplars for full chain of thought prompt for the last letter concatenation task.\\nPROMPT FOR LAST LETTER CONCATENATION\\nQ: Take the last letters of the words in \"Elon Musk\" and concatenate them.\\nA: The last letter of \"Elon\" is \"n\". The last letter of \"Musk\" is \"k\". Concatenating them is \"nk\". The answer is nk.\\nQ: Take the last letters of the words in \"Larry Page\" and concatenate them.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 35, 'page_label': '36'}, page_content='A: The last letter of \"Elon\" is \"n\". The last letter of \"Musk\" is \"k\". Concatenating them is \"nk\". The answer is nk.\\nQ: Take the last letters of the words in \"Larry Page\" and concatenate them.\\nA: The last letter of \"Larry\" is \"y\". The last letter of \"Page\" is \"e\". Concatenating them is \"ye\". The answer is ye.\\nQ: Take the last letters of the words in \"Sergey Brin\" and concatenate them.\\nA: The last letter of \"Sergey\" is \"y\". The last letter of \"Brin\" is \"n\". Concatenating them is \"yn\". The answer is\\nyn.\\nQ: Take the last letters of the words in \"Bill Gates\" and concatenate them.\\nA: The last letter of \"Bill\" is \"l\". The last letter of \"Gates\" is \"s\". Concatenating them is \"ls\". The answer is ls.\\n36'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 36, 'page_label': '37'}, page_content='Table 23: Few-shot exemplars for full chain of thought prompt for the coinﬂip task.\\nPROMPT FOR COIN FLIP\\nQ: Q: A coin is heads up. Ka ﬂips the coin. Sherrie ﬂips the coin. Is the coin still heads up?\\nA: The coin was ﬂipped by Ka and Sherrie. So the coin was ﬂipped 2 times, which is an even number. The coin\\nstarted heads up, so after an even number of ﬂips, it will still be heads up. So the answer is yes.\\nQ: A coin is heads up. Jamey ﬂips the coin. Teressa ﬂips the coin. Is the coin still heads up?\\nA: The coin was ﬂipped by Jamey and Teressa. So the coin was ﬂipped 2 times, which is an even number. The\\ncoin started heads up, so after an even number of ﬂips, it will still be heads up. So the answer is yes.\\nQ: A coin is heads up. Maybelle ﬂips the coin. Shalonda does not ﬂip the coin. Is the coin still heads up?\\nA: The coin was ﬂipped by Maybelle. So the coin was ﬂipped 1 time, which is an odd number. The coin started'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 36, 'page_label': '37'}, page_content='A: The coin was ﬂipped by Maybelle. So the coin was ﬂipped 1 time, which is an odd number. The coin started\\nheads up, so after an odd number of ﬂips, it will be tails up. So the answer is no.\\nQ: A coin is heads up. Millicent does not ﬂip the coin. Conception ﬂips the coin. Is the coin still heads up?\\nA: The coin was ﬂipped by Conception. So the coin was ﬂipped 1 time, which is an odd number. The coin\\nstarted heads up, so after an odd number of ﬂips, it will be tails up. So the answer is no.\\nQ: A coin is heads up. Sal ﬂips the coin. Raymond does not ﬂip the coin. Is the coin still heads up?\\nA: The coin was ﬂipped by Sal. So the coin was ﬂipped 1 time, which is an odd number. The coin started heads\\nup, so after an odd number of ﬂips, it will be tails up. So the answer is no.\\nQ: A coin is heads up. Conception ﬂips the coin. Kristian does not ﬂip the coin. Is the coin still heads up?\\nA: The coin was ﬂipped by Conception. So the coin was ﬂipped 1 time, which is an odd number. The coin'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 36, 'page_label': '37'}, page_content='A: The coin was ﬂipped by Conception. So the coin was ﬂipped 1 time, which is an odd number. The coin\\nstarted heads up, so after an odd number of ﬂips, it will be tails up. So the answer is no.\\nQ: A coin is heads up. Inga does not ﬂip the coin. Elanor does not ﬂip the coin. Is the coin still heads up?\\nA: The coin was ﬂipped by no one. So the coin was ﬂipped 0 times. The coin started heads up, and it was not\\nﬂipped, so it is still heads up. So the answer is yes.\\nQ: A coin is heads up. Ryan ﬂips the coin. Shaunda ﬂips the coin. Is the coin still heads up?\\nA: The coin was ﬂipped by Ryan and Shaunda. So the coin was ﬂipped 2 times, which is an even number. The\\ncoin started heads up, so after an even number of ﬂips, it will still be heads up. So the answer is yes.\\n37'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 37, 'page_label': '38'}, page_content='Table 24: Few-shot exemplars for full chain of thought prompt for CSQA. There are newlines\\nbetween the answer choices that are omitted in the table for space reasons.\\nPROMPT FOR CSQA\\nQ: What do people use to absorb extra ink from a fountain pen? Answer Choices: (a) shirt pocket (b)\\ncalligrapher’s hand (c) inkwell (d) desk drawer (e) blotter\\nA: The answer must be an item that can absorb ink. Of the above choices, only blotters are used to absorb ink.\\nSo the answer is (e).\\nQ: What home entertainment equipment requires cable?\\nAnswer Choices: (a) radio shack (b) substation (c) television (d) cabinet\\nA: The answer must require cable. Of the above choices, only television requires cable. So the answer is (c).\\nQ: The fox walked from the city into the forest, what was it looking for? Answer Choices: (a) pretty ﬂowers (b)\\nhen house (c) natural habitat (d) storybook\\nA: The answer must be something in the forest. Of the above choices, only natural habitat is in the forest. So the\\nanswer is (b).'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 37, 'page_label': '38'}, page_content='hen house (c) natural habitat (d) storybook\\nA: The answer must be something in the forest. Of the above choices, only natural habitat is in the forest. So the\\nanswer is (b).\\nQ: Sammy wanted to go to where the people were. Where might he go? Answer Choices: (a) populated areas\\n(b) race track (c) desert (d) apartment (e) roadblock\\nA: The answer must be a place with a lot of people. Of the above choices, only populated areas have a lot of\\npeople. So the answer is (a).\\nQ: Where do you put your grapes just before checking out? Answer Choices: (a) mouth (b) grocery cart (c)super\\nmarket (d) fruit basket (e) fruit market\\nA: The answer should be the place where grocery items are placed before checking out. Of the above choices,\\ngrocery cart makes the most sense for holding grocery items. So the answer is (b).\\nQ: Google Maps and other highway and street GPS services have replaced what? Answer Choices: (a) united\\nstates (b) mexico (c) countryside (d) atlas'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 37, 'page_label': '38'}, page_content='Q: Google Maps and other highway and street GPS services have replaced what? Answer Choices: (a) united\\nstates (b) mexico (c) countryside (d) atlas\\nA: The answer must be something that used to do what Google Maps and GPS services do, which is to give\\ndirections. Of the above choices, only atlases are used to give directions. So the answer is (d).\\nQ: Before getting a divorce, what did the wife feel who was doing all the work? Answer Choices: (a) harder (b)\\nanguish (c) bitterness (d) tears (e) sadness\\nA: The answer should be the feeling of someone getting divorced who was doing all the work. Of the above\\nchoices, the closest feeling is bitterness. So the answer is (c).\\n38'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 38, 'page_label': '39'}, page_content='Table 25: Few-shot exemplars for full chain of thought prompt for StrategyQA.\\nPROMPT FOR STRATEGY QA\\nQ: Do hamsters provide food for any animals?\\nA: Hamsters are prey animals. Prey are food for predators. Thus, hamsters provide food for some animals. So\\nthe answer is yes.\\nQ: Could Brooke Shields succeed at University of Pennsylvania?\\nA: Brooke Shields went to Princeton University. Princeton University is about as academically rigorous as the\\nUniversity of Pennsylvania. Thus, Brooke Shields could also succeed at the University of Pennsylvania. So the\\nanswer is yes.\\nQ: Yes or no: Hydrogen’s atomic number squared exceeds number of Spice Girls?\\nA: Hydrogen has an atomic number of 1. 1 squared is 1. There are 5 Spice Girls. Thus, Hydrogen’satomic\\nnumber squared is less than 5. So the answer is no.\\nQ: Yes or no: Is it common to see frost during some college commencements?\\nA: College commencement ceremonies can happen in December, May, and June. December is in the winter, so'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 38, 'page_label': '39'}, page_content='Q: Yes or no: Is it common to see frost during some college commencements?\\nA: College commencement ceremonies can happen in December, May, and June. December is in the winter, so\\nthere can be frost. Thus, there could be frost at some commencements. So the answer is yes.\\nQ: Yes or no: Could a llama birth twice during War in Vietnam (1945-46)?\\nA: The War in Vietnam was 6 months. The gestation period for a llama is 11 months, which is more than 6\\nmonths. Thus, a llama could not give birth twice during the War in Vietnam. So the answer is no.\\nQ: Yes or no: Would a pear sink in water?\\nA: The density of a pear is about 0.6g/cm3, which is less than water. Objects less dense than water ﬂoat. Thus,\\na pear would ﬂoat. So the answer is no.\\nTable 26: Few-shot exemplars for full chain of thought prompt for Date Understanding.\\nPROMPT FOR DATE UNDERSTANDING\\nQ: 2015 is coming in 36 hours. What is the date one week from today in MM/DD/YYYY?'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 38, 'page_label': '39'}, page_content='Table 26: Few-shot exemplars for full chain of thought prompt for Date Understanding.\\nPROMPT FOR DATE UNDERSTANDING\\nQ: 2015 is coming in 36 hours. What is the date one week from today in MM/DD/YYYY?\\nA: If 2015 is coming in 36 hours, then it is coming in 2 days. 2 days before 01/01/2015 is 12/30/2014, so today\\nis 12/30/2014. So one week from today will be 01/05/2015. So the answer is 01/05/2015.\\nQ: The ﬁrst day of 2019 is a Tuesday, and today is the ﬁrst Monday of 2019. What is the date today in\\nMM/DD/YYYY?\\nA: If the ﬁrst day of 2019 was Tuesday, then 01/01/2019 was a Tuesday. Today is the ﬁrst monday, would be six\\ndays later. So today is 01/07/2019. So the answer is 01/07/2019.\\nQ: The concert was scheduled to be on 06/01/1943, but was delayed by one day to today. What is the date 10\\ndays ago in MM/DD/YYYY?\\nA: One day after 06/01/1943 is 06/02/1943, so today is 06/02/1943. 10 days before today is 05/23/1943. So the\\nanswer is 05/23/1943.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 38, 'page_label': '39'}, page_content='days ago in MM/DD/YYYY?\\nA: One day after 06/01/1943 is 06/02/1943, so today is 06/02/1943. 10 days before today is 05/23/1943. So the\\nanswer is 05/23/1943.\\nQ: It is 4/19/1969 today. What is the date 24 hours later in MM/DD/YYYY?\\nA: Today is 04/19/1969. 24 hours later is one day after today, which would be 04/20/1969. So the answer is\\n04/20/1969.\\nQ: Jane thought today is 3/11/2002, but today is in fact Mar 12, which is 1 day later. What is the date 24 hours\\nlater in MM/DD/YYYY?\\nA: Today is 03/12/2002. So the date 24 hours later will be 03/13/2002. So the answer is 03/13/2002.\\nQ: Jane was born on the last day of Feburary in 2001. Today is her 16-year-old birthday. What is the date\\nyesterday in MM/DD/YYYY?\\nA: The last day of February is the 28th, so Jane was born on 02/28/2001. Today is her 16-year old birthday, so\\ntoday is 02/28/2017. So yesterday was 02/27/2017. So the answer is 02/27/2017.\\n39'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 39, 'page_label': '40'}, page_content='Table 27: Few-shot exemplars for full chain of thought prompt for Sports Understanding.\\nPROMPT FOR SPORTS UNDERSTANDING\\nQ: Is the following sentence plausible? “Kyle Palmieri was called for slashing.”\\nA: Kyle Palmieri is a hockey player. Being called for slashing is part of hockey. So the answer is yes.\\nQ: Is the following sentence plausible? “Joao Moutinho caught the screen pass in the NFC championship.”\\nA: Joao Moutinho is a soccer player. The NFC championship is part of American football, not soccer. So the\\nanswer is no.\\nQ: Is the following sentence plausible? “Carson Wentz set the pick and roll.”\\nA: Carson Wentz is an American football player. Pick and roll is part of basketball, not football. So the answer\\nis no.\\nQ: Is the following sentence plausible? “Jonas Valanciunas beat the buzzer.”\\nA: Jonas Valanciunas is a basketball player. Beating the buzzer is part of basketball. So the answer is yes.\\nQ: Is the following sentence plausible? “Jamel Murray was perfect from the line.”'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 39, 'page_label': '40'}, page_content='A: Jonas Valanciunas is a basketball player. Beating the buzzer is part of basketball. So the answer is yes.\\nQ: Is the following sentence plausible? “Jamel Murray was perfect from the line.”\\nA: Jamal Murray is a basketball player. Being perfect from the line is part of basketball. So the answer is yes.\\nQ: Is the following sentence plausible? “Sam Darnold passed the puck.”\\nA: Sam Darnold is a American football player. Passing the puck is part of hockey, not American football. So the\\nanswer is no.\\nQ: Is the following sentence plausible? “Draymond Green threw a touchdown.”\\nA: Draymond Green is an basketball player. Throwing a touchdown is part of football, not basketball. So the\\nanswer is no.\\nQ: Is the following sentence plausible? “Malcolm Brogdon banked the shot in.”\\nA: Malcolm Brogdon is a basketball player. Banking the shot in is part of basketball. So the answer is yes.\\n40'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 40, 'page_label': '41'}, page_content='Table 28: Few-shot exemplars for full chain of thought prompt for SayCan robot planning tasks.\\nPROMPT FOR SAYCAN ROBOT PLANNING\\nLocations = [counter, table, user, trash, bowl].\\nObjects = [7up, apple, kettle chips, tea, multigrain chips, coke, lime soda, jalapeno chips, rice chips, orange,\\ngrapefruit soda, pepsi, redbull, energy bar, sponge, water].\\nThe robot can pick up items with pick(object) and put down items with put(object) as well as ﬁnd objects or\\nlocations with ﬁnd(). The robot can only understand the explicit locations and objects listed.\\nHuman: I’m hungry, can you bring me some chips.\\nExplanation: The user is hungry and has asked for chips. There are several types of chips available, I will bring\\nthe user the kettle chips.\\nPlan: 1. ﬁnd(kettle chips), 2. pick(kettle chips), 3. ﬁnd(user), 4. put(kettle chips), 5. done().\\nHuman: How would you move the grapefruit drink from the table to the counter?\\nExplanation: The user has asked me to move the grapefruit drink to the counter.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 40, 'page_label': '41'}, page_content='Human: How would you move the grapefruit drink from the table to the counter?\\nExplanation: The user has asked me to move the grapefruit drink to the counter.\\nPlan: 1. ﬁnd(grapefruit soda), 2. pick(grapefruit soda), 3. ﬁnd(counter), 4. put(grapefruit soda), 5. done().\\nHuman: How would you bring me some snacks?\\nExplanation: The user has asked for snacks, I will choose two items and bring them. I will bring jalapeno chips\\nand an apple.\\nPlan: 1. ﬁnd(jalapeno chips), 2. pick(jalapeno chips), 3. ﬁnd(user), 4. put(jalapeno chips), 5. ﬁnd(apple), 6.\\npick(apple), 7. ﬁnd(user), 8. put(apple), 9. done().\\nHuman: How would you bring me something to eat that isn’t a fruit?\\nExplanation: The user has asked for a food that isn’ta fruit, I will bring an energy bar to them.\\nPlan: 1. ﬁnd(energy bar), 2. pick(energy bar), 3. ﬁnd(user), 4. put(energy bar), 5. done().\\nHuman: How would you put the rice chips in the bowl and then move the tea to the table?'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 40, 'page_label': '41'}, page_content='Plan: 1. ﬁnd(energy bar), 2. pick(energy bar), 3. ﬁnd(user), 4. put(energy bar), 5. done().\\nHuman: How would you put the rice chips in the bowl and then move the tea to the table?\\nExplanation: The user has asked me to do two tasks, I will do one and then the other.\\nPlan: 1. ﬁnd(rice chips), 2. pick(rice chips), 3. ﬁnd(bowl), 4. put(rice chips), 5. ﬁnd(tea), 6. pick(tea), 7.\\nﬁnd(table), 8. put(tea), 9. done().\\nHuman: How would you throw away a redbull?\\nExplanation: The user has asked me to throw away the redbull, I will move it to the trash.\\nPlan: 1. ﬁnd(redbull), 2. pick(redbull), 3. ﬁnd(trash), 4. put(redbull), 5. done().\\nHuman: Bring me a drink.\\nExplanation: The user has asked for a drink and there are many options. I will bring them a water.\\nPlan: 1. ﬁnd(water), 2. pick(water), 3. ﬁnd(user), 4. put(water), 5. done().\\n41'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 41, 'page_label': '42'}, page_content='H Appendix: Alternate Annotators for MWP\\nTable 29: Few-shot exemplars for full chain of thought prompt for math word problems. These\\nexemplars are the same as in Table 20, except that the chains of thought were written by a different\\nannotator (“Annotator B” instead of “Annotator A”). Annotators were co-authors and familiar with\\nthe goal of chain of thought prompting.\\nPROMPT FOR MATH WORD PROBLEMS\\nQ: There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there\\nwill be 21 trees. How many trees did the grove workers plant today?\\nA: There are 21 trees now and there are 15 trees in the beginning, so the workers plant 21 - 15 = 6 trees. The\\nanswer is 6.\\nQ: If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\\nA: There are 3 cars in the beginning, 2 more arrive, so now there should be 3 + 2 = 5 cars. The answer is 5.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 41, 'page_label': '42'}, page_content='A: There are 3 cars in the beginning, 2 more arrive, so now there should be 3 + 2 = 5 cars. The answer is 5.\\nQ: Leah had 32 chocolates and her sister had 42. If they ate 35, how many pieces do they have left in total?\\nA: Leah had 32 chocolates and her sister had 42, in total they have 32 + 42 = 74 chocolates. After they ate 35,\\nnow there are 74 - 35 = 39 chocolates. The answer is 39.\\nQ: Jason had 20 lollipops. He gave Denny some lollipops. Now Jason has 12 lollipops. How many lollipops did\\nJason give to Denny?\\nA: Jason started with 20 lollipops, but now he only has 12, so he gave Denny 20 - 12 = 8 lollipops. The answer\\nis 8.\\nQ: Shawn has ﬁve toys. For Christmas, he got two toys each from his mom and dad. How many toys does he\\nhave now?\\nA: Shawn got 2 toys each from his mom and dad, so he got 2 * 2 = 4 more, now he will have 5 + 4 = 9 toys. The\\nanswer is 9.\\nQ: There were nine computers in the server room. Five more computers were installed each day, from monday'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 41, 'page_label': '42'}, page_content='answer is 9.\\nQ: There were nine computers in the server room. Five more computers were installed each day, from monday\\nto thursday. How many computers are now in the server room?\\nA: 5 computers were installed from monday to thursday, so in total 5 * 4 = 20 computers are installed. 9\\ncomputers are there in the beginning, so now there are 20 + 9 = 29 computers. The answer is 29.\\nQ: Michael had 58 golf balls. On tuesday, he lost 23 golf balls. On wednesday, he lost 2 more. How many golf\\nballs did he have at the end of wednesday?\\nA: Michael started with 58 golf balls and lost 23, so he has 58 - 23 = 35. After he lost 2 more, he has 35 - 2 = 33\\nballs now. The answer is 33.\\nQ: Olivia has $23. She bought ﬁve bagels for $3 each. How much money does she have left?\\nA: 5 bagels for $3 each should cost 5 * 3 = 15 dollars. Olivia had $23 in the beginning, so now she has 23 - 15 =\\n8 dollars left. The answer is 8.\\n42'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 42, 'page_label': '43'}, page_content='Table 30: Few-shot exemplars for full chain of thought prompt for math word problems. These\\nexemplars are the same as in Table 20, except that the chains of thought were written by a different\\nannotator (“Annotator C” instead of “Annotator A”).\\nPROMPT FOR MATH WORD PROBLEMS\\nQ: There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there\\nwill be 21 trees. How many trees did the grove workers plant today?\\nA: We start with 15 trees. Later we have 21 trees. The difference must be the number of trees they planted. So,\\nthey must have planted 21 - 15 = 6 trees. The answer is 6.\\nQ: If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\\nA: There are 3 cars in the parking lot already. 2 more arrive. Now there are 3 + 2 = 5 cars. The answer is 5.\\nQ: Leah had 32 chocolates and her sister had 42. If they ate 35, how many pieces do they have left in total?'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 42, 'page_label': '43'}, page_content='Q: Leah had 32 chocolates and her sister had 42. If they ate 35, how many pieces do they have left in total?\\nA: Leah had 32 chocolates and Leah’ssister had 42. That means there were originally 32 + 42 = 74 chocolates.\\n35 have been eaten. So in total they still have 74 - 35 = 39 chocolates. The answer is 39.\\nQ: Jason had 20 lollipops. He gave Denny some lollipops. Now Jason has 12 lollipops. How many lollipops did\\nJason give to Denny?\\nA: Jason had 20 lollipops. Since he only has 12 now, he must have given the rest to Denny. The number of\\nlollipops he has given to Denny must have been 20 - 12 = 8 lollipops. The answer is 8.\\nQ: Shawn has ﬁve toys. For Christmas, he got two toys each from his mom and dad. How many toys does he\\nhave now?\\nA: He has 5 toys. He got 2 from mom, so after that he has 5 + 2 = 7 toys. Then he got 2 more from dad, so in\\ntotal he has 7 + 2 = 9 toys. The answer is 9.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 42, 'page_label': '43'}, page_content='have now?\\nA: He has 5 toys. He got 2 from mom, so after that he has 5 + 2 = 7 toys. Then he got 2 more from dad, so in\\ntotal he has 7 + 2 = 9 toys. The answer is 9.\\nQ: There were nine computers in the server room. Five more computers were installed each day, from monday\\nto thursday. How many computers are now in the server room?\\nA: There are 4 days from monday to thursday. 5 computers were added each day. That means in total 4 * 5 = 20\\ncomputers were added. There were 9 computers in the beginning, so now there are 9 + 20 = 29 computers. The\\nanswer is 29.\\nQ: Michael had 58 golf balls. On tuesday, he lost 23 golf balls. On wednesday, he lost 2 more. How many golf\\nballs did he have at the end of wednesday?\\nA: Michael initially had 58 balls. He lost 23 on Tuesday, so after that he has 58 - 23 = 35 balls. On Wednesday\\nhe lost 2 more so now he has 35 - 2 = 33 balls. The answer is 33.\\nQ: Olivia has $23. She bought ﬁve bagels for $3 each. How much money does she have left?'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-01-12T01:06:30+00:00', 'author': '', 'keywords': '', 'moddate': '2023-01-12T01:06:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf', 'total_pages': 43, 'page': 42, 'page_label': '43'}, page_content='he lost 2 more so now he has 35 - 2 = 33 balls. The answer is 33.\\nQ: Olivia has $23. She bought ﬁve bagels for $3 each. How much money does she have left?\\nA: She bought 5 bagels for $3 each. This means she spent 5 * $3 = $15 on the bagels. She had $23 in beginning,\\nso now she has $23 - $15 = $8. The answer is 8.\\n43'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 0, 'page_label': '1'}, page_content='A Path Towards Autonomous Machine Intelligence\\nVersion 0.9.2, 2022-06-27\\nYann LeCun\\nCourant Institute of Mathematical Sciences, New York Universityyann@cs.nyu.edu\\nMeta - Fundamental AI Researchyann@fb.com\\nJune 27, 2022\\nAbstract\\nHow could machines learn as eﬃciently as humans and animals? How could ma-\\nchines learn to reason and plan? How could machines learn representations of percepts\\nand action plans at multiple levels of abstraction, enabling them to reason, predict,\\nand plan at multiple time horizons? This position paper proposes an architecture and\\ntraining paradigms with which to construct autonomous intelligent agents. It combines\\nconcepts such as conﬁgurable predictive world model, behavior driven through intrinsic\\nmotivation, and hierarchical joint embedding architectures trained with self-supervised\\nlearning.\\nKeywords: Artiﬁcial Intelligence, Machine Common Sense, Cognitive Architecture, Deep'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 0, 'page_label': '1'}, page_content='motivation, and hierarchical joint embedding architectures trained with self-supervised\\nlearning.\\nKeywords: Artiﬁcial Intelligence, Machine Common Sense, Cognitive Architecture, Deep\\nLearning, Self-Supervised Learning, Energy-Based Model, World Models, Joint Embedding\\nArchitecture, Intrinsic Motivation.\\n1 Prologue\\nThis document is not a technical nor scholarly paper in the traditional sense, but a position\\npaper expressing my vision for a path towards intelligent machines that learn more like\\nanimals and humans, that can reason and plan, and whose behavior is driven by intrinsic\\nobjectives, rather than by hard-wired programs, external supervision, or external rewards.\\nMany ideas described in this paper (almost all of them) have been formulated by many\\nauthors in various contexts in various form. The present piece does not claim priority for\\nany of them but presents a proposal for how to assemble them into a consistent whole. In'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 0, 'page_label': '1'}, page_content='authors in various contexts in various form. The present piece does not claim priority for\\nany of them but presents a proposal for how to assemble them into a consistent whole. In\\nparticular, the piece pinpoints the challenges ahead. It also lists a number of avenues that\\nare likely or unlikely to succeed.\\nThe text is written with as little jargon as possible, and using as little mathematical\\nprior knowledge as possible, so as to appeal to readers with a wide variety of backgrounds\\nincluding neuroscience, cognitive science, and philosophy, in addition to machine learning,\\nrobotics, and other ﬁelds of engineering. I hope that this piece will help contextualize some\\nof the research in AI whose relevance is sometimes diﬃcult to see.\\n1'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 1, 'page_label': '2'}, page_content='2 Introduction\\nAnimals and humans exhibit learning abilities and understandings of the world that are far\\nbeyond the capabilities of current AI and machine learning (ML) systems.\\nHow is it possible for an adolescent to learn to drive a car in about 20 hours of practice\\nand for children to learn language with what amounts to a small exposure. How is it that\\nmost humans will know how to act in many situation they have never encountered? By\\ncontrast, to be reliable, current ML systems need to be trained with very large numbers of\\ntrials so that even the rarest combination of situations will be encountered frequently during\\ntraining. Still, our best ML systems are still very far from matching human reliability in\\nreal-world tasks such as driving, even after being fed with enormous amounts of supervisory\\ndata from human experts, after going through millions of reinforcement learning trials in\\nvirtual environments, and after engineers have hardwired hundreds of behaviors into them.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 1, 'page_label': '2'}, page_content='data from human experts, after going through millions of reinforcement learning trials in\\nvirtual environments, and after engineers have hardwired hundreds of behaviors into them.\\nThe answer may lie in the ability of humans and many animals to learn world models,\\ninternal models of how the world works.\\nThere are three main challenges that AI research must address today:\\n1. How can machines learn to represent the world, learn to predict, and learn to act\\nlargely by observation?\\nInteractions in the real world are expensive and dangerous, intelligent agents should\\nlearn as much as they can about the world without interaction (by observation) so\\nas to minimize the number of expensive and dangerous trials necessary to learn a\\nparticular task.\\n2. How can machine reason and plan in ways that are compatible with gradient-based\\nlearning?\\nOur best approaches to learning rely on estimating and using the gradient of a loss,'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 1, 'page_label': '2'}, page_content='particular task.\\n2. How can machine reason and plan in ways that are compatible with gradient-based\\nlearning?\\nOur best approaches to learning rely on estimating and using the gradient of a loss,\\nwhich can only be performed with diﬀerentiable architectures and is diﬃcult to rec-\\noncile with logic-based symbolic reasoning.\\n3. How can machines learn to represent percepts and action plans in a hierarchical man-\\nner, at multiple levels of abstraction, and multiple time scales?\\nHumans and many animals are able to conceive multilevel abstractions with which\\nlong-term predictions and long-term planning can be performed by decomposing com-\\nplex actions into sequences of lower-level ones.\\nThe present piece proposes an architecture for intelligent agents with possible solutions to\\nall three challenges.\\nThe main contributions of this paper are the following:\\n1. an overall cognitive architecture in which all modules are diﬀerentiable and many of\\nthem are trainable (Section 3, Figure 2).'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 1, 'page_label': '2'}, page_content='The main contributions of this paper are the following:\\n1. an overall cognitive architecture in which all modules are diﬀerentiable and many of\\nthem are trainable (Section 3, Figure 2).\\n2. JEPA and Hierarchical JEPA: a non-generative architecture for predictive world mod-\\nels that learn a hierarchy of representations (Sections 4.4 and 4.6, Figures 12 and 15).\\n3. a non-contrastive self-supervised learning paradigm that produces representations that\\nare simultaneously informative and predictable (Section 4.5, Figure 13).\\n2'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 2, 'page_label': '3'}, page_content='4. A way to use H-JEPA as the basis of predictive world models for hierarchical planning\\nunder uncertainty (section 4.7, Figure 16 and 17).\\nImpatient readers may prefer to jump directly to the aforementioned sections and ﬁgures.\\n2.1 Learning World Models\\nHuman and non-human animals seem able to learn enormous amounts of background knowl-\\nedge about how the world works through observation and through an incomprehensibly\\nsmall amount of interactions in a task-independent, unsupervised way. It can be hypoth-\\nesized that this accumulated knowledge may constitute the basis for what is often called\\ncommon sense . Common sense can be seen as a collection of models of the world that\\ncan tell an agent what is likely, what is plausible, and what is impossible. Using such\\nworld models, animals can learn new skills with very few trials. They can predict the con-\\nsequences of their actions, they can reason, plan, explore, and imagine new solutions to'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 2, 'page_label': '3'}, page_content='world models, animals can learn new skills with very few trials. They can predict the con-\\nsequences of their actions, they can reason, plan, explore, and imagine new solutions to\\nproblems. Importantly, they can also avoid making dangerous mistakes when facing an\\nunknown situation.\\nThe idea that humans, animals, and intelligent systems use world models goes back a\\nlong time in psychology (Craik, 1943). The use of forward models that predict the next\\nstate of the world as a function of the current state and the action being considered has been\\nstandard procedure in optimal control since the 1950s (Bryson and Ho, 1969) and bears\\nthe name model-predictive control. The use of diﬀerentiable world models in reinforcement\\nlearning has long been neglected but is making a comeback (see for example (Levine, 2021))\\nA self-driving system for cars may require thousands of trials of reinforcement learning\\nto learn that driving too fast in a turn will result in a bad outcome, and to learn to slow'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 2, 'page_label': '3'}, page_content='A self-driving system for cars may require thousands of trials of reinforcement learning\\nto learn that driving too fast in a turn will result in a bad outcome, and to learn to slow\\ndown to avoid skidding. By contrast, humans can draw on their intimate knowledge of\\nintuitive physics to predict such outcomes, and largely avoid fatal courses of action when\\nlearning a new skill.\\nCommon sense knowledge does not just allow animals to predict future outcomes, but\\nalso to ﬁll in missing information, whether temporally or spatially. It allows them to produce\\ninterpretations of percepts that are consistent with common sense. When faced with an\\nambiguous percept, common sense allows animals to dismiss interpretations that are not\\nconsistent with their internal world model, and to pay special attention as it may indicate\\na dangerous situation and an opportunity for learning a reﬁned world model.\\nI submit that devising learning paradigms and architectures that would allow machines'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 2, 'page_label': '3'}, page_content='a dangerous situation and an opportunity for learning a reﬁned world model.\\nI submit that devising learning paradigms and architectures that would allow machines\\nto learn world models in an unsupervised (or self-supervised) fashion, and to use those\\nmodels to predict, to reason, and to plan is one of the main challenges of AI and ML today.\\nOne major technical hurdle is how to devise trainable world models that can deal with\\ncomplex uncertainty in the predictions.\\n2.2 Humans and Animals learn Hierarchies of Models\\nHumans and non-human animals learn basic knowledge about how the world works in the\\nﬁrst days, weeks, and months of life. Although enormous quantities of such knowledge are\\nacquired quite quickly, the knowledge seems so basic that we take it for granted. In the\\nﬁrst few months of life, we learn that the world is three-dimensional. We learn that every\\n3'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 3, 'page_label': '4'}, page_content='Perception Production\\nPhysics\\nActions\\nObjects\\n0 1 2 3 4 5 6 7 8 9 10 11 12 13 14\\nAge (months)\\nstability,\\nsupport\\ngravity, iner�a\\nconserva�on of\\nmomentum\\nObject permanence\\nsolidity, rigidity\\nshape\\nconstancy\\ncrawling walking\\nemo�onal contagion\\nra�onal, goal-\\ndirected ac�ons\\nface tracking\\nproto-imita�on\\npoin�ng\\nbiological\\nmo�on\\nfalse perceptual\\nbeliefs\\nhelping vs\\nhindering\\nnatural kind categories\\nSocial\\nCommunication\\nFigure 1: This chart, (courtesy of Emmanuel Dupoux), indicates at what age infants generally\\nacquire various concepts about how the world works. It is consistent with the idea that abstract\\nconcepts, such as the fact that objects are subject to gravity and inertia, are acquired on top of less\\nabstract concepts, like object permanence and the assignment of objects to broad categories. Much\\nof this knowledge is acquired mostly by observation, with very little direct intervention, particularly\\nin the ﬁrst few weeks and months.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 3, 'page_label': '4'}, page_content='of this knowledge is acquired mostly by observation, with very little direct intervention, particularly\\nin the ﬁrst few weeks and months.\\nsource of light, sound, and touch in the world has a distance from us. The fact that every\\npoint in a visual percept has a distance is the best way to explain how our view of the\\nworld changes from our left eye to our right eye, or when our head is being moved. Parallax\\nmotion makes depth obvious, which in turn makes the notion of object obvious, as well\\nas the fact that objects can occlude more distant ones. Once the existence of objects is\\nestablished, they can be automatically assigned to broad categories as a function of their\\nappearance or behavior. On top of the notion of object comes the knowledge that objects\\ndo not spontaneously appear, disappear, change shape, or teleport: they move smoothly\\nand can only be in one place at any one time. Once such concepts are acquired, it becomes'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 3, 'page_label': '4'}, page_content='do not spontaneously appear, disappear, change shape, or teleport: they move smoothly\\nand can only be in one place at any one time. Once such concepts are acquired, it becomes\\neasy to learn that some objects are static, some have predictable trajectories (inanimate\\nobjects), some behave in somewhat unpredictable ways (collective phenomena like water,\\nsand, tree leaves in the wind, etc), and some seem to obey diﬀerent rules (animate objects).\\nNotions of intuitive physics such as stability, gravity, inertia, and others can emerge on top\\nof that. The eﬀect of animate objects on the world (including the eﬀects of the subject’s\\nown actions) can be used to deduce cause-and-eﬀect relationships, on top of which linguistic\\nand social knowledge can be acquired.\\nFigure 1, courtesy of Emmanuel Dupoux, shows at what age infants seem to acquire\\nbasic concepts such as object permanence, basic categories, intuitive physics, etc. Concepts'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 3, 'page_label': '4'}, page_content='Figure 1, courtesy of Emmanuel Dupoux, shows at what age infants seem to acquire\\nbasic concepts such as object permanence, basic categories, intuitive physics, etc. Concepts\\nat higher levels of abstraction seem to develop on top of lower-level ones.\\nEquipped with this knowledge of the world, combined with simple hard-wired behav-\\niors and intrinsic motivations/objectives, animals can quickly learn new tasks, predict the\\n4'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 4, 'page_label': '5'}, page_content='consequences of their actions and plan ahead, foreseeing successful courses of actions and\\navoiding dangerous situations.\\nBut can a human or animal brain contain all the world models that are necessary for\\nsurvival? One hypothesis in this paper is that animals and humans have only one world\\nmodel engine somewhere in their prefrontal cortex. That world model engine is dynamically\\nconﬁgurable for the task at hand. With a single, conﬁgurable world model engine, rather\\nthan a separate model for every situation, knowledge about how the world works may\\nbe shared across tasks. This may enable reasoning by analogy, by applying the model\\nconﬁgured for one situation to another situation.\\nTo make things concrete, I will directly dive into a description of the proposed model.\\n5'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 5, 'page_label': '6'}, page_content='percept\\naction\\nActor\\nWorld Model\\nIntrinsic\\ncost\\nPerception\\nShort-term\\nmemory\\nconfigurator\\nCritic\\nCost\\nFigure 2: A system architecture for autonomous intelligence. All modules in this model are as-\\nsumed to be “diﬀerentiable”, in that a module feeding into another one (through an arrow connecting\\nthem) can get gradient estimates of the cost’s scalar output with respect to its own output.\\nThe conﬁgurator module takes inputs (not represented for clarity) from all other modules and\\nconﬁgures them to perform the task at hand.\\nThe perception module estimates the current state of the world.\\nThe world model module predicts possible future world states as a function of imagined actions\\nsequences proposed by the actor.\\nThe cost module computes a single scalar output called “energy” that measures the level of dis-\\ncomfort of the agent. It is composed of two sub-modules, the intrinsic cost, which is immutable (not'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 5, 'page_label': '6'}, page_content='The cost module computes a single scalar output called “energy” that measures the level of dis-\\ncomfort of the agent. It is composed of two sub-modules, the intrinsic cost, which is immutable (not\\ntrainable) and computes the immediate energy of the current state (pain, pleasure, hunger, etc), and\\nthe critic, a trainable module that predicts future values of the intrinsic cost.\\nThe short-term memory module keeps track of the current and predicted world states and as-\\nsociated intrinsic costs.\\nThe actor module computes proposals for action sequences. The world model and the critic com-\\npute the possible resulting outcomes. The actor can ﬁnd an optimal action sequence that minimizes\\nthe estimated future cost, and output the ﬁrst action in the optimal sequence.\\nSee Section 3 for details.\\n6'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 6, 'page_label': '7'}, page_content='3 A Model Architecture for Autonomous Intelligence\\nThe proposed architecture for autonomous intelligent agents is depicted in Figure 2.\\nIt is composed of a number of modules whose functions are described below. Some\\nof the modules are conﬁgurable on the ﬂy, i.e. their precise function is determined by the\\nconﬁgurator module. The role of the conﬁgurator is executive control: given a task to be\\nexecuted, it pre-conﬁgures the perception, the world model, the cost and the actor for the\\ntask at hand. The conﬁgurator modulates the parameters of the modules it feeds into.\\nThe conﬁgurator module takes input from all other modules and conﬁgures them for\\nthe task at hand by modulating their parameters and their attention circuits. In particular,\\nthe conﬁgurator may prime the perception, world model, and cost modules to fulﬁll a\\nparticular goal.\\nThe perception module receives signals from sensors and estimates the current state'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 6, 'page_label': '7'}, page_content='the conﬁgurator may prime the perception, world model, and cost modules to fulﬁll a\\nparticular goal.\\nThe perception module receives signals from sensors and estimates the current state\\nof the world. For a given task, only a small subset of the perceived state of the world\\nis relevant and useful. The perception module may represent the state of the world in\\na hierarchical fashion, with multiple levels of abstraction. The conﬁgurator primes the\\nperception system to extract the relevant information from the percept for the task at\\nhand.\\nThe world model module constitutes the most complex piece of the architecture. Its\\nrole is twofold: (1) estimate missing information about the state of the world not provided\\nby perception, (2) predict plausible future states of the world. The world model may predict\\nnatural evolutions of the world, or may predict future world states resulting from a sequence\\nof actions proposed by the actor module. The world model may predict multiple plausible'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 6, 'page_label': '7'}, page_content='natural evolutions of the world, or may predict future world states resulting from a sequence\\nof actions proposed by the actor module. The world model may predict multiple plausible\\nworld states, parameterized by latent variables that represent the uncertainty about the\\nworld state. The world model is a kind of “simulator” of the relevant aspects of world.\\nWhat aspects of the world state is relevant depends on the task at hand. The conﬁgurator\\nconﬁgures the world model to handle the situation at hand. The predictions are performed\\nwithin an abstract representation space that contains information relevant to the task at\\nhand. Ideally, the world model would manipulate representations of the world state at\\nmultiple levels of abstraction, allowing it to predict over multiple time scales.\\nA key issue is that the world model must be able to represent multiple possible predic-\\ntions of the world state. The natural world is not completely predictable. This is particularly'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 6, 'page_label': '7'}, page_content='A key issue is that the world model must be able to represent multiple possible predic-\\ntions of the world state. The natural world is not completely predictable. This is particularly\\ntrue if it contains other intelligent agents that are potentially adversarial. But it is often\\ntrue even when the world only contains inanimate objects whose behavior is chaotic, or\\nwhose state is not fully observable.\\nThere are two essential questions to answer when building the proposed architectures:\\n(1) How to allow the world model to make multiple plausible prediction and represent\\nuncertainty in the predictions, and (2) how to train the world model.\\nThe cost module measures the level of “discomfort” of the agent, in the form of a\\nscalar quantity called the energy. The energy is the sum of two energy terms computed by\\ntwo sub-modules: the Intrinsic Cost module and the Trainable Critic module. The overall\\nobjective of the agent is to take actions so as to remain in states that minimize the average'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 6, 'page_label': '7'}, page_content='two sub-modules: the Intrinsic Cost module and the Trainable Critic module. The overall\\nobjective of the agent is to take actions so as to remain in states that minimize the average\\nenergy.\\nThe Intrinsic Cost module is hard-wired (immutable, non trainable) and computes a\\nsingle scalar, the intrinsic energy that measures the instantaneous “discomfort” of the agent\\n7'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 7, 'page_label': '8'}, page_content='– think pain (high intrinsic energy), pleasure (low or negative intrinsic energy), hunger, etc.\\nThe input to the module is the current state of the world, produced by the perception\\nmodule, or potential future states predicted by the world model. The ultimate goal of the\\nagent is minimize the intrinsic cost over the long run . This is where basic behavioral drives\\nand intrinsic motivations reside. The design of the intrinsic cost module determines the\\nnature of the agent’s behavior. Basic drives can be hard-wired in this module. This may\\ninclude feeling “good” (low energy) when standing up to motivate a legged robot to walk,\\nwhen inﬂuencing the state of the world to motivate agency, when interacting with humans\\nto motivate social behavior, when perceiving joy in nearby humans to motivate empathy,\\nwhen having a full energy supplies (hunger/satiety), when experiencing a new situation to\\nmotivate curiosity and exploration, when fulﬁlling a particular program, etc. Conversely, the'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 7, 'page_label': '8'}, page_content='when having a full energy supplies (hunger/satiety), when experiencing a new situation to\\nmotivate curiosity and exploration, when fulﬁlling a particular program, etc. Conversely, the\\nenergy would be high when facing a painful situation or an easily-recognizable dangerous\\nsituation (proximity to extreme heat, ﬁre, etc), or when wielding dangerous tools. The\\nintrinsic cost module may be modulated by the conﬁgurator, to drive diﬀerent behavior at\\ndiﬀerent times.\\nThe Trainable Critic module predicts an estimate of future intrinsic energies. Like the\\nintrinsic cost, its input is either the current state of the world or possible states predicted by\\nthe world model. For training, the critic retrieves past states and subsequent intrinsic costs\\nstored in the associative memory module, and trains itself to predict the latter from the\\nformer. The function of the critic module can be dynamically conﬁgured by the conﬁgurator'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 7, 'page_label': '8'}, page_content='stored in the associative memory module, and trains itself to predict the latter from the\\nformer. The function of the critic module can be dynamically conﬁgured by the conﬁgurator\\nto direct the system towards a particular sub-goal, as part of a bigger task.\\nBecause both sub-modules of the cost module are diﬀerentiable, the gradient of the\\nenergy can be back-propagated through the other modules, particularly the world model,\\nthe actor and the perception, for planning, reasoning, and learning.\\nThe short-term memory modulestores relevant information about the past, current,\\nand future states of the world, as well as the corresponding value of the intrinsic cost.\\nThe world model accesses and updates the short-term memory while temporally predicting\\nfuture (or past) states of the world, and while spatially completing missing information or\\ncorrecting inconsistent information about the current world state. The world model can'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 7, 'page_label': '8'}, page_content='future (or past) states of the world, and while spatially completing missing information or\\ncorrecting inconsistent information about the current world state. The world model can\\nsend queries to the short-term memory and receive retrieved values, or store new values of\\nstates. The critic module can be trained by retrieving past states and associated intrinsic\\ncosts from the memory. The architecture may be similar to that of Key-Value Memory\\nNetworks (Miller et al., 2016) This module can be seen as playing some of same roles as the\\nhippocampus in vertebrates.\\nThe actor module computes proposals for sequences of actions and outputs actions to\\nthe eﬀectors. The actor proposes a sequence of actions to the world model. The world model\\npredicts future world state sequences from the action sequence, and feeds it to the cost.\\nGiven a goal deﬁned by the cost (as conﬁgured by the conﬁgurator), the cost computes the'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 7, 'page_label': '8'}, page_content='predicts future world state sequences from the action sequence, and feeds it to the cost.\\nGiven a goal deﬁned by the cost (as conﬁgured by the conﬁgurator), the cost computes the\\nestimated future energy associated with the proposed action sequence. Since the actor has\\naccess to the gradient of the estimated cost with respect to the proposed action sequence, it\\ncan compute an optimal action sequence that minimizes the estimated cost using gradient-\\nbased methods. If the action space is discrete, dynamic programming may be used to\\nﬁnd an optimal action sequence. Once the optimization is completed, the actor outputs\\nthe ﬁrst action (or a short sequence of actions) to the eﬀectors. This process is akin to\\nmodel-predictive control in optimal control (Bryson and Ho, 1969).\\n8'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 8, 'page_label': '9'}, page_content='Pred(s,a)\\nC(s[1])\\ns[1]\\naction\\ns[0]\\nActor\\nA(s)\\na[0]\\nC(s[0])\\nFigure 3: Mode-1 perception-action episode. The perception module estimates the state of the\\nworld s[0] = Enc(x). The actor directly computes an action, or a short sequence of actions, through\\na policy module a[0] = A(s[0]).\\nThis reactive process does not make use of the world model nor of the cost. The cost module computes\\nthe energy of the initial state f[0] = C(s[0]) and stores the pairs (s[0],f[0]) in the short-term memory.\\nOptionally, it may also predict the next state using the world model s[1] = Pred(s[0],a[0]), and the\\nassociated energy f[0] = C(s[0]) so that the world model can be adjusted once the next observation\\nresulting from the action taken becomes available.\\nThe actor may comprise two components: (1) a policy module that directly produces\\nan action from the world state estimate produced by the perception and retrieved from the'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 8, 'page_label': '9'}, page_content='The actor may comprise two components: (1) a policy module that directly produces\\nan action from the world state estimate produced by the perception and retrieved from the\\nshort-term memory, and (2) the action optimizer, as described above, for model-predictive\\ncontrol. The ﬁrst mode is similar to Daniel Kahneman’s “System 1”, while the second mode\\nis similar to “System 2” (Kahneman, 2011)\\nIn the following, we will use speciﬁc symbols to represent various components in archi-\\ntectural diagrams. An brief explanation is given in Appendix 8.3.3.\\n3.1 Typical Perception-Action Loops\\nThere are two possible modes that the model can employ for a perception-action episode.\\nThe ﬁrst one involves no complex reasoning, and produces an action directly from the output\\nof the perception and a possible short-term memory access. We will call it “Mode-1”, by\\nanalogy with Kahneman’s “System 1”. The second mode involves reasoning and planning'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 8, 'page_label': '9'}, page_content='of the perception and a possible short-term memory access. We will call it “Mode-1”, by\\nanalogy with Kahneman’s “System 1”. The second mode involves reasoning and planning\\nthrough the world model and the cost. It is akin to model-predictive control (MPC), a\\nclassical planning and reasoning paradigm in optimal control and robotics. We will call\\nit “Mode-2” by analogy to Kahneman’s “System 2”. We use the term “reasoning” in a\\nbroad sense here to mean constraint satisfaction (or energy minimization). Many types of\\nreasoning can be viewed as forms of energy minimization.\\n3.1.1 Mode-1: Reactive behavior\\nA perception-action episode for Mode-1 is depicted in Figure 3.\\nThe perception module, through an encoder module, extracts a representation of the\\nstate of the world s[0] = Enc( x) containing relevant information for the task at hand. A\\n9'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 9, 'page_label': '10'}, page_content='policy module, a component of the actor, produces an action as a function of the state\\na[0] = A(s[0]). The resulting action is sent to the eﬀectors.\\nThe function of the policy module is modulated by the conﬁgurator, which conﬁgures\\nit for the task at hand.\\nThe policy module implements a purely reactive policy that does not involve delib-\\nerate planning nor prediction through the world model. Yet, its structure can be quite\\nsophisticated. For example, in addition to the state s[0], the policy module may access the\\nshort-term memory to acquire a more complete information about previous world states. It\\nmay use the short-term memory for the associative retrieval of an action given the current\\nstate.\\nWhile the cost module is diﬀerentiable, its output f[0] = C(s[0]) is indirectly inﬂuenced\\nby previous actions through the external world. Since the world is not diﬀerentiable, one\\ncannot back-propagate gradients from the cost through the chain cost ← perception ←'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 9, 'page_label': '10'}, page_content='by previous actions through the external world. Since the world is not diﬀerentiable, one\\ncannot back-propagate gradients from the cost through the chain cost ← perception ←\\nworld ← action. In this mode, gradients of the cost f[0] with respect to actions can only\\nbe estimated by polling the world with multiple perturbed actions, but that is slow and\\npotentially dangerous. This process would correspond to classical policy gradient methods\\nin reinforcement learning.\\nDuring Mode-1, the system can optionally adjust the world model. It runs the world\\nmodel for one step, predicting the next state s[1], then it waits for the next percept resulting\\nfrom the action taken, and uses the observed world state as a target for the predictor.\\nWith the use of a world model, the agent can imagine courses of actions and predict\\ntheir eﬀect and outcome, lessening the need to perform an expensive and dangerous search'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 9, 'page_label': '10'}, page_content='With the use of a world model, the agent can imagine courses of actions and predict\\ntheir eﬀect and outcome, lessening the need to perform an expensive and dangerous search\\nfor good actions and policies by trying multiple actions in the external world and measuring\\nthe result.\\n3.1.2 Mode-2: reasoning and planning using the world model\\nA typical perception-action episode for Mode 2 is depicted in Figure 4.\\n1. perception: the perception system extract a representation of the current state of\\nthe world s[0] = P(x). The cost module computes and stores the immediate cost\\nassociated with that state.\\n2. action proposal: the actor proposes an initial sequence of actions to be fed to the\\nworld model for evaluation ( a[0],...,a[t],...,a[T]).\\n3. simulation: the world model predicts one or several likely sequence of world state\\nrepresentations resulting from the proposed action sequence ( s[1],...,s[t],...,s[T]).'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 9, 'page_label': '10'}, page_content='3. simulation: the world model predicts one or several likely sequence of world state\\nrepresentations resulting from the proposed action sequence ( s[1],...,s[t],...,s[T]).\\n4. evaluation: the cost module estimates a total cost from the predicted state sequence,\\ngenerally as a sum over time steps F(x) = ∑T\\nt=1 C(s[t])\\n5. planning: the actor proposes a new action sequence with lower cost. This can be done\\nthrough a gradient-based procedure in which gradients of the cost are back-propagated\\nthrough the compute graph to the action variables. The resulting minimum-cost\\naction sequence is denoted (ˇa[0],...,ˇa[T]). Full optimization may require iterating\\nsteps 2-5.\\n10'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 10, 'page_label': '11'}, page_content='Pred(s,a)\\nC(s[t])\\n Pred(s,a)\\nC(s[t+1])\\n Pred(s,a)\\nC(s[T-1])\\n Pred(s,a)\\nC(s[T])\\n  \\ns[t] s[t+1]\\naction\\ns[0]\\na[0]\\nActor\\nC(s[0])\\ns[T-1]\\na[t] a[t+1] a[T-1]\\nFigure 4: Mode-2 perception-action episode. The perception module estimates the state of the world\\ns[0]. The actor proposes a sequence of actions a[0],a[1],...,a[t],a[t+ 1],...,a[T]. The world model\\nrecursively predicts an estimate of the world state sequence using s[t+ 1] = Pred(s[t],a[t]). The cost\\nC(s[t]) computes an energy for each predicted state in the sequence, the total energy being the sum\\nof them. Through an optimization or search procedure, the actor infers a sequence of actions that\\nminimizes the total energy. It then sends the ﬁrst action in the sequence (or the ﬁrst few actions)\\nto the eﬀectors. This is, in eﬀect, an instance of classical model-predictive control with receding-\\nhorizon planning. Since the cost and the model are diﬀerentiable, gradient-based methods can be'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 10, 'page_label': '11'}, page_content='to the eﬀectors. This is, in eﬀect, an instance of classical model-predictive control with receding-\\nhorizon planning. Since the cost and the model are diﬀerentiable, gradient-based methods can be\\nused to search for optimal action sequences as in classical optimal control. Since the total energy\\nis additive over time, dynamic programming can also be used, particularly when the action space is\\nsmall and discretized. Pairs of states (computed by the encoder or predicted by the predictor) and\\ncorresponding energies from the intrinsic cost and the trainable critic are stored in the short-term\\nmemory for subsequent training of the critic.\\n6. acting: after converging on a low-cost action sequence, the actor sends the ﬁrst action\\n(or ﬁrst few actions) in the low-cost sequence to the eﬀectors. The entire process is\\nrepeated for the next perception-action episode.\\n7. memory: after every action, the states and associated costs from the intrinsic cost'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 10, 'page_label': '11'}, page_content='repeated for the next perception-action episode.\\n7. memory: after every action, the states and associated costs from the intrinsic cost\\nand the critic are stored in the short-term memory. These pairs can be used later to\\ntrain or adapt the critic.\\nThis procedure is essentially what is known as Model-Predictive Control (MPC) with\\nreceding horizon in the optimal control literature. The diﬀerence with classical optimal\\ncontrol is that the world model and the cost function are learned.\\nIn principle, any form of optimization strategy can be used, for step 5. While gradient-\\nbased optimization methods can be eﬃcient when the world model and cost are well-\\nbehaved, situations in which the action-cost mapping has discontinuities may require to\\nuse other optimization strategies, particularly if the state and/or action spaces can be\\ndiscretized. These strategies include dynamic programming, combinatorial optimization,'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 10, 'page_label': '11'}, page_content='use other optimization strategies, particularly if the state and/or action spaces can be\\ndiscretized. These strategies include dynamic programming, combinatorial optimization,\\nsimulate annealing and other gradient-free methods, heuristic search techniques (e.g. tree\\nsearch with pruning), etc.\\nTo simplify, the process was described in the deterministic case, i.e. when there is no\\nneed to handle the possibility of multiple predictions for s[t+ 1] resulting from a given\\ninitial state s[t] and action a[t]. In real situations, the world is likely to be somewhat\\nunpredictable. Multiple states may result from a single initial state and action due to\\nthe fact that the world is intrinsically stochastic (aleatoric uncertainty), or that the state\\nrepresentation s[t] contains incomplete information about the true world state (epistemic\\nuncertainty), or that the world model’s prediction accuracy is imperfect due to limited\\ntraining data, representational power, or computational constraints.\\n11'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 11, 'page_label': '12'}, page_content='Pred(s,a) Pred(s,a) Pred(s,a)\\nC(s[T])\\ns[t] s[t+1]\\naction\\ns[0]\\na[t] a[T-1]a[0]\\nActor\\n A(s[0])  A(s[t])   A(s[t+1])D D\\nC(s[t]) C(s[t+1])C(s[0])\\nFigure 5: Training a reactive policy module from the result of Mode-2 reasoning. Using Mode-2 is\\nonerous, because it mobilizes all the resources of the agent for the task at hand. It involves running\\nthe world model for multiple time steps repeatedly. This diagram depicts how to train a policy module\\nA(s[t]) to approximate the action that results from Mode-2 optimization. The system ﬁrst operates\\nin Mode-2 and produces an optimal sequence of actions (ˇa[0],...,ˇa[T]). Then the parameters of the\\npolicy module are adjusted to minimize a divergence D(ˇa[t]),A(s[t])) between the optimal action and\\nthe output of the policy module. This results in a policy module that performs amortized inference,\\nand produces an approximation for a good action sequence. The policy module can then be used to'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 11, 'page_label': '12'}, page_content='the output of the policy module. This results in a policy module that performs amortized inference,\\nand produces an approximation for a good action sequence. The policy module can then be used to\\nproduce actions reactively in Mode-1, or to initialize the action sequence prior to Mode-2 inference\\nand thereby accelerate the optimization.\\n3.1.3 From Mode-2 to Mode-1: Learning New Skills\\nUsing Mode-2 is onerous. The agent only possesses one world model “engine”. It is conﬁg-\\nurable by the conﬁgurator for the task at hand, but it can only be used for a single task\\nat a time. Hence, similarly to humans, the agent can only focus on one complex task at a\\ntime.\\nMode-1 is considerably less onerous, since it only requires a single pass through a policy\\nmodule. The agent may possess multiple policy modules working simultaneously, each\\nspecialized for a particular set of tasks.\\nThe process described in Figure 5 shows how a policy module A(s[t]) can be trained'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 11, 'page_label': '12'}, page_content='specialized for a particular set of tasks.\\nThe process described in Figure 5 shows how a policy module A(s[t]) can be trained\\nto produce approximations of the optimal actions resulting from Mode-2 reasoning. The\\nsystem is run on Mode-2, producing an optimal action sequence (ˇ a[0],...,ˇa[t],...,ˇa[T]).\\nThen, the parameters of the policy module A(s[t]) are updated to minimize a divergence\\nmeasure between its output and the optimal action at that time D(ˇa[t],A(s[t])). Once\\nproperly trained, the policy module can be used to directly produce an action in Mode-1\\n˜a[0] = A(s[0]). It can also be used to recursively compute an initial action sequence proposal\\nbefore Mode-2 optimization:\\ns[t+ 1] = Pred(s[t],a[t]) ; ˜ a[t+ 1] = A(s[t+ 1])\\nThe policy module can be seen as performing a form of amortized inference.\\nThis process allows the agent to use the full power of its world model and reasoning\\ncapabilities to acquire new skills that are then “compiled” into a reactive policy module'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 11, 'page_label': '12'}, page_content='This process allows the agent to use the full power of its world model and reasoning\\ncapabilities to acquire new skills that are then “compiled” into a reactive policy module\\nthat no longer requires careful planning.\\n3.1.4 Reasoning as Energy Minimization\\nThe process of elaborating a suitable action sequence in Mode-2 can be seen as a form\\nof reasoning. This form of reasoning is based on simulation using the world model, and\\n12'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 12, 'page_label': '13'}, page_content='TC1(s)\\n s\\n IC1(s)  IC2(s)  ICk(s)... TC2(s) TCl(s)...\\nIntrinsic Cost (IC) Trainable Cost / Critic (TC)\\nFigure 6: Architecture of the cost module. The cost module comprises the intrinsic cost module\\nwhich is immutable ICi(s) (left) and the critic or Trainable Cost TCj(s) (right), which is trainable.\\nBoth IC and TC are composed of multiple submodules whose output energies are linearly combined.\\nEach submodule imparts a particular behavioral drive in the agent. The weights in the linear com-\\nbination, ui and vj, are determined by the conﬁgurator module and allow the agent to focus on\\ndiﬀerent subgoals at diﬀerent times.\\noptimization of the energy with respect to action sequences. More generally, the “actions”\\ncan be seen as latent variables representing abstract transformations from one state to the\\nnext. This type of planning though simulation and optimization may constitute the kind\\nof reasoning that is most frequent in natural intelligence.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 12, 'page_label': '13'}, page_content='next. This type of planning though simulation and optimization may constitute the kind\\nof reasoning that is most frequent in natural intelligence.\\nMany classical forms of reasoning in AI can actually be formulated as optimization\\nproblems (or constraint satisfaction problems). It is certainly the case for the kind of\\nprobabilistic inference performed with factor graphs and probabilistic graphical models.\\nThe proposed architecture is, in fact, a factor graph in which the cost modules are log\\nfactors. But the kind of reasoning that the proposed architecture enables goes beyond\\ntraditional logical and probabilistic reasoning. It allows reasoning by simulation and by\\nanalogy.\\n3.2 The Cost Module as the Driver of Behavior\\nThe overall architecture of the cost module is shown in Figure 6. It is composed of the\\nintrinsic cost module which is immutable IC i(s) and the critic or Trainable Cost TC j(s),\\nwhich is trainable. Both IC and TC are composed of multiple submodules whose output'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 12, 'page_label': '13'}, page_content='intrinsic cost module which is immutable IC i(s) and the critic or Trainable Cost TC j(s),\\nwhich is trainable. Both IC and TC are composed of multiple submodules whose output\\nenergies are linearly combined\\nC(s) = IC( s) + TC(s) (1)\\nIC(s) =\\nk∑\\ni=1\\nuiICi(s) (2)\\n13'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 13, 'page_label': '14'}, page_content='TC(s) =\\nl∑\\nj=1\\nvjTCj(s) (3)\\nEach submodule imparts a particular behavioral drive to the agent. The weights in the\\nlinear combination, ui and vj, are modulated by the conﬁgurator module and allow the\\nagent to focus on diﬀerent subgoals at diﬀerent times.\\nThe intrinsic cost module (IC) is where the basic behavioral nature of the agent is\\ndeﬁned. It is where basic behaviors can be indirectly speciﬁed.\\nFor a robot, these terms would include obvious proprioceptive measurements corre-\\nsponding to “pain”, “hunger”, and “instinctive fears”, measuring such things as external\\nforce overloads, dangerous electrical, chemical, or thermal environments, excessive power\\nconsumption, low levels of energy reserves in the power source, etc.\\nThey may also include basic drives to help the agent learn basic skills or accomplish its\\nmissions. For example, a legged robot may comprise an intrinsic cost to drive it to stand\\nup and walk. This may also include social drives such as seeking the company of humans,'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 13, 'page_label': '14'}, page_content='missions. For example, a legged robot may comprise an intrinsic cost to drive it to stand\\nup and walk. This may also include social drives such as seeking the company of humans,\\nﬁnding interactions with humans and praises from them rewarding, and ﬁnding their pain\\nunpleasant (akin to empathy in social animals). Other intrinsic behavioral drives, such as\\ncuriosity, or taking actions that have an observable impact, may be included to maximize\\nthe diversity of situations with which the world model is trained (Gottlieb et al., 2013)\\nThe IC can be seen as playing a role similar to that of the amygdala in the mammalian\\nbrain and similar structures in other vertebrates.\\nTo prevent a kind of behavioral collapse or an uncontrolled drift towards bad behaviors,\\nthe IC must be immutable and not subject to learning (nor to external modiﬁcations).\\nThe role of the critic (TC) is twofold: (1) to anticipate long-term outcomes with minimal'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 13, 'page_label': '14'}, page_content='the IC must be immutable and not subject to learning (nor to external modiﬁcations).\\nThe role of the critic (TC) is twofold: (1) to anticipate long-term outcomes with minimal\\nuse of the onerous world model, and (2) to allow the conﬁgurator to make the agent focus\\non accomplishing subgoals with a learned cost.\\nIn general, the behavioral nature of an AI agent can be speciﬁed in four ways:\\n1. by explicitly programming a speciﬁc behavior activated when speciﬁc conditions are\\nmet\\n2. by deﬁning an objective function in such a way that the desired behavior is executed\\nby the agent as a result of ﬁnding action sequences that minimize the objective.\\n3. by training the agent to behave a certain way through direct supervision. The agent\\nobserves the actions of an expert teacher, and trains a Mode-1 policy module to\\nreproduce it.\\n4. by training the agent through imitation learning. The agent observes expert teachers,'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 13, 'page_label': '14'}, page_content='observes the actions of an expert teacher, and trains a Mode-1 policy module to\\nreproduce it.\\n4. by training the agent through imitation learning. The agent observes expert teachers,\\nand infers an objective function that their behavior appears to be optimizing when\\nthey act. This produces a critic submodule for Mode-2 behavior. This process is\\nsometimes called inverse reinforcement learning.\\nThe second method is considerably simpler to engineer than the ﬁrst one, because it\\nmerely requires to design an objective, and not design a complete behavior. The second\\nmethod is also more robust: a preordained behavior may be invalidated by unexpected\\nconditions or a changing environment. With an objective, the agent may adapt its behavior\\n14'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 14, 'page_label': '15'}, page_content='... ...\\n ... ...\\nwrite write\\nread read\\nLoss\\nwrite\\nShort-Term\\nAssociative\\nMemory\\nIntrinsic Cost\\nCritic\\nState Sequence\\nFigure 7: Training the critic. During planning episodes, the intrinsic cost module stores triplets\\n(time, state, intrinsic energy): (τ,sτ,IC(sτ)) into the associative short-term memory. During critic\\ntraining episodes, the critic retrieves a past state vectorsτ, together with an intrinsic energy at a later\\ntime IC(sτ+δ). In the simplest scenario, the critic adjusts its parameters to minimize a divergence\\nmeasure between the target IC(stau+δ) and the predicted energy C(sτ). In more complex schemes,\\nit may use combinations of future intrinsic energies as targets. Note that the state sequence may\\ncontain information about the actions planned or taken by the agent.\\nto satisfy the objective despite unexpected conditions and changes in the environment. The\\nsecond method exploits the learning and inference abilities of the agent to minimize the'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 14, 'page_label': '15'}, page_content='to satisfy the objective despite unexpected conditions and changes in the environment. The\\nsecond method exploits the learning and inference abilities of the agent to minimize the\\namount of priors hard-wired by the designer that are likely to be brittle.\\n3.3 Training the Critic\\nAn essential question is how to train the critic.\\nThe principal role of the critic is to predict future values of the intrinsic energy. To do\\nso, it uses the short-term memory module. This module is an associative memory in which\\nthe intrinsic cost module stores triplets (time, state, intrinsic energy): ( τ,sτ,IC(sτ)). The\\nstored states and corresponding intrinsic energies may correspond to a perceived state or to\\na state imagined by the world model during a Mode-2 episode. The memory may retrieve\\na state sτ given a time τ, and may retrieve an energy IC(sτ) given a time τor a state sτ.\\nWith a suitable memory architecture, the retrieval may involve interpolations of keys and'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 14, 'page_label': '15'}, page_content='a state sτ given a time τ, and may retrieve an energy IC(sτ) given a time τor a state sτ.\\nWith a suitable memory architecture, the retrieval may involve interpolations of keys and\\nretrieved values. The process is shown in Figure 7\\nThe critic can be trained to predict future intrinsic energy values by retrieving a past\\nstate vector sτ together with an intrinsic energy at a later time IC( sτ+δ). The parameters\\nof the critic can then be optimized to minimize a prediction loss, for example ||IC(sτ+δ) −\\nTC(sτ)||2. This is a simple scenario. More complex schemes can be devised to predict\\nexpectations of discounted future energies, or distributions thereof. Note that the state\\nvectors may contain information about the actions taken or imagined by the actor.\\nAt a general level, this is similar to critic training methods used in such reinforcement\\nlearning approaches as A2C.\\n15'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 15, 'page_label': '16'}, page_content='The short-term memory can be implemented as the memory module in a key-value\\nmemory network ??: a query vector is compared to a number of key vectors, producing\\na vector of scores. The scores are normalized and used as coeﬃcients to output a linear\\ncombination of the stored values. It can be seen as a “soft” associative memory capable of\\ninterpolation. One advantage of it is that, with a proper allocation scheme of new key/value\\nslots, it is capable of one-shot learning, yet can interpolate between keys and is end-to-end\\ndiﬀerentiable.\\n4 Designing and Training the World Model\\nArguably, designing architectures and training paradigms for the world model constitute\\nthe main obstacles towards real progress in AI over the next decades. One of the main\\ncontributions of the present proposal is precisely a hierarchical architecture and a training\\nprocedure for world models that can represent multiple outcomes in their predictions.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 15, 'page_label': '16'}, page_content='contributions of the present proposal is precisely a hierarchical architecture and a training\\nprocedure for world models that can represent multiple outcomes in their predictions.\\nTraining the world model is a prototypical example of Self-Supervised Learning (SSL),\\nwhose basic idea is pattern completion. The prediction of future inputs (or temporarily\\nunobserved inputs) is a special case of pattern completion. In this work, the primary\\npurpose of the world model is seen as predicting future representations of the state of the\\nworld.\\nThere are three main issues to address. First, quite evidently, the quality of the world\\nmodel will greatly depend on the diversity of state sequences, or triplets of (state, action,\\nresulting state) it is able to observe while training. Second, because the world is not entirely\\npredictable, there may be multiple plausible world state representations that follow a given'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 15, 'page_label': '16'}, page_content='resulting state) it is able to observe while training. Second, because the world is not entirely\\npredictable, there may be multiple plausible world state representations that follow a given\\nworld state representation and an action from the agent. The world model must be able to\\nmeaningfully represent this possibly-inﬁnite collection of plausible predictions. Third, the\\nworld model must be able to make predictions at diﬀerent time scales and diﬀerent levels\\nof abstraction.\\nThe ﬁrst issue touches on one of the main questions surrounding learning for sequential\\ndecision processes: the diversity of the “training set” depends on the actions taken. The\\nissue is discussed in Section 4.10 below.\\nThe second issue is even more dire: the world is not entirely predictable. Hence, the\\nworld model should be able to represent multiple plausible outcomes from a given state and\\n(optionally) an action. This may constitute one of the most diﬃcult challenges to which'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 15, 'page_label': '16'}, page_content='world model should be able to represent multiple plausible outcomes from a given state and\\n(optionally) an action. This may constitute one of the most diﬃcult challenges to which\\nthe present proposal brings a solution. This issue is discussed in Section 4.8 below.\\nThe third issue relates to the problem of long-term prediction and planning. Humans\\nplan complex goals at an abstract level and use high-level descriptions of the world states\\nand actions to make predictions. High-level goals are then decomposed into sequences of\\nmore elementary sequences of subgoals, using shorter-term prediction from the world model\\nto produce lower-level actions. This decomposition process is repeated all the way down\\nto millisecond-by-millisecond muscle control, informed by local conditions. The question of\\nhow world models could represent action plans at multiple time scales and multiple levels\\nof abstraction is discussed in Section 4.6\\n16'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 16, 'page_label': '17'}, page_content='4.1 Self-Supervised Learning\\nSelf-Supervised Learning (SSL) is a paradigm in which a learning system is trained to\\ncapture the mutual dependencies between its inputs. Concretely, this often comes down to\\ntraining a system to tell us if various parts of its input are consistent with each other.\\nFor example, in a video prediction scenario, the system is given two video clips, and\\nmust tell us to what degree the second video clip is a plausible continuation of the ﬁrst one.\\nIn a pattern completion scenario, the system is given part of an input (image, text, audio\\nsignal) together with a proposal for the rest of the input, and tells us whether the proposal\\nis a plausible completion of the ﬁrst part. In the following, we will denote the observed part\\nof the input by x and the possibly-unobserved part by y.\\nImportantly, we do not impose that the model be able to predict y from x. The reason\\nis that there may be an inﬁnite number of y that are compatible with a given x. In a video'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 16, 'page_label': '17'}, page_content='Importantly, we do not impose that the model be able to predict y from x. The reason\\nis that there may be an inﬁnite number of y that are compatible with a given x. In a video\\nprediction setting, there is an inﬁnite number of video clips that are plausible continuations\\nof a given clip. It may be diﬃcult, or intractable, to explicitly represent the set of plausible\\npredictions. But it seems less inconvenient to merely ask the system to tell us if a proposed\\ny is compatible with a given x.\\nA general formulation can be done with the framework of Energy-Based Models (EBM).\\nThe system is a scalar-valued function F(x,y) that produces low energy values when xand\\ny are compatible and higher values when they are not. The concept is depicted in Figure 8.\\nData points are black dots. The energy function produces low energy values around the data\\npoints, and higher energies away from the regions of high data density, as symbolized by the'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 16, 'page_label': '17'}, page_content='Data points are black dots. The energy function produces low energy values around the data\\npoints, and higher energies away from the regions of high data density, as symbolized by the\\ncontour lines of the energy landscape. The EBM implicit function formulation enables the\\nsystem to represent multi-modal dependencies in which multiple values of y are compatible\\nwith a given x. The set of y compatible with a given x may be a single point, multiple\\ndiscrete points, a manifold, or a collection of points and manifolds.\\nTo enable Mode-2 planning, a predictive world model should be trained to capture the\\ndependencies between past and future percepts. It should be able to predict representations\\nof the future from representations of the past and present . The general learning principle\\nis as follows: given two inputs x and y, learn two functions that compute representations\\nsx = gx(x) and sy = gy(y) such that (1) sx and sy are maximally informative about x and'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 16, 'page_label': '17'}, page_content='is as follows: given two inputs x and y, learn two functions that compute representations\\nsx = gx(x) and sy = gy(y) such that (1) sx and sy are maximally informative about x and\\ny and (2) sy can easily be predicted from sx. This principle ensures a trade-oﬀ between\\nmaking the evolution of the world predictable in the representation space, and capturing as\\nmuch information as possible about the world state in the representation.\\nWhat concepts could such an SSL system learn by being trained on video? Our hypoth-\\nesis is that a hierarchy of abstract concepts about how the world works could be acquired.\\nLearning a representation of a small image region such that it is predictable from neigh-\\nboring regions surrounding it in space and time would cause the system to extract local\\nedges and contours in images, and to detect moving contours in videos. Learning a repre-\\nsentation of images such that the representation of a scene from one viewpoint is predictable'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 16, 'page_label': '17'}, page_content='edges and contours in images, and to detect moving contours in videos. Learning a repre-\\nsentation of images such that the representation of a scene from one viewpoint is predictable\\nfrom the representation of the same scene from a slightly diﬀerent viewpoint would cause\\nthe system to implicitly represent a depth map. A depth map is the simplest way to explain\\nhow a view of a scene changes when the camera moves slightly. Once the notion of depth has\\nbeen learned, it would become simple for the system to identify occlusion edges, as well as\\nthe collective motion of regions belonging to a rigid object. An implicit representation of 3D\\n17'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 17, 'page_label': '18'}, page_content='time or space → \\nEnergy\\nFunction\\nx\\nF(x,y)\\ny\\nx\\ny\\nFigure 8: Self-Supervised Learning (SSL) and Energy-Based Models (EBM). SSL is a learning\\nparadigm in which a learning system is trained to “ﬁll in the blanks”, or more precisely to capture the\\ndependencies between observed parts of the input and possibly unobserved parts of the input. Part of\\nthe input signal is observed and denoted x (in pink), and part of the input signal is either observed\\nor unobserved and denoted y (in blue). In a temporal prediction scenario, x represents past and\\npresent observations, and y represent future observations. In a general pattern completion scenario,\\nvarious parts of the input may be observed or unobserved at various times. The learning system is\\ntrained to capture the dependencies between x and y through a scalar-valued energy function F(x,y)\\nthat takes low values when x and y are consistent or compatible, and higher values if x and y are'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 17, 'page_label': '18'}, page_content='trained to capture the dependencies between x and y through a scalar-valued energy function F(x,y)\\nthat takes low values when x and y are consistent or compatible, and higher values if x and y are\\ninconsistent or incompatible. In a video prediction scenario, the system would produce a low energy\\nvalue if a video clip yis a plausible continuation of the video clip x. This energy-based model (EBM)\\nformulation enables the system to represent multi-modal dependencies in which multiple values of y\\n(perhaps an inﬁnite set) may be compatible with a given x. In the right panel, an energy landscape\\nis represented in which dark discs represent data points, and closed lines represents contours (level\\nsets) of the energy function.\\nobjects may spontaneously emerge. Once the notion of object emerges in the representation,\\nconcepts like object permanence may become easy to learn: objects that disappear behind\\nothers due to parallax motion will invariably reappear. The distinction between inanimate'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 17, 'page_label': '18'}, page_content='concepts like object permanence may become easy to learn: objects that disappear behind\\nothers due to parallax motion will invariably reappear. The distinction between inanimate\\nand animate object would follow: inanimate object are those whose trajectories are easily\\npredictable. Intuitive physics concepts such as stability, gravity, momentum, may follow by\\ntraining the system to perform longer-term predictions at the object representation level.\\nOne may imagine that through predictions at increasingly abstract levels of representation\\nand increasingly long time scales, more and more complex concepts about how the world\\nworks may be acquired in a hierarchical fashion.\\nThe idea that abstract concepts can be learned through prediction is an old one, for-\\nmulated in various way by many authors in cognitive science, neuroscience, and AI over\\nseveral decades. The question is how to do it, precisely.\\n18'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 18, 'page_label': '19'}, page_content='Figure 9: Latent-Variable Energy-Based Model (LVEBM).\\nTo evaluate the degree of compatibility betweenxand y, an EBM may need the help of a latent variable\\nz. The latent variable can be seen as parameterizing the set of possible relationships between an x\\nand a set of compatible y. Latent variables represent information about y that cannot be extracted\\nfrom x. For example, if x is a view of an object, and y another view of the same object, z may\\nparameterize the camera displacement between the two views. Inference consists in ﬁnding the latent\\nthat minimizes the energy ˇz = argminz∈Z Ew(x,y,z ). The resulting energy Fw(x,y) = Ew(x,y, ˇz)\\nonly depends on x and y. In the dual view example, inference ﬁnds the camera motion that best\\nexplains how x could be transformed into y.\\n4.2 Handling Uncertainty with Latent Variables\\nAs was pointed out above, one of the main issues is enabling the model to represent mul-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 18, 'page_label': '19'}, page_content='explains how x could be transformed into y.\\n4.2 Handling Uncertainty with Latent Variables\\nAs was pointed out above, one of the main issues is enabling the model to represent mul-\\ntiple predictions. This may require the use of a latent variable. A latent variable is an\\ninput variable whose value is not observed but inferred. A latent variable can be seen as\\nparameterizing the set of possible relationships between an x and a set of compatible y.\\nLatent variables are used to represent information about y that cannot be extracted from\\nx.\\nImagine a scenario in which x is a photo of a scene, and y a photo of the same scene\\nfrom a slightly diﬀerent viewpoint. To tell whether x and y are indeed views from the\\nsame scene, one may need to infer the displacement of the camera between the two views.\\nSimilarly, if x is a picture of a car coming to a fork in the road, and y is a picture of the\\nsame car a few seconds later on one of the branches of the fork, the compatibility between'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 18, 'page_label': '19'}, page_content='Similarly, if x is a picture of a car coming to a fork in the road, and y is a picture of the\\nsame car a few seconds later on one of the branches of the fork, the compatibility between\\nx and y depends on a binary latent variable that can be inferred: did the car turn left or\\nright.\\nIn a temporal prediction scenario, the latent variable represents what cannot be pre-\\ndicted about y (the future) solely from x and from past observations (the past). It should\\ncontain all information that would be useful for the prediction, but is not observable, or\\nnot knowable. I may not know whether the driver in front of me will turn left or right,\\naccelerate or brake, but I can represent those options by a latent variable.\\nA latent-variable EBM (LVEBM) is a parameterized energy function that depends on\\nx, y, and z: Ew(x,y,z ). When presented with a pair ( x,y) the inference procedure of the\\nEBM ﬁnds a value of the latent variable z that minimizes the energy\\nˇz= argmin\\nz∈Z\\nEw(x,y,z ) (4)\\n19'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 19, 'page_label': '20'}, page_content='This latent-variable inference by minimization allows us to eliminate z from the energy\\nfunction:\\nFw(x,y) = min\\nz∈Z\\nEw(x,y,z ) = Ew(x,y, ˇz) (5)\\nTechnically, Fw(x,y) should be called a zero-temperature free energy, but we will continue\\nto call it the energy.\\n4.3 Training Energy-Based Models\\nBefore we discuss EBM training, it is important to note that the deﬁnition of EBM does not\\nmake any reference to probabilistic modeling . Although many EBMs can easily be turned\\ninto probabilistic models, e.g. through a Gibbs distribution, this is not at all a necessity.\\nHence the energy function is viewed as the fundamental object and is not assumed to\\nimplicitly represent the unnormalized logarithm of a probability distribution.\\nTraining an EBM consists in constructing an architecture (e.g. a deep neural network)\\nto compute the energy function Fw(x,y) parameterized with a parameter vector w. The\\ntraining process must seek a w vector that gives the right shape to the energy function.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 19, 'page_label': '20'}, page_content='to compute the energy function Fw(x,y) parameterized with a parameter vector w. The\\ntraining process must seek a w vector that gives the right shape to the energy function.\\nFor a given x from the training set, a well-trained Fw(x,y) will produce lower energies for\\nvalues of ythat are associated with xin the training set, and higher energies to other values\\nof y.\\nGiven a training sample (x,y), training an EBM comes down to devising a suitable loss\\nfunctional L(x,y,F w(x,y)), which can be expressed directly as a function of the parameter\\nvector L(x,y,w ), and such that minimizing this loss will make the energy of the training\\nsample Fw(x,y) lower than the energies Fw(x,ˆy) of any ˆy diﬀerent from y.\\nMaking the energy of the training sample low is easy: it is suﬃcient for the loss to be\\nan increasing function of the energy, and for the energy to have a lower bound.\\nThe diﬃcult question is how to ensure that the energies of ˆy diﬀerent from y are higher'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 19, 'page_label': '20'}, page_content='an increasing function of the energy, and for the energy to have a lower bound.\\nThe diﬃcult question is how to ensure that the energies of ˆy diﬀerent from y are higher\\nthan the energy of y. Without a speciﬁc provision to ensure that Fw(x,y′) > Fw(x,y)\\nwhenever ˆy̸= ythe energy landscape may suﬀer a collapse: given an xthe energy landscape\\ncould become “ﬂat”, giving essentially the same energy to all values of y.\\nWhat EBM architectures are susceptible to collapse? Whether an EBM may be\\nsusceptible to collapse depends on its architecture. Figure 10 shows a number of standard\\narchitectures and indicates whether they can be subject to collapse.\\nA regular predictive or deterministic-generative architecture (Figure 10(a)) cannot col-\\nlapse. For any x, a single ˜yis produced. The energy is zero whenever y= ˜y. Any ydiﬀerent\\nfrom ˜y will have a higher energy, as long as D(y,˜y) is strictly larger than zero whenever y\\nis diﬀerent from ˜y.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 19, 'page_label': '20'}, page_content='from ˜y will have a higher energy, as long as D(y,˜y) is strictly larger than zero whenever y\\nis diﬀerent from ˜y.\\nA generative latent-variable architecture (non-deterministic generative) (Figure 10(b))\\ncan collapse when the latent variable has too much information capacity. When the latent\\nvariable z varies over the set Z, the prediction ˜y varies over a set Pred(sx,Z), which must\\nmatch the set of y that are compatible with x. If Zis too “large” then the region of low-\\nenergy y may be larger than the region of high data density. If z has the same dimension\\nas y, the system could very well give zero energy to the entire y space.\\nAn auto-encoder (AE) (Figure 10(c)) can collapse when the representation sy has too\\nmuch information capacity. For example, if the dimension of sy is equal or higher than that\\n20'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 20, 'page_label': '21'}, page_content='d) Joint Embedding Architecture\\n    CAN COLLAPSE\\nb) Generative latent-variable Architecture\\n    CAN COLLAPSE\\na) Prediction / regression\\n    NO COLLAPSE\\nc) Auto-Encoder\\n    CAN COLLAPSE\\nFigure 10: A few standard architectures and their capacity for collapse.\\n(a) Deterministic generative architecture: cannot collapse because it can only produce a single out-\\nput. For a given x, only one value of y may have zero energy: y = ˜y. Other values of y will have\\nhigher energy if D(u,˜y) is larger than zero when y̸= ˜y.\\n(b) Non-deterministic generative architecture: can collapse when the latent variable has excessive\\ninformation capacity. If for a given x and for all y there exists a z that produces zero prediction\\nenergy (e.g. if z has the same or higher dimension as y), the entire y space will have low energy.\\nThe information capacity of z should be just enough so that varying z over its set will produce all\\nthe plausible ˜y for a given x.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 20, 'page_label': '21'}, page_content='The information capacity of z should be just enough so that varying z over its set will produce all\\nthe plausible ˜y for a given x.\\n(c) Auto-encoder: can collapse if the system learns the identity function or if it can correctly recon-\\nstruct a region of y space that is much larger than the region of high data density, thereby giving low\\nenergy to an overly large region.\\n(d) Simple joint embedding architecture: can collapse if the encoders ignore the inputs and produce\\nrepresentations that remain constant and equal, or if the encoders are invariant over overly broad\\nregions of the space.\\nof y, the AE could learn the identity function, producing a reconstruction error equal to\\nzero over the entire y space.\\nLastly, a Joint Embedding Architecture (JEA) (Figure 10(d)) can collapse when the\\ninformation carried by sx and/or sy are insuﬃcient. If the encoders ignore the inputs, and\\nproduce constant and equal codes sx = sy, the entire space will have zero energy.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 20, 'page_label': '21'}, page_content='information carried by sx and/or sy are insuﬃcient. If the encoders ignore the inputs, and\\nproduce constant and equal codes sx = sy, the entire space will have zero energy.\\nThese are but a few examples of architectures.\\nHow do we design the loss to prevent collapse? There are two approaches:\\ncontrastive methods and regularized methods. In the following, I will argue that contrastive\\nmethods have ﬂaws and that regularized (non contrastive) methods are much more likely\\nto be preferable in the long run.\\nContrastive methods consist in using a loss functional whose minimization has the\\neﬀect of pushing down on the energies of training samples ( x,y), and pulling up on the\\nenergies of suitably-hallucinated “contrastive” samples ( x,ˆy). The contrastive sample ˆ y\\nshould be picked in such a way as to ensure that the EBM assigns higher energies to points\\noutside the regions of high data density. This translates into designing a loss that is an'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 20, 'page_label': '21'}, page_content='should be picked in such a way as to ensure that the EBM assigns higher energies to points\\noutside the regions of high data density. This translates into designing a loss that is an\\nincreasing function of Fw(x,y) and a decreasing function of Fw(x,ˆy), at least whenever\\nFw(x,ˆy) is not suﬃciently higher than Fw(x,y). There are many such contrastive loss\\n21'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 21, 'page_label': '22'}, page_content='Contrastive\\nMethod\\nRegularized\\nMethod\\nLow energy\\nregion\\nTraining\\nsamples\\nContrastive\\nsamples\\nx\\nx\\nx\\ny\\ny\\ny\\nFigure 11: Contrastive and regularized methods for EBM training. A conceptual diagram of an\\nenergy landscape is shown on the left. Training samples are blue dots. The region of low energy is\\nshown in orange (a level set of the energy function).\\nContrastive methods (top right) push down on the energy of training samples (blue dots) and\\npulls up on the energies of suitably-placed contrastive samples (green dots).\\nregularized methods (bottom right) push down on the energy of training samples and use a reg-\\nularizer term that minimizes the volume of low-energy regions. This regularization has the eﬀect of\\n“shrink-wrapping” the regions of high data density within the low-energy regions, to the extent that\\nthe ﬂexibility of the energy function permits it.\\nOne issue with contrastive methods is that the energy will only be pulled up wherever contrastive'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 21, 'page_label': '22'}, page_content='the ﬂexibility of the energy function permits it.\\nOne issue with contrastive methods is that the energy will only be pulled up wherever contrastive\\nsamples have been placed. One must devise methods that preferentially place contrastive samples in\\nregions of low energy, which is what Monte-Carlo and MCMC methods do. However, a disadvantage\\nof contrastive methods is that the number of contrastive samples necessary to make an energy surface\\nadopt a good shape may grow exponentially with the dimension of y space.\\nfunctions, some of them taking a single triplet ( x,y, ˆy), others requiring a batch of positive\\nand contrastive values of y.\\nA simple example of contrastive loss functions is as follows:\\nL(w,x,y, ˆy) = H(Fw(x,y),Fw(x,ˆy),m(y,ˆy)) (6)\\nwhere His an increasing function ofFw(x,y), and a decreasing function ofFw(x,ˆy) whenever\\nthe latter is less than the former plus a positive margin function m(y,ˆy). A simple instance\\nof such loss is the distance-dependent hinge loss:\\nL(w,x,y, ˆy) ='),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 21, 'page_label': '22'}, page_content='the latter is less than the former plus a positive margin function m(y,ˆy). A simple instance\\nof such loss is the distance-dependent hinge loss:\\nL(w,x,y, ˆy) =\\n[\\nFw(x,y) −Fw(x,ˆy) + µ||y−ˆy||2\\n]+\\n(7)\\nwhere [a]+ is the identity when a is positive and zero otherwise. This makes the energy\\ngrow at least quadratically with the distance to the data manifold. Other contrastive loss\\n22'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 22, 'page_label': '23'}, page_content='functionals take multiple contrastive samples into consideration:\\nL(w,x,y, ˆy[1],...,ˆy[K]) = H(Fw(x,y),Fw(x,ˆy[1]),...,Fw(x,ˆy[K])) (8)\\nWhich must be an increasing function of the ﬁrst argument, and a decreasing function of\\nall other arguments. An example of such loss is the popular InfoNCE:\\nL(w,x,y, ˆy[1],...,ˆy[K]) = Fw(x,y) + log\\n[\\nexp(−Fw(x,y)) +\\nK∑\\nk=1\\nexp(−Fw(x,ˆy[k]))\\n]\\n(9)\\nContrastive methods are very popular, particularly for Siamese network architectures\\ntrained with pairs where xis a distorted or corrupted version of yand ˆyanother random (or\\nsuitably chosen) training sample. This includes such methods as the original Siamese net,\\nas well as more recent methods including DrLIM, PIRL, MoCO, SimCLR, CPT, and others.\\nContrastive methods also include such classical methods as probabilistic models trained with\\nmaximum likelihood that are not automatically normalized. Contrastive samples ˆyare often'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 22, 'page_label': '23'}, page_content='Contrastive methods also include such classical methods as probabilistic models trained with\\nmaximum likelihood that are not automatically normalized. Contrastive samples ˆyare often\\nproduced using Monte Carlo methods, Markov-Chain Monte Carlo methods, or approximate\\nversions thereof, such as Contrastive Divergence. Generative Adversarial Networks can also\\nbe seen as contrastive methods in which the ˆ y are produced by the trainable generator\\nnetwork. Denoising Auto-Encoders and their special case, Masked Auto-Encoders, are also\\nexamples of contrastive training methods in which the ˆyis generated by corrupting the clean\\ny. A more detailed discussion of various contrastive methods is given in appendix 8.3.3.\\nBut there are two main issues with contrastive methods. First, one has to design a\\nscheme to generate or pick suitable ˆy. Second, when yis in a high-dimensional space, and if\\nthe EBM is ﬂexible, it may require a very large number of contrastive samples to ensure that'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 22, 'page_label': '23'}, page_content='scheme to generate or pick suitable ˆy. Second, when yis in a high-dimensional space, and if\\nthe EBM is ﬂexible, it may require a very large number of contrastive samples to ensure that\\nthe energy is higher in all dimensions unoccupied by the local data distribution. Because of\\nthe curse of dimensionality, in the worst case, the number of contrastive samples may grow\\nexponentially with the dimension of the representation. This is the main reason why I will\\nargue against contrastive methods.\\nRegularized methods for EBM training are much more promising in the long run\\nthan contrastive methods because they can eschew the curse of dimensionality that plagues\\ncontrastive methods. They consist in constructing a loss functional that has the eﬀect\\nof pushing down on the energies of training samples, and simultaneously minimizing the\\nvolume of y space to which the model associates a low energy . The volume of the low-energy'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 22, 'page_label': '23'}, page_content='of pushing down on the energies of training samples, and simultaneously minimizing the\\nvolume of y space to which the model associates a low energy . The volume of the low-energy\\nregion is measured by a regularization term in the energy and/or in the loss. By minimizing\\nthis regularization term while pushing down on the energies of data points, the regions of\\nlow energy will “shrink-wrap” the regions of high data density. The main advantage of\\nnon-contrastive regularized methods is that they are less likely than contrastive methods\\nto fall victim to the curse of dimensionality. The main question is precisely how to design\\nsuch volume-minimizing regularizers. The answer depends greatly on the architecture of\\nthe model, which is discussed in the next sections. However, non-contrastive methods have\\nexisted for a long time. Examples include sparse modeling, sparse auto-encoders, and auto-\\nencoders with noisy latent variables, such as VAE.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 22, 'page_label': '23'}, page_content='existed for a long time. Examples include sparse modeling, sparse auto-encoders, and auto-\\nencoders with noisy latent variables, such as VAE.\\nIt is important to note that contrastive and regularized methods are not incompatible\\nwith each other, and can be used simultaneously on the same model.\\nHow would regularized methods apply to the architectures of Figure 10(b-d)?\\n23'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 23, 'page_label': '24'}, page_content='In the latent-variable generative architecture, restricting the information capacity of z\\nwill restrict the volume of y space that can take low energy. If z is discrete with possible k\\nvalues, at most k points in y space will have zero energy. if Zis a manifold of dimension d\\nthen the region of y space with zero energy will have at most d dimensions.\\nSimilarly, in the auto-encoder architecture, restricting the information capacity of sy\\nwill restrict the volume of y space that can be reconstructed with low energy.\\nLastly, in the Joint Embedding Architecture, Maximizing the information that sx con-\\ntains about x and sy contains about y will minimize the volume of y space that can take\\nlow energy.\\nIn the following, we will focus on an architecture for SSL the Joint Embedding Predictive\\nArchitectures (JEPA) which can seen as a combination of the Joint Embedding Architecture\\nand the Latent-Variable Generative Architecture. The JEPA is non-generative in that it'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 23, 'page_label': '24'}, page_content='Architectures (JEPA) which can seen as a combination of the Joint Embedding Architecture\\nand the Latent-Variable Generative Architecture. The JEPA is non-generative in that it\\ndoes not actually predict y, but predicts the representation of y, sy from that of x, sx.\\n4.4 Joint Embedding Predictive Architecture (JEPA)\\nThe centerpiece of this paper is the Joint Embedding Predictive Architecture (JEPA). JEPA\\nis not generative in the sense that it cannot easily be used to predict y from x. It merely\\ncapture the dependencies between x and y without explicitly generating predictions of y.\\nA generic JEPA is shown in Figure 12. The two variablesxand yare fed to two encoders\\nproducing two presentations sx and sy. These two encoders may be diﬀerent. They are not\\nrequired to possess the same architecture nor are they required to share their parameters.\\nThis allows x and y to be diﬀerent in nature (e.g. video and audio). A predictor module'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 23, 'page_label': '24'}, page_content='required to possess the same architecture nor are they required to share their parameters.\\nThis allows x and y to be diﬀerent in nature (e.g. video and audio). A predictor module\\npredicts the representation of y from the representation of x. The predictor may depend\\non a latent variable z. The energy is simply the prediction error in representation space:\\nEw(x,y,z ) = D(sy,Pred(sx,z)) (10)\\nThe overall energy is obtained by minimizing over z:\\nˇz = argmin\\nz∈Z\\nEw(x,y,z ) = argmin\\nz∈Z\\nD(sy,Pred(sx,z)) (11)\\nFw(x,y) = min\\nz∈Z\\nEw(x,y,z ) = D(sy,Pred(sx,ˇz)) (12)\\n(13)\\nThe main advantage of JEPA is that it performs predictions in representation space ,\\neschewing the need to predict every detail of y. This is enabled by the fact that the encoder\\nof y may choose to produce an abstract representation from which irrelevant details have\\nbeen eliminated.\\nBut there are two ways a JEPA may represent the multiplicity of values ofy compatible'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 23, 'page_label': '24'}, page_content='of y may choose to produce an abstract representation from which irrelevant details have\\nbeen eliminated.\\nBut there are two ways a JEPA may represent the multiplicity of values ofy compatible\\nwith x. The ﬁrst one is invariance properties of the y encoder, the second one is the latent\\nvariable z, as explained below.\\nmulti-modality through encoder invariance : The encoder function sy = Enc(y)\\nmay have invariance properties. If all the y’s in a set map to the same value of sy, all those\\ny’s will have identical energies. With JEPA, we lose the ability to generate outputs, but we\\ngain a powerful way to represent multi-modal dependencies between inputs and outputs.\\n24'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 24, 'page_label': '25'}, page_content='Figure 12: The Joint-Embedding Predictive Architecture (JEPA) consists of two encoding branches.\\nThe ﬁrst branch computes sx, a representation of x and the second branch sy a representation of y.\\nThe encoders do not need to be identical. A predictor module predicts sy from sx with the possible\\nhelp of a latent variable z. The energy is the prediction error. Simple variations of the JEPA may\\nuse no predictor, forcing the two representations to be equal, or may use a ﬁxed predictor with no\\nlatent, or may use simple latents such as discrete variables.\\nThe main advantage of JEPA is that it performs predictions in representation space, eschewing the\\nneed to predict every detail of y, and enabling the elimination of irrelevant details by the encoders.\\nMore precisely, the main advantage of this architecture for representing multi-modal dependencies is\\ntwofold: (1) the encoder function sy = Enc(y) may possess invariance properties that will make it'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 24, 'page_label': '25'}, page_content='More precisely, the main advantage of this architecture for representing multi-modal dependencies is\\ntwofold: (1) the encoder function sy = Enc(y) may possess invariance properties that will make it\\nproduce the same sy for a set of diﬀerent y. This makes the energy constant over this set and allows\\nthe model to capture complex multi-modal dependencies; (2) The latent variable z, when varied over\\na set Z, can produce a set of plausible predictions Pred(sx,Z) = {˜sy = Pred(sx,z) ∀z∈Z}\\nIf x is a video clip of a car approaching a fork in the road, sx and sy may represent the position,\\norientation, velocity and other characteristics of the car before and after the fork, respectively, ig-\\nnoring irrelevant details such as the trees bordering the road or the texture of the sidewalk. z may\\nrepresent whether the car takes the left branch or the right branch of the road.\\nmulti-modality through latent variable predictor: The predictor may use a latent'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 24, 'page_label': '25'}, page_content='represent whether the car takes the left branch or the right branch of the road.\\nmulti-modality through latent variable predictor: The predictor may use a latent\\nvariable zto capture the information necessary to predict sy that is not present in sx. When\\nz is varied over a set Z, the predictor produces a set of plausible predictions Pred( sx,Z) =\\n{˜sy = Pred(sx,z) ∀z ∈Z}. For example, if x is a video clip of a car approaching a fork\\nin the road, sx and sy may represent the past and future positions, orientations, velocities\\nand other characteristics of the car, ignoring irrelevant details such as the trees bordering\\nthe road or the texture of the sidewalk. The latent z may be a binary variable indicating\\nwhether the car takes the left branch ( z = 0) or the right branch ( z = 1 if the road. If the\\ncar takes the left branch, the value z= 0 will produce a lower energy D(sy,˜sy) than z= 1.\\n4.5 Training a JEPA'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 24, 'page_label': '25'}, page_content='car takes the left branch, the value z= 0 will produce a lower energy D(sy,˜sy) than z= 1.\\n4.5 Training a JEPA\\nLike any EBM, a JEPA can be trained with contrastive methods. But, as pointed out\\nabove, contrastive methods tend to become very ineﬃcient in high dimension. The relevant\\n25'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 25, 'page_label': '26'}, page_content='Maximize\\nInformation\\nContent\\nMaximize\\nInformation\\nContent\\nMinimize\\nInformation\\nContent\\nMinimize\\nPrediction\\nError\\nFigure 13: Non-contrastive training of JEPA.\\nThe main attraction of JEPAs is that they can be trained with non-contrastive methods. The basic\\nprinciple of such training is that (1) sx should be maximally informative about x; (2) sy should\\nbe maximally informative about y; (3) sy should be easily predictable from sx; and (4) z should\\nhave minimal information content. Criteria 1, 2, and 4 collectively prevent a collapse of the energy\\nfunction.\\nExamples of such non-contrastive criteria for JEPA training include VICReg and Barlow Twins.\\nAs with every EBM, JEPAs can also be trained with contrastive methods. But doing so runs into\\nthe curse of dimensionality and limits the practical dimension of sy.\\ndimension here is that of sy, which may be considerably smaller than y, but still too high\\nfor eﬃcient training.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 25, 'page_label': '26'}, page_content='the curse of dimensionality and limits the practical dimension of sy.\\ndimension here is that of sy, which may be considerably smaller than y, but still too high\\nfor eﬃcient training.\\nWhat makes JEPAs particularly interesting is that we can devise non-contrastive meth-\\nods to train them. As explained in section 4.3, non-contrastive methods use regularizers\\nthat measure the volume of space that can take low energy values. In the case of the JEPA,\\nthis can be done through four criteria, as depicted in Figure 13:\\n1. maximize the information content of sx about x\\n2. maximize the information content of sy about y\\n3. make sy easily predictable from sx\\n4. minimize the information content of the latent variable z used in the prediction.\\nCriteria 1 and 2 prevent the energy surface from becoming ﬂat by informational col-\\nlapse. They ensure that sx and sy carry as much information as possible about their inputs.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 25, 'page_label': '26'}, page_content='Criteria 1 and 2 prevent the energy surface from becoming ﬂat by informational col-\\nlapse. They ensure that sx and sy carry as much information as possible about their inputs.\\nWithout these criteria the system could choose to make sx and sy constant, or weakly in-\\nformative, which would make the energy constant over large swaths of the input space.\\nCriterion 3 is enforced by the energy term D(sy,˜sy) and ensures that yis predictable from\\nx in representation space.\\nCriterion 4 prevents the system from falling victim to another type of informational col-\\nlapse by forcing the model to predict sy with as little help from the latent as possible. This\\n26'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 26, 'page_label': '27'}, page_content='type of collapse can be understood with the following thought experiment. Imagine that\\nz has the same dimension as sy. Assume that the predictor is a parameterized function\\n(e.g. a neural net) that can choose to ignore sx and to simply copy z on its output ˜sy = z.\\nFor any sy it is possible to set ˇz = sy, which would make the energy D(sy,˜sy) zero. This\\ncorresponds to a totally ﬂat and collapsed energy surface.\\nHow do we prevent this collapse from happening?\\nBy limiting or minimizing the information content of the latent variable.\\nHow can this be done?\\nBy making z discrete, low-dimensional, sparse, or noisy, among other methods.\\nA few concrete examples may help build an intuitive understanding of the phenomenon.\\nSuppose that D(sy,˜sy) = ||sy −˜sy||2 and that z is discrete with K possible integer values\\n[0,K −1]. For a given x, there can be only K possible values of ˜sy:\\nPred(sx,0),Pred(sx,1),...,Pred(sx,K −1).'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 26, 'page_label': '27'}, page_content='[0,K −1]. For a given x, there can be only K possible values of ˜sy:\\nPred(sx,0),Pred(sx,1),...,Pred(sx,K −1).\\nHence, these can be the only values of sy with zero energy, and there are only K of them.\\nConsider a point sy that starts from Pred(sx,0) and moves towards Pred(sx,1). Its energy\\nwill start from zero, increase quadratically as sy moves away from Pred( sx,0), until sy.\\nWhen sy becomes closer to Pred(sx,1) than to Pred(sx,0), the energy will decrease, reaching\\nzero when sy reaches Pred(sx,1). In representation space, the energy will be the minimum\\nof K quadratic energy wells.\\nSimilarly, imagine that z is a vector whose dimension d is lower than that of ˜sy. Then,\\nassuming that Pred( sx,z) is a smooth function of z, the set of possible predictions will be\\nat most a d-dimensional manifold in the space of sy.\\nMore to the point, imagine that the energy function is augmented by a regularization\\nterm on zof the form R(z) = α∑d'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 26, 'page_label': '27'}, page_content='at most a d-dimensional manifold in the space of sy.\\nMore to the point, imagine that the energy function is augmented by a regularization\\nterm on zof the form R(z) = α∑d\\ni=1 |zi|, i.e. the L1 norm of z. This will drive ˇzto be sparse.\\nAs with classical sparse coding, this will cause the region of low energy to be approximated\\nby a union of low-dimensional manifolds (a union of low-dimensional linear subspaces if\\nPred(sx,z) is linear in z), whose dimension will be minimized by the L1 regularizer.\\nMaking z a stochastic sample from a distribution whose entropy is maximized will also\\nhave a proper regularization eﬀect. This is the basis of Variational Auto-Encoders and\\nsimilar models.\\nA more complete discussion of regularizers that can minimize the information content\\nof latent variables is beyond the scope of this paper. For now, we can mention four classes\\nof methods: discretization/quantiﬁcation (e.g. as in VQ-VAE (Walker et al., 2021), dimen-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 26, 'page_label': '27'}, page_content='of latent variables is beyond the scope of this paper. For now, we can mention four classes\\nof methods: discretization/quantiﬁcation (e.g. as in VQ-VAE (Walker et al., 2021), dimen-\\nsionality/rank minimization (e.g. as in Implicit Rank-Minimizing AE (Jing et al., 2020),\\nsparsiﬁcation (as in linear sparse modeling (Olshausen and Field, 1996), LISTA (Gregor\\nand LeCun, 2010b), and non-linear sparse modeling (Evtimova and LeCun, 2022)), and\\nfuzzyﬁcation (as in noisy AE (Doi et al., 2007), VAE (Kingma and Welling, 2013), and\\nvariants used in control problems (Henaﬀ et al., 2019)).\\nThe ability of the JEPA to predict in representation space makes it considerably prefer-\\nable to generative models that directly produce a prediction of y. In a video prediction\\nscenario, it is essentially impossible to predict every pixel value of every future frame. The\\ndetails of the texture on a carpet, the leaves of a tree moving in the wind, or the ripples on'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 26, 'page_label': '27'}, page_content='scenario, it is essentially impossible to predict every pixel value of every future frame. The\\ndetails of the texture on a carpet, the leaves of a tree moving in the wind, or the ripples on\\na pond, cannot be predicted accurately, at least not over long time periods and not without\\nconsuming enormous resources. A considerable advantage of JEPA is that it can choose to\\n27'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 27, 'page_label': '28'}, page_content='Figure 14: Training a JEPA with VICReg.\\nVICReg is a non sample-contrastive method for training embeddings. The information content of the\\nrepresentations sx and sy is maximized by ﬁrst mapping them to higher-dimensional embeddings vx\\nand vy through an expander (e.g. a trainable neural net with a few layers). The loss function drives\\nthe covariance matrix of the embeddings towards the identity (e.g. computed over a batch).\\nVICReg can be seen as a dimension-contrastive method as opposed to sample-contrastive methods.\\nignore details of the inputs that are not easily predictable . Yet, Criteria 1 and 2 will ensure\\nthat the information content of the ignored details are kept to a minimum.\\nHow can we implement Criteria 1 and 2?\\nIn other words, given a parameterized deterministic encoding function sy = Encw(y), how\\ndo we maximize the information content of sy?\\nIf Enc w(y) is invertible, sy contains all the information about y, but that may be sub-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 27, 'page_label': '28'}, page_content='do we maximize the information content of sy?\\nIf Enc w(y) is invertible, sy contains all the information about y, but that may be sub-\\noptimal for Criterion 3, as sy will contain many irrelevant or hard-to-predict details about\\ny. More precisely, sy is maximally informative about y if the function Encw(y) is minimally\\nsurjective, i.e. if the volume of sets of y that map to the same sy is minimal. The same\\nreasoning applies to the xencoder. To turn this criterion into a diﬀerentiable loss, we need\\nto make some assumptions.\\n4.5.1 VICReg\\nThe VICReg method (Bardes et al., 2021) makes a few assumptions about the distributions\\nof sx and sy. A graphical representation is shown in Figure 14. To maximize the information\\ncontent of sx, VICReg uses the following two sub-criteria: (1) the components ofsx must not\\nbe constant, (2) the components ofsx must be as independent of each other as possible. This\\nis approximated by ﬁrst non-linearly mapping sx and sy to higher-dimensional embeddings'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 27, 'page_label': '28'}, page_content='be constant, (2) the components ofsx must be as independent of each other as possible. This\\nis approximated by ﬁrst non-linearly mapping sx and sy to higher-dimensional embeddings\\nvx and vy through a trainable expander module (e.g. a neural net with a few layers), and\\nusing a loss function with two diﬀerentiable loss terms computed over a batch of samples:\\n28'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 28, 'page_label': '29'}, page_content='1. Variance: a hinge loss that maintains the standard deviation of each component of\\nsy and vy above a threshold over a batch.\\n2. Covariance: a covariance loss in which the covariance between pairs of diﬀerent\\ncomponents of vy are pushed towards zero. This has the eﬀect of decorrelating the\\ncomponents of vy, which will in turn make the components of sy somewhat indepen-\\ndent.\\nThe same criteria are applied to sx and vx separately.\\nThe third criterion of VICReg is the representation prediction error D(sy,˜sy). In the\\nsimplest implementations of VICReg, the predictor is constant (equal to the identity func-\\ntion), making the representations invariant to the transformation that turns x into y. In\\nmore sophisticated versions, the predictor may have no latent variable, or may depend on\\na latent variable that is either discrete, low dimensional, or stochastic.\\nThe fourth criterion is necessary when the predictor uses a latent variable whose infor-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 28, 'page_label': '29'}, page_content='a latent variable that is either discrete, low dimensional, or stochastic.\\nThe fourth criterion is necessary when the predictor uses a latent variable whose infor-\\nmation content must be minimized, for example a vector whose dimension approaches or\\nsurpasses that of ˜sy.\\nA simple instantiation of VICReg to learn invariant representations consists in making\\nxand y be diﬀerent views (or distorted versions) of the same content, setting the predictor\\nto the identity function, and deﬁning D(sy,˜sy) = D(sy,sx) = ||sy −sx||2.\\nInferring the latent variable through gradient-based methods may be onerous. But the\\ncomputational cost can be greatly reduced by using amortized inference, as explained in\\nAppendix 8.3.3.\\nWhile contrastive methods ensure that representations of diﬀerent inputs in a batch\\nare diﬀerent, VICReg ensures that diﬀerent components of representations over a batch are\\ndiﬀerent. VICReg is contrastive over components, while traditional contrastive methods'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 28, 'page_label': '29'}, page_content='are diﬀerent, VICReg ensures that diﬀerent components of representations over a batch are\\ndiﬀerent. VICReg is contrastive over components, while traditional contrastive methods\\nare contrastive over vectors, which requires a large number of contrastive samples.\\nBut the most promising aspect of JEPA trained with VICReg and similar non-contrastive\\nmethods is for learning hierarchical predictive world models, as we examine in the next sec-\\ntion.\\n4.5.2 Biasing a JEPA towards learning “useful” representations\\nWith the training criteria listed above, the JEPA ﬁnds a trade-oﬀ between the completeness\\nand the predictability of the representations. What is predictable and what does not get\\nrepresented is determined implicitly by the architectures of the encoders and predictor.\\nThey determine a inductive bias that deﬁnes what information is predictable or not.\\nBut it would be useful to have a way to bias the system towards representations that'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 28, 'page_label': '29'}, page_content='They determine a inductive bias that deﬁnes what information is predictable or not.\\nBut it would be useful to have a way to bias the system towards representations that\\ncontain information relevant to a class of tasks. This can be done by adding prediction\\nheads that take ˜sy as input and are trained to predict variables that are easily derived from\\nthe data and known to be relevant to the task.\\n4.6 Hierarchical JEPA (H-JEPA)\\nJEPA models trained non-contrastively may constitute our best tool for learning world\\nmodels that are able to learn relevant abstractions. When trained with VICReg and similar\\n29'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 29, 'page_label': '30'}, page_content='x y\\nJEPA-1\\nJEPA-2\\nFigure 15: Hierarchical JEPA (H-JEPA)\\nThe ability of the JEPA to learn abstract representations in which accurate prediction can be per-\\nformed allows hierarchical stacking. In this diagram JEPA-1 extracts low-level representations and\\nperforms short-term predictions. JEPA-2 takes the representations extracted by JEPA-1 as inputs\\nand extracts higher-level representations with which longer-term predictions can be performed. More\\nabstract representations ignore details of the inputs that are diﬃcult to predict in the long term,\\nenabling them to perform longer-term predictions with coarser descriptions of the world state.\\ncriteria, a JEPA can choose to train its encoders to eliminate irrelevant details of the inputs\\nso as to make the representations more predictable. In other words, a JEPA will learn\\nabstract representations that make the world predictable. Unpredictable details will be'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 29, 'page_label': '30'}, page_content='so as to make the representations more predictable. In other words, a JEPA will learn\\nabstract representations that make the world predictable. Unpredictable details will be\\neliminated by the invariance properties of the encoder, or will be pushed into the predictor’s\\nlatent variable. The amount of information thereby ignored will be minimized by the\\ntraining criteria and by the latent variable regularizer.\\nIt is important to note that generative latent-variable models are not capable of elimi-\\nnating irrelevant details, other than by pushing them into a latent variable. This is because\\nthey do not produce abstract (and invariant) representations of y. This is why we advocate\\nagainst the use of generative architectures.\\nThe capacity of JEPA to learn abstractions suggests an extension of the architecture to\\nhandle prediction at multiple time scales and multiple levels of abstraction. Intuitively, low-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 29, 'page_label': '30'}, page_content='The capacity of JEPA to learn abstractions suggests an extension of the architecture to\\nhandle prediction at multiple time scales and multiple levels of abstraction. Intuitively, low-\\nlevel representations contain a lot of details about the input, and can be used to predict in\\nthe short term. But it may be diﬃcult to produce accurate long-term predictions with the\\nsame level of details. Conversely high-level, abstract representation may enable long-term\\npredictions, but at the cost of eliminating a lot of details.\\n30'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 30, 'page_label': '31'}, page_content='Let’s take a concrete example. When driving a car, given a proposed sequence of actions\\non the steering wheel and pedals over the next several seconds, drivers can accurately\\npredict the trajectory of their car over the same period. The details of the trajectory over\\nlonger periods are harder to predict because they may depend on other cars, traﬃc lights,\\npedestrians, and other external events that are somewhat unpredictable. But the driver\\ncan still make accurate predictions at a higher level of abstraction: ignoring the details of\\ntrajectories, other cars, traﬃc signals, etc, the car will probably arrive at its destination\\nwithin a predictable time frame. The detailed trajectory will be absent from this level of\\ndescription. But the approximate trajectory, as drawn on a map, is represented. A discrete\\nlatent variable may be used to represent multiple alternative routes.\\nFigure 15 shows a possible architecture for multilevel, multi-scale world state prediction.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 30, 'page_label': '31'}, page_content='latent variable may be used to represent multiple alternative routes.\\nFigure 15 shows a possible architecture for multilevel, multi-scale world state prediction.\\nVariables x0,x1,x2 represent a sequence of observations. The ﬁrst-level network, denoted\\nJEPA-1 performs short-term predictions using low-level representations. The second-level\\nnetwork JEPA-2 performs longer-term predictions using higher-level representations. One\\ncan envision architectures of this type with many levels, possibly using convolutional and\\nother modules, and using temporal pooling between levels to coarse-grain the representation\\nand perform longer-term predictions. Training can be performed level-wise or globally, using\\nany non-contrastive method for JEPA.\\nI submit that the ability to represent sequences of world states at several levels of\\nabstraction is essential to intelligent behavior. With multi-level representations of world'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 30, 'page_label': '31'}, page_content='I submit that the ability to represent sequences of world states at several levels of\\nabstraction is essential to intelligent behavior. With multi-level representations of world\\nstates and actions, a complex task can be decomposed into successively more detailed sub-\\ntasks, instantiated into actions sequences when informed by local conditions. For example,\\nplanning a complex task, like commuting to work, can be decomposed into driving to the\\ntrain station, catching a train, etc. Driving to the train station can be decomposed into\\nwalking out of the house, starting the car, and driving. Getting out of the house requires\\nstanding up, walking to the door, opening the door, etc. This decomposition descends all\\nthe way down to millisecond-by-millisecond muscle controls, which can only be instantiated\\nwhen the relevant environmental conditions are perceived (obstacles, traﬃc lights, moving\\nobjects, etc).\\n4.7 Hierarchical Planning'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 30, 'page_label': '31'}, page_content='when the relevant environmental conditions are perceived (obstacles, traﬃc lights, moving\\nobjects, etc).\\n4.7 Hierarchical Planning\\nIf our world model can perform predictions hierarchically, can it be used to perform Mode-2\\nreasoning and planning hierarchically?\\nHierarchical planning is a diﬃcult topic with few solutions, most of which require that\\nthe intermediate vocabulary of actions be predeﬁned. But if one abides by the deep learning\\nphilosophy, those intermediate representations of action plans should also be learned .\\nFigure 16 shows a possible architecture for hierarchical Mode-2 planning that can exploit\\nthe hierarchical nature of a multi-scale world model.\\nA percept is encoded into representations at multiple levels of abstractions by a cascade\\nof encoders:\\ns[0] = Enc1(x); s2[0] = Enc2(s[0]); ... (14)\\nPrediction takes place at all levels. Higher levels perform longer-term prediction, while lower'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 30, 'page_label': '31'}, page_content='of encoders:\\ns[0] = Enc1(x); s2[0] = Enc2(s[0]); ... (14)\\nPrediction takes place at all levels. Higher levels perform longer-term prediction, while lower\\nlevels perform shorter-term predictions. The overall task is deﬁned by a high-level objective,\\ndepicted as C(s2[4]) in the diagram. The top level infers a sequence of high-level actions\\n31'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 31, 'page_label': '32'}, page_content='Pred1(s,a)  Pred1(s,a)\\nC(s[2])\\n Pred1(s,a)  Pred1(s,a)\\nC(s[4])\\nEnc1(x)\\ns[1] s[2]\\naction\\ns[0]\\nActor1\\n Pred2(s,a)Enc2(s[0])\\ns2[0] s2[2]\\nActor2\\n Pred2(s,a)\\nC(s2[4])\\ns[3] s[4]\\ns2[4]\\na2[2] a2[4]\\na[1] a[2] a[3]a[0]\\nFigure 16: Hierarchical JEPA for Mode-2 hierarchical planning.\\nA complex task is deﬁned by a high-level cost computed from a high-level world-state representation\\nC(s2[4]). A sequence of high-level abstract actions (a2[2],a2[4]) is inferred that minimizes C(s2[4]).\\nThe inferred abstract actions are fed to lower-level cost modules C(s[2]),C(s[4]) which deﬁne subgoals\\nfor the lower layer. The lower layer then infers an action sequence that minimizes the subgoal costs.\\nAlthough only a 2-layer hierarchy is shown here, it is straightforward to extend the concept to multiple\\nlevels.\\nThe process described here is sequential top-down, but a better approach would be to perform a joint\\noptimization of the actions in all the layers.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 31, 'page_label': '32'}, page_content='levels.\\nThe process described here is sequential top-down, but a better approach would be to perform a joint\\noptimization of the actions in all the layers.\\n(a2[2],a2[4]) to optimize this objective. These high-level “actions” are not real actions but\\ntargets for the lower level predicted states. One can think of them as conditions that the\\nlower-level state must satisfy in order for the high-level predictions to be accurate. Whether\\nthese conditions are satisﬁed can be computed by cost modules C(s[2]) and C(s[4]). They\\ntake a lower-level state s[2] and a high-level condition a2[2] and measure to what extent\\nthe state satisﬁes the condition. With these subgoals deﬁned, the lower level can perform\\ninference and ﬁnd a low-level action sequence that minimizes the mid-level subgoals C(s[2])\\nand C(s[4]).\\nThe process just described is top down and greedy. But one may advantageously iterate\\nthe optimization so that high level and low-level action sequences are optimized jointly. The'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 31, 'page_label': '32'}, page_content='and C(s[4]).\\nThe process just described is top down and greedy. But one may advantageously iterate\\nthe optimization so that high level and low-level action sequences are optimized jointly. The\\ncost modules may be conﬁgured by the conﬁgurator for the situation at hand.\\nThe idea that an action is merely a condition to be satisﬁed by the level below is actually\\nan old one in control theory. For a example, a classical proportional servomechanism can be\\nseen as being given a target state. A quadratic cost measures the squared distance between\\nthe target and the current state, and the control is simply proportional to the negative\\ngradient of the cost with respect to the action variables.\\n4.8 Handling uncertainty\\nThe real world is not entirely predictable. Uncertainty in predictions of future world states\\nmay be due to a number of reasons:\\n• the world is intrinsically stochastic (aleatoric uncertainty, type 1)\\n32'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 32, 'page_label': '33'}, page_content='Pred1(s,a,z)  Pred1(s,a,z)\\nC(s[2])\\n Pred1(s,a,z)  Pred1(s,a,z)\\nC(s[4])\\nEnc1(x)\\ns[1] s[2]\\naction\\ns[0]\\na[1] a[2] a[3]a[0]\\nActor1\\n Pred2(s,a,z)Enc2(s[0])\\ns2[0] s2[2]\\na2[2]\\nActor2\\n Pred2(s,a,z)\\nC(s2[4])\\ns[3] s[4]\\ns2[4]\\na2[4]\\nz1[0]R1 z1[1]R1 z1[2]R1 z1[3]R1\\nz2[2]R2 z2[4]R2\\nFigure 17: Hierarchical JEPA for Mode-2 hierarchical planning in an uncertain environment.\\nRealistic environments are not entirely predictable, even when using highly-abstract representations.\\nUncertainty about predictions can be handled by predictors with latent variables. The latent variables\\n(red circles) contain information about the prediction that cannot be derived from the prior observa-\\ntion. The latent variables must be regularized to prevent an energy collapse and to force the system\\nto predict as much as possible without the help of it.\\nAt planning time, latent variables are sampled from distributions obtained by applying a Gibbs dis-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 32, 'page_label': '33'}, page_content='to predict as much as possible without the help of it.\\nAt planning time, latent variables are sampled from distributions obtained by applying a Gibbs dis-\\ntribution to the regularizers. Each sample leads to a diﬀerent prediction. To produce consistent\\nlatent sequences, the parameters of the regularizer can be functions of previous states and retrieved\\nmemories.\\nAs the prediction progresses, the number of generated state trajectories may grow exponentially. If\\neach latent variable has k possible discrete values, the number of possible trajectories will grow as\\nkt, where t is the number of time steps. Directed search and pruning strategies must be employed.\\nWith multiple predicted trajectories, optimal action sequences can be computed that minimize the\\naverage cost, or a combination of average and variance of the cost so as to minimize risk.\\n• the world is deterministic but chaotic, hence diﬃcult to predict without inﬁnitely\\nprecise perception (aleatoric uncertainty, type 2)'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 32, 'page_label': '33'}, page_content='• the world is deterministic but chaotic, hence diﬃcult to predict without inﬁnitely\\nprecise perception (aleatoric uncertainty, type 2)\\n• the world is deterministic but partially observable (aleatoric uncertainty type 3).\\n• the world is fully observable, but the sensors only give partial information about the\\nworld state (epistemic uncertainty, type 1)\\n• the representation of the world state extracted by the perception module does not\\ncontain the full information necessary for accurate prediction (epistemic uncertainty,\\ntype 2).\\n• the world model is inaccurate due to limitations of its representational power (bounded\\nrationality or epistemic uncertainty, type 3).\\n33'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 33, 'page_label': '34'}, page_content='• the world model is inaccurate due to it having been trained with limited amount of\\ndata (epistemic uncertainty, type 4).\\nMuch of the literature in reinforcement learning is focused on dealing with the stochastic\\nnature of the environment. It is often assumed from the start that models, critics and\\npolicies must represent distributions. In the present work, we push the possible stochasticity\\nof a predicted variable into a latent variable, which may be optimized, predicted, or sampled.\\nThis is what is often referred to in the ML literature as “the reparameterization trick”. We\\ndo not need to use this trick here, since we view the latent-variable parameterization of the\\npredictions as fundamental.\\nFigure 17 represents a hierachical planning episode in the presence of uncertainty.\\nA prediction at a given level and time step, e.g. s2[2] requires a sample of the corre-\\nsponding latent variable z2[2]. The sample may come from the distribution whose negative'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 33, 'page_label': '34'}, page_content='A prediction at a given level and time step, e.g. s2[2] requires a sample of the corre-\\nsponding latent variable z2[2]. The sample may come from the distribution whose negative\\nlogarithm is the regularizer R2(z2[2])). The parameters of the regularizer may be constant\\n(e.g. ﬁxed Gaussian), predicted from currently-available data using amortized inference (e.g.\\na multinomial or Gaussian whose parameters are computed from s2[0]) or produced by the\\nconﬁgurator. Using previous predictions to conﬁgure the latent regularizer biases the system\\ntowards generating “good” trajectories.\\nAs the prediction progresses, the number of generated state trajectories may grow ex-\\nponentially: if each latent variable has k possible discrete values, the number of possible\\ntrajectories will grow as kt, where tis the number of time steps. Directed search and prun-\\ning strategies can be employed, as in classical Monte-Carlo Tree Search (MCTS). In the case'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 33, 'page_label': '34'}, page_content='trajectories will grow as kt, where tis the number of time steps. Directed search and prun-\\ning strategies can be employed, as in classical Monte-Carlo Tree Search (MCTS). In the case\\nof continuous latents, one may sample latents from the continuous distributions deﬁned by\\nthe regularizer.\\nGiven a sample of all the latents, the optimal action sequences at every levels can be\\ninferred. However, the prediction process may need to be repeated for multiple drawings\\nof the latents, so as to cover the set of plausible outcomes. The inference process may be\\nused for multiple predictions to produce an action that does not just minimize the expected\\ncost, but also minimizes the uncertainty on the expected cost.\\n4.8.1 World Model Architecture\\nThe details of the architecture of the world model should depend on the type of environment\\nthe agent evolves in.\\nIt is likely that the best module architectures in a JEPA should include some sort of\\ngating or dynamic routing mechanism.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 33, 'page_label': '34'}, page_content='the agent evolves in.\\nIt is likely that the best module architectures in a JEPA should include some sort of\\ngating or dynamic routing mechanism.\\nFor example, the best way to handle low-level, short-term predictions in videos is by\\nextracting simple local feature vectors and displacing those feature vectors from one frame\\nto the next, depending on predicted motions. The latent variables may encode a map of\\ndisplacements, which can modulate routing connections between one frame and the next.\\nFor longer-term prediction at a higher level of abstraction, the relevant features are\\nobjects and their interactions. The evolution may be best modeled by a transformer ar-\\nchitecture, which has the property of being equivariant to permutation and is appropriate\\nto capture interactions between discrete objects (Vaswani et al., 2017; Carion et al., 2020;\\nBattaglia et al., 2016).\\n34'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 34, 'page_label': '35'}, page_content='Separating the World Model from the Ego Model: The natural world is complex\\nand somewhat unpredictable, requiring a powerful model with latent variables to account\\nfor the unpredictability.\\nOn the other hand, the agent itself is somewhat more predictable: a particular ac-\\ntion on eﬀector will produce a motion that can often be predicted deterministically. This\\nsuggests that the agent should possess a separate model of itself, perhaps without latent\\nvariables (Sobal et al., 2022) as the eﬀect of actions on proprioception somewhat easier to\\npredict than the evolution of the external world or the eﬀect of actions on it.\\nIn turn, the ego-model that the agent has of itself can be used as a template for a model\\nof other agents in a multi-agent scenario.\\n4.9 Keeping track of the state of the world\\nTraditionally, modules in deep learning architectures communicate states through vectors\\nor multi-dimensional arrays. But this tends to be a very ineﬃcient method when the state'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 34, 'page_label': '35'}, page_content='Traditionally, modules in deep learning architectures communicate states through vectors\\nor multi-dimensional arrays. But this tends to be a very ineﬃcient method when the state\\nof the object being modeled only changes in minor ways from one time to the next.\\nA typical action of an agent will only modify a small portion of the state of the world.\\nIf a bottle is being moved from the kitchen to the dining room, the states of the bottle, the\\nkitchen, and the dining room will be modiﬁed. But the rest of the world will be unaﬀected.\\nThis suggests that the state of the world should be maintained in some sort of writable\\nmemory. Whenever an event occurs, only the part of the world-state memory aﬀected by\\nthe event is to be updated, while the rest is to be left unchanged.\\nA conventional key-value associative memory can be used for this purpose, similar to\\nwhat has been proposed in the context of memory-augmented networks (Bordes et al., 2015;'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 34, 'page_label': '35'}, page_content='A conventional key-value associative memory can be used for this purpose, similar to\\nwhat has been proposed in the context of memory-augmented networks (Bordes et al., 2015;\\nSukhbaatar et al., 2015; Miller et al., 2016), and entity networks (Henaﬀ et al., 2017).\\nThe output of the world model at a given time step is a set of query-value pairs (q[i],v[i]),\\nwhich are used to modify existing entries in the world-state memory, or to add new entries.\\nGiven a query q, the world-state memory returns\\nMem(q) =\\n∑\\nj\\ncjvj (15)\\n˜cj = Match( kj,q) (16)\\nc = Normalize(˜c) (17)\\nwhere the kj are keys, the vj are stored values, function Match(k,q) measures a divergence\\nor dissimilarity between a key and a query, vector c contains scalar coeﬃcients cj, and\\nfunction Normalize(˜c) performs some sort of competitive normalization or thresholding,\\nsuch as the commonly-used cj = exp(˜cj)/[γ+ ∑\\nkexp(˜ck)], where γis a positive constant.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 34, 'page_label': '35'}, page_content='function Normalize(˜c) performs some sort of competitive normalization or thresholding,\\nsuch as the commonly-used cj = exp(˜cj)/[γ+ ∑\\nkexp(˜ck)], where γis a positive constant.\\nWriting a value r using query (or address) q into the memory can be done by updating\\nexisting entries:\\n˜cj = Match( kj,q) (18)\\nc = Normalize(˜c) (19)\\nvj = Update( r,vj,cj) (20)\\nFunction Update(r,v,c ) may be as simple as cr+ (1 −c)v.\\n35'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 35, 'page_label': '36'}, page_content='If the query is distant from all keys, the memory may allocate a new entry whose key is\\nq and corresponding value is r. The γ constant in the example Normalize function above\\nmay serve as a threshold for acceptable key-query divergence.\\nOne can view each entry as representing the state of an entity in the world. In the\\nabove example of the bottle, the world model may contain keys kbottle,kkitchen,kdining−room\\nrespectively representing the bottle, the kitchen and the dining room. The initial value of\\nvbottle encodes its location as “kitchen”, the inital value of vkitchen encodes its content as\\nincluding the bottle, and the initial value of vdining−room encodes its content as not including\\nthe bottle. After the event, the location and contents are updated.\\nAll of these operations can be done in a diﬀerentiable manner, and would hence allow\\nto back-propagate gradients through them.\\n4.10 Data Streams\\nMuch knowledge about the world is learnable through pure observation. The laws of mo-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 35, 'page_label': '36'}, page_content='to back-propagate gradients through them.\\n4.10 Data Streams\\nMuch knowledge about the world is learnable through pure observation. The laws of mo-\\ntion of physical objects can, in principle, be derived from observation, without a need for\\nintervention. But training a world model eﬃciently may require more active or “agentive”\\ninformation gathering.\\nOne can list ﬁve modes of information gathering with which an agent can learn about\\nhow the world works:\\n1. passive observation: the agent is being fed a sensor stream (e.g. video, audio, etc)\\n2. active foveation: the agent is being fed a stream within which the focus of attention\\ncan be directed without aﬀecting the environment. For example, watching a scene\\nwhile being able to orient the vision and sound sensors, or being being fed a wide-\\nangle, high resolution video and/or audio stream within which the focus of attention\\ncan be directed.\\n3. passive agency: sensory streams in which another agent acting on the environment'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 35, 'page_label': '36'}, page_content='angle, high resolution video and/or audio stream within which the focus of attention\\ncan be directed.\\n3. passive agency: sensory streams in which another agent acting on the environment\\nis being observed, enabling the inference of causal eﬀects of agent actions on the state\\nof the environment.\\n4. active egomotion: the agent receives sensory streams from a real or virtual environ-\\nment within which the position of the sensors can be modiﬁed without signiﬁcantly\\naﬀecting the environment. This may include steerable active sensors (e.g. range sen-\\nsors, heat sensors, chemical sensors) as well as touch sensors.\\n5. active agency : sensory streams that are inﬂuenced by the agent’s actions. This\\nenables the establishment of causal models in which the agent can learn to predict the\\nconsequences of its actions. This mode brings the exploration-exploitation dilemma\\nto the forefront.\\nIn a complex environment, it may not be practical to collect enough passive data for the'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 35, 'page_label': '36'}, page_content='consequences of its actions. This mode brings the exploration-exploitation dilemma\\nto the forefront.\\nIn a complex environment, it may not be practical to collect enough passive data for the\\nworld model to capture a suﬃcient portion of the environment’s behavior. Mode 2, 4, and\\n5 allow the agent to collect information that maximizes its understanding of the environ-\\nment. But to do so may require intrinsic motivation modules that drive attention, curiosity,\\n36'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 36, 'page_label': '37'}, page_content='and exploration into corners of the state space in which the world model’s prediction are\\ncurrently inexact or uncertain.\\nThe main open question is how much can be learned using passive observation (modes\\n1, 2, 4), how much requires egomotion (mode 3), and how much requires full agency (mode\\n5).\\n5 Designing and Training the Actor\\nThe role of the actor module is threefold:\\n1. inferring optimal action sequences that minimize the cost, given the predictions pro-\\nduced by the world model for Mode-2 actions.\\n2. producing multiple conﬁgurations of latent variables that represent the portion of the\\nworld state the agent does not know.\\n3. training policy networks for producing Mode-1 actions.\\nThere is no conceptual diﬀerence between an action and a latent variable. The conﬁgurations\\nof both sets of variables must be explored by the actor. For latent variables, conﬁgurations\\nmust be explored to plan under uncertainty. For action variables conﬁgurations must be'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 36, 'page_label': '37'}, page_content='of both sets of variables must be explored by the actor. For latent variables, conﬁgurations\\nmust be explored to plan under uncertainty. For action variables conﬁgurations must be\\nexplored to produce an optimal one that minimizes the cost. In adversarial scenarios (such\\nas games), the latent conﬁgurations must be explored that maximize the cost. In eﬀect, the\\nactor plays the role of an optimizer and explorer.\\nWhen the world model and the cost are well-behaved, the actor module can use a\\ngradient-based optimization process to infer an optimal action sequence. To do so, it receives\\nestimates of the gradient of the cost computed by backpropagating gradients through the\\ncost and the unfolded world model. It uses those estimates to update the action sequence.\\nWhen the world model or the cost are not so well-behaved, a gradient-based search\\nfor an optimal action sequence may fail. In this case another search/planning method'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 36, 'page_label': '37'}, page_content='When the world model or the cost are not so well-behaved, a gradient-based search\\nfor an optimal action sequence may fail. In this case another search/planning method\\nmay be applied. If the action space is discrete or can be discretized, one can use dynamic\\nprogramming methods or approximate dynamic programming methods such as beam search\\nor Monte-Carlo tree search. In eﬀect, any planning method developed in the context of\\noptimal control, robotic, or “classical” AI may be used in this context.\\nOnce an optimal action sequence is obtained through the planning / inference / opti-\\nmization process, one can use the actions as targets to train a policy network. The policy\\nnetwork may subsequently be used to act quickly, or merely to initialize the proposed action\\nsequence to a good starting point before the optimization phase. Multiple policy networks\\ncan be trained for multiple tasks.\\nThe actor also produces conﬁgurations of latent variables. These latent variables repre-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 36, 'page_label': '37'}, page_content='can be trained for multiple tasks.\\nThe actor also produces conﬁgurations of latent variables. These latent variables repre-\\nsent the portion of the world state that the agent does not know. Ideally, the actor would\\nsystematically explore likely conﬁgurations of the latents. Ideally, the regularizer for the\\nlatents, R1 and R2 in Figure 17, would represent log-priors from which the latent could be\\nsampled. But in a similar way as the policy network, one may devise a latent amortized\\ninference module that learns distributions of latent variables. Good distributions would\\nproduce predictions that are plausible. The distribution primate’s may depend on all the\\nvariables available at that time.\\n37'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 37, 'page_label': '38'}, page_content='6 Designing the Conﬁgurator\\nThe conﬁgurator is the main controller of the agent. It takes input from all other modules\\nand modulates their parameters and connection graphs. The modulation can route signals,\\nactivate sub-networks, focus attention, etc. In a scenario in which the predictor and the\\nupper layers of the perception encoder are transformer blocks, the conﬁgurator outputs\\nmay constitute extra input tokens to these transformer blocks, thereby modulating their\\nconnection graphs and functions.\\nThe conﬁgurator module is necessary for two reasons: hardware reuse, and knowledge\\nsharing. There is an obvious advantage to be able to reuse the same circuit for multiple\\ntasks, particularly if the tasks can be accomplished sequentially, and if the amount of\\nresources (e.g. parameter memory) is limited. But there is another advantage: knowledge\\nreuse. A reasonable hypothesis is that a world model trained for a given environment can be'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 37, 'page_label': '38'}, page_content='resources (e.g. parameter memory) is limited. But there is another advantage: knowledge\\nreuse. A reasonable hypothesis is that a world model trained for a given environment can be\\nused for a range of diﬀerent tasks with minor changes. One can imagine a “generic” world\\nmodel for the environment with a small portion of the parameters being modulated by the\\nconﬁgurator for the task at hand. This would be more data eﬃcient and computationally\\neﬃcient than having separate world models for each skill. The disadvantage is that the\\nagent can only accomplish one task at a time.\\nThe conﬁgurator may prime the perception module for a particular task by modulating\\nthe parameters at various levels. The human perceptual system can be primed for a par-\\nticular task, such as detecting an item in a cluttered drawer, detecting fruits or preys in a\\nforest, reading, counting certain events, assembling two parts, etc. For tasks that require a'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 37, 'page_label': '38'}, page_content='ticular task, such as detecting an item in a cluttered drawer, detecting fruits or preys in a\\nforest, reading, counting certain events, assembling two parts, etc. For tasks that require a\\nrapid detection of simple motifs, the conﬁgurator may modulate the weights of low-level lay-\\ners in a convolutional architecture. For tasks that involve satisfying relationships between\\nobjects (such as assembling two parts with screws) the conﬁguration may be performed by\\nmodulating tokens in high-level transformer modules.\\nThe predictor part of the world model must be able to perform a wide range of functions\\ndepending on the task at hand. For predictors performing short-term predictions at a\\nlow level of abstraction, conﬁguration may mean dynamic signal routing. In a low-level\\nretinotopic feature array representation, prediction may be reduced to local displacements\\nof individual feature vectors, accompanied with small transformations of those vectors.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 37, 'page_label': '38'}, page_content='retinotopic feature array representation, prediction may be reduced to local displacements\\nof individual feature vectors, accompanied with small transformations of those vectors.\\nThis may be advantageously implemented with local gating/routing circuits. For longer-\\nterm prediction at higher-levels of abstraction, it may be preferable to use a transformer\\narchitecture. Transformer blocks are particularly appropriate for object-based reasoning in\\nwhich objects interact. The reason is that the function of transformer blocks is equivariant\\nto permutation. Thanks to that property, one does not need to worry about which object\\nis assigned to which input token: the result will be identical and consistent with the input\\nassignment. Recent work in model-based robotics have proposed to use a transformer\\noperating at the level of an entire trajectory, imposing constraints on the attention circuits\\nto conﬁgure the predictor for causal prediction or other tasks (Janner et al., 2021).'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 37, 'page_label': '38'}, page_content='operating at the level of an entire trajectory, imposing constraints on the attention circuits\\nto conﬁgure the predictor for causal prediction or other tasks (Janner et al., 2021).\\nConveniently, the function of a transformer block is easy to conﬁgure by adding extra\\ninput tokens. Those extra inputs have the eﬀect of modulating the connection graph used\\nby the rest of the network, thereby allowing the speciﬁcation of a wide range of input-output\\nfunctions.\\n38'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 38, 'page_label': '39'}, page_content='Perhaps the most important function of the conﬁgurator is to set subgoals for the agent\\nand to conﬁgure the cost module for this subgoal. As mentioned in Section 3.2, a simple\\nway to make the cost conﬁgurable is by modulating the weights of a linear combination of\\nelementary cost sub-modules. This may be appropriate for the immutable Intrinsic Cost\\nsubmodule: allowing for a complex modulation of the Intrinsic Cost may make the basic\\ndrives of the agent diﬃcult to control, including cost terms that implement safety guardrails.\\nIn contrast, one can imagine more sophisticated architectures allowing the Trainable Critic\\npart of the cost to be ﬂexibly modulated. As with the predictor, if the high-level cost is\\nformulated as a set of desired relationships between objects (“is the nut set on the screw?”)\\none may use a transformer architecture trained to measure to what extent the state of the\\nworld diverges from the condition to be satisﬁed. As with the predictor, extra token inputs'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 38, 'page_label': '39'}, page_content='one may use a transformer architecture trained to measure to what extent the state of the\\nworld diverges from the condition to be satisﬁed. As with the predictor, extra token inputs\\ncan be used to modulate the function.\\nOne question that is left unanswered is how the conﬁgurator can learn to decompose\\na complex task into a sequence of subgoals that can individually be accomplished by the\\nagent. I shall leave this question open for future investigation.\\n7 Related Work\\nMost of the ideas presented in the paper are not new, and have been discussed at length in\\nvarious forms in cognitive science, neuroscience, optimal control, robotics, AI, and machine\\nlearning, particularly in reinforcement learning.\\nPerhaps the main original contributions of the paper reside in\\n• an overall cognitive architecture in which all modules are diﬀerentiable and many of\\nthem are trainable.\\n• H-JEPA: a non-generative hierarchical architecture for predictive world models that'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 38, 'page_label': '39'}, page_content='• an overall cognitive architecture in which all modules are diﬀerentiable and many of\\nthem are trainable.\\n• H-JEPA: a non-generative hierarchical architecture for predictive world models that\\nlearn representations at multiple levels of abstraction and multiple time scales.\\n• a family of non-contrastive self-supervised learning paradigm that produces represen-\\ntations that are simultaneously informative and predictable.\\n• A way to use H-JEPA as the basis of predictive world models for hierarchical planning\\nunder uncertainty.\\nBelow is an attempt to connect the present proposal with relevant prior work. Given\\nthe scope of the proposal, the references cannot possibly be exhaustive.\\n7.1 Trained World Models, Model-Predictive Control, Hierarchical PLan-\\nning\\nThe use of models in optimal control goes back to the early days with the Kelley-Bryson\\nmethod (see (Bryson and Ho, 1969) and reference therein, or the review (Morari and Lee,'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 38, 'page_label': '39'}, page_content='ning\\nThe use of models in optimal control goes back to the early days with the Kelley-Bryson\\nmethod (see (Bryson and Ho, 1969) and reference therein, or the review (Morari and Lee,\\n1997)). Some methods allowed for online system identiﬁcation (Richalet et al., 1978).\\nUsing neural networks to learn models for control is an old idea, going back to the early\\n1990s (Jordan and Rumelhart, 1992; Narendra and Parthasarathy, 1990; Miller et al., 1995).\\n39'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 39, 'page_label': '40'}, page_content='In the context of optimal control, learning a Mode-1 like policy network is known as direct\\ninverse control.\\nThe idea of Mode-2 style inference over actions using a predictive model in the context\\nof reinforcement learning is also an old idea with, for example, Sutton’s Dyna architec-\\nture (Sutton, 1991). See (Bertsekas, 2019) for an extensive review.\\nThe idea of learnable models has recently enjoyed a renewal of interest in various con-\\ntexts (Ha and Schmidhuber, 2018b; Ha and Schmidhuber, 2018a; Hafner et al., 2018; Hafner\\net al., 2020) (see (Moerland et al., 2020) for a recent survey of model-based reinforcement\\nlearning).\\nLearning world models is particularly important in the context of robotics, especially\\nfor grasping and manipulation where sample eﬃciency is paramount and simulation is often\\ninaccurate. In fact, because classical reinforcement learning approaches require too many\\ntrials for real-world applications, interesting advances in learned model for control have'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 39, 'page_label': '40'}, page_content='inaccurate. In fact, because classical reinforcement learning approaches require too many\\ntrials for real-world applications, interesting advances in learned model for control have\\nemerged from ML-based robotics research (Agrawal et al., 2016; Finn and Levine, 2017;\\nChua et al., 2018; Srinivas et al., 2018; Yu et al., 2020; Yarats et al., 2021). For a recent\\nreview, see (Levine, 2021) and references therein.\\nA diﬃcult setting is one in which the main input is visual, and a world model must be\\nlearned from video. Early attempts to train predictive models without latent variables from\\nsimple video produced blurry predictions (Lerer et al., 2016). To handle uncertainty in the\\npredictions, one can use various ﬂavors of latent variable models such as generative adver-\\nsarial networks (GAN) (Goodfellow et al., 2014), variational auto-encoders (VAE) (Kingma\\nand Welling, 2013) vector-quantized VAE (VQ-VAE) (van den Oord et al., 2017). Vari-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 39, 'page_label': '40'}, page_content='sarial networks (GAN) (Goodfellow et al., 2014), variational auto-encoders (VAE) (Kingma\\nand Welling, 2013) vector-quantized VAE (VQ-VAE) (van den Oord et al., 2017). Vari-\\nations of these methods have been applied to video prediction and help represent multi-\\nmodal outputs and reduce blurriness using GAN (Mathieu et al., 2015; Luc et al., 2020),\\nVAE (Babaeizadeh et al., 2017; Denton and Fergus, 2018; Henaﬀ et al., 2019), or VQ-\\nVAE (Walker et al., 2021). Although many of these methods have not been applied to\\ncontrol problems, some have been applied to vehicle trajectory prediction for autonomous\\ndriving (Henaﬀ et al., 2019; Mercat et al., 2020), or various robot control tasks (Oh et al.,\\n2015; Fragkiadaki et al., 2015; Agrawal et al., 2016; Finn et al., 2016; Nagabandi et al.,\\n2017; Babaeizadeh et al., 2017; Srinivas et al., 2018). Unlike the proposed JEPA, these\\nmodels are generative. The key issue of how to represent uncertainty in the prediction\\nremains.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 39, 'page_label': '40'}, page_content='2017; Babaeizadeh et al., 2017; Srinivas et al., 2018). Unlike the proposed JEPA, these\\nmodels are generative. The key issue of how to represent uncertainty in the prediction\\nremains.\\nThe alternative to regularized latent-variable models is constrative methods, such as\\nContrastive Predictive Coding (CPC) (H´ enaﬀ et al., 2019), which has been applied to\\nlearning visual representations through video prediction (van den Oord et al., 2018).\\nTo solve the multi-modality/blurriness problem, other works have proposed to perform\\nvideo prediction in representations spaces. In some works, the representation space is\\nobtained from a vision pipeline that has been trained in supervised mode, for example to\\nperform semantic segmentation (Luc et al., 2017; Luc et al., 2018). Unfortunately, the\\nrequirement for a pre-trained vision pipeline reduces the general usability of these methods\\nfor learning world models by observation.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 39, 'page_label': '40'}, page_content='requirement for a pre-trained vision pipeline reduces the general usability of these methods\\nfor learning world models by observation.\\nIn the same spirit as JEPA, there have been proposals for automatically learning rep-\\nresentations of video frames so they can be easily predicted. These proposals are generally\\nlimited to learning low-level features, and often use reconstruction through a decoder as a\\nway to prevent collapse (Goroshin et al., 2015a; Srivastava et al., 2015). Some authors have\\n40'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 40, 'page_label': '41'}, page_content='proposed to use temporal invariance (or consistency) to separate the content of an image\\nregion from its instantiation parameters (Wiskott and Sejnowski, 2002; Gregor and LeCun,\\n2010a; Goroshin et al., 2015b).\\nAt least one recent work has applied non-contrastive SSL methods to a joint embedding\\narchitecture for robotics control with some success (Pari et al., 2021; ?).\\nContrastive methods applied to joint-embedding and prediction have been applied suc-\\ncessfully to speech recognition (Baevski et al., 2020) (see (Mohamed et al., 2022) for a recent\\nreview of SSL to speech).\\nTo perform state trajectory predictions, recent works have advocated the use of trans-\\nformers, as proposed in the present paper. Transformers are ideal to represent the dynamics\\nof discrete objects in interaction, and have successfully been applied to the prediction of\\ncar trajectories (Mercat et al., 2020).\\nAn interesting proposal is the trajectory transformer architecture in which a transformer'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 40, 'page_label': '41'}, page_content='car trajectories (Mercat et al., 2020).\\nAn interesting proposal is the trajectory transformer architecture in which a transformer\\nis fed with the sequence of predicted states over an entire episode (Janner et al., 2021). The\\npattern of attention can be constrained so as to force the system to only attend to the\\npast so it can be operated in a causal manner (without looking at the future), and trained\\nto predict the next state, actions, and cost from previously observed or predicted states,\\nactions, and costs.\\nHierarchical planning is a largely unsolved problem. Wayne and Abbott proposed an\\narchitecture that uses a stack of trained forward models that specify intermediate goals for\\nthe lower layers (Wayne and Abbott, 2014). Some recent works specify intermediate goals\\nfor robots in terms of pose parameters (Gehring et al., 2021). A more recent proposal is\\nthe Director system (Hafner et al., 2022) which contains a hierarchical world model and'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 40, 'page_label': '41'}, page_content='for robots in terms of pose parameters (Gehring et al., 2021). A more recent proposal is\\nthe Director system (Hafner et al., 2022) which contains a hierarchical world model and\\nplanning architecture trained end-to-end through reinforcement learning.\\nThe idea of intrinsic motivation to train an agent has been studied in the context of\\nrobotics (Gottlieb et al., 2013). The presence of an Intrinsic Cost provides a diﬀerentiable\\nand eﬃcient way to direct the agent to follow certain behaviors and to learn certain skills.\\n7.2 Energy-Based Models and Joint-Embedding Architectures\\nFor many authors, Energy-Based Model (EBM) designates a probabilistic model whose\\ndistribution is the normalized negative exponential of an energy function.\\nIn this paper, EBM designates a much broader category of models that treat the energy\\nfunction as fundamental, and directly manipulate its landscape through learning. Many\\nmethods have been proposed in the past that directly manipulate the energy. In fact, all'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 40, 'page_label': '41'}, page_content='function as fundamental, and directly manipulate its landscape through learning. Many\\nmethods have been proposed in the past that directly manipulate the energy. In fact, all\\ntraditional optimization-based learning methods can be interpreted as energy-based meth-\\nods (LeCun et al., 2006). In particular, discriminative training methods for structure pre-\\ndiction problems can be formulated as EBM (LeCun et al., 1998; LeCun et al., 2006).\\nMost EBM approaches for unsupervised or self-supervised learning have been con-\\ntrastive. The earliest example is the Boltzmann Machine (Hinton and Sejnowski, 1983),\\nwhich is a probabilistic generative energy-based model trained contrastively.\\nJoint Embedding Architectures (JEA) trained with contrastive methods and mutual\\ninformation maximization methods have a long history. The ﬁrst non-contrastive JEA\\nwas (Becker and Hinton, 1992) which was based on maximizing a measure of mutual in-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 40, 'page_label': '41'}, page_content='information maximization methods have a long history. The ﬁrst non-contrastive JEA\\nwas (Becker and Hinton, 1992) which was based on maximizing a measure of mutual in-\\nformation between the representations from two branches seeing to diﬀerent views of the\\n41'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 41, 'page_label': '42'}, page_content='same scene. Perhaps the ﬁrst contrastive method for JEA is the so-called “Siamese Net-\\nwork” (Bromley et al., 1994). This was trained contrastively for the purpose of verifying\\nsignatures handwritten on a pen tablet.\\nThe idea of JEA remained largely untouched for over a decade, until it was revived in\\na series of papers from my group (Chopra et al., 2005; Hadsell et al., 2006), and Geoﬀrey\\nHinton’s group (Goldberger et al., 2005). Following the rebirth of deep learning, a few\\npapers used JEA for ﬁne-grained recognition, including face recognition (Taigman et al.,\\n2014).\\nWith the emergence of SSL approaches, the use of JEA trained contrastively has ex-\\nploded in the last few years with methods such as PIRL (Misra and Maaten, 2020), MoCo\\nand MoCo-v2 (He et al., 2020; Chen et al., 2020b), and SimCLR (Chen et al., 2020a).\\nSome methods can be seen as “distillation” approaches in which one branch of the\\nSiamese network is a teacher whose output are used as targets for the other branch. This'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 41, 'page_label': '42'}, page_content='Some methods can be seen as “distillation” approaches in which one branch of the\\nSiamese network is a teacher whose output are used as targets for the other branch. This\\nincludes methods in which the output vectors are quantized to discrete cluster prototypes\\n(see (Caron et al., 2020) and predecessors).\\nIn recent years, a number of new non-contrastive methods have appeared, such as\\nBYOL (Grill et al., 2020). But the class of non-contrastive methods advocated in the\\npresent proposal prevent collapse by maximizing the information content of the embed-\\ndings. This includes Barlow Twins (Zbontar et al., 2021), VICReg (Bardes et al., 2021),\\nwhitening-based methods (Ermolov et al., 2021), and Maximum Coding Rate Reduction\\nmethods (see (Dai et al., 2022) and references therein).\\n7.3 Human and animal cognition\\nThe limitations of current approaches to machine learning when compared with human\\nlearning are obvious (Lake et al., 2017a; Zaadnoordijk et al., 2022).'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 41, 'page_label': '42'}, page_content='7.3 Human and animal cognition\\nThe limitations of current approaches to machine learning when compared with human\\nlearning are obvious (Lake et al., 2017a; Zaadnoordijk et al., 2022).\\nYoung children quickly learn abstract concepts (Murphy, 2002), and models that allow\\nthem to navigate, to form goals, and to plan complex action sequences to fulﬁll them (Gopnik\\nand Meltzoﬀ, 1997; Spelke and Kinzler, 2007; Carey, 2009; Gopnik et al., 2001).\\nIn cognitive science, the idea that the brain builds predictive world models is a common\\none, and have inspired attempt to reproduce the process in machines (Lake et al., 2017b;\\nOrhan et al., 2020). Some eﬀorts have been devoted to building video datasets to test\\nintuitive physics common sense in machines and infants (Riochet et al., 2019).\\nThe ability to plan is a well-studied feature of human intelligence (Mattar and Lengyel,\\n2022). There is evidence that people construct simpliﬁed representations of the world for'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 41, 'page_label': '42'}, page_content='The ability to plan is a well-studied feature of human intelligence (Mattar and Lengyel,\\n2022). There is evidence that people construct simpliﬁed representations of the world for\\nplanning in which irrelevant details are abstracted away (Ho et al., 2022)\\nConsciousness is a rather speculative topic, owing to the diﬃculty of deﬁning what con-\\nsciousness is. I will not speculate about whether some version of the proposed architecture\\ncould possess a property assimilable to consciousness, but will only mention the work of\\nDehaene and collaborators who have proposed two types of consciousness that they call\\nC1 and C2. C1 is largely related with the modulation of attention, while C2 requires a\\nself-monitoring ability, perhaps assimilable to what the conﬁgurator module needs to do in\\nthe present proposal (Dehaene et al., 2021).\\n42'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 42, 'page_label': '43'}, page_content='8 Discussion, Limitations, Broader Relevance\\nConstructing the cognitive architecture of the present proposal, instantiating all the details,\\nand making the system work for non-trivial tasks will not be an easy task. The path to\\nsuccess is likely riddled with unforeseen obstacles. It will probably take many years to work\\nthem all out.\\n8.1 What is missing from the Proposed Model?\\nA lot of hard work needs to be done to instantiate the proposed architecture and turn it\\ninto a functional system. There may be ﬂaws and pitfalls that may appear to be unsolvable\\nwithin the speciﬁcations of the proposed architecture.\\nThe ﬁrst question is whether a Hierarchical JEPA can be built and trained from videos.\\nCould it learn the type of abstract concept hierarchy mentioned in section 4.1?\\nOne somewhat open question relative to the JEPA is how precisely to regularize the\\nlatent variable so as to minimize its information content. A number of possible mechanisms'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 42, 'page_label': '43'}, page_content='One somewhat open question relative to the JEPA is how precisely to regularize the\\nlatent variable so as to minimize its information content. A number of possible mechanisms\\nare proposed: making the latent variable discrete, low-dimensional, sparse, or stochastic.\\nBut it is not clear which approach will ultimately be the best.\\nThe current proposal does not prescribe a particular way for the actor to infer latent\\nvariable instantiations and optimal action sequences. While the diﬀerentiability of all the\\nmodules makes it possible in principle to use gradient-based optimization to infer optimal\\naction sequences, the optimization problem may be very diﬃcult in practice. In particular,\\nwhen the action space is discrete, or when the function from actions to cost is highly non\\nsmooth, gradient-based method may be ineﬀective, requiring to use other (gradient-free)\\nsearch methods (dynamic programming, belief propagation, MCTS, SAT, etc).'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 42, 'page_label': '43'}, page_content='smooth, gradient-based method may be ineﬀective, requiring to use other (gradient-free)\\nsearch methods (dynamic programming, belief propagation, MCTS, SAT, etc).\\nInstantiating multiple conﬁgurations of latent variables in Mode-2 planning/reasoning\\nmay require additional mechanisms not described in the present proposal. Humans seem\\nto be endowed with an ability to spontaneously cycle through alternative interpretations\\nof a percept, as demonstrated by the Necker cube and other visual illusions that have\\nseveral equally-plausible interpretations. In the context of the present model, diﬀerent\\ninterpretation of an ambiguous percept may be represented by diﬀerent values of a latent\\nvariable. While one could imagine a number of exploratory mechanisms to systematically\\nexplore the space of possible latent variable values, no such mechanism is described here.\\nThe present proposal does not specify the details of the architecture of the various'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 42, 'page_label': '43'}, page_content='explore the space of possible latent variable values, no such mechanism is described here.\\nThe present proposal does not specify the details of the architecture of the various\\nmodules. For example, it is probable that the predictor will require some sort of dynamic\\nrouting and gating circuits in its micro-architecture. Predictors for low-level representation\\nmay have to be specialized to represent the kind of small transformations of the repre-\\nsentation that can occur in the short term. Predictor modules dealing with higher level\\nrepresentations may require more generic architectures that manipulate objects and their\\nrelationships. But none of this is speciﬁed in the present proposal.\\nSimilarly, the precise architecture and function of the short-term memory and how it\\nmay be used to represent beliefs about the state of the world are somewhat fuzzy. The\\noriginal Memory Network system and its successors contained the idea that a neural net'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 42, 'page_label': '43'}, page_content='may be used to represent beliefs about the state of the world are somewhat fuzzy. The\\noriginal Memory Network system and its successors contained the idea that a neural net\\ncould use an associative memory as a working memory to store and retrieve beliefs about\\nthe state of the world between compute cycles (Bordes et al., 2015; Sukhbaatar et al.,\\n43'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 43, 'page_label': '44'}, page_content='2015). But getting such an architecture to work for complex planning and control may\\nprove diﬃcult.\\nOf all the least understood aspects of the current proposal, the conﬁgurator module is the\\nmost mysterious. In particular, while planning a complex task, the conﬁgurator is supposed\\nto identify sequences of subgoals and conﬁgure the agent to successively accomplish those\\nsubgoals. Precisely how to do that is not speciﬁed.\\nThis is merely a list of foreseeable questions, but many questions and problems will\\ninevitably surface as instances of the proposed systems are put together.\\n8.2 Broader Relevance of the Proposed Approach\\nAlthough the proposed architecture is not speciﬁcally designed to model autonomous intel-\\nligence, reasoning, and learning in humans and other animals, one can draw some parallels.\\nThe following is somewhat speculative and provided as a way to connect some concepts\\nin cognitive science and neuroscience that have inspired the present work.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 43, 'page_label': '44'}, page_content='The following is somewhat speculative and provided as a way to connect some concepts\\nin cognitive science and neuroscience that have inspired the present work.\\n8.2.1 Could this Architecture be the Basis of a Model of Animal Intelligence?\\nMany of the modules in the proposed architecture have counterparts in the mammalian\\nbrain that perform similar functions.\\nThe perception module corresponds to the visual, auditory, and other sensory areas\\nof the cortex, as well as some of the association areas. The world model and the critic\\ncorrespond to various part of the prefrontal cortex. The intrinsic cost module corresponds\\nto structures in the basal ganglia involved in rewards, including the amygdala. The trainable\\ncritic may correspond to part of the prefrontal cortex involved in reward prediction. The\\nfunction of the short-term memory overlaps with what is known of the hippocampus. The\\nconﬁgurator may correspond to structures in the prefrontal cortex that perform executive'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 43, 'page_label': '44'}, page_content='function of the short-term memory overlaps with what is known of the hippocampus. The\\nconﬁgurator may correspond to structures in the prefrontal cortex that perform executive\\ncontrol and modulate attention. The actor regroups areas in the pre-motor cortex that\\nelaborate and encode motor plans.\\nThe idea of predictive world model has long been a prominent concept in cognitive\\nscience, and the idea of predictive coding has been a prominent concept in neuroscience. The\\nJEPA architecture and the corresponding non-sample-contrastive self-supervised learning\\nmethod are somewhat consistent with ideas of predictive coding and eﬃcient coding.\\nThe proposed architecture has a single world model engine that can be conﬁgured for\\nthe task at hand by the conﬁgurator. I have argued that this may not only confer a\\ncomputational advantage through hardware reuse, but also allow knowledge to be shared\\nacross multiple tasks. The hypothesis of a single, conﬁgurable world model engine in the'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 43, 'page_label': '44'}, page_content='computational advantage through hardware reuse, but also allow knowledge to be shared\\nacross multiple tasks. The hypothesis of a single, conﬁgurable world model engine in the\\nhuman brain may explain why humans can essentially perform a single “conscious” reasoning\\nand planning task at a time. A highly-speculative idea is that the illusion of consciouness\\nmay be a side-eﬀect of a conﬁgurator-like module in the brain that oversees the function\\nof the rest of brain and conﬁgures it for the task at hand. Perhaps if the brain were large\\nenough to contain many independent, non-conﬁgurable world models, a conﬁgurator would\\nbe unnecessary, and the illusion of consciousness would disappear.\\nWhat is the substrate of emotions in animals and humans? Instantaneous emotions (e.g.\\npain, pleasure, hunger, etc) may be the result of brain structures that play a role similar\\nto the Intrinsic Cost module in the proposed architecture. Other emotions such as fear or\\n44'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 44, 'page_label': '45'}, page_content='elation may be the result of anticipation of outcome by brain structures whose function is\\nsimilar to the Trainable Critic.\\nThe presence of a cost module that drives the behavior of the agent by searching for\\noptimal actions suggests that autonomous intelligent agents of the type proposed here will\\ninevitably possess the equivalent of emotions. In an analogous way to animal and humans,\\nmachine emotions will be the product of an intrinsic cost, or the anticipation of outcomes\\nfrom a trainable critic.\\n8.2.2 Could this be a Path towards Machine Common Sense?\\nIt is a widely-held opinion that none of the current AI systems possess any level of common\\nsense, even at the level that can be observed in a house cat. Animals seem to be able to\\nacquire enough background knowledge about how the world works to exhibit some level\\nof common sense. By contrast, AI systems, even when (pre-)trained with self-supervised\\nmode (e.g. from text) seem to exhibit very limited levels of common sense, making them'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 44, 'page_label': '45'}, page_content='of common sense. By contrast, AI systems, even when (pre-)trained with self-supervised\\nmode (e.g. from text) seem to exhibit very limited levels of common sense, making them\\nsomewhat brittle.\\nFor example, Large language models (LLMs) seem to possess a surprisingly large amount\\nof background knowledge extracted from written text. But much of human common-sense\\nknowledge is not represented in any text and results from our interaction with the physical\\nworld. Because LLMs have no direct experience with an underlying reality, the type of\\ncommon-sense knowledge they exhibit is very shallow and can be disconnected from reality.\\nA possible characterization of common sense is the ability to use models of the world\\nto ﬁll in blanks, for example predicting the future, or more generally ﬁlling in information\\nabout the world that is unavailable from perception or from memory. With this deﬁnition,\\ncommon sense is an ability that emerges from a collection of models of the world or from'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 44, 'page_label': '45'}, page_content='about the world that is unavailable from perception or from memory. With this deﬁnition,\\ncommon sense is an ability that emerges from a collection of models of the world or from\\na single model engine conﬁgurable to handle the situation at hand. This view of common\\nsense sits squarely in the camp of “grounded intelligence”: common sense is a collection of\\nmodels from low-levels of abstraction to high levels, all the way up to knowledge acquired\\nthrough language.\\nCould SSL applied to conﬁgurable H-JEPA constitute the substrate of machine common\\nsense? Could a properly-trained and conﬁgured H-JEPA embed enough predictive knowl-\\nedge and capture enough dependencies about the world to exhibit some level of common\\nsense?\\nI speculate that common sense may emerge from learning world models that capture the\\nself-consistency and mutual dependencies of observations in the world, allowing an agent to\\nﬁll in missing information and detect violations of its world model.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 44, 'page_label': '45'}, page_content='self-consistency and mutual dependencies of observations in the world, allowing an agent to\\nﬁll in missing information and detect violations of its world model.\\n8.3 Is it all about scaling? Is reward really enough?\\nThe section reviews a few potential paths towards human-level intelligence that have been\\nproposed in recent years. The surprising power of large transformer architectures trained\\nto predict text and other modalities have led some to claim that we merely need to scale up\\nthose models (Brown et al., 2020; Brown et al., 2020). The surprising power of reinforcement\\nlearning for games and other simple environments have led other to claim that reward is\\nenough (Silver et al., 2021). ﬁnally, the limitations of current deep-learning systems when it\\n45'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 45, 'page_label': '46'}, page_content='comes to reasoning have led some to claim that deep learning systems need to be augmented\\nby hard-wired circuitry to enable symbol manipulation (Marcus and Davis, 2019)\\n8.3.1 Scaling is not enough\\nLarge Language Models (LLMs), and more generally, large-scale transformer architectures\\ntrained with a form of generative self-supervised learning, have been astonishingly successful\\nat capturing knowledge present in text. This has led to a debate in the AI community as\\nto whether human-level AI can be attained by scaling up these architectures. My position\\nin this debate is that I do not believe that scaling is enough for two main reasons.\\nFirst, current models operate on “tokenized” data and are generative. Every input\\nmodality must be turned into a sequence (or a collection) of “tokens” encoded as vectors.\\nWhile this works well for text, which is already a sequence of discrete tokens, it is less\\nsuitable for continuous, high dimensional signals such as video. The type of SSL training'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 45, 'page_label': '46'}, page_content='While this works well for text, which is already a sequence of discrete tokens, it is less\\nsuitable for continuous, high dimensional signals such as video. The type of SSL training\\nused for LLM-style models can be seen as a particular kind of latent-free generative model\\ntrained with a particular kind of contrastive method called denoising auto-encoder (Vincent\\net al., 2010), or in this case masked auto-encoder (Devlin et al., 2018). Hence, they are\\nsubject to the limitations of generative models, latent-variable free models, and contrastive\\nmethods. Generative models have diﬃculty representing complex uncertainties in contin-\\nuous spaces. LLMs simplify the representation of uncertainty in the prediction by only\\ndealing with discrete objects from a ﬁnite collection (e.g. words from a dictionary). Repre-\\nsenting uncertainty about a word being predicted comes down to producing a vector whose\\ncomponents are scores or probabilities for each word (or discrete token) in the dictionary.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 45, 'page_label': '46'}, page_content='senting uncertainty about a word being predicted comes down to producing a vector whose\\ncomponents are scores or probabilities for each word (or discrete token) in the dictionary.\\nBut this approach doesn’t work for high-dimensional continuous modalities, such as video.\\nTo represent such data, it is necessary to eliminate irrelevant information about the variable\\nto be modeled through an encoder, as in the JEPA. Furthermore, the high-dimensionality\\nof the signal precludes the representation of uncertainty through a normalized distribution.\\nSecond, current models are only capable of very limited forms of reasoning. The absence\\nof abstract latent variables in these models precludes the exploration of multiple interpre-\\ntations of a percept and the search for optimal courses of action to achieve a goal. In fact,\\ndynamically specifying a goal in such models is essentially impossible.\\n8.3.2 Reward is not enough'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 45, 'page_label': '46'}, page_content='tations of a percept and the search for optimal courses of action to achieve a goal. In fact,\\ndynamically specifying a goal in such models is essentially impossible.\\n8.3.2 Reward is not enough\\nThe proposed architecture is designed to minimize the number of actions a system needs\\nto take in the real world to learn a task. It does so by learning a world model that capture\\nas much knowledge about the world as possible without taking actions in the world. It uses\\nintrinsic costs that are diﬀerentiable functions of measured or predicted world states. This\\nmakes the proposal more similar to optimal control than to reinforcement learning. In the\\nproposed model, much of learning takes place at the level of the world model (perceptual\\nencoder and predictor). In this context, what is the role of reinforcement learning (RL)?\\nIn most RL settings the reward (or the cost, which is a negative reward) is fed to the'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 45, 'page_label': '46'}, page_content='encoder and predictor). In this context, what is the role of reinforcement learning (RL)?\\nIn most RL settings the reward (or the cost, which is a negative reward) is fed to the\\nagent by the environment. In other words, Intrinsic Cost module is the environment itself,\\nand is therefore an unknown function. The value of the function can be probed by observing\\nthe state of the world, taking an action, and observing the resulting reward. The gradient\\nof the reward with respect to the action or the state is unknown and must be estimated by\\n46'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 46, 'page_label': '47'}, page_content='multiple action trials as in policy gradient methods. In Actor-Critic methods, the reward\\nfunction is approximated by a critic module that is trained to approximate expected future\\nvalues of the reward. The critic provides a diﬀerentiable approximation of the reward\\nfunction.\\nBut model-free RL is extremely sample-ineﬃcient, at least when compared with human\\nand animal learning, requiring very large numbers of trials to learn a skill. Scalar rewards\\nprovide low-information feedback to a learning system. As a consequence, a pure RL system\\nrequires a very large number of trials to learn even relatively simple tasks. Model-based\\nRL clearly has the potential of being considerably more sample eﬃcient. But the question\\nbecomes how to train the world model: is it trained from taking actions and getting rewards,\\nor is it trained by predicting the world state? In the latter case,reward is clearly not enough:'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 46, 'page_label': '47'}, page_content='becomes how to train the world model: is it trained from taking actions and getting rewards,\\nor is it trained by predicting the world state? In the latter case,reward is clearly not enough:\\nmost of the parameters in the systems are trained to predict large amounts of observations\\nin the world. Contrary to the title of a recent position paper by Silver et al. (Silver et al.,\\n2021), the reward plays a relatively minor role in this scenario.\\n8.3.3 Do We Need Symbols for Reasoning?\\nIn the proposed architecture, reasoning comes down to energy minimization or constraint\\nsatisfaction by the actor using various search methods to ﬁnd a suitable combination of\\nactions and latent variables, as stated in Section 3.1.4.\\nIf the actions and latent variables are continuous, and if the predictor and the cost\\nmodules are diﬀerentiable and relatively well behaved, one can use gradient-based methods\\nto perform the search. But there may be situations where the predictor output changes'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 46, 'page_label': '47'}, page_content='modules are diﬀerentiable and relatively well behaved, one can use gradient-based methods\\nto perform the search. But there may be situations where the predictor output changes\\nquickly as a function of the action, and where the action space is essentially discontinuous.\\nThis is likely to occur at high levels of abstractions where choices are more likely to be\\nqualitative. A high-level decision for a self-driving car may correspond to “turning left or\\nright at the fork”, while the low-level version would be a sequence of wheel angles.\\nIf the action space is discrete with low cardinality, the actor may use exhaustive search\\nmethods. If the action set cardinality, and hence the branching factor, are too large, the\\nactor may have to resort to heuristic search methods, including Monte-Carlo Tree Search,\\nor other gradient-free methods. If the cost function satisﬁed Bellman’s equations, one may\\nuse dynamic programming.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 46, 'page_label': '47'}, page_content='or other gradient-free methods. If the cost function satisﬁed Bellman’s equations, one may\\nuse dynamic programming.\\nBut the eﬃciency advantage of gradient-based search methods over gradient-free search\\nmethods motivates us to ﬁnd ways for the world-model training procedure to ﬁnd hierar-\\nchical representations with which the planning/reasoning problem constitutes a continuous\\nrelaxation of an otherwise discrete problem.\\nA remain question is whether the type of reasoning proposed here can encompass all\\nforms of reasoning that humans and animals are capable of.\\nAcknowledgments\\nIdeas in this paper are a distillation of years of interactions with many people. It is impos-\\nsible to list them all here.\\nI will list some of the more salient ones: L´ eon Bottou, Yoshua Bengio, Geoﬀrey Hinton,\\nRob Fergus, and Jitendra Malick; Emmanuel Dupoux and Stanislas Dehaene; Mikael Henaﬀ,\\n47'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 47, 'page_label': '48'}, page_content='Alfredo Canziani, and Nicolas Carion at NYU; Li Jing, Yubei Chen, Randall Balestriero,\\nand St´ ephane Deny at FAIR; Vlad Sobal, Jiachen Zhu, and Katrina Evtimova at NYU.\\nI am thankful to the following colleagues for their comments on the manuscript: Olivier\\nDelalleau, Gus Xia, Yoshua Bengio, and Emmanuel Dupoux.\\n48'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 48, 'page_label': '49'}, page_content='References\\nAgrawal, P., Nair, A., Abbeel, P., Malik, J., and Levine, S. (2016). Learning to poke by\\npoking: Experiential learning of intuitive physics. CoRR, abs/1606.07419.\\nBabaeizadeh, M., Finn, C., Erhan, D., Campbell, R. H., and Levine, S. (2017). Stochastic\\nvariational video prediction. CoRR, abs/1710.11252.\\nBaevski, A., Zhou, Y., Mohamed, A., and Auli, M. (2020). wav2vec 2.0: A framework for\\nself-supervised learning of speech representations. In Larochelle, H., Ranzato, M., Had-\\nsell, R., Balcan, M., and Lin, H., editors, Advances in Neural Information Processing\\nSystems, volume 33, pages 12449–12460. Curran Associates, Inc.\\nBardes, A., Ponce, J., and LeCun, Y. (2021). Vicreg: Variance-invariance-covariance regu-\\nlarization for self-supervised learning. In International Conference on Learning Repre-\\nsentations (ICLR 2022) . arXiv preprint arXiv:2105.04906.\\nBattaglia, P., Pascanu, R., Lai, M., Jimenez Rezende, D., et al. (2016). Interaction net-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 48, 'page_label': '49'}, page_content='sentations (ICLR 2022) . arXiv preprint arXiv:2105.04906.\\nBattaglia, P., Pascanu, R., Lai, M., Jimenez Rezende, D., et al. (2016). Interaction net-\\nworks for learning about objects, relations and physics. Advances in neural information\\nprocessing systems, 29.\\nBecker, S. and Hinton, G. E. (1992). Self-organizing neural network that discovers surfaces\\nin random-dot stereograms. Nature, 355(6356):161–163.\\nBertsekas, D. (2019). Reinforcement learning and optimal control. Athena Scientiﬁc.\\nBordes, A., Usunier, N., Chopra, S., and Weston, J. (2015). Large-scale simple question\\nanswering with memory networks. arXiv:1506.02075.\\nBromley, J., Guyon, I., LeCun, Y., Sackinger, E., and Shah, R. (1994). Signature veriﬁcation\\nusing a “siamese” time delay neural network. In NeurIPS.\\nBrown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., Neelakantan,\\nA., Shyam, P., Sastry, G., Askell, A., Agarwal, S., Herbert-Voss, A., Krueger, G.,'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 48, 'page_label': '49'}, page_content='Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., Neelakantan,\\nA., Shyam, P., Sastry, G., Askell, A., Agarwal, S., Herbert-Voss, A., Krueger, G.,\\nHenighan, T., Child, R., Ramesh, A., Ziegler, D., Wu, J., Winter, C., Hesse, C., Chen,\\nM., Sigler, E., Litwin, M., Gray, S., Chess, B., Clark, J., Berner, C., McCandlish,\\nS., Radford, A., Sutskever, I., and Amodei, D. (2020). Language models are few-\\nshot learners. In Larochelle, H., Ranzato, M., Hadsell, R., Balcan, M., and Lin, H.,\\neditors, Advances in Neural Information Processing Systems , volume 33, pages 1877–\\n1901. Curran Associates, Inc.\\nBryson, A. and Ho, Y. (1969). Applied optimal control. Blaisdell, Waltham, MA.\\nCarey, S. (2009). The Origin of Concepts . Oxford University Press, New York, New York,\\nUSA.\\nCarion, N., Massa, F., Synnaeve, G., Usunier, N., Kirillov, A., and Zagoruyko, S. (2020).\\nEnd-to-end object detection with transformers. In 16th European Conference, Glasgow,\\nUK (ECCV 2020) , page 213–229.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 48, 'page_label': '49'}, page_content='End-to-end object detection with transformers. In 16th European Conference, Glasgow,\\nUK (ECCV 2020) , page 213–229.\\n49'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 49, 'page_label': '50'}, page_content='Caron, M., Misra, I., Mairal, J., Goyal, P., Bojanowski, P., and Joulin, A. (2020). Unsu-\\npervised learning of visual features by contrasting cluster assignments. In Advances in\\nNeural Information Processing Systems.\\nCarreira-Perpi˜ n´ an, M. A. and Hinton, G. (2005). On contrastive divergence learning. In\\nCowell, R. G. and Ghahramani, Z., editors, Proceedings of the Tenth International\\nWorkshop on Artiﬁcial Intelligence and Statistics, volume R5 ofProceedings of Machine\\nLearning Research, pages 33–40. PMLR. Reissued by PMLR on 30 March 2021.\\nChen, T., Kornblith, S., Swersky, K., Norouzi, M., and Hinton, G. (2020a). Big self-\\nsupervised models are strong semi-supervised learners. In NeurIPS.\\nChen, X., Fan, H., Girshick, R., and He, K. (2020b). Improved baselines with momentum\\ncontrastive learning. arXiv preprint arXiv:2003.04297 .\\nChopra, S., Hadsell, R., and LeCun, Y. (2005). Learning a similarity metric discriminatively,'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 49, 'page_label': '50'}, page_content='contrastive learning. arXiv preprint arXiv:2003.04297 .\\nChopra, S., Hadsell, R., and LeCun, Y. (2005). Learning a similarity metric discriminatively,\\nwith application to face veriﬁcation. In 2005 IEEE Computer Society Conference on\\nComputer Vision and Pattern Recognition (CVPR’05), volume 1, pages 539–546. IEEE.\\nChua, K., Calandra, R., McAllister, R., and Levine, S. (2018). Deep reinforcement learning\\nin a handful of trials using probabilistic dynamics models. CoRR, abs/1805.12114.\\nCraik, K. J. W. (1943). The nature of explanation . University Press, Macmillan.\\nDai, X., Tong, S., Li, M., Wu, Z., Psenka, M., Chan, K. H. R., Zhai, P., Yu, Y., Yuan,\\nX., Shum, H.-Y., and Ma, Y. (2022). Ctrl: Closed-loop transcription to an ldr via\\nminimaxing rate reduction. Entropy, 24(4):456.\\nDehaene, S., Lau, H., and Kouider, S. (2021). What is consciousness, and could machines\\nhave it? Robotics, AI, and Humanity , pages 43–56.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 49, 'page_label': '50'}, page_content='minimaxing rate reduction. Entropy, 24(4):456.\\nDehaene, S., Lau, H., and Kouider, S. (2021). What is consciousness, and could machines\\nhave it? Robotics, AI, and Humanity , pages 43–56.\\nDenton, E. and Fergus, R. (2018). Stochastic video generation with a learned prior. arXiv\\npreprint arXiv 1802.07687 .\\nDevlin, J., Chang, M.-W., Lee, K., and Toutanova, K. (2018). Bert: Pre-training\\nof deep bidirectional transformers for language understanding. arXiv preprint\\narXiv:1810.04805.\\nDoi, E., Balcan, D. C., and Lewicki, M. S. (2007). Robust coding over noisy overcomplete\\nchannels. IEEE Transactions on Image Processing, 16(2):442–452.\\nErmolov, A., Siarohin, A., Sangineto, E., and Sebe, N. (2021). Whitening for self-supervised\\nrepresentation learning.\\nEvtimova, K. and LeCun, Y. (2022). Sparse coding with multi-layer decoders using variance\\nregularization. arXiv:2112.09214.\\nFinn, C., Goodfellow, I. J., and Levine, S. (2016). Unsupervised learning for physical'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 49, 'page_label': '50'}, page_content='regularization. arXiv:2112.09214.\\nFinn, C., Goodfellow, I. J., and Levine, S. (2016). Unsupervised learning for physical\\ninteraction through video prediction. CoRR, abs/1605.07157.\\n50'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 50, 'page_label': '51'}, page_content='Finn, C. and Levine, S. (2017). Deep visual foresight for planning robot motion. In 2017\\nIEEE International Conference on Robotics and Automation (ICRA), pages 2786–2793.\\nIEEE.\\nFragkiadaki, K., Agrawal, P., Levine, S., and Malik, J. (2015). Learning visual predictive\\nmodels of physics for playing billiards. CoRR, abs/1511.07404.\\nGehring, J., Synnaeve, G., Krause, A., and Usunier, N. (2021). Hierarchical skills for eﬃcient\\nexploration. Advances in Neural Information Processing Systems , 34:11553–11564.\\nGoldberger, J., S.Roweis, Hinton, G., and Salakhutdinov, R. (2005). Neighbourhood com-\\nponents analysis. In Saul, L. K., Weiss, Y., and Bottou, L., editors, Advances in Neural\\nInformation Processing Systems 17 , pages 513–520. MIT Press, Cambridge, MA.\\nGoodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville,\\nA., and Bengio, Y. (2014). Generative adversarial nets. In Advances in Neural Infor-\\nmation Processing Systems, pages 2672–2680.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 50, 'page_label': '51'}, page_content='A., and Bengio, Y. (2014). Generative adversarial nets. In Advances in Neural Infor-\\nmation Processing Systems, pages 2672–2680.\\nGopnik, A. and Meltzoﬀ, A. N. (1997). Words, Thoughts, and Theories . MIT Press,\\nCambridge, MA.\\nGopnik, A., Meltzoﬀ, A. N., and Kuhl, P. K. (2001). The Scientist in the Crib: What Early\\nLearning Tells Us About the Mind . Perennial, New York, NY.\\nGoroshin, R., Bruna, J., Tompson, J., Eigen, D., and LeCun, Y. (2015a). Unsupervised\\nfeature learning from temporal data. In International Conference on Computer Vision\\n(ICCV 2015).\\nGoroshin, R., Mathieu, M., and LeCun, Y. (2015b). Learning to linearize under uncertainty.\\nIn Advances in Neural Information Processing Systems (NIPS 2015) , volume 28.\\nGottlieb, J., Oudeyer, P. Y., Lopes, M., and Baranes, A. (2013). Information-seeking,\\ncuriosity, and attention: Computational and neural mechanisms. Trends in Cognitive\\nSciences, 17:585–593.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 50, 'page_label': '51'}, page_content='Gottlieb, J., Oudeyer, P. Y., Lopes, M., and Baranes, A. (2013). Information-seeking,\\ncuriosity, and attention: Computational and neural mechanisms. Trends in Cognitive\\nSciences, 17:585–593.\\nGregor, K. and LeCun, Y. (2010a). Emergence of complex-like cells in a temporal product\\nnetwork with local receptive ﬁelds. arXiv preprint arXiv:1006.0448 .\\nGregor, K. and LeCun, Y. (2010b). Learning fast approximations of sparse coding. In Proc.\\nInternational Conference on Machine learning (ICML’10) .\\nGrill, J.-B., Strub, F., Altch´ e, F., Tallec, C., Richemond, P. H., Buchatskaya, E., Doersch,\\nC., Pires, B. A., Guo, Z. D., Azar, M. G., Piot, B., Kavukcuoglu, K., Munos, R.,\\nand Valko, M. (2020). Bootstrap your own latent: A new approach to self-supervised\\nlearning. In NeurIPS.\\nHa, D. and Schmidhuber, J. (2018a). Recurrent world models facilitate policy evolution. In\\nBengio, S., Wallach, H., Larochelle, H., Grauman, K., Cesa-Bianchi, N., and Garnett,'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 50, 'page_label': '51'}, page_content='learning. In NeurIPS.\\nHa, D. and Schmidhuber, J. (2018a). Recurrent world models facilitate policy evolution. In\\nBengio, S., Wallach, H., Larochelle, H., Grauman, K., Cesa-Bianchi, N., and Garnett,\\nR., editors, Advances in Neural Information Processing Systems , volume 31.\\n51'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 51, 'page_label': '52'}, page_content='Ha, D. and Schmidhuber, J. (2018b). World models. arXiv preprint arXiv:1803.10122 .\\nHadsell, R., Chopra, S., and LeCun, Y. (2006). Dimensionality reduction by learning an\\ninvariant mapping. In CVPR.\\nHafner, D., Lee, K.-H., Fischer, I., and Abbeel, P. (2022). Deep hierarchical planning from\\npixels. arXiv preprint arXiv:2206.04114 .\\nHafner, D., Lillicrap, T., Fischer, I., Villegas, R., Ha, D., Lee, H., and Davidson, J. (2018).\\nLearning latent dynamics for planning from pixels. arXiv 1811.04551.\\nHafner, D., Lillicrap, T., Norouzi, M., and Ba, J. (2020). Mastering atari with discrete\\nworld models. arXiv preprint arXiv:2010.02193 .\\nHe, K., Fan, H., Wu, Y., Xie, S., and Girshick, R. (2020). Momentum contrast for unsu-\\npervised visual representation learning. In CVPR.\\nHenaﬀ, M., Canziani, A., and LeCun, Y. (2019). Model-predictive policy learning with\\nuncertainty regularization for driving in dense traﬃc. In ICLR-19. arXiv:1901.02705.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 51, 'page_label': '52'}, page_content='Henaﬀ, M., Canziani, A., and LeCun, Y. (2019). Model-predictive policy learning with\\nuncertainty regularization for driving in dense traﬃc. In ICLR-19. arXiv:1901.02705.\\nHenaﬀ, M., Weston, J., Szlam, A., Bordes, A., and LeCun, Y. (2017). Tracking the world\\nstate with recurrent entity networks. In International Conference on Learning Repre-\\nsentations (ICLR 2017) .\\nHinton, G. and Sejnowski, T. (1983). Optimal perceptual inference. In Proceedings of\\nthe IEEE Conference on Computer Vision and Pattern Recognition , pages 448–453,\\nWashington 1983. IEEE, New York.\\nHo, M. K., Abel, D., Correa, C. G., Littman, M. L., Cohen, J. D., and Griﬃths, T. L. (2022).\\nPeople construct simpliﬁed mental representations to plan. Nature, 606(7912):129–136.\\nH´ enaﬀ, O. J., Srinivas, A., De Fauw, J., Razavi, A., Doersch, C., Eslami, S. M. A., and\\nvan den Oord, A. (2019). Data-eﬃcient image recognition with contrastive predictive\\ncoding. In ICML.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 51, 'page_label': '52'}, page_content='H´ enaﬀ, O. J., Srinivas, A., De Fauw, J., Razavi, A., Doersch, C., Eslami, S. M. A., and\\nvan den Oord, A. (2019). Data-eﬃcient image recognition with contrastive predictive\\ncoding. In ICML.\\nJanner, M., Li, Q., and Levine, S. (2021). Oﬄine reinforcement learning as one big sequence\\nmodeling problem. In Advances in Neural Information Processing Systems .\\nJing, L., Zbontar, J., et al. (2020). Implicit rank-minimizing autoencoder. Advances in\\nNeural Information Processing Systems, 33:14736–14746.\\nJordan, M. I. and Rumelhart, D. E. (1992). Forward models: Supervised learning with a\\ndistal teacher. Cognitive science, 16(3):307–354.\\nKahneman, D. (2011). Thinking, fast and slow . Macmillan.\\nKingma, D. P. and Welling, M. (2013). Auto-encoding variational bayes. arXiv preprint\\narXiv:1312.6114.\\nLake, B. M., Ullman, T. D., Tenenbaum, J. B., and Gershman, S. J. (2017a). Building\\nmachines that learn and think like people. Behavioral and brain sciences , 40.\\n52'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 52, 'page_label': '53'}, page_content='Lake, B. M., Ullman, T. D., Tenenbaum, J. B., and Gershman, S. J. (2017b). Building\\nmachines that learn and think like people. Behavioral and Brain Sciences , 40:E253.\\nLeCun, Y., Bottou, L., Bengio, Y., and Haﬀner, P. (1998). Gradient-based learning applied\\nto document recognition. Proceedings of the IEEE, 86(11):2278–2324.\\nLeCun, Y., Chopra, S., Hadsell, R., Ranzato, M., and Huang, F. (2006). A tutorial on\\nenergy-based learning. In Bakir, G., Hofman, T., Sch¨ olkopf, B., Smola, A., and Taskar,\\nB., editors, Predicting Structured Data. MIT Press.\\nLerer, A., Gross, S., and Fergus, R. (2016). Learning physical intuition of block towers by\\nexample. In Proceedings of the 33nd International Conference on Machine Learning,\\nICML 2016, New York City, NY, USA, June 19-24, 2016 , pages 430–438.\\nLevine, S. (2021). Understanding the world through action. arXiv:2110.12543. https:\\n//arxiv.org/abs/2110.12543.\\nLuc, P., Clark, A., Dieleman, S., Casas, D. d. L., Doron, Y., Cassirer, A., and Simonyan, K.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 52, 'page_label': '53'}, page_content='//arxiv.org/abs/2110.12543.\\nLuc, P., Clark, A., Dieleman, S., Casas, D. d. L., Doron, Y., Cassirer, A., and Simonyan, K.\\n(2020). Transformation-based adversarial video prediction on large-scale data. arXiv\\npreprint arXiv:2003.04035.\\nLuc, P., Couprie, C., Lecun, Y., and Verbeek, J. (2018). Predicting future instance segmen-\\ntation by forecasting convolutional features. In Proceedings of the european conference\\non computer vision (ECCV) , pages 584–599.\\nLuc, P., Neverova, N., Couprie, C., Verbeek, J., and LeCun, Y. (2017). Predicting deeper\\ninto the future of semantic segmentation. In Proceedings of the IEEE international\\nconference on computer vision, pages 648–657.\\nMarcus, G. and Davis, E. (2019). Rebooting AI: Building artiﬁcial intelligence we can trust .\\nVintage.\\nMathieu, M., Couprie, C., and LeCun, Y. (2015). Deep multi-scale video prediction beyond\\nmean square error. In ICLR 16. arXiv preprint arXiv:1511.05440.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 52, 'page_label': '53'}, page_content='Vintage.\\nMathieu, M., Couprie, C., and LeCun, Y. (2015). Deep multi-scale video prediction beyond\\nmean square error. In ICLR 16. arXiv preprint arXiv:1511.05440.\\nMattar, M. G. and Lengyel, M. (2022). Planning in the brain. Neuron, 110(6):914–934.\\nMercat, J., Gilles, T., El Zoghby, N., Sandou, G., Beauvois, D., and Gil, G. P. (2020). Multi-\\nhead attention for multi-modal joint vehicle motion forecasting. In 2020 IEEE Inter-\\nnational Conference on Robotics and Automation (ICRA) , pages 9638–9644. IEEE.\\nMiller, A. H., Fisch, A., Dodge, J., Karimi, A.-H., Bordes, A., and Weston, J. (2016).\\nKey-value memory networks for directly reading documents. In EMNLP-16.\\nMiller, W. T., Sutton, R. S., and Werbos, P. J. (1995). Neural networks for control . MIT\\npress.\\nMisra, I. and Maaten, L. v. d. (2020). Self-supervised learning of pretext-invariant repre-\\nsentations. In CVPR.\\n53'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 53, 'page_label': '54'}, page_content='Moerland, Thomas, M., Broekens, J., and Jonker, Catholijn, M. (2020). Model-based\\nreinforcement learning: A survey. arXiv:2006.16712. https://arxiv.org/abs/2006.\\n16712.\\nMohamed, A., Lee, H.-y., Borgholt, L., Havtorn, J. D., Edin, J., Igel, C., Kirchhoﬀ, K.,\\nLi, S.-W., Livescu, K., Maaløe, L., et al. (2022). Self-supervised speech representation\\nlearning: A review. arXiv preprint arXiv:2205.10643 .\\nMorari, M. and Lee, J. H. (1997). Model predictive control: Past, present and future.\\nComputers and Chemical Engineering , 23:667–682.\\nMurphy, G. L. (2002). The Big Book of Concepts . MIT Press, Cambridge, MA.\\nNagabandi, A., Kahn, G., Fearing, R. S., and Levine, S. (2017). Neural network dynam-\\nics for model-based deep reinforcement learning with model-free ﬁne-tuning. CoRR,\\nabs/1708.02596.\\nNarendra, K. and Parthasarathy, K. (1990). Identiﬁcation and control of dynamical systems\\nusing neural networks. IEEE Transactions on neural networks , 1(1):4–27.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 53, 'page_label': '54'}, page_content='abs/1708.02596.\\nNarendra, K. and Parthasarathy, K. (1990). Identiﬁcation and control of dynamical systems\\nusing neural networks. IEEE Transactions on neural networks , 1(1):4–27.\\nOh, J., Guo, X., Lee, H., Lewis, R. L., and Singh, S. (2015). Action-conditional video pre-\\ndiction using deep networks in atari games. Advances in neural information processing\\nsystems, 28.\\nOlshausen, B. A. and Field, D. J. (1996). Emergence of simple-cell receptive ﬁeld properties\\nby learning a sparse code for natural images. Nature, 381(6583):607–609.\\nOrhan, E., Gupta, V., and Lake, B. M. (2020). Self-supervised learning through the eyes\\nof a child. Advances in Neural Information Processing Systems , 33:9960–9971.\\nPari, J., Shaﬁullah, N. M., Arunachalam, S. P., and Pinto, L. (2021). The surprising\\neﬀectiveness of representation learning for visual imitation. In Robotics Science and\\nSystems 2022. arXiv preprint arXiv:2112.01511.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 53, 'page_label': '54'}, page_content='eﬀectiveness of representation learning for visual imitation. In Robotics Science and\\nSystems 2022. arXiv preprint arXiv:2112.01511.\\nRichalet, J., Rault, A., Testud, J. L., and Papon, J. (1978). Model predictive heuristic\\ncontrol: Applications to industrial processes. Automatica, 14(5):413–428.\\nRiochet, R., Castro, M. Y., Bernard, M., Lerer, A., Fergus, R., Izard, V., and Dupoux, E.\\n(2019). Intphys: A benchmark for visual intuitive physics reasoning. arXiv:1803.07616.\\nSilver, D., Singh, S., Precup, D., and Sutton, R. S. (2021). Reward is enough. Artiﬁcial\\nIntelligence, 299:103535.\\nSobal, V., Canziani, A., Carion, N., Cho, K., and LeCun, Y. (2022). Separating the world\\nand ego models for self-driving. arXiv:2204.07184.\\nSpelke, E. S. and Kinzler, K. D. (2007). Core knowledge. Developmental Science, 10:89–96.\\nSrinivas, A., Jabri, A., Abbeel, P., Levine, S., and Finn, C. (2018). Universal planning\\nnetworks. CoRR, abs/1804.00645.\\n54'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 54, 'page_label': '55'}, page_content='Srivastava, N., Mansimov, E., and Salakhudinov, R. (2015). Unsupervised learning of video\\nrepresentations using lstms. In Bach, F. and Blei, D., editors, Proceedings of the 32nd\\nInternational Conference on Machine Learning , volume 37 of Proceedings of Machine\\nLearning Research, pages 843–852, Lille, France. PMLR.\\nSukhbaatar, S., Weston, J., Fergus, R., et al. (2015). End-to-end memory networks. Ad-\\nvances in neural information processing systems , 28.\\nSutton, R. S. (1991). Dyna, an integrated architecture for learning, planning, and reacting.\\nACM Sigart Bulletin , 2(4):160–163.\\nTaigman, Y., Yang, M., Ranzato, M., and Wolf, L. (2014). Deepface: Closing the gap to\\nhuman-level performance in face veriﬁcation. In Proceedings of the IEEE conference\\non computer vision and pattern recognition , pages 1701–1708.\\nvan den Oord, A., Li, Y., and Vinyals, O. (2018). Representation learning with contrastive\\npredictive coding. arXiv preprint arXiv:1807.03748 .'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 54, 'page_label': '55'}, page_content='van den Oord, A., Li, Y., and Vinyals, O. (2018). Representation learning with contrastive\\npredictive coding. arXiv preprint arXiv:1807.03748 .\\nvan den Oord, A., Vinyals, O., and Kavukcuoglu, K. (2017). Neural discrete representation\\nlearning. In Guyon, I., Luxburg, U. V., Bengio, S., Wallach, H., Fergus, R., Vish-\\nwanathan, S., and Garnett, R., editors, Advances in Neural Information Processing\\nSystems, volume 30.\\nVaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser,  L.,\\nand Polosukhin, I. (2017). Attention is all you need. Advances in neural information\\nprocessing systems, 30.\\nVincent, P., Larochelle, H., Lajoie, I., Bengio, Y., Manzagol, P.-A., and Bottou, L. (2010).\\nStacked denoising autoencoders: Learning useful representations in a deep network\\nwith a local denoising criterion. Journal of machine learning research , 11(12).\\nWalker, J., Razavi, A., and Oord, A. v. d. (2021). Predicting video with vqvae. arXiv\\npreprint arXiv:2103.01950.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 54, 'page_label': '55'}, page_content='with a local denoising criterion. Journal of machine learning research , 11(12).\\nWalker, J., Razavi, A., and Oord, A. v. d. (2021). Predicting video with vqvae. arXiv\\npreprint arXiv:2103.01950.\\nWayne, G. and Abbott, L. (2014). Hierarchical control using networks trained with higher-\\nlevel forward models. Neural Computation, 26(10):2163–2193.\\nWiskott, L. and Sejnowski, T. J. (2002). Slow feature analysis: Unsupervised learning of\\ninvariances. Neural computation, 14(4):715–770.\\nYarats, D., Kostrikov, I., and Fergus, R. (2021). Image augmentation is all you need:\\nRegularizing deep reinforcement learning from pixels. In ICLR.\\nYu, T., Thomas, G., Yu, L., Ermon, S., Zou, J., Levine, S., Finn, C., and Ma, T. (2020).\\nMopo: Model-based oﬄine policy optimization. arXiv preprint arXiv:2005.13239 .\\nZaadnoordijk, L., Besold, T., and Cusack, R. (2022). Lessons from infant learning for\\nunsupervised machine learning. Nature Machine Intelligence , 4:510–520.\\n55'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 55, 'page_label': '56'}, page_content='Zbontar, J., Jing, L., Misra, I., LeCun, Y., and Deny, S. (2021). Barlow twins: Self-\\nsupervised learning via redundancy reduction. In International Conference on Machine\\nLearning, pages 12310–12320. PMLR.\\n56'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 56, 'page_label': '57'}, page_content='Observed variable\\nUnobserved (latent) variables Deterministic function\\ninput output\\nEnergy term\\n \\n  \\nNon-deterministic function\\nFigure 18: Symbols used in architectural diagrams.\\nArchitectural diagrams use symbols commonly used to draw factor graphs – circles for variables,\\nrectangles for factors – plus rounded rectangles to represent deterministic functions. Filled circles\\nrepresent observed variables, or variables that are outputs of deterministic functions.\\nHollow circles represent latent variables, i.e. variables that must be inferred by minimizing some\\ncost, or sampled from a distribution.\\nRed rectangles represent energy terms. These modules have an implicit scalar output that contributes\\nadditively to the total energy of the system. This is similar to the convention used for factor graphs.\\nRounded rectangles represent deterministic functions, which may have one or several inputs. Given'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 56, 'page_label': '57'}, page_content='Rounded rectangles represent deterministic functions, which may have one or several inputs. Given\\na set of inputs, the output is assumed to be easily computable and unique. The function is generally\\nassumed to be diﬀerentiable. It may contain trainable parameters.\\nNon-deterministic functions are represented as shown on the right. They are composed of a deter-\\nministic function g(x,z) in which one of the inputs is a latent variabl z. The latent variable is seen\\nas varying within a level set of a regularizing energy term R(z). When z varies in the level set\\nZh = {z|R(z) <h}, the output ˜y will vary over the set Yh = {y|y= g(x,z),∀z∈Zh}.\\nIn some cases, the energy term can be transformed into a probability distribution (see text).\\nAppendix: Symbols and Notations\\nArchitectural diagrams in this paper use the symbols shown in Figure 18.\\nWe use symbols that are somewhat similar to the representation of factor graphs: circles'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 56, 'page_label': '57'}, page_content='Appendix: Symbols and Notations\\nArchitectural diagrams in this paper use the symbols shown in Figure 18.\\nWe use symbols that are somewhat similar to the representation of factor graphs: circles\\nfor variables, rectangles for factors. There are two major diﬀerences, however. First, the\\nfactors represent additive energy terms, not multiplicative probability factors. Second, we\\nuse an additional symbol, rounded rectangles, to represent deterministic functions with a\\nclear directionality from inputs to outputs.\\nMore precisely:\\n• Filled circles represent observed variables, or variables that are outputs of determin-\\nistic functions.\\n• Hollow circles represent latent variables, i.e. variables that must be inferred by mini-\\nmizing some cost, varied over a set, or sampled from a distribution.\\n• Red rectangles represent energy terms. These modules have an implicit scalar output\\nthat contributes additively to the total energy of the system.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 56, 'page_label': '57'}, page_content='• Red rectangles represent energy terms. These modules have an implicit scalar output\\nthat contributes additively to the total energy of the system.\\n• Rounded rectangles represent deterministic functions, which may have one or sev-\\neral inputs. Given a set of inputs, the output is assumed to be easily computable\\nand unique. The function is generally assumed to be diﬀerentiable. It may contain\\ntrainable parameters. Such a module is typically implemented as a deep neural net.\\n57'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 57, 'page_label': '58'}, page_content='Non-deterministic functions do not have a dedicated symbol, but must be represented\\nas a combination of deterministic functions, energy modules, and latent variables. An\\nexample is shown on the right of Figure 18. A non-deterministic function is represented\\nby a deterministic function ˜y = g(x,z) whose output depends on a latent variable z. The\\nlatent variable is fed to a regularizing energy term R(z). We ﬁrst deﬁne Zh as the level set\\nof z, i.e. the set of z for which R(z) is less than a threshold h:\\nZh = {z/R(z) <h} (21)\\nAs z varies over Zh, the output will vary over the set:\\nYh = {y|y= g(x,z),∀z∈Zh} (22)\\nIn some cases, this setup may be used to represent probability distributions. Forst,\\nthe energy term is transformed into a probability distribution using a Gibbs-Boltzmann\\nformula:\\nP(z) = exp(−R(z))∫\\nz′ exp(−R(z′)) (23)\\nDrawing the latent variable from this distribution implies a distribution over y:\\nP(y|x) =\\n∫\\nz\\nδ(y−g(x,z))P(z) (24)\\nwhere δ() is the Dirac delta function.\\n58'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 58, 'page_label': '59'}, page_content='Figure 19: Amortized Inference with an EBM. An encoder is trained to produce ˜z = Enc(sx,y)\\nto approximate the value of the latent that minimizes the energy ˇz = argminz∈Z Ew(x,y,z ). The\\nregularizer R(z) plays the essential role of limiting the information that z contains about y. This\\nis particularly important here because the system has access to y and can “cheat” by carrying the\\ncomplete information about y through the encoder.\\nAppendix: Amortized Inference for Latent Variables\\nInference in latent variable models consists in performing the optimization\\nˇz = argmin z∈ZEw(x,y,z ). When z is continuous, this may be best performed through\\na gradient-based optimization that involves backpropagating gradients through the model\\ndowen to z for multiple iterations. In generative architectures, this may be expensive,\\nrequiring to back-propagate through the decoder and the predictor. One way to reduce the'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 58, 'page_label': '59'}, page_content='dowen to z for multiple iterations. In generative architectures, this may be expensive,\\nrequiring to back-propagate through the decoder and the predictor. One way to reduce the\\ncost of inference is to use amortized inference. The idea is to train a neural net to predict\\nan approximate solution to the inference optimization problem.\\nThe architecture is depicted in Figure 20. An encoder ˜ z = Enc( sx,y) is trained to\\nminimize a divergence measure H(ˇz,˜z) between the encoder output and the optimal latent\\nvariable ˇz = argmin z∈ZEw(x,y,z ). Once trained, the prediction ˜ z may be use as an\\nestimate of ˇz or as an initial value for the inference optimization.\\n59'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 59, 'page_label': '60'}, page_content='Figure 20: Amortized Inference with a Regularized Generative Latent-Variable EBM architecture.\\nAn encoder is trained to produce ˜z = Enc( sx,y) to approximate the value ˇz that minimizes the\\nenergy. The regularizer R(z) plays the essential role of limiting the information that z contains\\nabout y. This is particularly important here because the system has access to y and can “cheat” by\\ncarrying the complete information about y through the encoder.\\nThe regularizer R(z) is even more important than in the regular inference case because\\nthe prediction pathway has access toyand can “cheat” by carrying the complete information\\nabout ythrough the encoder. Without an information-limiting regularizer This would cause\\na collapse of the energy function, since it would allow any y to be reconstructed perfectly.\\nThe regularizer is there to minimize the information that ˇz may contains about y.\\nVariational Auto-Encoders, and LISTA-style sparse Auto-Encoders belong to the family'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 59, 'page_label': '60'}, page_content='The regularizer is there to minimize the information that ˇz may contains about y.\\nVariational Auto-Encoders, and LISTA-style sparse Auto-Encoders belong to the family\\nof Regularized GLVEBM with amortized inference. Most of those models are unconditional\\nand do not possess an x nor an Enc(x) module.\\n60'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 60, 'page_label': '61'}, page_content='Appendix: Loss functions for Contrastive Training of EBM\\nMuch can be said about contrastive methods. Table 1 lists a few examples of contrastive\\nmethods, together with their strategy for picking contrastive samples ˆy and their loss func-\\ntional.\\nRows 1-2 in the table are exact maximum likelihood methods. They assume that the\\ngradient of the log partition function can be computed exactly. Rows 2-4 are approxi-\\nmate maximum likelihood methods. Rows 5-10 are not interpretable within a probabilistic\\nframework.\\nRow 1: Maximum Conditional Likelihood for discrete y is used whenever the\\nenergy needs to be turned into a probability distribution. through a Gibbs formulaP(y|x) =\\nexp(−Fw(x,y))/∑\\ny′∈Yexp(−Fw(x,y′). The loss is the negative log conditional likelihood.\\nThis is the prevalent approach when y is a discrete variable within a ﬁnite set (e.g. for\\nclassiﬁcation).\\nRow 2 and 3: Maximum Conditional Likelihood is used for any model that should'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 60, 'page_label': '61'}, page_content='This is the prevalent approach when y is a discrete variable within a ﬁnite set (e.g. for\\nclassiﬁcation).\\nRow 2 and 3: Maximum Conditional Likelihood is used for any model that should\\nproduce probability estimates. Row 2 only applies to tractable models in which the integral\\nin the contrastive term (or its gradient) can be computed analytically. Row 3 applies to\\nsituations where the integral is intractable and its gradient must be approximated by Monte\\nCarlo sampling methods. It then comes down to devising good methods to sample ˆy values\\nfrom the model’s Gibbs distribution: Pw(y|x) = exp(−βFw(x,y)/\\n∫\\ny′ exp(−βFw(x,y′).\\nRow 4: Contrastive Divergence . MCMC sampling methods for Row 3 may take a\\nlong time to mix. One may start from a training sample and let the Markov chain evolve\\nfor a short time, and then accept or reject the resulting sample so as to satisfy detailed\\nbalance (Carreira-Perpi˜ n´ an and Hinton, 2005).'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 60, 'page_label': '61'}, page_content='for a short time, and then accept or reject the resulting sample so as to satisfy detailed\\nbalance (Carreira-Perpi˜ n´ an and Hinton, 2005).\\nRow 5: Pairwise hinge , also known as triplet loss, drives the energy of the correct\\noutput to be lower than the energy of the contrastive output by at least a margin m(y,ˆy)\\nwhich may grow with a measure of divergence between y and ˆy. The diﬃculty is to ﬁnd\\nsuitable contrastive samples whose energy is low and “threatening”, a task sometimes called\\n“hard negative mining”.\\nRows 6-8: Min-hinge, Square-hinge, Square-exp . Assumes that the energy has\\na lower bound. minimizes the energy of the correct output and pushes the energy of con-\\ntrastive outputs above a margin equal to m(y,ˆy) for rows 6 and 7, and inﬁnite for row\\n8.\\nRow 8: Logistic. As with the pairwise hinge, the logistic loss maximizes the diﬀerence\\nbetween the energies of the contrastive output and the correct output. Unlike the pairwise'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 60, 'page_label': '61'}, page_content='8.\\nRow 8: Logistic. As with the pairwise hinge, the logistic loss maximizes the diﬀerence\\nbetween the energies of the contrastive output and the correct output. Unlike the pairwise\\nhinge, the diﬀerence is pushed to inﬁnity, but with a force that decreases quickly.\\nRow 9: GAN . A GAN diﬀers from other contrastive methods in the way contrastive\\nsamples are generated. The contrastive samples are produced by a generator network that\\nis trained preferentially generate samples that have low energy according to the model. In\\nprinciple, any loss function can be used, as long as it increases with the energy of the correct\\noutput, and decreases with the energy of the contrastive sample.\\nRow 10: Denoising Auto-Encoder . A denoising AE produces contrastive samples\\nby corrupting outputs from training samples. The corruption can be performed by adding\\nnoise or by masking parts of the output. The energy function is the reconstruction error,\\n61'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 61, 'page_label': '62'}, page_content='hence the energy is trained to be zero on the data manifold, and to grow with D(y,ˆy) as ˆy\\nmoves away from y on the data manifold.\\nMethod Energy ˆy Generation Loss\\n1 Max Likelihood discrete y exhaustive Fw(x,y) + log∑\\ny′∈Yexp(−Fw(x,y′))\\n2 Max Likelihood tractable exhaustive Fw(x,y) + log\\n∫\\ny′∈Yexp(−Fw(x,y′))\\n3 Max likelihood any MC or MCMC Fw(x,y) −Fw(x,ˆy)\\n4 Contr. Divergence any trunc’d MCMC Fw(x,y) −Fw(x,ˆy)\\n5 Pairwise Hinge any most oﬀending [Fw(x,y) −Fw(x,ˆy) + m(y,ˆy)]+\\n6 Min-Hinge positive most oﬀending Fw(x,y) + [m(y,ˆy) −Fw(x,ˆy)]+\\n6 Square-Hinge divergence most oﬀending Fw(x,y)2 +\\n(\\n[m(y,ˆy) −Fw(x,ˆy)]+)2\\n7 Square-Exp any most oﬀending Fw(x,y)2 + exp(−βFw(x,ˆy))\\n8 Logistic any most oﬀending log(1 + exp(Fw(x,y) −Fw(x,ˆy))\\n9 GAN any ˆy= gu(z) H(Fw(x,y),Fw(x,ˆy),m(y,ˆy))\\n10 Denoising AE D(y,gw(y)) ˆy= N(y) D(y,gw(ˆy)\\nTable 1: A of list of contrastive methods and loss functions to train energy-based models. They'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 61, 'page_label': '62'}, page_content='9 GAN any ˆy= gu(z) H(Fw(x,y),Fw(x,ˆy),m(y,ˆy))\\n10 Denoising AE D(y,gw(y)) ˆy= N(y) D(y,gw(ˆy)\\nTable 1: A of list of contrastive methods and loss functions to train energy-based models. They\\nare all use loss functions with two terms, one that pushes down on the energy of a training sample,\\nand one the pulls up the energies of one or several contrastive samples.\\nThey diﬀer by the strategy they employ to generate contrastive samples, and by the precise form of\\nthe loss function.\\nExact or approximate Maximum Likelihood methods (rows 1-4) are used whenever the model needs to\\nproduce probability estimates. When the second term is intractable, its gradient may be approximated\\nthrough Monte-Carlo methods, which can be seen as particular ways to produce ˆy. Many contrastive\\nself-supervised methods for joint embedding architectures (Siamese nets) use Row 1 (InfoNCE).\\nA number of contrastive methods (Rows 5-8) are based on ﬁnding a ˆy that is “highly oﬀending”,'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 61, 'page_label': '62'}, page_content='self-supervised methods for joint embedding architectures (Siamese nets) use Row 1 (InfoNCE).\\nA number of contrastive methods (Rows 5-8) are based on ﬁnding a ˆy that is “highly oﬀending”,\\nmeaning diﬀerent from the desired y, yet given a low energy by the model. Pairs of energies for y\\nand ˆy are fed to a loss function that pushes the former to low values and the latter to higher values.\\nThis can be done with a variety of losses including hinge loss.\\nGANs (row 9) are contrastive methods in which the contrastive samples are produced by a generator\\nnetwork whose input is a random vector. The generator is trained to produce samples to which the\\nmodel currently attributes a low energy, but should attribute a high energy.\\nDenoising Auto-Encoders (row 10) apply a corruption process to training samples to produce con-\\ntrastive samples ˆy = N(y). The energy function is the reconstruction error Fw(y) = D(y,gw(y))'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.22', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-27T03:39:14-04:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2022-06-27T03:39:14-04:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.22 (TeX Live 2021) kpathsea version 6.3.3', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\LeCun - A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27.pdf', 'total_pages': 62, 'page': 61, 'page_label': '62'}, page_content='Denoising Auto-Encoders (row 10) apply a corruption process to training samples to produce con-\\ntrastive samples ˆy = N(y). The energy function is the reconstruction error Fw(y) = D(y,gw(y))\\nwhere D() is a symmetric divergence measure and gw(y) a parameterized function. By training gw()\\nto map ˆy to y, the energy for ˆy is trained to be equal to D(ˆy,y), while the energy of y is trained to\\nbe zero.\\n62'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 0, 'page_label': '1'}, page_content='Harms from Increasingly Agentic Algorithmic Systems\\nALAN CHAN∗†‡ , Mila, Université de Montréal, Canada\\nREBECCA SALGANIK†, Mila, Université de Montréal, Canada\\nALVA MARKELIUS†, University of Cambridge, UK\\nCHRIS PANG†, University of Cambridge, UK\\nNITARSHAN RAJKUMAR†, University of Cambridge, UK\\nDMITRII KRASHENINNIKOV†, University of Cambridge, UK\\nLAURO LANGOSCO†, University of Cambridge, UK\\nZHONGHAO HE†, University of Cambridge, UK\\nYAWEN DUAN†, University of Cambridge, UK\\nMICAH CARROLL†, University of California, Berkeley, SUA\\nMICHELLE LIN,McGill University, Canada\\nALEX MAYHEW,University of Western Ontario, Canada\\nKATHERINE COLLINS,University of Cambridge, UK\\nMARYAM MOLAMOHAMMADI,Mila, Canada\\nJOHN BURDEN,Center for the Study of Existential Risk, University of Cambridge, UK\\nWANRU ZHAO,University of Cambridge, UK\\nSHALALEH RISMANI,McGill University, Mila, Canada\\nKONSTANTINOS VOUDOURIS,University of Cambridge, UK\\nUMANG BHATT,University of Cambridge, UK'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 0, 'page_label': '1'}, page_content='WANRU ZHAO,University of Cambridge, UK\\nSHALALEH RISMANI,McGill University, Mila, Canada\\nKONSTANTINOS VOUDOURIS,University of Cambridge, UK\\nUMANG BHATT,University of Cambridge, UK\\nADRIAN WELLER,University of Cambridge, UK\\nDAVID KRUEGER∗, University of Cambridge, UK\\nTEGAN MAHARAJ∗† , University of Toronto, Canada\\nResearch in Fairness, Accountability, Transparency, and Ethics (FATE)1 has established many sources and forms of algorithmic harm,\\nin domains as diverse as health care, finance, policing, and recommendations. Much work remains to be done to mitigate the serious\\nharms of these systems, particularly those disproportionately affecting marginalized communities. Despite these ongoing harms, new\\nsystems are being developed and deployed, typically without strong regulatory barriers, threatening the perpetuation of the same\\nharms and the creation of novel ones. In response, the FATE community has emphasized the importance of anticipating harms, rather'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 0, 'page_label': '1'}, page_content='harms and the creation of novel ones. In response, the FATE community has emphasized the importance of anticipating harms, rather\\nthan just responding to them. Anticipation of harms is especially important given the rapid pace of developments in machine learning\\n(ML). Our work focuses on the anticipation of harms from increasingly agentic systems. Rather than providing a definition of agency\\n∗Major contributions to the project direction and framing.\\n†Major contributions to the writing. Authors with only this mark have had their order randomized. Authors without a mark also have their orders\\nrandomized.\\n‡Correspondence to alan.chan@mila.quebec.\\n1We use the term FATEas a shorthand, keeping in mind and valuing the ideological diversity of those who work on FATE and related disciplines not\\ncaptured in this acronym.\\n2023. Manuscript submitted to ACM\\nManuscript submitted to ACM 1\\narXiv:2302.10329v1  [cs.CY]  20 Feb 2023'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 1, 'page_label': '2'}, page_content='2 Chan et al.\\nas a binary property, we identify 4 key characteristics which, particularly in combination, tend to increase the agency of a given\\nalgorithmic system: underspecification, directness of impact, goal-directedness, and long-term planning. We also discuss important\\nharms which arise from increasing agency – notably, these include systemic and/or long-range impacts, often on marginalized or\\nunconsidered stakeholders. We emphasize that recognizing agency of algorithmic systems does not absolve or shift the human\\nresponsibility for algorithmic harms. Rather, we use the term agency to highlight the increasingly evident fact that ML systems are not\\nfully under human control. Our work explores increasingly agentic algorithmic systems in three parts. First, we explain the notion of\\nan increase in agency for algorithmic systems in the context of diverse perspectives on agency across disciplines. Second, we argue for'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 1, 'page_label': '2'}, page_content='an increase in agency for algorithmic systems in the context of diverse perspectives on agency across disciplines. Second, we argue for\\nthe need to anticipate harms from increasingly agentic systems. Third, we discuss important harms from increasingly agentic systems\\nand ways forward for addressing them. We conclude by reflecting on implications of our work for anticipating algorithmic harms\\nfrom emerging systems.\\nAdditional Key Words and Phrases: algorithmic systems, harms, safety, sociotechnical systems, negative externalities, agency, autonomy,\\npower, delayed impacts, ethics, FATE\\nACM Reference Format:\\nAlan Chan, Rebecca Salganik, Alva Markelius, Chris Pang, Nitarshan Rajkumar, Dmitrii Krasheninnikov, Lauro Langosco, Zhonghao\\nHe, Yawen Duan, Micah Carroll, Michelle Lin, Alex Mayhew, Katherine Collins, Maryam Molamohammadi, John Burden, Wanru\\nZhao, Shalaleh Rismani, Konstantinos Voudouris, Umang Bhatt, Adrian Weller, David Krueger, and Tegan Maharaj. 2023. Harms from'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 1, 'page_label': '2'}, page_content='Zhao, Shalaleh Rismani, Konstantinos Voudouris, Umang Bhatt, Adrian Weller, David Krueger, and Tegan Maharaj. 2023. Harms from\\nIncreasingly Agentic Algorithmic Systems. 1, 1 (February 2023), 25 pages. https://doi.org/10.1145/nnnnnnn.nnnnnnn\\n1 INTRODUCTION\\nThe promised benefits of algorithmic systems have not always been borne out, and benefits are often tempered by\\nsignificant negative externalities. Although the deployment of algorithmic systems may result in increased safety or\\nmaterial improvements to human well-being [Abebe and Goldner 2018; Jumper et al . 2021; Li et al . 2017], diverse\\nlines of work in Fairness, Accountability, Transparency, and Ethics (FATE) have established the roles that algorithmic\\nsystems play in causing harm. Examples include the perpetuation of existing, unjust power relations [Barabas et al.\\n2018; Buolamwini and Gebru 2018; Ehsan et al. 2022; Kasy and Abebe 2021; steven t. piantadosi [@spiantado] 2022;'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 1, 'page_label': '2'}, page_content='2018; Buolamwini and Gebru 2018; Ehsan et al. 2022; Kasy and Abebe 2021; steven t. piantadosi [@spiantado] 2022;\\nWolfe and Caliskan 2022], the generation of toxic language [Abid et al. 2021; Gehman et al. 2020], and informational\\nharms [Carroll et al. 2022; Jiang et al. 2019; Li et al. 2022; Weidinger et al. 2022].\\nDespite the clear evidence of harms from existing systems, new types of algorithmic systems are continually being\\ndeveloped and deployed, often without strong regulatory barriers [Gesley et al. 2019]. The pace of development has\\nbeen particularly rapid in the machine learning (ML) community. Just in the last five years, we have witnessed large\\nimprovements in the capabilities of systems to perform a variety of real-world tasks, including search [Nayak 2019],\\ndrug discovery [Jumper et al. 2021; Stokes et al. 2020], and dialogue [OpenAI 2022].\\nResearchers in the FATE community have responded to the rapid pace of ML developments by emphasizing the need'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 1, 'page_label': '2'}, page_content='drug discovery [Jumper et al. 2021; Stokes et al. 2020], and dialogue [OpenAI 2022].\\nResearchers in the FATE community have responded to the rapid pace of ML developments by emphasizing the need\\nto anticipate harms, rather than just react to them. In particular, many have identified the impact of computational\\nmodeling and development in social change [Abebe et al. 2020; Jacobs and Wallach 2021; Selbst et al. 2019] and scoped\\nnumerous taxonomies of risks, harms, and failures of algorithmic systems [Raji et al. 2022; Shelby et al. 2022; Weidinger\\net al. 2022]. While it is crucial not to idealize or over-hype a model’s performance by ignoring model failures [Bender\\net al. 2021; Bender and Koller 2020; Blodgett et al. 2021; Collins et al. 2022; Lin et al. 2022; Raji et al. 2022; Vinsel 2021],\\nit is also important not to understate (and thus fail to anticipate negative consequences of) what these models can do'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 1, 'page_label': '2'}, page_content='it is also important not to understate (and thus fail to anticipate negative consequences of) what these models can do\\nand may be capable of doing in the near future [Bowman 2022; Hoffmann et al. 2022; Kaplan et al. 2020], especially\\ngiven growing investments in the field [Giattino et al. 2022].\\nManuscript submitted to ACM'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 2, 'page_label': '3'}, page_content='Harms from Increasingly Agentic Algorithmic Systems 3\\nIn this paper, we continue the work of anticipating harms by drawing attention to increasingly agentic algorithmic\\nsystems. We use agency and agentic in a narrow sense for our work as applied to algorithmic systems, particularly ML\\nsystems. While recognizing the many meanings of agency, as well as the need not to absolve humans of responsibility\\npertaining to algorithmic harms [Cooper et al . 2022; Nissenbaum 1996; Wieringa 2020], we use the term agency\\nconsciously to counter the somewhat view that the developers of an algorithmic system have full control over its\\nbehaviour. Johnson and Verdicchio [2017] claims that “the behaviour of computational artefacts is in the control of the\\nhumans that design them. ” In a systematic review on algorithmic accountability, Wieringa [2020] defines algorithms\\nas “basically instructions fed to a computer”. While this description is accurate for many purposes, we argue that,'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 2, 'page_label': '3'}, page_content='as “basically instructions fed to a computer”. While this description is accurate for many purposes, we argue that,\\nparticularly for ML-based algorithmic systems, it elides responsive and interactive qualities of these systems which can\\nso easily lead to unforeseen outcomes. Cooper et al. [2022]; Nissenbaum [1996] do identify bugs – including faulty\\nmodeling premises and bad model performance – as one way in which humans may not have total control of the\\noperation of an algorithmic system. However, we view agency as distinct from mistakes or bugs and demonstrate the\\nunique and important harms that can result. We note there are significant economic and military incentives to build\\nincreasingly agentic systems. Indeed, many in the ML community are explicitly building such systems as a research\\ngoal [Chen et al. 2021; Reed et al. 2022; Sutton et al. 2022]. In summary, our contributions are :'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 2, 'page_label': '3'}, page_content='goal [Chen et al. 2021; Reed et al. 2022; Sutton et al. 2022]. In summary, our contributions are :\\n(1) We identify characteristics that tend to increase agency of algorithmic systems, and situate our characterization\\nin the context of diverse perspectives on agency across disciplines. We articulate that even when recognizing\\nagency in algorithmic systems, we can and should emphasize the human responsibility to prevent harms.\\n(2) We argue for the need to anticipate harms from increasingly agentic systems. Increasingly agentic systems are\\nbeing developed and there exist strong incentives for this work to continue.\\n(3) We discuss some harms to be anticipated from increasingly agentic systems. In so doing, we connect to ongoing\\nlines of work in the FATE community, including systemic and delayed effects, an impoverishment of collective\\ndecision-making power, and exacerbation of extreme concentrations of power in the hands of a few. We also'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 2, 'page_label': '3'}, page_content='decision-making power, and exacerbation of extreme concentrations of power in the hands of a few. We also\\ndiscuss the role of increasing agency as a source of harms that are yet to be identified.\\nThis paper is not about the moral agency or consciousness of algorithms or machines. Instead, we focus on identifying\\na property of emerging ML systems, argue for the need to anticipate harms from systems that increasingly satisfy this\\nproperty, and discuss the harms to be anticipated.\\n2 AGENCY\\nIn colloquial use, agency refers to the ability to take actions or affect outcomes. A difficulty of having concrete\\ndiscussions on agency is the variety of perspectives through which such a concept can be defined, making confusion\\nand disagreement common. In recognition of this variety of perspectives, we do not attempt to define agency in a\\nbinary manner, but instead present a set of characteristics we take to be associated with increasing agency, i.e. the more'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 2, 'page_label': '3'}, page_content='binary manner, but instead present a set of characteristics we take to be associated with increasing agency, i.e. the more\\nof these characteristics a system has, particularly in combination, the more agency we can consider it to have. We first\\npresent our characterization, and follow by contextualizing it in some of the most relevant perspectives and related\\nconcepts to our work.\\n2.1 Characteristics that are Associated with Increasing Agency in Algorithmic Systems\\nWe identify 4 key characteristics associated with increasing agency in algorithmic systems, especially in combination:\\nunderspecification, directness of impact, goal-directedness, and long-term planning. When we say that an algorithmic\\nsystem has a degree of agency, we mean that it is to some extent an agent or agentic.Agency is the property, agent\\nManuscript submitted to ACM'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 3, 'page_label': '4'}, page_content='4 Chan et al.\\nis the role, and agentic is the adjective. Our characterization of agency is specific to algorithmic systems and is not\\nmeant to define agency for humans or arbitrary entities. We will sometimes use “agentic system” in place of “agentic\\nalgorithmic system” for brevity.\\n(1) Underspecification: the degree to which the algorithmic system can accomplish a goal provided by operators\\nor designers, without a concrete specification of how the goal is to be accomplished [D’Amour et al. 2020a].\\n(2) Directness of impact: the degree to which the algorithmic system’s actions affect the world without mediation\\nor intervention by a human, i.e. without a human in the loop.\\n(3) Goal-directedness: the degree to which the system is designed/trained to achieve a particular quantifiable\\nobjective.\\n(4) Long-term planning: the degree to which the algorithmic system is designed/trained to make decisions that'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 3, 'page_label': '4'}, page_content='objective.\\n(4) Long-term planning: the degree to which the algorithmic system is designed/trained to make decisions that\\nare temporally dependent upon one another to achieve a goal and/or make predictions over a long time horizon.\\nTo illustrate the notion of increasing agency, consider the task of compiling a literature review on a certain sub-\\nject. With a search engine, the human user must type in queries, click on related works, read papers, look through\\nbibliographies, record relevant information in a document, and edit the text. A system that was more agentic than\\nthe search engine, still for the same task, could simply be queried with the topic of the desired literature review, and\\nwould automatically look through related works on the internet without user intervention, like WebGPT can do to\\nsome extent [Nakano et al. 2022]. The user would not need (or be able to) to specify which papers were relevant nor\\nhave to compile papers manually into a document.\\n2.2 Prior Work on Agency'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 3, 'page_label': '4'}, page_content='some extent [Nakano et al. 2022]. The user would not need (or be able to) to specify which papers were relevant nor\\nhave to compile papers manually into a document.\\n2.2 Prior Work on Agency\\nAgency is a central concept in many fields of academia [Schlosser 2019]. Dennett [1981] provides one of the most\\npopular analyses of when and how to attribute agency, focusing on the notion that agents behave intentionally. Orseau\\net al. [2018] and more recently Kenton et al. [2022] have attempted to formalize this notion of agency in the context\\nof artificial intelligence. In cognitive science and psychology, agency is conceptualized relatively similarly, as having\\nintentions, plans, goals, communication, and reasoning [Lake et al. 2017; Spelke and Kinzler 2007] – entities with agency\\ncan plan, act, memorize, exert self-control, and communicate with others. While these notions of agency focus on'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 3, 'page_label': '4'}, page_content='can plan, act, memorize, exert self-control, and communicate with others. While these notions of agency focus on\\nindividuals making rational choices in pursuit of some goal, in sociology, agency is often thought of as contextualized\\nwithin, constrained by, and/or contrasted with structure [Emirbayer and Mische 1998].\\nPrincipal-agent theory [Eisenhardt 1989; Jensen and Meckling 1976] provides more intuition for how we charac-\\nterize agency. Principal-agent theory concerns itself with aprincipal who delegates tasks to an agent in order to achieve\\ntheir goals. The agent acts (directness of impact) on behalf of the principal to achieve the principal’s goals, which may\\nbe long-horizon (long-term planning). Crucially, the agent and principal have different incentives2 and information: the\\nprincipal does not tell the agent how to complete the tasks (underspecification). In our context, we view the principal'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 3, 'page_label': '4'}, page_content='principal does not tell the agent how to complete the tasks (underspecification). In our context, we view the principal\\nas humans and the agent as algorithmic systems, as done in prior work [Hadfield-Menell and Hadfield 2019]. It is in\\nthis sense that we consider algorithmic systems to have agency.\\nOur notion of increasing agency also takes inspiration from how the term agent is used in AI research. In the\\nmost popular introductory text on artificial intelligence, Russell and Norvig [2021, p. 58] define a rational agent as\\nfollows: “For each possible percept sequence, a rational agent should select an action that is expected to maximize its\\nperformance measure, given the evidence provided by the percept sequence and whatever built-in knowledge the agent\\n2It is coherent to talk about the incentives of algorithmic systems. See Everitt et al. [2021].\\nManuscript submitted to ACM'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 4, 'page_label': '5'}, page_content='Harms from Increasingly Agentic Algorithmic Systems 5\\nhas. ” Russell and Norvig [2021, p. 60] further states that “To the extent that an agent relies on the prior knowledge of its\\ndesigner rather than on its own percepts and learning processes, we say that the agent lacks autonomy. A rational\\nagent should be autonomous—it should learn what it can to compensate for partial or incorrect prior knowledge. ” While\\nour characterization does not consider (ir)rationality, goal-directedness and underspecification are captured in this\\ndefinition.\\nReinforcement learning is a field that concentrates on the construction of agents. In the field’s premier introductory\\ntext, Sutton and Barto [2018, p. 47-8] states that the “learner and decision maker is called the agent. The thing it interacts\\nwith, comprising everything outside the agent, is called the environment. These interact continually, the agent selecting'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 4, 'page_label': '5'}, page_content='with, comprising everything outside the agent, is called the environment. These interact continually, the agent selecting\\nactions and the environment responding to these actions and presenting new situations to the agent. The environment\\nalso gives rise to rewards, special numerical values that the agent seeks to maximize over time through its choice of\\nactions. ” Note that reinforcement learning is not the only way of constructing agents, however. For instance, recent work\\nhas shown that foundation models can perform planning tasks [Huang et al. 2022]. Even simple predictive algorithms,\\ndepending on their training procedure, can follow incentives to affect the world in unexpected ways – for example by\\nshifting user interests rather than improving at their predictive task [Krueger et al. 2020], thus increasing their agency.\\nOne of the difficult discussions surrounding agency is interaction of agency and responsibility, for humans and for'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 4, 'page_label': '5'}, page_content='One of the difficult discussions surrounding agency is interaction of agency and responsibility, for humans and for\\nmachines. Goetze [2022] identifies aresponsibility gap between engineers and the outcomes of their designed systems\\n– people designing autonomous systems are far removed from the consequences of their deployment. The authors\\ncontend that regardless of the system’s autonomy, human designers must be the ones held accountable. [Sullivan and\\nFosso Wamba 2022] investigate attitudes toward agency of fictional AI robots, and find survey respondents do not\\ntypically consider AI systems to be moral agents – they tend to place moral responsibility on developers, not on AI\\nsystems as agents. Similarly, Robinette et al. [2016] examines (over)trust of autonomous systems and find in emergency\\nsituations, people will follow robots into further danger, because they attribute the agency of the robot to the (assumed'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 4, 'page_label': '5'}, page_content='situations, people will follow robots into further danger, because they attribute the agency of the robot to the (assumed\\ncapable and responsible) designers. As people in these situations appear to, we distinguish agency from responsibility,\\nand emphasize that attribution of agency to an autonomous system in no way intends to shift moral responsibility from\\nhumans onto that system.\\nLeufer [2020]; Myths [[n. d.]] examine another aspect of this problem, describing AI agency as a myth which\\nmasks human agency (and therefore responsibility). The authors contend that anthropomorphization of AI systems\\ncontributes to mystification of the underlying technology and sociotechnical blindness [Johnson and Verdicchio 2017],\\nwherein people “believe AI systems got to be the way they are without human intervention”, and obscuring of the\\n(often exploitative) human labour which enables AI systems to exist [Gray and Suri 2019; Pasquinelli and Joler 2021;'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 4, 'page_label': '5'}, page_content='(often exploitative) human labour which enables AI systems to exist [Gray and Suri 2019; Pasquinelli and Joler 2021;\\nPerrigo 2023]. While we strongly agree with all these points, we reach the opposite conclusion – AI agency (in the\\nsense of our work) is not a myth, it is a reality of increasing sociotechnical importance. It is precisely because of the\\nimportance of problems like these (responsibility gap, mystification, sociotechnical blindness, masking human agency\\nand labour, etc.) and their far-ranging implications that we need to carefully examine the agency of AI systems, not\\ndismiss it out of hand. If we think it is categorically impossible for AI systems to have agency, we will never be able to\\naccurately recognize when we are giving up our agency to them.\\nA related concept we wish to distinguish from agency is autonomy. Bekey [2005] defines autonomy as “the ability'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 4, 'page_label': '5'}, page_content='accurately recognize when we are giving up our agency to them.\\nA related concept we wish to distinguish from agency is autonomy. Bekey [2005] defines autonomy as “the ability\\nto operate without a human operator for a protracted period of time. ” Many factory robots are highly autonomous, but\\nthey operate strictly within the confines of a factory, and the actions they take affect only the intended outcome (e.g.\\nthe product they’re making) – they are autonomous but do not have agency. Welsh [2019] presents a series of protocols\\nManuscript submitted to ACM'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 5, 'page_label': '6'}, page_content='6 Chan et al.\\nwhich can be used to govern the use of lethal autonomous weapons, emphasizing the need for human-in-the-loop\\ndecision making – i.e. to ensure all agency rests with human controllers.\\nIn this vein, our focus on agency also shares many commonalities with work from the FATE community on establishing\\nthe harms of automated decision-making (ADM) . ADM involves the use of algorithms to make decisions or enact\\npolicies without human intervention. Given its applications in recommendations [Li et al. 2022; Milano et al. 2020],\\nhealth-care systems [Fogliato et al. 2022; Obermeyer and Mullainathan 2019; Sendak et al. 2020], the judicial sector\\n[Barabas et al. 2020; Green 2020; Zilka et al . 2022], and public services [Black et al . 2022; Loi and Spielkamp 2021;\\nStapleton et al. 2022], ADM can often exhibit similar kinds of diffuse and long-term harms to those we discuss coming'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 5, 'page_label': '6'}, page_content='Stapleton et al. 2022], ADM can often exhibit similar kinds of diffuse and long-term harms to those we discuss coming\\nfrom increased agency. Given the commonalities, many of the harms of ADM also apply to increasingly agentic systems,\\nas we discuss in Section 4. But there are two key differences between the body of work on ADM and our work. First,\\nwith the term agency we emphasize lack of explicit or low-level instructions for behaviour - we might specify a\\ntask, but not how to solve that task. Second, our work explicitly targets systems that are increasingly agentic, such as\\nreinforcement-learning systems that are capable of making decisions in an open-ended environment over long time\\nhorizons without human intervention. Such systems have not been the focus of work in ADM simply because they\\nhave not yet seen widespread public deployment. We thus consider our focus on agency to be a continuation of current\\nwork on ADM.'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 5, 'page_label': '6'}, page_content='have not yet seen widespread public deployment. We thus consider our focus on agency to be a continuation of current\\nwork on ADM.\\nSome philosophical work on agency also focuses on mental states such as, consciousness, emotional states, and\\nsubjective experience [Schlosser 2019]. Entities with these mental states have personalities, and feel things like pleasure,\\ncuriosity, pain, embarrassment, fear and joy. Our work does not address experience or consciousness, only agency.\\n2.3 Potential Objections to our Use of Agency\\nOne objection against framing algorithmic systems as agents is that it distracts from the responsibility of humans. As\\nnoted above, we characterize agency as separate from responsiblity. More attention should be directed towards holding\\ncorporations, regulators, developers, etc (actors for short in this section) accountable [Cooper et al. 2022; Johnson and\\nVerdicchio 2017; Nissenbaum 1996; Wieringa 2020].'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 5, 'page_label': '6'}, page_content='corporations, regulators, developers, etc (actors for short in this section) accountable [Cooper et al. 2022; Johnson and\\nVerdicchio 2017; Nissenbaum 1996; Wieringa 2020].\\nWe strongly agree with the need to hold actors accountable. This claim is not in contention with the idea that\\nalgorithmic systems can be agentic in our narrow sense. Principals can be held responsible on behalf of their agents,\\nsuch as when employers are held liable for negligent hiring when employees cause harm [Hickox 2010].\\nWe should also require more than just individual accountability. In addition to focusing on individual actors, we\\nshould also attend to structural factors that shape their behaviours. A developer is likely blameworthy at least to\\nsome extent when a system causes harm, but structural factors like economic incentives to push forward likely also\\nplay significant roles [van der Loeff et al. 2019; Zwetsloot and Dafoe 2019]. As we will discuss in Section 4, viewing'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 5, 'page_label': '6'}, page_content='play significant roles [van der Loeff et al. 2019; Zwetsloot and Dafoe 2019]. As we will discuss in Section 4, viewing\\nalgorithmic systems as agents can in fact highlight harms and the collective responsibility we have to prevent them.\\n3 THE NEED TO ANTICIPATE HARMS FROM INCREASINGLY AGENTIC SYSTEMS\\nWe argue for the need to anticipate harms from increasingly agentic systems. Anticipation is about two things: (1)\\nthe development of systems with increasing agency and (2) the deployment of systems with more agency than those\\nalready deployed. We touch upon trends in ML development and deployment as well as some reasons to expect these\\ntrends to continue. In Section 3.3 we respond to some potential objections.\\nManuscript submitted to ACM'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 6, 'page_label': '7'}, page_content='Harms from Increasingly Agentic Algorithmic Systems 7\\n3.1 Trends in Development and Deployment\\nWe aim to show two things in this section. First, the development of increasingly agentic systems has proceeded by\\nconsistently overcoming technical challenges. Second, the deployment of increasingly agentic systems has occurred\\nbecause these systems have increasingly practical skills that are useful for real-world applications.\\n3.1.1 Overcoming Technical Challenges to Build Increasingly Agentic Systems. Reinforcement learning (RL), as one of\\nthe major paradigms of machine learning, has a major focus on the construction of agents [Sutton and Barto 2018;\\nSutton et al. 2022]. In particular, RL is about designing systems to learn, without human intervention, to achieve a goal\\nencoded in a reward function. Prior to 2013, RL systems were developed mainly for a restricted set of simple domains'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 6, 'page_label': '7'}, page_content='encoded in a reward function. Prior to 2013, RL systems were developed mainly for a restricted set of simple domains\\n[Coulom 2002]. The introduction of deep learning to RL systems produced superhuman performance on a wider variety\\nof narrow tasks with limited to no human supervision, including but not limited to increasingly complex board games\\n[Brown and Sandholm 2019; Perolat et al. 2022; Silver et al. 2016, 2017] and video games [Mnih et al. 2013; Schrittwieser\\net al. 2020; Ye et al. 2021]. Subsequent work has greatly improved the performance of RL systems on more complex,\\nopen-ended environments. For instance, DreamerV3 [Hafner et al . 2023] collected diamonds from scratch without\\nhuman data or curricula in MineCraft, which has been a longstanding challenge because the task is extremely complex\\nand open-ended. Another striking example comes from Diplomacy, a complex, multiplayer board game involving'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 6, 'page_label': '7'}, page_content='and open-ended. Another striking example comes from Diplomacy, a complex, multiplayer board game involving\\ntactical coordination and natural language negotiation. The recent Cicero [Bakhtin et al. 2022], integrating a language\\nmodel with planning and RL algorithms, is the first AI to achieve human-level performance in Diplomacy. Such systems\\nhave demonstrated strong capabilities to interact with complex environments and humans to accomplish their goals\\nthat require long-horizon planning.\\nWe emphasize that for all the systems we have mentioned in this section so far, designers do not specify how the tasks\\nwere to be completed. In the current scientific paradigm of large-scale deep-learning, one instead provides high-level\\nlearning algorithms that tend to be task-agnostic or adapt to new tasks efficiently [Beck et al. 2023; Dong et al. 2022].\\nOne particular example to highlight is AdA [Team et al . 2023], which adapts to open-ended, novel, embodied 3D'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 6, 'page_label': '7'}, page_content='One particular example to highlight is AdA [Team et al . 2023], which adapts to open-ended, novel, embodied 3D\\nproblems as quickly as humans, without human specification of how to solve problems.\\n3.1.2 The Increasing Deployment of Increasingly Agentic Systems. The practicality of systems has increased along\\nwith their agency. Increasing practicality means that increasingly agentic systems are more likely to be found making\\ndecisions in the real world. Major companies have been deploying increasingly agentic systems to control parts of their\\noperation. For example, DeepMind and Google use RL for controlling commercial cooling systems and data centers\\n[Evans and Gao 2016; Kava 2014]. Amazon has applied RL to supply chain optimization problems [Schmelzer 2019].\\nAdditionally, there has been an increasing amount of research in recommender systems to optimize long-term metrics\\nsuch as engagement via reinforcement learning [Afsar et al. 2022]. Major recommendation companies such as Meta'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 6, 'page_label': '7'}, page_content='such as engagement via reinforcement learning [Afsar et al. 2022]. Major recommendation companies such as Meta\\n[Gauci et al. 2019], YouTube [Association for Computing Machinery (ACM) 2019], and Spotify [Engineering 2021] have\\nalready deployed RL-based recommender systems on their live products.\\nSystems that can competently operate across different data modalities and tasks are plausibly more useful than\\nmore narrow systems, regardless of how agentic they are. Before the current era of large language models (LLMs)\\n[Bommasani et al. 2022; Brown et al. 2020; Rae et al. 2022; Srivastava et al. 2022], few systems competently performed\\nout-of-the-box on a range of natural language tasks [Brown et al. 2020]. Recent models [Alayrac et al. 2022; Reed et al.\\n2022; Zeng et al. 2022] can even handle multiple data modalities simultaneously. GATO [Reed et al. 2022] can complete\\ntasks using the same model and weights in vastly different domains, such as Atari, image captioning, dialogue, and'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 6, 'page_label': '7'}, page_content='tasks using the same model and weights in vastly different domains, such as Atari, image captioning, dialogue, and\\nManuscript submitted to ACM'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 7, 'page_label': '8'}, page_content='8 Chan et al.\\nrobotics. As systems become increasingly agentic, the systems that are increasingly domain general seem likely to see\\nmore practical application.\\nIncreasingly agentic systems are also becoming more available to the general public. Although language models are\\nonly trained on next-token prediction, they can be leveraged to interact with APIs and accomplish a wide variety of\\nmulti-step digital tasks with increasingly less explicit human intervention [Chase 2022; Menick et al. 2022; Nakano et al.\\n2022]. Adept’s ACT-1 [Adept 2022] is a system in development which purportedly can perform an arbitrary task on\\nyour computer, such as searching for and buying an item online, through a single text command.\\nDespite the progress so far, systems still have limitations and there are still barriers to the deployment of more\\nagentic systems. For example, the raw task performance of generalist systems [Reed et al. 2022; Zeng et al. 2022] is still'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 7, 'page_label': '8'}, page_content='agentic systems. For example, the raw task performance of generalist systems [Reed et al. 2022; Zeng et al. 2022] is still\\nlimited to tasks where expert data is available and has not achieved human level on all tasks. In the realm of language\\nmodels, recent studies [Ji et al. 2022; Valmeekam et al. 2022] have shown that large language models can perform poorly\\non planning and reasoning tasks, and such systems are prone to hallucinate unintended text, which fails to meet users’\\nintents on many real-world scenarios.\\n3.2 Factors in the Continued Development and Deployment of Increasingly Agentic Systems\\nFor current AI models, there are strong incentives for continued investment and development despite uncertainty\\naround how their future capabilities will emerge [Ganguli et al . 2022]. Similarly, a number of reasons suggest the\\npotential for development and deployment of increasingly agentic algorithmic systems. These factors are the economic'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 7, 'page_label': '8'}, page_content='potential for development and deployment of increasingly agentic algorithmic systems. These factors are the economic\\nand military advantages afforded by increasingly agentic systems, scientific curiosity and prestige, a lack of regulatory\\nbarriers, and emergent agency. The first three reasons are sociopolitical, while the last reason concerns potentially\\nsurprising technical properties of ML systems. Taken together, these increase our subjective likelihood that systems\\nwill become increasingly agentic.\\n3.2.1 Economic Incentives. Actors who deploy more agentic systems than their competitors would likely generate more\\nprofit because of increased automation. First, more agentic systems might be able to perform tasks much more cheaply\\nthan a less agentic systems. A less agentic system by definition would require more human intervention, whether to\\nmake decisions or specify explicit procedures for task completion. Second, more agentic systems will often be more'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 7, 'page_label': '8'}, page_content='make decisions or specify explicit procedures for task completion. Second, more agentic systems will often be more\\neffective at performing tasks than less agentic systems. Part of an increase of agency is the degree to which a system\\nachieves a goal without operators or designers to specify how. The upshot is that the search space of solutions to a\\nproblem is larger for a more agentic system, which could result in solutions that would be much more efficient than\\nthose a human could have found. That AlphaGo [Silver et al. 2016] beat Lee Sedol, the world Go champion, with the\\napparently confusing move 37 is evidence of this possibility.\\n3.2.2 Military Incentives. Militaries may perceive that increasingly agentic systems could provide capability advantages\\nto over adversaries that are constrained by human decision-making. The introduction by any one military of a more\\nagentic system could upset a balance of power and force others to pursue similar developments in an unsafe race to the'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 7, 'page_label': '8'}, page_content='agentic system could upset a balance of power and force others to pursue similar developments in an unsafe race to the\\nbottom, mirroring other races for technologies such as nuclear weapons, and ballistic and hypersonic missiles [Dafoe\\n2018]. The UK’s defence AI strategy [noa 2022a] frames advances in AI as being an area of “geostrategic competition”\\nand “a battleground for competing ideologies”, but also imposes no governance or oversight mechanisms on increasingly\\nagentic systems, focusing such efforts “on effects rather than the nature of any particular technology. ” Total bans on\\ndevelopments for such highly autonomous systems may be difficult to introduce and maintain, and it may be easier to\\npursue nonproliferation of such advances beyond a small set of technologically advanced users [Trager 2022].\\nManuscript submitted to ACM'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 8, 'page_label': '9'}, page_content='Harms from Increasingly Agentic Algorithmic Systems 9\\n3.2.3 Scientific Curiosity and Prestige. Developing increasingly agentic systems is an object of scientific curiosity and\\nalso confers status, a motivation that contributes to a prestige race at varying levels between actors in the AI research\\nsystem. For individual researchers this emerges through standard metrics such as paper publications and grant awards\\nthat support climbing the academic career ladder, but for many leading figures the ambitions transcend these: Geoffrey\\nHinton – a pioneer deep learning research – has stated that “the prospect of discovery is too sweet” in spite of his\\nbeliefs that “political systems will use [AI] to terrorize people” [Khatchadourian 2015], and Rich Sutton – a pioneer\\nin reinforcement learning – has stated that creating “beings of far greater intelligence than current humans” (that'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 8, 'page_label': '9'}, page_content='in reinforcement learning – has stated that creating “beings of far greater intelligence than current humans” (that\\nwould necessarily be agentic) will be “the greatest intellectual achievement of all time” and “a great and glorious goal”\\n[Sutton 2022]. For companies, developing increasingly agentic systems could drive the most impactful research and\\ndevelopment outputs, increasing attractiveness to the best scientific talent in a competitive hiring pool. For nations,\\nhighly visible scientific demonstrations may act as demonstrations of broader state capacity, and prestige may be as\\nmotivating a force as security for competitive races with peers and adversaries [Barnhart 2022]\\n3.2.4 Lack of Regulatory Barriers. Regulatory efforts for AI have focused largely on salient risks, rather than on\\nanticipatory governance mechanisms that are proactive to future advances in AI capabilities [Gesley et al. 2019]. For'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 8, 'page_label': '9'}, page_content='anticipatory governance mechanisms that are proactive to future advances in AI capabilities [Gesley et al. 2019]. For\\nexample, the EU AI act currently proposes to target regulation according to tiers of risk determined by type of data\\nuse and deployment setting, and efforts in the UK take a sectoral focus on regulating only the applications of AI, but\\nneither covers development of agentic AI systems that could both be intrinsically high-risk and could underlie progress\\nand use across a variety of sectors and domains [noa 2022b; Edwards 2022]. Accordingly, development and deployment\\nin this space is effectively unregulated and without any clear possibility of regulation in the near future.\\n3.2.5 Emergent Agency. Even if designers do not explicitly build more agency into their systems, it may emerge from\\ngeneral capability improvements. Recent works discuss emergent behaviors of large language models. Bommasani et al.'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 8, 'page_label': '9'}, page_content='general capability improvements. Recent works discuss emergent behaviors of large language models. Bommasani et al.\\n[2022] introduce emergence as a “behavior of a system [that] is implicitly induced rather than explicitly constructed; it\\nis both the source of scientific excitement and anxiety about unintended consequences. ” For example, LLMs are trained\\nto model a distribution of internet text; this training leads toemergent behavior such as learning from very few examples\\n[Olsson et al. 2022], or arithmetic [Brown et al. 2020], or even the ability itself to perform sequential reasoning [Wei\\net al. 2023]. Many of these abilities only emerge at a certain scale, or after a certain point in the training process [Wei\\net al. 2022].\\nWhen emergent behavior increases the agency of a system we can speak ofemergent agency. One particularly striking\\nexample is the ability of LLMs to simulate the human agents who are the sources of the training data. For example,'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 8, 'page_label': '9'}, page_content='example is the ability of LLMs to simulate the human agents who are the sources of the training data. For example,\\nmaraoz [2021] uses GPT-3 to write a transcript of a conversation between themselves and Albert Einstein, and others\\nhave used LLMs to retroactively simulate user studies from psychology and economics [Aher et al. 2022]. The seeming\\nfidelity of such texts has motivated some to argue that LLMs have a general ability to simulate human agents [Andreas\\n2022].\\nSome emergent capabilities relate directly to our characterization of agency. Wei et al . [2023] show that adding\\n“let’s think step-by-step” vastly improves sequential reasoning capabilities in LLMs, a capability which is useful for\\nperforming tasks over long time horizons. Team et al. [2023] show that scaling up a particular approach leads to RL\\nsystems that capably adapt to open-ended, novel 3D problems as well as humans can, without human intervention on\\nhow to solve the problem.\\nManuscript submitted to ACM'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 9, 'page_label': '10'}, page_content='10 Chan et al.\\n3.3 Potential Objections to our Characterization of ML Progress\\n3.3.1 The Need for Anticipation of Increasingly Agentic Systems is Small. Earlier, we distinguished between two things\\nto anticipate: (1) the increasing agency of developed systems and (2) the deployment of systems with more agency\\nthan those already deployed. We respond to objections against both points.\\nOne could accept the need for attention to (1), but maintain that the need is small given that technical improvements\\nto increase agency occur much more slowly than we have characterized. Indeed, past beliefs in rapid pace of artificial\\nintelligence research have been overoptimistic [Dreyfus 1965]. Barriers to increasing agency include acting capably\\nover long time horizons [Valmeekam et al. 2022] and with an accurate understanding of the world [Bender and Koller\\n2020]. These challenges are real and there is by no means any certainty that the ML research community will overcome'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 9, 'page_label': '10'}, page_content='2020]. These challenges are real and there is by no means any certainty that the ML research community will overcome\\nthem. Even the perceived agency of algorithmic systems depends heavily on (sometimes exploitative) human labor\\nand data extraction [Gray and Suri 2019; Pasquinelli and Joler 2021]. Moreover, it can be difficult to measure the rate\\nof progress towards agentic systems. Dehghani et al. [2021] provide evidence that factors other than “fundamental\\nalgorithmic superiority” may lead to the perception that a particular method is superior. Raji et al. [2021] discuss several\\nissues with benchmarking, including construct invalidity and limitations in scope.\\nWe have no disagreements on the technical challenges of developing systems of increased agency. We are also not\\nclaiming that systems of significantly greater agency than those in development already (e.g., compared to ACT-1'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 9, 'page_label': '10'}, page_content='claiming that systems of significantly greater agency than those in development already (e.g., compared to ACT-1\\n[Adept 2022], GATO [Reed et al. 2022]) will be coming soon. Rather, our view is that even absent significant technical\\nbreakthroughs, continued work within the current scientific paradigm [Kuhn and Hacking 2012] of scaling deep-\\nlearning seems likely to generate systems that are appreciably more agentic than current systems. Scaling laws provide\\npredictable relationships between the amount of compute and data used to train model of a given size, and the\\nperformance of a model on some metric. Of particular interest for increasing agency is that scaling laws have been\\nderived for reinforcement learning [Gao et al . 2022; Hilton et al . 2023; Team et al. 2023] and generative modeling\\n[Hoffmann et al. 2022; Kaplan et al. 2020]. There is also initial work into developing scaling laws for robotics [Caballero'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 9, 'page_label': '10'}, page_content='[Hoffmann et al. 2022; Kaplan et al. 2020]. There is also initial work into developing scaling laws for robotics [Caballero\\net al. 2023]. The upshot is that continued training of larger models with more compute and data seems likely to increase\\nthe ability of systems to act in environments of increasing scope, over longer time horizons, to achieve goals without\\nsignificant designer/operator intervention.\\nOne could also object to the need for attention to (2). Even if a system that is more agentic than those currently\\ndeployed has been developed, there might still be strong reasons against deployment, despite the incentives in Sec-\\ntion 3.2.1. Raji et al. [2022] argues that deployed AI systems often simply do not work, suffering from issues such as\\nrobustness failures, missing safety features, or being set to perform impossible tasks (such as inferring criminality\\nfrom appearance). Given that increasingly agentic systems would be more capable of achieving goals without human'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 9, 'page_label': '10'}, page_content='from appearance). Given that increasingly agentic systems would be more capable of achieving goals without human\\nspecification of how, the failures that Raji et al. [2022] highlight could disincentivize adoption of increasingly agentic\\nsystems, even if they were developed.\\nThe likely failures of a more agentic system (relative to what has been deployed already) are certainly a barrier to\\ndeployment – given the disproportionate impact of these failures on already marginalized groups, we would hope and\\nadvocate for restrictions on deployment [Brundage et al. 2020]. However, we think that this barrier is unfortunately\\nweak relative to countervailing forces. Hype around the (claimed) functionalities of ML systems is strong [Broussard\\net al. 2019; Natale and Ballatore 2020; Schulz et al. 2019], which is unsurprising given massive financial investments\\n[Giattino et al. 2022]. Continued cycles of deployment and failure [Barabas et al. 2020; Buolamwini and Gebru 2018;'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 9, 'page_label': '10'}, page_content='[Giattino et al. 2022]. Continued cycles of deployment and failure [Barabas et al. 2020; Buolamwini and Gebru 2018;\\nObermeyer and Mullainathan 2019; Piantadosi and Hill 2022; Ribeiro et al. 2020; Wallace et al. 2019; Wolfe and Caliskan\\nManuscript submitted to ACM'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 10, 'page_label': '11'}, page_content='Harms from Increasingly Agentic Algorithmic Systems 11\\n2022] suggest that increasingly agentic systems will likely be deployed according to industry interests, and not the\\ninterest of those most likely to be harmed.\\n3.3.2 Techno-Determinism. An objection against our characterization of increasingly agentic systems is that it is\\ntechno-deterministic – it assumes that AI development is inevitable and determines the direction of sociocultural\\ndevelopment [Wyatt 2008]. This objection comes in two parts. Firstly, the perceived inevitability of ML progress nullifies\\naccountability of those developing the systems and removes reason to regulate or stop development. Secondly, techno-\\ndeterminism neglects social and cultural structures and implies a reductionist view of the harms caused by ML systems.\\nRelated to this is the adoption of discourse around ML systems that their capabilities are both scientifically impossible'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 10, 'page_label': '11'}, page_content='Related to this is the adoption of discourse around ML systems that their capabilities are both scientifically impossible\\nto explain, and yet deterministic in their societal impact [Campolo and Crawford 2020]. Some who study the harms of\\nmore agentic systems have also been accused of techno-optimism – optimism about the potential of technology to solve\\nmajor social problems – and techno-determinism [Cremer and Kemp 2021]. The problems include a disproportionately\\nhigh reliance on technological solutions and neglect of insights from structural aspects of risk-analysis.\\nWe do not dispute the dangers of techno-determinism or techno-optimism. However, careful work on identifying\\nand mitigating harms of increasingly agentic systems need not rely on or contribute to either. For example, one can\\nbe engaged in activism to ban specific uses or developments of increasingly agentic AI, while concurrently pursuing'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 10, 'page_label': '11'}, page_content='be engaged in activism to ban specific uses or developments of increasingly agentic AI, while concurrently pursuing\\nsociotechnical research to mitigate those systems’ potential harms. In this framing, the sociotechnical work can be\\nseen as an attempt to reduce harm in the case that one’s broader attempts to change the field’s course of action are not\\nsuccessful. While it can be argued that working on such harm reduction contributes to perceptions of inevitability or\\ndeployment incentives, being thoughtful in the framing of one’s work can significantly contribute to avoiding this issue.\\n4 ANTICIPATED HARMS FROM INCREASINGLY AGENTIC SYSTEMS\\nThe previous section argued for the need to anticipate the harms of increasingly agentic systems. We now delve into\\nsome of these harms and why they are of especial importance for the FATE community.\\n4.1 Systemic, Delayed Harms\\nA systemic harm is a harm that is pervasively embedded in society. A delayed harm is a harm whose cause has a'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 10, 'page_label': '11'}, page_content='4.1 Systemic, Delayed Harms\\nA systemic harm is a harm that is pervasively embedded in society. A delayed harm is a harm whose cause has a\\nnon-immediate impact. Systemic, delayed harms from algorithmic systems negatively influence groups of people in\\nnon-immediate ways. While harder to analyze than immediate harms, systemic and delayed harms might also be more\\ninsidious, as they can be caused even by low-stakes decision making systems. Each action might not seem consequential\\non its own, but, in aggregate, the outcomes can be destructive, long-lasting, and hard to fix. For example, there has\\nrecently been evidence that a single rent-setting algorithm might have significantly contributed to an increase in\\nhousing rental costs across the US [Vogell et al. 2022].\\nThe FATE community has studied systemic and delayed harms in the past, such as environmental risks [Bender\\net al. 2021], concentration of power [Abdalla and Abdalla 2021; Pratyusha 2020], unfair algorithmic hiring decisions'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 10, 'page_label': '11'}, page_content='et al. 2021], concentration of power [Abdalla and Abdalla 2021; Pratyusha 2020], unfair algorithmic hiring decisions\\n[Sühr et al. 2021], and privacy infringements [Ekstrand et al. 2018]. Another line of work focusing on the long-term\\nfairness implications of decisions [Bird et al. 2016; D’Amour et al. 2020b; Jabbari et al. 2017; Joseph et al. 2016; Liu et al.\\n2018; Zhang and Liu 2020]. More broadly, many have identified the systemic nature of general classes of harms, such as\\nfinancial risk [Armour and Gordon 2014], racism [Braveman et al. 2022], and misogyny [Manne 2017].\\nSocial media is speculated to be a contributing factor to many systemic and delayed harms, including mental health\\nissues [Hou et al. 2019; Yoon et al. 2019], the amplification of political polarisation [Whittaker et al . 2021], and the\\nManuscript submitted to ACM'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 11, 'page_label': '12'}, page_content='12 Chan et al.\\nspread of fake news [Allcott and Gentzkow 2017]. There is evidence on both sides for many of these issues [Boxell et al.\\n2017; Keles et al. 2020; Lewis-Kraus 2022], but caution seems warranted due to the sheer scale of these platforms (e.g.,\\nFacebook has almost three-billion users [Meta 2023]).\\nWhile many of these harms do not involve the use of algorithms that are trained to act over long time horizons\\n[Jiang et al. 2019], the application of reinforcement-learning based recommendation systems (RLRS) in today’s social\\nmedia platforms warrant additional reason for concern. In particular, Carroll et al. [2022]; Evans and Kasirzadeh [2022];\\nKrueger et al. [2020] show that long time-horizon systems, such as RLRS, will have incentives to change or manipulate\\nusers’ internal states (e.g. preferences, beliefs, and psychology) for the purposes of increasing the metrics the RLRS'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 11, 'page_label': '12'}, page_content='users’ internal states (e.g. preferences, beliefs, and psychology) for the purposes of increasing the metrics the RLRS\\nsystems are optimizing. While some work has also investigated potential solutions [Carroll et al. 2022; Farquhar et al.\\n2022], how to practically measure and address these issues in real-world RLRS remains an open problem. Notably, such\\nsystems are not speculative: RLRS are now increasingly applied by major social media providers (such as YouTube or\\nFacebook), as discussed in Section 3.1.2.\\n4.2 Collective Disempowerment\\nWe take collective self-governance to be the capacity and ongoing act of deciding collectively how to govern one’s\\ncommunity, whether it be a small, local community, a state, or human societies at large [Christiano and Bajaj 2022].\\nCollective self-governance is about power, which is a core theme in FATE work [Abdalla and Abdalla 2021; Barabas et al.'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 11, 'page_label': '12'}, page_content='Collective self-governance is about power, which is a core theme in FATE work [Abdalla and Abdalla 2021; Barabas et al.\\n2020; Birhane et al. 2022; Boag et al. 2022; Kasy and Abebe 2021; Young et al. 2022]. Indeed, the FATE community has\\nextensively studied the ways in which automated decision-making can disempower individuals, by impairing human\\ndecision-making [Green and Chen 2019; Green 2021] or subjecting individuals to oppressive institutions [Barabas\\net al. 2020, 2018; Green 2020; Zilka et al. 2022]. We extend this ongoing discussion by pointing to some ways in which\\nincreasingly agentic systems can result in collective disempowerment. A key underlying point will be that increasingly\\nagentic systems will likely seem more capable of handling more important societal functions without significant\\noperator or designer intervention, as we discussed in Section 3.2.1. We discuss two possibilities: a situation in which'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 11, 'page_label': '12'}, page_content='operator or designer intervention, as we discussed in Section 3.2.1. We discuss two possibilities: a situation in which\\npower diffuses away from all humans, and a situation in which power concentrates in the hands of a few.\\n4.2.1 Diffusion of Power Away from Humans. As systems become increasingly agentic, they have increasing control of\\nsocietal functions in many ways. At one end, humans in a particular social structure may decide to cede decision-making\\npower to an particular system, such as one that decides taxation policy [Zheng et al. 2021]. At the other end, power\\nmay gradually be ceded, as separate groups are incentivized to delegate more central functions to increasingly agentic\\nsystems per Section 3.2.1. Cooper et al. [2022]; Nissenbaum [1996] examine the erosion of accountability that externalizes\\nalgorithmic harms. Even if collective disempowerment is a risk, it might not be a large enough risk for a single party to'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 11, 'page_label': '12'}, page_content='algorithmic harms. Even if collective disempowerment is a risk, it might not be a large enough risk for a single party to\\nbe concerned. In either case, ceding decision-making power to such systems is not inevitable; it would be a result of\\ncollective human decisions.\\nRegardless of how power is ceded, any group might have increasing difficulty in controlling increasingly agentic\\nsystems. Specifying a correct objective function is quite difficult [Krakovna et al. 2020; Skalse et al. 2022]. Even a system\\nsuccessfully trained under a correctly specified objective function may do something completely different in a different\\nenvironment [Langosco et al. 2022; Shah et al. 2022]. Additional problems remain in understanding how to manage the\\ninterests of multiple stakeholders [Dafoe et al. 2020]. As well, it would likely be extremely difficult to understand the\\ndecisions of the controlling system(s). Analysis of a single decision is likely insufficient for understanding the reasons'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 11, 'page_label': '12'}, page_content='decisions of the controlling system(s). Analysis of a single decision is likely insufficient for understanding the reasons\\nfor a series of long-term decisions (i.e., the overall plan). Collective self-governance requires not just having decisions\\nbe made, but understanding why those decisions are made, which Lazar [2022] terms the publicity requirement. Lazar\\nManuscript submitted to ACM'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 12, 'page_label': '13'}, page_content='Harms from Increasingly Agentic Algorithmic Systems 13\\n[2022] argues that failure to satisfy this requirement delegitimizes the exercise of political authority, by nullifying the\\nmoral effectiveness of consent.\\n4.2.2 Exacerbating the Extreme Concentration of Power Amongst the “Coding Elite”. The FATE community has highlighted\\nthe concerning ways in which the deployment of algorithmic systems has concentrated power in the hands of designers\\nand/or operators. Kasy and Abebe [2021] argues that common notions of fairness legitimize hierarchies that are the\\nresult of historical injustice. They also provide a framework to reason about the impact of algorithmic decisions on the\\ndistribution of power. Burrell and Fourcade [2021, p. 217] identifies the coding elite – a nebula of software developers,\\ntech CEOs, investors, and computer science and engineering professors, among others, often circulating effortlessly'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 12, 'page_label': '13'}, page_content='tech CEOs, investors, and computer science and engineering professors, among others, often circulating effortlessly\\nbetween these influential roles – as a main beneficiary of the concentration of power. According to Burrell and Fourcade\\n[2021], the coding elite concentrates power by controlling the algorithms underlying the modern digital world, using\\nthat power to affect politics for their own gains. The amount of control exerted is already substantial with existing\\nalgorithmic systems, considering the centrality of the products of a handful of tech companies in our daily lives.\\nIncreasingly agentic systems threaten to exacerbate an already extreme concentration of power. First, Ganguli et al.\\n[2022, p. 11] show that the proportion of large-scale ML results from industry has dominated in the past few years. The\\nimportance of large-scale results for increasing agency is that, as we discussed in Section 3, scaling up the compute,'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 12, 'page_label': '13'}, page_content='importance of large-scale results for increasing agency is that, as we discussed in Section 3, scaling up the compute,\\ndata, and parameters of a system provides a significant way to increase its agency, and is in some sense easier than\\nderiving fundamental algorithmic insights. It therefore seems plausible that large industrial labs will continue to be the\\nones who deploy and profit the most from increasingly agentic systems. Second, increasingly agentic systems would\\nlikely enable the coding elite to integrate algorithms into more of society. There are many tasks now that are yet outside\\nthe reach of algorithmic systems, such as deciding national economic policy or running a business. Increasingly agentic\\nsystems seem more likely to be able to assume many of those tasks than current systems.\\n4.3 Harms that have yet to be Identified\\nIn Section 3.2.5, we identified emergent behaviours as a possible cause of increasingly agentic algorithmic systems.'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 12, 'page_label': '13'}, page_content='4.3 Harms that have yet to be Identified\\nIn Section 3.2.5, we identified emergent behaviours as a possible cause of increasingly agentic algorithmic systems.\\nHere, we explain some emergent behaviours that could be the source of harms that have yet to be identified and the\\nlink of those behaviours with increasing agency.\\n4.3.1 Reward Hacking. An RL system trained to maximize its score in the video game CoastRunners will drive off-track\\nand keep turning in circles forever, thus achieving a high score despite not completing the race-track as intended by the\\nprogrammers [Clark and Amodei 2016]. This kind of failure is called reward hacking [Krakovna et al. 2020; Skalse\\net al. 2022], which is when a system exploits a reward signal to achieve a goal in an unforeseen, perhaps undesirable\\nway. As an instance of Goodhart’s law [Goodhart 1975], reward hacking is a common problem in ML systems that'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 12, 'page_label': '13'}, page_content='way. As an instance of Goodhart’s law [Goodhart 1975], reward hacking is a common problem in ML systems that\\ninvolve elements associated with increasing agency, in particular goal-directedness.3 Increased model size or training\\ntime can result in abrupt increases in reward hacking, because a more capable model is better able find unforeseen\\nmaxima of its reward function [Pan et al. 2022].\\nIf increasingly agentic systems are deployed in consequential domains like finance, health care, and law, reward\\nhacking could result in extremely negative outcomes. Even with knowledge of the possibility of reward hacking,\\ndesigners might still deploy systems anyway if the harms from their systems are externalized, or if they judge the\\nimmediate likelihood of reward hacking to be low.\\n4.3.2 Instrumental Goals. An instrumental goal is a goal that is useful as a subobjective in pursuit of a specified'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 12, 'page_label': '13'}, page_content='immediate likelihood of reward hacking to be low.\\n4.3.2 Instrumental Goals. An instrumental goal is a goal that is useful as a subobjective in pursuit of a specified\\ngoal. A convergent instrumental goal is a goal that would be useful in pursuit of a wide range of possible goals. For\\n3A large number of examples of reward hacking are compiled in this online spreadsheet.\\nManuscript submitted to ACM'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 13, 'page_label': '14'}, page_content='14 Chan et al.\\nexample, acquiring money is a convergent instrumental goal since money increases economic power and optionality.\\nMany convergent instrumental goals involve gaining some sort of power over the environment and other actors within\\nit [Omohundro 2008].\\nAn algorithmic system that sought to gain power over other actors, such as through manipulation or threats [Kenton\\net al. 2021], would be concerning. An additional concern would be if the same thing were to happen without explicit,\\nmalicious instructions from their designer(s) or operator(s) to perform such behaviour. While this possibility remains\\nuncertain, some initial evidence does not dismiss it. Perez et al . [2022] show that increased training of a LLM with\\nRL techniques can increase the proportion of the time that the LLM expresses the pursuit of convergent instrumental\\ngoals, such as gaining wealth and persuading the operator not to shut it off, without any apparent designer or operator'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 13, 'page_label': '14'}, page_content='goals, such as gaining wealth and persuading the operator not to shut it off, without any apparent designer or operator\\ninstruction to do so. To recall, RL is about the construction of agents, by training systems to act over long time horizons\\nto achieve goals without explicit human intervention. Training LLMs with RL techniques plausibly increases their\\nagency; therefore, Perez et al. [2022] provides some evidence that increasing the agency of LLMs can be associated with\\nan increase in the expression of convergent instrumental goals. It is important not to overstate this early evidence;\\nexpressing a desire to pursue a goal is different from actually pursuing the goal in the world. Yet, this evidence should\\nbe taken as an additional reason for caution regarding increasingly agentic systems.\\n5 POSSIBILITIES FOR FUTURE WORK\\nMuch work remains in figuring out how to address the present need we have highlighted throughout our piece. We'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 13, 'page_label': '14'}, page_content='5 POSSIBILITIES FOR FUTURE WORK\\nMuch work remains in figuring out how to address the present need we have highlighted throughout our piece. We\\nprovide a preliminary discussion of some directions and tie them to existing work from the FATE community.\\n5.1 Investigating the Sociotechnical Attributes of Increasingly Agentic Systems\\nSeveral landmark works in the FATE community have involved audits [Raji et al. 2020] of algorithmic systems [Black\\net al. 2022; Buolamwini and Gebru 2018; Obermeyer and Mullainathan 2019; Ribeiro et al. 2020]. Audits have motivated\\naction from designers to reduce the harms of their systems [Raji and Buolamwini 2019].\\nSince one typically audits a deployed system, it will be difficult to perform thorough audits of increasingly agentic\\nsystems before they are widely deployed. Nevertheless, there are a variety of ways to reason about the potential impacts'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 13, 'page_label': '14'}, page_content='systems before they are widely deployed. Nevertheless, there are a variety of ways to reason about the potential impacts\\nof a system’s deployment. Assuming either that we have the system in question or that we can simulate it faithfully\\n[Aher et al. 2022; Elzayn and Fish 2020; Park et al. 2022], we can formulate and test hypotheses in simple experiments\\nor simulation. More broadly, it might be possible to take inspiration from policymaking techniques such as scenario\\nplanning [Volkery and Ribeiro 2009], which involve thinking ahead about how to make effective policy decisions when\\nuncertain about what the world will look like in the future. The emerging science of forecasting [Tetlock and Gardner\\n2016] may also provide insights into anticipating the impacts of emerging systems.\\nOther tools from the FATE community may be helpful for characterizing the sociotechnical attributes of increasingly'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 13, 'page_label': '14'}, page_content='2016] may also provide insights into anticipating the impacts of emerging systems.\\nOther tools from the FATE community may be helpful for characterizing the sociotechnical attributes of increasingly\\nagentic systems, even before widespread deployment. For example, datasheets [Gebru et al . 2021] and model cards\\n[Mitchell et al. 2019] can highlight sources of harm, such as accountability gaps [Nissenbaum 1996], in a way that\\ndoes not depend upon a particular application. In the same vein, Gilbert et al . [2022] introduces reward reports to\\ndocument what it appears that systems are optimizing for, which may help to reduce the likelihood of unintended\\nnegative consequences from system operation.\\nManuscript submitted to ACM'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 14, 'page_label': '15'}, page_content='Harms from Increasingly Agentic Algorithmic Systems 15\\n5.2 Stronger Regulations\\nStronger regulations could prevent some harms of increasingly agentic systems from occurring. Compute limits enforced\\nby compute usage tracking [Brundage et al. 2020], while a source of serious privacy risks, could help to control the pace\\nat which systems become increasngly agentic and permit more time to develop mitigations. Along this line, it might be\\ncollectively beneficial to decide upon a level of agency as a deployment bar. If a system surpassed this level of agency, it\\nwould be forbidden from application in certain consequential sectors, like energy, the military, finance, health care,\\nand criminal justice. The FATE community has previously rallied around deeming certain applications off-limits for\\nparticular technologies, such as the use of deep learning to predict criminality [for Critical Technology 2020]. Such an'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 14, 'page_label': '15'}, page_content='particular technologies, such as the use of deep learning to predict criminality [for Critical Technology 2020]. Such an\\nidea could be implemented in what Tutt [2017] calls an “FDA for algorithms”, which would scrutinize each algorithmic\\nsystem before permitting its deployment, just as drugs are regulated in the United States.\\n6 CONCLUSION\\nOur work focused on the increasing prevalence of agency in machine-learning systems and associated harms. We\\nsituated our characterization of increasing agency in the context of diverse work on the meaning of agency. We\\nargued that there is a need to anticipate the harms from increasingly agentic systems, given a strong track record\\nof, and incentives for, technical developments and increasing deployment. We described some anticipated harms\\nfrom increasingly agentic systems, namely that they could cause systemic and delayed harms, disempower human'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 14, 'page_label': '15'}, page_content='from increasingly agentic systems, namely that they could cause systemic and delayed harms, disempower human\\ndecision-making, exacerbate extreme concentrations of power, and be a source of additional unknown threats through\\nemergent capabilities.\\nAddressing the harms of increasingly agentic systems shares commonalities with central lines of work in the FATE\\ncommunity on anticipating the harms of algorithmic decision-making systems. Future work, such as investigations into\\nthe sociotechnical attributes of increasingly agentic systems and interventions upon the structural factors underlying\\ntheir harms, readily follows from ongoing efforts. Immense pressure to develop and deploy emerging technologies\\nshould be met with similarly strong attempts to guide and constrain their impact.\\nACKNOWLEDGMENTS\\nIn no particular order, we would like to thank Robert Harling, Max Kaufmann, Fernando Diaz, Seth Lazar, Janarthan'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 14, 'page_label': '15'}, page_content='ACKNOWLEDGMENTS\\nIn no particular order, we would like to thank Robert Harling, Max Kaufmann, Fernando Diaz, Seth Lazar, Janarthan\\nRajendran, Nicolas Le Roux, Shahar Avin, Kayla Matteucci, Thomas Gilbert, Herbie Bradley, and Usman Anwar for\\ninsightful comments about the direction of the project and parts of the paper. All mistakes remain our own.\\nREFERENCES\\n2022a. Defence Artificial Intelligence Strategy . Technical Report. Ministry of Defence. https://www.gov.uk/government/publications/defence-artificial-\\nintelligence-strategy/defence-artificial-intelligence-strategy\\n2022b. Establishing a pro-innovation approach to regulating AI . Technical Report. Office for Artificial Intelligence. https://www.gov.uk/government/\\npublications/establishing-a-pro-innovation-approach-to-regulating-ai/establishing-a-pro-innovation-approach-to-regulating-ai-policy-statement'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 14, 'page_label': '15'}, page_content='publications/establishing-a-pro-innovation-approach-to-regulating-ai/establishing-a-pro-innovation-approach-to-regulating-ai-policy-statement\\nMohamed Abdalla and Moustafa Abdalla. 2021. The Grey Hoodie Project: Big Tobacco, Big Tech, and the Threat on Academic Integrity. In Proceedings of\\nthe 2021 AAAI/ACM Conference on AI, Ethics, and Society . ACM. https://doi.org/10.1145/3461702.3462563\\nRediet Abebe, Solon Barocas, Jon Kleinberg, Karen Levy, Manish Raghavan, and David G. Robinson. 2020. Roles for computing in social change. In\\nProceedings of the 2020 Conference on Fairness, Accountability, and Transparency . ACM. https://doi.org/10.1145/3351095.3372871\\nRediet Abebe and Kira Goldner. 2018. Mechanism design for social good. AI Matters 4, 3 (Oct. 2018), 27–34. https://doi.org/10.1145/3284751.3284761\\nAbubakar Abid, Maheen Farooqi, and James Zou. 2021. Persistent Anti-Muslim Bias in Large Language Models. In Proceedings of the 2021 AAAI/ACM'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 14, 'page_label': '15'}, page_content='Abubakar Abid, Maheen Farooqi, and James Zou. 2021. Persistent Anti-Muslim Bias in Large Language Models. In Proceedings of the 2021 AAAI/ACM\\nConference on AI, Ethics, and Society . ACM. https://doi.org/10.1145/3461702.3462624\\nAdept. 2022. ACT-1: Transformer for Actions. https://www.adept.ai/act\\nManuscript submitted to ACM'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 15, 'page_label': '16'}, page_content='16 Chan et al.\\nM. Mehdi Afsar, Trafford Crump, and Behrouz Far. 2022. Reinforcement learning based recommender systems: A survey. https://doi.org/10.48550/arXiv.\\n2101.06286 arXiv:2101.06286 [cs].\\nGati Aher, Rosa I Arriaga, and Adam Tauman Kalai. 2022. Using Large Language Models to Simulate Multiple Humans. arXiv preprint arXiv:2208.10264\\n(2022).\\nJean-Baptiste Alayrac, Jeff Donahue, Pauline Luc, Antoine Miech, Iain Barr, Yana Hasson, Karel Lenc, Arthur Mensch, Katie Millican, Malcolm Reynolds,\\nRoman Ring, Eliza Rutherford, Serkan Cabi, Tengda Han, Zhitao Gong, Sina Samangooei, Marianne Monteiro, Jacob Menick, Sebastian Borgeaud,\\nAndrew Brock, Aida Nematzadeh, Sahand Sharifzadeh, Mikolaj Binkowski, Ricardo Barreira, Oriol Vinyals, Andrew Zisserman, and Karen Simonyan.\\n2022. Flamingo: a Visual Language Model for Few-Shot Learning. https://doi.org/10.48550/arXiv.2204.14198 arXiv:2204.14198 [cs].'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 15, 'page_label': '16'}, page_content='2022. Flamingo: a Visual Language Model for Few-Shot Learning. https://doi.org/10.48550/arXiv.2204.14198 arXiv:2204.14198 [cs].\\nHunt Allcott and Matthew Gentzkow. 2017. Social Media and Fake News in the 2016 Election. Journal of Economic Perspectives 31, 2 (May 2017), 211–236.\\nhttps://doi.org/10.1257/jep.31.2.211\\nJacob Andreas. 2022. Language Models as Agent Models. https://doi.org/10.48550/arXiv.2212.01681 arXiv:2212.01681 [cs].\\nJohn Armour and Jeffrey N. Gordon. 2014. Systemic Harms and Shareholder Value. Journal of Legal Analysis 6, 1 (Oct. 2014), 35–85. https://doi.org/10.\\n1093/jla/lau004\\nAssociation for Computing Machinery (ACM). 2019. \"Reinforcement Learning for Recommender Systems: A Case Study on Youtube, \" by Minmin Chen.\\nhttps://www.youtube.com/watch?v=HEqQ2_1XRTs\\nAnton Bakhtin, Noam Brown, Emily Dinan, Gabriele Farina, Colin Flaherty, Daniel Fried, Andrew Goff, Jonathan Gray, Hengyuan Hu, Athul Paul Jacob,'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 15, 'page_label': '16'}, page_content='https://www.youtube.com/watch?v=HEqQ2_1XRTs\\nAnton Bakhtin, Noam Brown, Emily Dinan, Gabriele Farina, Colin Flaherty, Daniel Fried, Andrew Goff, Jonathan Gray, Hengyuan Hu, Athul Paul Jacob,\\nMojtaba Komeili, Karthik Konath, Minae Kwon, Adam Lerer, Mike Lewis, Alexander H. Miller, Sasha Mitts, Adithya Renduchintala, Stephen Roller,\\nDirk Rowe, Weiyan Shi, Joe Spisak, Alexander Wei, David Wu, Hugh Zhang, and Markus Zijlstra. 2022. Human-level play in the game of Diplomacy\\nby combining language models with strategic reasoning. Science 378, 6624 (Dec. 2022), 1067–1074. https://doi.org/10.1126/science.ade9097 Publisher:\\nAmerican Association for the Advancement of Science.\\nChelsea Barabas, Colin Doyle, J. B. Rubinovitz, and Karthik Dinakar. 2020. Studying up. In Proceedings of the 2020 Conference on Fairness, Accountability,\\nand Transparency. ACM. https://doi.org/10.1145/3351095.3372859'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 15, 'page_label': '16'}, page_content='and Transparency. ACM. https://doi.org/10.1145/3351095.3372859\\nChelsea Barabas, Madars Virza, Karthik Dinakar, Joichi Ito, and Jonathan Zittrain. 2018. Interventions over Predictions: Reframing the Ethical Debate for\\nActuarial Risk Assessment. In Proceedings of the 1st Conference on Fairness, Accountability and Transparency (Proceedings of Machine Learning Research,\\nVol. 81), Sorelle A. Friedler and Christo Wilson (Eds.). PMLR, 62–76. https://proceedings.mlr.press/v81/barabas18a.html\\nJoslyn Barnhart. 2022. Emerging Technologies, Prestige Motivations and the Dynamics of International Competition. (Jan. 2022). https://www.governance.\\nai/research-paper/emerging-technologies-prestige-motivations-and-the-dynamics-of-international-competition\\nJacob Beck, Risto Vuorio, Evan Zheran Liu, Zheng Xiong, Luisa Zintgraf, Chelsea Finn, and Shimon Whiteson. 2023. A Survey of Meta-Reinforcement\\nLearning. https://doi.org/10.48550/arXiv.2301.08028 arXiv:2301.08028 [cs].'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 15, 'page_label': '16'}, page_content='Learning. https://doi.org/10.48550/arXiv.2301.08028 arXiv:2301.08028 [cs].\\nG.A. Bekey. 2005. Autonomous Robots: From Biological Inspiration to Implementation and Control . MIT Press. https://books.google.ca/books?id=\\n3xwfia2DpmoC\\nEmily M. Bender, Timnit Gebru, Angelina McMillan-Major, and Shmargaret Shmitchell. 2021. On the Dangers of Stochastic Parrots: Can Language\\nModels Be Too Big?. In Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency (FAccT ’21) . Association for Computing\\nMachinery, New York, NY, USA, 610–623. https://doi.org/10.1145/3442188.3445922 event-place: Virtual Event, Canada.\\nEmily M. Bender and Alexander Koller. 2020. Climbing towards NLU: On Meaning, Form, and Understanding in the Age of Data. In Proceedings of\\nthe 58th Annual Meeting of the Association for Computational Linguistics . Association for Computational Linguistics, Online, 5185–5198. https:\\n//doi.org/10.18653/v1/2020.acl-main.463'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 15, 'page_label': '16'}, page_content='the 58th Annual Meeting of the Association for Computational Linguistics . Association for Computational Linguistics, Online, 5185–5198. https:\\n//doi.org/10.18653/v1/2020.acl-main.463\\nSarah Bird, Solon Barocas, Kate Crawford, Fernando Diaz, and Hanna Wallach. 2016. Exploring or Exploiting? Social and Ethical Implications of\\nAutonomous Experimentation in AI. https://papers.ssrn.com/abstract=2846909\\nAbeba Birhane, Elayne Ruane, Thomas Laurent, Matthew S. Brown, Johnathan Flowers, Anthony Ventresque, and Christopher L. Dancy. 2022. The\\nForgotten Margins of AI Ethics. In 2022 ACM Conference on Fairness, Accountability, and Transparency . ACM. https://doi.org/10.1145/3531146.3533157\\nEmily Black, Hadi Elzayn, Alexandra Chouldechova, Jacob Goldin, and Daniel Ho. 2022. Algorithmic Fairness and Vertical Equity: Income Fairness with\\nIRS Tax Audit Models. In 2022 ACM Conference on Fairness, Accountability, and Transparency . ACM. https://doi.org/10.1145/3531146.3533204'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 15, 'page_label': '16'}, page_content='IRS Tax Audit Models. In 2022 ACM Conference on Fairness, Accountability, and Transparency . ACM. https://doi.org/10.1145/3531146.3533204\\nSu Lin Blodgett, Gilsinia Lopez, Alexandra Olteanu, Robert Sim, and Hanna Wallach. 2021. Stereotyping Norwegian Salmon: An Inventory of Pitfalls in\\nFairness Benchmark Datasets. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International\\nJoint Conference on Natural Language Processing (Volume 1: Long Papers) . Association for Computational Linguistics, Online, 1004–1015. https:\\n//doi.org/10.18653/v1/2021.acl-long.81\\nWilliam Boag, Harini Suresh, Bianca Lepe, and Catherine D’Ignazio. 2022. Tech Worker Organizing for Power and Accountability. In2022 ACM Conference\\non Fairness, Accountability, and Transparency . ACM. https://doi.org/10.1145/3531146.3533111'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 15, 'page_label': '16'}, page_content='on Fairness, Accountability, and Transparency . ACM. https://doi.org/10.1145/3531146.3533111\\nRishi Bommasani, Drew A. Hudson, Ehsan Adeli, Russ Altman, Simran Arora, Sydney von Arx, Michael S. Bernstein, Jeannette Bohg, Antoine Bosselut,\\nEmma Brunskill, Erik Brynjolfsson, Shyamal Buch, Dallas Card, Rodrigo Castellon, Niladri Chatterji, Annie Chen, Kathleen Creel, Jared Quincy\\nDavis, Dora Demszky, Chris Donahue, Moussa Doumbouya, Esin Durmus, Stefano Ermon, John Etchemendy, Kawin Ethayarajh, Li Fei-Fei, Chelsea\\nFinn, Trevor Gale, Lauren Gillespie, Karan Goel, Noah Goodman, Shelby Grossman, Neel Guha, Tatsunori Hashimoto, Peter Henderson, John Hewitt,\\nDaniel E. Ho, Jenny Hong, Kyle Hsu, Jing Huang, Thomas Icard, Saahil Jain, Dan Jurafsky, Pratyusha Kalluri, Siddharth Karamcheti, Geoff Keeling,\\nFereshte Khani, Omar Khattab, Pang Wei Koh, Mark Krass, Ranjay Krishna, Rohith Kuditipudi, Ananya Kumar, Faisal Ladhak, Mina Lee, Tony Lee,'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 15, 'page_label': '16'}, page_content='Fereshte Khani, Omar Khattab, Pang Wei Koh, Mark Krass, Ranjay Krishna, Rohith Kuditipudi, Ananya Kumar, Faisal Ladhak, Mina Lee, Tony Lee,\\nJure Leskovec, Isabelle Levent, Xiang Lisa Li, Xuechen Li, Tengyu Ma, Ali Malik, Christopher D. Manning, Suvir Mirchandani, Eric Mitchell, Zanele\\nManuscript submitted to ACM'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 16, 'page_label': '17'}, page_content='Harms from Increasingly Agentic Algorithmic Systems 17\\nMunyikwa, Suraj Nair, Avanika Narayan, Deepak Narayanan, Ben Newman, Allen Nie, Juan Carlos Niebles, Hamed Nilforoshan, Julian Nyarko, Giray\\nOgut, Laurel Orr, Isabel Papadimitriou, Joon Sung Park, Chris Piech, Eva Portelance, Christopher Potts, Aditi Raghunathan, Rob Reich, Hongyu Ren,\\nFrieda Rong, Yusuf Roohani, Camilo Ruiz, Jack Ryan, Christopher Ré, Dorsa Sadigh, Shiori Sagawa, Keshav Santhanam, Andy Shih, Krishnan Srinivasan,\\nAlex Tamkin, Rohan Taori, Armin W. Thomas, Florian Tramèr, Rose E. Wang, William Wang, Bohan Wu, Jiajun Wu, Yuhuai Wu, Sang Michael Xie,\\nMichihiro Yasunaga, Jiaxuan You, Matei Zaharia, Michael Zhang, Tianyi Zhang, Xikun Zhang, Yuhui Zhang, Lucia Zheng, Kaitlyn Zhou, and Percy\\nLiang. 2022. On the Opportunities and Risks of Foundation Models. https://doi.org/10.48550/arXiv.2108.07258 arXiv:2108.07258 [cs].'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 16, 'page_label': '17'}, page_content='Liang. 2022. On the Opportunities and Risks of Foundation Models. https://doi.org/10.48550/arXiv.2108.07258 arXiv:2108.07258 [cs].\\nSamuel Bowman. 2022. The Dangers of Underclaiming: Reasons for Caution When Reporting How NLP Systems Fail. In Proceedings of the 60th Annual\\nMeeting of the Association for Computational Linguistics (Volume 1: Long Papers) . Association for Computational Linguistics, Dublin, Ireland, 7484–7499.\\nhttps://doi.org/10.18653/v1/2022.acl-long.516\\nLevi Boxell, Matthew Gentzkow, and Jesse M Shapiro. 2017. Greater Internet use is not associated with faster growth in political polarization among US\\ndemographic groups. Proceedings of the National Academy of Sciences 114, 40 (2017), 10612–10617. Publisher: National Acad Sciences.\\nPaula A. Braveman, Elaine Arkin, Dwayne Proctor, Tina Kauh, and Nicole Holm. 2022. Systemic And Structural Racism: Definitions, Examples, Health'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 16, 'page_label': '17'}, page_content='Paula A. Braveman, Elaine Arkin, Dwayne Proctor, Tina Kauh, and Nicole Holm. 2022. Systemic And Structural Racism: Definitions, Examples, Health\\nDamages, And Approaches To Dismantling. Health Affairs 41, 2 (Feb. 2022), 171–178. https://doi.org/10.1377/hlthaff.2021.01394 Publisher: Health\\nAffairs.\\nMeredith Broussard, Nicholas Diakopoulos, Andrea L Guzman, Rediet Abebe, Michel Dupagne, and Ching-Hua Chuan. 2019. Artificial intelligence and\\njournalism. Journalism & Mass Communication Quarterly 96, 3 (2019), 673–695. Publisher: SAGE Publications Sage CA: Los Angeles, CA.\\nNoam Brown and Tuomas Sandholm. 2019. Superhuman AI for multiplayer poker. Science 365, 6456 (Aug. 2019), 885–890. https://doi.org/10.1126/science.\\naay2400 Publisher: American Association for the Advancement of Science.\\nTom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 16, 'page_label': '17'}, page_content='Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda\\nAskell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens\\nWinter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec\\nRadford, Ilya Sutskever, and Dario Amodei. 2020. Language Models are Few-Shot Learners. In Advances in Neural Information Processing Systems ,\\nVol. 33. Curran Associates, Inc., 1877–1901. https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html\\nMiles Brundage, Shahar Avin, Jasmine Wang, Haydn Belfield, Gretchen Krueger, Gillian Hadfield, Heidy Khlaaf, Jingying Yang, Helen Toner, Ruth\\nFong, Tegan Maharaj, Pang Wei Koh, Sara Hooker, Jade Leung, Andrew Trask, Emma Bluemke, Jonathan Lebensold, Cullen O’Keefe, Mark Koren,'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 16, 'page_label': '17'}, page_content='Fong, Tegan Maharaj, Pang Wei Koh, Sara Hooker, Jade Leung, Andrew Trask, Emma Bluemke, Jonathan Lebensold, Cullen O’Keefe, Mark Koren,\\nThéo Ryffel, J. B. Rubinovitz, Tamay Besiroglu, Federica Carugati, Jack Clark, Peter Eckersley, Sarah de Haas, Maritza Johnson, Ben Laurie, Alex\\nIngerman, Igor Krawczuk, Amanda Askell, Rosario Cammarota, Andrew Lohn, David Krueger, Charlotte Stix, Peter Henderson, Logan Graham, Carina\\nPrunkl, Bianca Martin, Elizabeth Seger, Noa Zilberman, Seán Ó hÉigeartaigh, Frens Kroeger, Girish Sastry, Rebecca Kagan, Adrian Weller, Brian\\nTse, Elizabeth Barnes, Allan Dafoe, Paul Scharre, Ariel Herbert-Voss, Martijn Rasser, Shagun Sodhani, Carrick Flynn, Thomas Krendl Gilbert, Lisa\\nDyer, Saif Khan, Yoshua Bengio, and Markus Anderljung. 2020. Toward Trustworthy AI Development: Mechanisms for Supporting Verifiable Claims.\\nhttps://doi.org/10.48550/arXiv.2004.07213 arXiv:2004.07213 [cs].'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 16, 'page_label': '17'}, page_content='https://doi.org/10.48550/arXiv.2004.07213 arXiv:2004.07213 [cs].\\nJoy Buolamwini and Timnit Gebru. 2018. Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification. In Proceedings of the\\n1st Conference on Fairness, Accountability and Transparency (Proceedings of Machine Learning Research, Vol. 81) , Sorelle A. Friedler and Christo Wilson\\n(Eds.). PMLR, 77–91. https://proceedings.mlr.press/v81/buolamwini18a.html\\nJenna Burrell and Marion Fourcade. 2021. The Society of Algorithms. Annual Review of Sociology 47, 1 (2021), 213–237. https://doi.org/10.1146/annurev-\\nsoc-090820-020800 _eprint: https://doi.org/10.1146/annurev-soc-090820-020800.\\nEthan Caballero, Kshitij Gupta, Irina Rish, and David Krueger. 2023. Broken Neural Scaling Laws. https://doi.org/10.48550/arXiv.2210.14891\\narXiv:2210.14891 [cs].\\nAlexander Campolo and Kate Crawford. 2020. Enchanted Determinism: Power without Responsibility in Artificial Intelligence. Engaging Science,'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 16, 'page_label': '17'}, page_content='arXiv:2210.14891 [cs].\\nAlexander Campolo and Kate Crawford. 2020. Enchanted Determinism: Power without Responsibility in Artificial Intelligence. Engaging Science,\\nTechnology, and Society 6 (Jan. 2020), 1–19. https://doi.org/10.17351/ests2020.277\\nMicah D. Carroll, Anca Dragan, Stuart Russell, and Dylan Hadfield-Menell. 2022. Estimating and Penalizing Induced Preference Shifts in Recommender\\nSystems. In Proceedings of the 39th International Conference on Machine Learning . PMLR, 2686–2708. https://proceedings.mlr.press/v162/carroll22a.html\\nISSN: 2640-3498.\\nHarrison Chase. 2022. LangChain 0.0.77 Docs. https://langchain.readthedocs.io/en/latest/modules/agents/getting_started.html\\nLili Chen, Kevin Lu, Aravind Rajeswaran, Kimin Lee, Aditya Grover, Misha Laskin, Pieter Abbeel, Aravind Srinivas, and Igor Mordatch. 2021. Decision\\nTransformer: Reinforcement Learning via Sequence Modeling. In Advances in Neural Information Processing Systems , Vol. 34. Curran Associates, Inc.,'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 16, 'page_label': '17'}, page_content='Transformer: Reinforcement Learning via Sequence Modeling. In Advances in Neural Information Processing Systems , Vol. 34. Curran Associates, Inc.,\\n15084–15097. https://proceedings.neurips.cc/paper/2021/hash/7f489f642a0ddb10272b5c31057f0663-Abstract.html\\nTom Christiano and Sameer Bajaj. 2022. Democracy. In The Stanford Encyclopedia of Philosophy (spring 2022 ed.), Edward N. Zalta (Ed.). Metaphysics\\nResearch Lab, Stanford University. https://plato.stanford.edu/archives/spr2022/entries/democracy/\\nJack Clark and Dario Amodei. 2016. Faulty Reward Functions in the Wild. https://openai.com/blog/faulty-reward-functions/\\nKatherine M. Collins, Catherine Wong, Jiahai Feng, Megan Wei, and Joshua B. Tenenbaum. 2022. Structured, flexible, and robust: benchmarking and\\nimproving large language models towards more human-like behavior in out-of-distribution reasoning tasks. (May 2022). https://doi.org/10.48550/\\narXiv.2205.05718'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 16, 'page_label': '17'}, page_content='improving large language models towards more human-like behavior in out-of-distribution reasoning tasks. (May 2022). https://doi.org/10.48550/\\narXiv.2205.05718\\nA. Feder Cooper, Emanuel Moss, Benjamin Laufer, and Helen Nissenbaum. 2022. Accountability in an Algorithmic Society: Relationality, Responsibility, and\\nRobustness in Machine Learning. In2022 ACM Conference on Fairness, Accountability, and Transparency . ACM. https://doi.org/10.1145/3531146.3533150\\nRémi Coulom. 2002. Reinforcement Learning Using Neural Networks, with Applications to Motor Control. (June 2002).\\nManuscript submitted to ACM'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 17, 'page_label': '18'}, page_content='18 Chan et al.\\nCarla Zoe Cremer and Luke Kemp. 2021. Democratising Risk: In Search of a Methodology to Study Existential Risk. https://papers.ssrn.com/abstract=\\n3995225\\nAllan Dafoe. 2018. AI Governance: A Research Agenda. (Aug. 2018). https://www.fhi.ox.ac.uk/wp-content/uploads/GovAI-Agenda.pdf\\nAllan Dafoe, Edward Hughes, Yoram Bachrach, Tantum Collins, Kevin R. McKee, Joel Z. Leibo, Kate Larson, and Thore Graepel. 2020. Open Problems in\\nCooperative AI. https://doi.org/10.48550/arXiv.2012.08630 arXiv:2012.08630 [cs].\\nAlexander D’Amour, Katherine Heller, Dan Moldovan, Ben Adlam, Babak Alipanahi, Alex Beutel, Christina Chen, Jonathan Deaton, Jacob Eisenstein,\\nMatthew D. Hoffman, Farhad Hormozdiari, Neil Houlsby, Shaobo Hou, Ghassen Jerfel, Alan Karthikesalingam, Mario Lucic, Yian Ma, Cory McLean,\\nDiana Mincu, Akinori Mitani, Andrea Montanari, Zachary Nado, Vivek Natarajan, Christopher Nielson, Thomas F. Osborne, Rajiv Raman, Kim'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 17, 'page_label': '18'}, page_content='Diana Mincu, Akinori Mitani, Andrea Montanari, Zachary Nado, Vivek Natarajan, Christopher Nielson, Thomas F. Osborne, Rajiv Raman, Kim\\nRamasamy, Rory Sayres, Jessica Schrouff, Martin Seneviratne, Shannon Sequeira, Harini Suresh, Victor Veitch, Max Vladymyrov, Xuezhi Wang, Kellie\\nWebster, Steve Yadlowsky, Taedong Yun, Xiaohua Zhai, and D. Sculley. 2020a. Underspecification Presents Challenges for Credibility in Modern\\nMachine Learning. https://doi.org/10.48550/arXiv.2011.03395 arXiv:2011.03395 [cs, stat].\\nAlexander D’Amour, Hansa Srinivasan, James Atwood, Pallavi Baljekar, D. Sculley, and Yoni Halpern. 2020b. Fairness is not static. InProceedings of the\\n2020 Conference on Fairness, Accountability, and Transparency . ACM. https://doi.org/10.1145/3351095.3372878\\nMostafa Dehghani, Yi Tay, Alexey A. Gritsenko, Zhe Zhao, Neil Houlsby, Fernando Diaz, Donald Metzler, and Oriol Vinyals. 2021. The Benchmark\\nLottery. https://doi.org/10.48550/arXiv.2107.07002 arXiv:2107.07002 [cs].'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 17, 'page_label': '18'}, page_content='Lottery. https://doi.org/10.48550/arXiv.2107.07002 arXiv:2107.07002 [cs].\\nDaniel Clement Dennett. 1981. The Intentional Stance . MIT Press.\\nQingxiu Dong, Lei Li, Damai Dai, Ce Zheng, Zhiyong Wu, Baobao Chang, Xu Sun, Jingjing Xu, Lei Li, and Zhifang Sui. 2022. A Survey for In-context\\nLearning. https://doi.org/10.48550/arXiv.2301.00234 arXiv:2301.00234 [cs].\\nHubert L Dreyfus. 1965. Alchemy and artificial intelligence . Technical Report. RAND CORP SANTA MONICA CA.\\nLilian Edwards. 2022. The EU AI Act: a summary of its significance and scope . Technical Report. https://www.adalovelaceinstitute.org/wp-content/\\nuploads/2022/04/Expert-explainer-The-EU-AI-Act-11-April-2022.pdf\\nUpol Ehsan, Ranjit Singh, Jacob Metcalf, and Mark Riedl. 2022. The Algorithmic Imprint. In 2022 ACM Conference on Fairness, Accountability, and\\nTransparency. ACM. https://doi.org/10.1145/3531146.3533186'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 17, 'page_label': '18'}, page_content='Transparency. ACM. https://doi.org/10.1145/3531146.3533186\\nKathleen M. Eisenhardt. 1989. Agency Theory: An Assessment and Review. The Academy of Management Review 14, 1 (1989), 57–74. https://doi.org/10.\\n2307/258191 Publisher: Academy of Management.\\nMichael D. Ekstrand, Mucun Tian, Ion Madrazo Azpiazu, Jennifer D. Ekstrand, Oghenemaro Anuyah, David McNeill, and Maria Soledad Pera. 2018. All\\nThe Cool Kids, How Do They Fit In?: Popularity and Demographic Biases in Recommender Evaluation and Effectiveness. In Proceedings of the 1st\\nConference on Fairness, Accountability and Transparency (Proceedings of Machine Learning Research, Vol. 81) , Sorelle A. Friedler and Christo Wilson\\n(Eds.). PMLR, 172–186. https://proceedings.mlr.press/v81/ekstrand18b.html\\nHadi Elzayn and Benjamin Fish. 2020. The effects of competition and regulation on error inequality in data-driven markets. In Proceedings of the 2020'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 17, 'page_label': '18'}, page_content='Hadi Elzayn and Benjamin Fish. 2020. The effects of competition and regulation on error inequality in data-driven markets. In Proceedings of the 2020\\nConference on Fairness, Accountability, and Transparency . ACM. https://doi.org/10.1145/3351095.3372842\\nMustafa Emirbayer and Ann Mische. 1998. What is Agency? American journal of sociology 103, 4 (1998), 962–1023. Publisher: The University of Chicago\\nPress.\\nSpotify Engineering. 2021. Shifting Consumption towards Diverse content via Reinforcement Learning. https://research.atspotify.com/2021/03/shifting-\\nconsumption-towards-diverse-content-via-reinforcement-learning/ Section: Algorithmic Responsibility.\\nCharles Evans and Atoosa Kasirzadeh. 2022. User Tampering in Reinforcement Learning Recommender Systems. https://doi.org/10.48550/arXiv.2109.04083\\narXiv:2109.04083 [cs].\\nRichard Evans and Jim Gao. 2016. DeepMind AI Reduces Google Data Centre Cooling Bill by 40%. https://www.deepmind.com/blog/deepmind-ai-'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 17, 'page_label': '18'}, page_content='arXiv:2109.04083 [cs].\\nRichard Evans and Jim Gao. 2016. DeepMind AI Reduces Google Data Centre Cooling Bill by 40%. https://www.deepmind.com/blog/deepmind-ai-\\nreduces-google-data-centre-cooling-bill-by-40\\nTom Everitt, Ryan Carey, Eric D. Langlois, Pedro A. Ortega, and Shane Legg. 2021. Agent Incentives: A Causal Perspective. Proceedings of the AAAI\\nConference on Artificial Intelligence 35, 13 (May 2021), 11487–11495. https://doi.org/10.1609/aaai.v35i13.17368 Number: 13.\\nSebastian Farquhar, Ryan Carey, and Tom Everitt. 2022. Path-Specific Objectives for Safer Agent Incentives. https://doi.org/10.48550/arXiv.2204.10018\\narXiv:2204.10018 [cs, stat].\\nRiccardo Fogliato, Shreya Chappidi, Matthew Lungren, Paul Fisher, Diane Wilson, Michael Fitzke, Mark Parkinson, Eric Horvitz, Kori Inkpen, and Besmira\\nNushi. 2022. Who Goes First? Influences of Human-AI Workflow on Decision Making in Clinical Imaging. In 2022 ACM Conference on Fairness,'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 17, 'page_label': '18'}, page_content='Nushi. 2022. Who Goes First? Influences of Human-AI Workflow on Decision Making in Clinical Imaging. In 2022 ACM Conference on Fairness,\\nAccountability, and Transparency . ACM. https://doi.org/10.1145/3531146.3533193\\nCoalition for Critical Technology. 2020. Abolish the #TechToPrisonPipeline. https://medium.com/@CoalitionForCriticalTechnology/abolish-the-\\ntechtoprisonpipeline-9b5b14366b16\\nDeep Ganguli, Danny Hernandez, Liane Lovitt, Amanda Askell, Yuntao Bai, Anna Chen, Tom Conerly, Nova Dassarma, Dawn Drain, Nelson Elhage,\\nSheer El Showk, Stanislav Fort, Zac Hatfield-Dodds, Tom Henighan, Scott Johnston, Andy Jones, Nicholas Joseph, Jackson Kernian, Shauna Kravec,\\nBen Mann, Neel Nanda, Kamal Ndousse, Catherine Olsson, Daniela Amodei, Tom Brown, Jared Kaplan, Sam McCandlish, Christopher Olah, Dario\\nAmodei, and Jack Clark. 2022. Predictability and Surprise in Large Generative Models. In 2022 ACM Conference on Fairness, Accountability, and'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 17, 'page_label': '18'}, page_content='Amodei, and Jack Clark. 2022. Predictability and Surprise in Large Generative Models. In 2022 ACM Conference on Fairness, Accountability, and\\nTransparency. ACM. https://doi.org/10.1145/3531146.3533229\\nLeo Gao, John Schulman, and Jacob Hilton. 2022. Scaling Laws for Reward Model Overoptimization. https://doi.org/10.48550/arXiv.2210.10760\\narXiv:2210.10760 [cs, stat].\\nManuscript submitted to ACM'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 18, 'page_label': '19'}, page_content='Harms from Increasingly Agentic Algorithmic Systems 19\\nJason Gauci, Edoardo Conti, Yitao Liang, Kittipat Virochsiri, Yuchen He, Zachary Kaden, Vivek Narayanan, Xiaohui Ye, Zhengxing Chen, and Scott Fujimoto.\\n2019. Horizon: Facebook’s Open Source Applied Reinforcement Learning Platform. https://doi.org/10.48550/arXiv.1811.00260 arXiv:1811.00260 [cs,\\nstat].\\nTimnit Gebru, Jamie Morgenstern, Briana Vecchione, Jennifer Wortman Vaughan, Hanna Wallach, Hal Daumé Iii, and Kate Crawford. 2021. Datasheets\\nfor datasets. Commun. ACM 64, 12 (Dec. 2021), 86–92. https://doi.org/10.1145/3458723\\nSamuel Gehman, Suchin Gururangan, Maarten Sap, Yejin Choi, and Noah A. Smith. 2020. RealToxicityPrompts: Evaluating Neural Toxic Degeneration\\nin Language Models. In Findings of the Association for Computational Linguistics: EMNLP 2020 . Association for Computational Linguistics, Online,\\n3356–3369. https://doi.org/10.18653/v1/2020.findings-emnlp.301'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 18, 'page_label': '19'}, page_content='3356–3369. https://doi.org/10.18653/v1/2020.findings-emnlp.301\\nJenny Gesley, Tariq Ahmad, Edouardo Soares, Ruth Levush, Gustavo Guerra, James Martin, Kelly Buchanan, Laney Zhang, Sayuri Umeda, Astghik Grigoryan,\\nNicolas Boring, Elin Hofverberg, Clare Feikhert-Ahalt, Graciela Rodriguez-Ferrand, George Sadek, and Hanibal Goitom. 2019. Regulation of Artificial\\nIntelligence in Selected Jurisdictions. Copyright, Fair Use, Scholarly Communication, etc. (Jan. 2019). https://digitalcommons.unl.edu/scholcom/177\\nCharlie Giattino, Edouard Mathieu, Julia Broden, and Max Roser. 2022. Artificial Intelligence. Our World in Data (2022).\\nThomas Krendl Gilbert, Sarah Dean, Nathan Lambert, Tom Zick, and Aaron Snoswell. 2022. Reward Reports for Reinforcement Learning. https:\\n//doi.org/10.48550/arXiv.2204.10817 arXiv:2204.10817 [cs].\\nTrystan S. Goetze. 2022. Mind the Gap: Autonomous Systems, the Responsibility Gap, and Moral Entanglement. In 2022 ACM Conference on Fairness,'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 18, 'page_label': '19'}, page_content='Trystan S. Goetze. 2022. Mind the Gap: Autonomous Systems, the Responsibility Gap, and Moral Entanglement. In 2022 ACM Conference on Fairness,\\nAccountability, and Transparency . ACM. https://doi.org/10.1145/3531146.3533106\\nCharles Goodhart. 1975. Problems of monetary management: the UK experience in papers in monetary economics. Monetary Economics 1 (1975).\\nMary L. Gray and Siddharth Suri. 2019. Ghost work: how to stop Silicon Valley from building a new global underclass . Houghton Mifflin Harcourt, Boston.\\nBen Green. 2020. The false promise of risk assessments. In Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency . ACM.\\nhttps://doi.org/10.1145/3351095.3372869\\nBen Green and Yiling Chen. 2019. Disparate Interactions. In Proceedings of the Conference on Fairness, Accountability, and Transparency . ACM. https:\\n//doi.org/10.1145/3287560.3287563'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 18, 'page_label': '19'}, page_content='Ben Green and Yiling Chen. 2019. Disparate Interactions. In Proceedings of the Conference on Fairness, Accountability, and Transparency . ACM. https:\\n//doi.org/10.1145/3287560.3287563\\nNancy Green. 2021. An AI Ethics Course Highlighting Explicit Ethical Agents. In Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society .\\nACM. https://doi.org/10.1145/3461702.3462552\\nDylan Hadfield-Menell and Gillian K. Hadfield. 2019. Incomplete Contracting and AI Alignment. In Proceedings of the 2019 AAAI/ACM Conference on AI,\\nEthics, and Society . ACM. https://doi.org/10.1145/3306618.3314250\\nDanijar Hafner, Jurgis Pasukonis, Jimmy Ba, and Timothy Lillicrap. 2023. Mastering Diverse Domains through World Models. https://doi.org/10.48550/\\narXiv.2301.04104 arXiv:2301.04104 [cs, stat].\\nStacy A. Hickox. 2010. Employer Liability of Negligent Hiring of Ex-Offenders. Saint Louis University Law Journal 55, 3 (2010), 1001–1046. https:\\n//heinonline.org/HOL/P?h=hein.journals/stlulj55&i=1029'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 18, 'page_label': '19'}, page_content='//heinonline.org/HOL/P?h=hein.journals/stlulj55&i=1029\\nJacob Hilton, Jie Tang, and John Schulman. 2023. Scaling laws for single-agent reinforcement learning. https://doi.org/10.48550/arXiv.2301.13442\\narXiv:2301.13442 [cs, stat].\\nJordan Hoffmann, Sebastian Borgeaud, Arthur Mensch, Elena Buchatskaya, Trevor Cai, Eliza Rutherford, Diego de las Casas, Lisa Anne Hendricks,\\nJohannes Welbl, Aidan Clark, Tom Hennigan, Eric Noland, Katherine Millican, George van den Driessche, Bogdan Damoc, Aurelia Guy, Simon\\nOsindero, Karen Simonyan, Erich Elsen, Oriol Vinyals, Jack William Rae, and Laurent Sifre. 2022. An empirical analysis of compute-optimal large\\nlanguage model training. In Advances in Neural Information Processing Systems , Alice H. Oh, Alekh Agarwal, Danielle Belgrave, and Kyunghyun Cho\\n(Eds.). https://openreview.net/forum?id=iBBcRUlOAPR\\nYubo Hou, Dan Xiong, Tonglin Jiang, Lily Song, and Qi Wang. 2019. Social media addiction: Its impact, mediation, and intervention. Cyberpsychology:'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 18, 'page_label': '19'}, page_content='(Eds.). https://openreview.net/forum?id=iBBcRUlOAPR\\nYubo Hou, Dan Xiong, Tonglin Jiang, Lily Song, and Qi Wang. 2019. Social media addiction: Its impact, mediation, and intervention. Cyberpsychology:\\nJournal of Psychosocial Research on Cyberspace 13, 1 (Feb. 2019). https://doi.org/10.5817/CP2019-1-4 Number: 1.\\nWenlong Huang, Fei Xia, Ted Xiao, Harris Chan, Jacky Liang, Pete Florence, Andy Zeng, Jonathan Tompson, Igor Mordatch, Yevgen Chebotar, Pierre\\nSermanet, Noah Brown, Tomas Jackson, Linda Luu, Sergey Levine, Karol Hausman, and Brian Ichter. 2022. Inner Monologue: Embodied Reasoning\\nthrough Planning with Language Models. https://doi.org/10.48550/arXiv.2207.05608 arXiv:2207.05608 [cs].\\nShahin Jabbari, Matthew Joseph, Michael Kearns, Jamie Morgenstern, and Aaron Roth. 2017. Fairness in Reinforcement Learning. In Proceedings of the\\n34th International Conference on Machine Learning . PMLR, 1617–1626. https://proceedings.mlr.press/v70/jabbari17a.html ISSN: 2640-3498.'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 18, 'page_label': '19'}, page_content='34th International Conference on Machine Learning . PMLR, 1617–1626. https://proceedings.mlr.press/v70/jabbari17a.html ISSN: 2640-3498.\\nAbigail Z. Jacobs and Hanna Wallach. 2021. Measurement and Fairness. In Proceedings of the 2021 ACM Conference on Fairness, Accountability, and\\nTransparency (FAccT ’21) . Association for Computing Machinery, New York, NY, USA, 375–385. https://doi.org/10.1145/3442188.3445901 event-place:\\nVirtual Event, Canada.\\nMichael C. Jensen and William H. Meckling. 1976. Theory of the firm: Managerial behavior, agency costs and ownership structure. Journal of Financial\\nEconomics 3, 4 (Oct. 1976), 305–360. https://doi.org/10.1016/0304-405X(76)90026-X\\nZiwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan Su, Yan Xu, Etsuko Ishii, Yejin Bang, Wenliang Dai, Andrea Madotto, and Pascale Fung. 2022. Survey\\nof Hallucination in Natural Language Generation. Comput. Surveys (Nov. 2022), 3571730. https://doi.org/10.1145/3571730 arXiv:2202.03629 [cs].'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 18, 'page_label': '19'}, page_content='of Hallucination in Natural Language Generation. Comput. Surveys (Nov. 2022), 3571730. https://doi.org/10.1145/3571730 arXiv:2202.03629 [cs].\\nRay Jiang, Silvia Chiappa, Tor Lattimore, András György, and Pushmeet Kohli. 2019. Degenerate Feedback Loops in Recommender Systems. InProceedings\\nof the 2019 AAAI/ACM Conference on AI, Ethics, and Society . ACM. https://doi.org/10.1145/3306618.3314288\\nDeborah G. Johnson and Mario Verdicchio. 2017. Reframing AI Discourse. Minds and Machines 27, 4 (Dec. 2017), 575–590. https://doi.org/10.1007/s11023-\\n017-9417-6\\nManuscript submitted to ACM'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 19, 'page_label': '20'}, page_content='20 Chan et al.\\nMatthew Joseph, Michael Kearns, Jamie H Morgenstern, and Aaron Roth. 2016. Fairness in Learning: Classic and Contextual Bandits. In Advances in\\nNeural Information Processing Systems , Vol. 29. Curran Associates, Inc. https://papers.nips.cc/paper/2016/hash/eb163727917cbba1eea208541a643e74-\\nAbstract.html\\nJohn Jumper, Richard Evans, Alexander Pritzel, Tim Green, Michael Figurnov, Olaf Ronneberger, Kathryn Tunyasuvunakool, Russ Bates, Augustin Žídek,\\nAnna Potapenko, Alex Bridgland, Clemens Meyer, Simon A. A. Kohl, Andrew J. Ballard, Andrew Cowie, Bernardino Romera-Paredes, Stanislav Nikolov,\\nRishub Jain, Jonas Adler, Trevor Back, Stig Petersen, David Reiman, Ellen Clancy, Michal Zielinski, Martin Steinegger, Michalina Pacholska, Tamas\\nBerghammer, Sebastian Bodenstein, David Silver, Oriol Vinyals, Andrew W. Senior, Koray Kavukcuoglu, Pushmeet Kohli, and Demis Hassabis. 2021.'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 19, 'page_label': '20'}, page_content='Berghammer, Sebastian Bodenstein, David Silver, Oriol Vinyals, Andrew W. Senior, Koray Kavukcuoglu, Pushmeet Kohli, and Demis Hassabis. 2021.\\nHighly accurate protein structure prediction with AlphaFold. Nature 596, 7873 (Aug. 2021), 583–589. https://doi.org/10.1038/s41586-021-03819-2\\nNumber: 7873 Publisher: Nature Publishing Group.\\nJared Kaplan, Sam McCandlish, Tom Henighan, Tom B. Brown, Benjamin Chess, Rewon Child, Scott Gray, Alec Radford, Jeffrey Wu, and Dario Amodei.\\n2020. Scaling Laws for Neural Language Models. https://doi.org/10.48550/arXiv.2001.08361 arXiv:2001.08361 [cs, stat].\\nMaximilian Kasy and Rediet Abebe. 2021. Fairness, Equality, and Power in Algorithmic Decision-Making. In Proceedings of the 2021 ACM Conference on\\nFairness, Accountability, and Transparency (FAccT ’21) . Association for Computing Machinery, New York, NY, USA, 576–586. https://doi.org/10.1145/\\n3442188.3445919 event-place: Virtual Event, Canada.'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 19, 'page_label': '20'}, page_content='Fairness, Accountability, and Transparency (FAccT ’21) . Association for Computing Machinery, New York, NY, USA, 576–586. https://doi.org/10.1145/\\n3442188.3445919 event-place: Virtual Event, Canada.\\nJoe Kava. 2014. Better data centers through machine learning. https://blog.google/inside-google/infrastructure/better-data-centers-through-machine/\\nBetul Keles, Niall McCrae, and Annmarie Grealish. 2020. A systematic review: the influence of social media on depression, anxiety and psychological\\ndistress in adolescents. International Journal of Adolescence and Youth 25, 1 (Dec. 2020), 79–93. https://doi.org/10.1080/02673843.2019.1590851\\nPublisher: Routledge _eprint: https://doi.org/10.1080/02673843.2019.1590851.\\nZachary Kenton, Tom Everitt, Laura Weidinger, Iason Gabriel, Vladimir Mikulik, and Geoffrey Irving. 2021. Alignment of Language Agents.arXiv:2103.14659\\n[cs] (March 2021). http://arxiv.org/abs/2103.14659 arXiv: 2103.14659.'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 19, 'page_label': '20'}, page_content='[cs] (March 2021). http://arxiv.org/abs/2103.14659 arXiv: 2103.14659.\\nZachary Kenton, Ramana Kumar, Sebastian Farquhar, Jonathan Richens, Matt MacDermott, and Tom Everitt. 2022. Discovering Agents. https:\\n//doi.org/10.48550/arXiv.2208.08345 arXiv:2208.08345 [cs].\\nRaffi Khatchadourian. 2015. The Doomsday Invention. The New Yorker (Nov. 2015). https://www.newyorker.com/magazine/2015/11/23/doomsday-\\ninvention-artificial-intelligence-nick-bostrom\\nVictoria Krakovna, Jonathan Uesato, Vladimir Mikulik, Matthew Rahtz, Tom Everitt, Ramana Kumar, Zac Kenton, Jan Leike, and Shane Legg. 2020.\\nSpecification gaming: the flip side of AI ingenuity. DeepMind Blog (2020).\\nDavid Krueger, Tegan Maharaj, and Jan Leike. 2020. Hidden Incentives for Auto-Induced Distributional Shift. https://doi.org/10.48550/arXiv.2009.09153\\narXiv:2009.09153 [cs, stat].\\nT.S. Kuhn and I. Hacking. 2012. The Structure of Scientific Revolutions . University of Chicago Press. https://books.google.co.uk/books?id=3eP5Y_OOuzwC'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 19, 'page_label': '20'}, page_content='arXiv:2009.09153 [cs, stat].\\nT.S. Kuhn and I. Hacking. 2012. The Structure of Scientific Revolutions . University of Chicago Press. https://books.google.co.uk/books?id=3eP5Y_OOuzwC\\nBrenden M. Lake, Tomer D. Ullman, Joshua B. Tenenbaum, and Samuel J. Gershman. 2017. Building machines that learn and think like people. Behavioral\\nand Brain Sciences 40 (2017), e253. https://doi.org/10.1017/S0140525X16001837 Publisher: Cambridge University Press.\\nLauro Langosco Di Langosco, Jack Koch, Lee D Sharkey, Jacob Pfau, and David Krueger. 2022. Goal Misgeneralization in Deep Reinforcement Learning. In\\nProceedings of the 39th International Conference on Machine Learning (Proceedings of Machine Learning Research, Vol. 162) , Kamalika Chaudhuri, Stefanie\\nJegelka, Le Song, Csaba Szepesvari, Gang Niu, and Sivan Sabato (Eds.). PMLR, 12004–12019. https://proceedings.mlr.press/v162/langosco22a.html'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 19, 'page_label': '20'}, page_content='Jegelka, Le Song, Csaba Szepesvari, Gang Niu, and Sivan Sabato (Eds.). PMLR, 12004–12019. https://proceedings.mlr.press/v162/langosco22a.html\\nSeth Lazar. 2022. Legitimacy, Authority, and the Political Value of Explanations. https://doi.org/10.48550/arXiv.2208.08628 arXiv:2208.08628 [cs].\\nDaniel Leufer. 2020. Why We Need to Bust Some Myths about AI. Patterns 1, 7 (Oct. 2020), 100124. https://doi.org/10.1016/j.patter.2020.100124\\nGideon Lewis-Kraus. 2022. How harmful is social media? https://www.newyorker.com/culture/annals-of-inquiry/we-know-less-about-social-media-\\nthan-we-think Publication Title: The New Yorker.\\nBo-hu Li, Bao-cun Hou, Wen-tao Yu, Xiao-bing Lu, and Chun-wei Yang. 2017. Applications of artificial intelligence in intelligent manufacturing: a review.\\nFrontiers of Information Technology & Electronic Engineering 18, 1 (Jan. 2017), 86–96. https://doi.org/10.1631/FITEE.1601885'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 19, 'page_label': '20'}, page_content='Frontiers of Information Technology & Electronic Engineering 18, 1 (Jan. 2017), 86–96. https://doi.org/10.1631/FITEE.1601885\\nYunqi Li, Hanxiong Chen, Shuyuan Xu, Yingqiang Ge, Juntao Tan, Shuchang Liu, and Yongfeng Zhang. 2022. Fairness in Recommendation: A Survey.\\nhttps://doi.org/10.48550/arXiv.2205.13619 arXiv:2205.13619 [cs].\\nStephanie Lin, Jacob Hilton, and Owain Evans. 2022. TruthfulQA: Measuring How Models Mimic Human Falsehoods. In Proceedings of the 60th Annual\\nMeeting of the Association for Computational Linguistics (Volume 1: Long Papers) . Association for Computational Linguistics, Dublin, Ireland, 3214–3252.\\nhttps://doi.org/10.18653/v1/2022.acl-long.229\\nLydia T Liu, Sarah Dean, Esther Rolf, Max Simchowitz, and Moritz Hardt. 2018. Delayed impact of fair machine learning. In International Conference on\\nMachine Learning . PMLR, 3150–3158.'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 19, 'page_label': '20'}, page_content='Lydia T Liu, Sarah Dean, Esther Rolf, Max Simchowitz, and Moritz Hardt. 2018. Delayed impact of fair machine learning. In International Conference on\\nMachine Learning . PMLR, 3150–3158.\\nMichele Loi and Matthias Spielkamp. 2021. Towards Accountability in the Use of Artificial Intelligence for Public Administrations. In Proceedings of the\\n2021 AAAI/ACM Conference on AI, Ethics, and Society . ACM. https://doi.org/10.1145/3461702.3462631\\nKate Manne. 2017. Down Girl: The Logic of Misogyny . Oxford University Press.\\nmaraoz. 2021. Interviewing Albert Einstein via GPT-3. https://maraoz.substack.com/embed\\nJacob Menick, Maja Trebacz, Vladimir Mikulik, John Aslanides, Francis Song, Martin Chadwick, Mia Glaese, Susannah Young, Lucy Campbell-Gillingham,\\nGeoffrey Irving, and Nat McAleese. 2022. Teaching language models to support answers with verified quotes. https://doi.org/10.48550/arXiv.2203.11147\\narXiv:2203.11147 [cs].'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 19, 'page_label': '20'}, page_content='Geoffrey Irving, and Nat McAleese. 2022. Teaching language models to support answers with verified quotes. https://doi.org/10.48550/arXiv.2203.11147\\narXiv:2203.11147 [cs].\\nMeta. 2023. Meta Reports Fourth Quarter and Full Year 2022 Results. https://investor.fb.com/investor-news/press-release-details/2023/Meta-Reports-\\nFourth-Quarter-and-Full-Year-2022-Results/default.aspx\\nManuscript submitted to ACM'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 20, 'page_label': '21'}, page_content='Harms from Increasingly Agentic Algorithmic Systems 21\\nSilvia Milano, Mariarosaria Taddeo, and Luciano Floridi. 2020. Recommender systems and their ethical challenges. AI & SOCIETY 35, 4 (Dec. 2020),\\n957–967. https://doi.org/10.1007/s00146-020-00950-y\\nMargaret Mitchell, Simone Wu, Andrew Zaldivar, Parker Barnes, Lucy Vasserman, Ben Hutchinson, Elena Spitzer, Inioluwa Deborah Raji, and Timnit\\nGebru. 2019. Model Cards for Model Reporting. In Proceedings of the Conference on Fairness, Accountability, and Transparency . ACM. https:\\n//doi.org/10.1145/3287560.3287596\\nVolodymyr Mnih, Koray Kavukcuoglu, David Silver, Alex Graves, Ioannis Antonoglou, Daan Wierstra, and Martin Riedmiller. 2013. Playing Atari with\\nDeep Reinforcement Learning. https://doi.org/10.48550/arXiv.1312.5602 arXiv:1312.5602 [cs].\\nAI Myths. [n. d.]. Myth: AI has agency. https://www.aimyths.org/ai-has-agency'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 20, 'page_label': '21'}, page_content='Deep Reinforcement Learning. https://doi.org/10.48550/arXiv.1312.5602 arXiv:1312.5602 [cs].\\nAI Myths. [n. d.]. Myth: AI has agency. https://www.aimyths.org/ai-has-agency\\nReiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu, Long Ouyang, Christina Kim, Christopher Hesse, Shantanu Jain, Vineet Kosaraju, William Saunders,\\nXu Jiang, Karl Cobbe, Tyna Eloundou, Gretchen Krueger, Kevin Button, Matthew Knight, Benjamin Chess, and John Schulman. 2022. WebGPT:\\nBrowser-assisted question-answering with human feedback. https://doi.org/10.48550/arXiv.2112.09332 arXiv:2112.09332 [cs].\\nSimone Natale and Andrea Ballatore. 2020. Imagining the thinking machine: Technological myths and the rise of artificial intelligence. Convergence 26, 1\\n(2020), 3–18. Publisher: SAGE Publications Sage UK: London, England.\\nPandu Nayak. 2019. Understanding searches better than ever before. https://blog.google/products/search/search-language-understanding-bert/'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 20, 'page_label': '21'}, page_content='Pandu Nayak. 2019. Understanding searches better than ever before. https://blog.google/products/search/search-language-understanding-bert/\\nHelen Nissenbaum. 1996. Accountability in a computerized society. Science and Engineering Ethics 2, 1 (March 1996), 25–42. https://doi.org/10.1007/\\nBF02639315\\nZiad Obermeyer and Sendhil Mullainathan. 2019. Dissecting Racial Bias in an Algorithm that Guides Health Decisions for 70 Million People. InProceedings\\nof the Conference on Fairness, Accountability, and Transparency . ACM. https://doi.org/10.1145/3287560.3287593\\nCatherine Olsson, Nelson Elhage, Neel Nanda, Nicholas Joseph, Nova DasSarma, Tom Henighan, Ben Mann, Amanda Askell, Yuntao Bai, Anna Chen,\\nTom Conerly, Dawn Drain, Deep Ganguli, Zac Hatfield-Dodds, Danny Hernandez, Scott Johnston, Andy Jones, Jackson Kernion, Liane Lovitt, Kamal\\nNdousse, Dario Amodei, Tom Brown, Jack Clark, Jared Kaplan, Sam McCandlish, and Chris Olah. 2022. In-context Learning and Induction Heads.'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 20, 'page_label': '21'}, page_content='Ndousse, Dario Amodei, Tom Brown, Jack Clark, Jared Kaplan, Sam McCandlish, and Chris Olah. 2022. In-context Learning and Induction Heads.\\nTransformer Circuits Thread (2022).\\nStephen M Omohundro. 2008. The Basic AI Drives. In AGI, Vol. 171. 483–492.\\nOpenAI. 2022. ChatGPT: Optimizing Language Models for Dialogue. https://openai.com/blog/chatgpt/\\nLaurent Orseau, Simon McGregor McGill, and Shane Legg. 2018. Agents and Devices: A Relative Definition of Agency. https://doi.org/10.48550/arXiv.\\n1805.12387 arXiv:1805.12387 [cs, stat].\\nAlexander Pan, Kush Bhatia, and Jacob Steinhardt. 2022. The Effects of Reward Misspecification: Mapping and Mitigating Misaligned Models. In\\nInternational Conference on Learning Representations . https://openreview.net/forum?id=JYtwGwIL7ye\\nJoon Sung Park, Lindsay Popowski, Carrie Cai, Meredith Ringel Morris, Percy Liang, and Michael S. Bernstein. 2022. Social Simulacra: Creating Populated'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 20, 'page_label': '21'}, page_content='Joon Sung Park, Lindsay Popowski, Carrie Cai, Meredith Ringel Morris, Percy Liang, and Michael S. Bernstein. 2022. Social Simulacra: Creating Populated\\nPrototypes for Social Computing Systems. In Proceedings of the 35th Annual ACM Symposium on User Interface Software and Technology (UIST ’22) .\\nAssociation for Computing Machinery, New York, NY, USA, 1–18. https://doi.org/10.1145/3526113.3545616\\nMatteo Pasquinelli and Vladan Joler. 2021. The Nooscope manifested: AI as instrument of knowledge extractivism. AI & SOCIETY 36, 4 (Dec. 2021),\\n1263–1280. https://doi.org/10.1007/s00146-020-01097-6\\nEthan Perez, Sam Ringer, Kamil˙e Lukoši¯ut˙e, Karina Nguyen, Edwin Chen, Scott Heiner, Craig Pettit, Catherine Olsson, Sandipan Kundu, Saurav Kadavath,\\nAndy Jones, Anna Chen, Ben Mann, Brian Israel, Bryan Seethor, Cameron McKinnon, Christopher Olah, Da Yan, Daniela Amodei, Dario Amodei,'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 20, 'page_label': '21'}, page_content='Andy Jones, Anna Chen, Ben Mann, Brian Israel, Bryan Seethor, Cameron McKinnon, Christopher Olah, Da Yan, Daniela Amodei, Dario Amodei,\\nDawn Drain, Dustin Li, Eli Tran-Johnson, Guro Khundadze, Jackson Kernion, James Landis, Jamie Kerr, Jared Mueller, Jeeyoon Hyun, Joshua Landau,\\nKamal Ndousse, Landon Goldberg, Liane Lovitt, Martin Lucas, Michael Sellitto, Miranda Zhang, Neerav Kingsland, Nelson Elhage, Nicholas Joseph,\\nNoemí Mercado, Nova DasSarma, Oliver Rausch, Robin Larson, Sam McCandlish, Scott Johnston, Shauna Kravec, Sheer El Showk, Tamera Lanham,\\nTimothy Telleen-Lawton, Tom Brown, Tom Henighan, Tristan Hume, Yuntao Bai, Zac Hatfield-Dodds, Jack Clark, Samuel R. Bowman, Amanda Askell,\\nRoger Grosse, Danny Hernandez, Deep Ganguli, Evan Hubinger, Nicholas Schiefer, and Jared Kaplan. 2022. Discovering Language Model Behaviors\\nwith Model-Written Evaluations. https://doi.org/10.48550/arXiv.2212.09251 arXiv:2212.09251 [cs].'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 20, 'page_label': '21'}, page_content='with Model-Written Evaluations. https://doi.org/10.48550/arXiv.2212.09251 arXiv:2212.09251 [cs].\\nJulien Perolat, Bart De Vylder, Daniel Hennes, Eugene Tarassov, Florian Strub, Vincent de Boer, Paul Muller, Jerome T. Connor, Neil Burch, Thomas\\nAnthony, Stephen McAleer, Romuald Elie, Sarah H. Cen, Zhe Wang, Audrunas Gruslys, Aleksandra Malysheva, Mina Khan, Sherjil Ozair, Finbarr\\nTimbers, Toby Pohlen, Tom Eccles, Mark Rowland, Marc Lanctot, Jean-Baptiste Lespiau, Bilal Piot, Shayegan Omidshafiei, Edward Lockhart, Laurent\\nSifre, Nathalie Beauguerlange, Remi Munos, David Silver, Satinder Singh, Demis Hassabis, and Karl Tuyls. 2022. Mastering the game of Stratego with\\nmodel-free multiagent reinforcement learning. Science 378, 6623 (Dec. 2022), 990–996. https://doi.org/10.1126/science.add4679 Publisher: American\\nAssociation for the Advancement of Science.'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 20, 'page_label': '21'}, page_content='model-free multiagent reinforcement learning. Science 378, 6623 (Dec. 2022), 990–996. https://doi.org/10.1126/science.add4679 Publisher: American\\nAssociation for the Advancement of Science.\\nBilly Perrigo. 2023. Exclusive: The $2 Per Hour Workers Who Made ChatGPT Safer. Time (Jan. 2023). https://time.com/6247678/openai-chatgpt-kenya-\\nworkers/\\nSteven T. Piantadosi and Felix Hill. 2022. Meaning without reference in large language models. https://doi.org/10.48550/arXiv.2208.02957 arXiv:2208.02957\\n[cs].\\nBy Pratyusha. 2020. World view. Nature 583 (2020), 169.\\nJack W. Rae, Sebastian Borgeaud, Trevor Cai, Katie Millican, Jordan Hoffmann, Francis Song, John Aslanides, Sarah Henderson, Roman Ring, Susannah\\nYoung, Eliza Rutherford, Tom Hennigan, Jacob Menick, Albin Cassirer, Richard Powell, George van den Driessche, Lisa Anne Hendricks, Maribeth\\nRauh, Po-Sen Huang, Amelia Glaese, Johannes Welbl, Sumanth Dathathri, Saffron Huang, Jonathan Uesato, John Mellor, Irina Higgins, Antonia'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 20, 'page_label': '21'}, page_content='Rauh, Po-Sen Huang, Amelia Glaese, Johannes Welbl, Sumanth Dathathri, Saffron Huang, Jonathan Uesato, John Mellor, Irina Higgins, Antonia\\nCreswell, Nat McAleese, Amy Wu, Erich Elsen, Siddhant Jayakumar, Elena Buchatskaya, David Budden, Esme Sutherland, Karen Simonyan, Michela\\nManuscript submitted to ACM'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 21, 'page_label': '22'}, page_content='22 Chan et al.\\nPaganini, Laurent Sifre, Lena Martens, Xiang Lorraine Li, Adhiguna Kuncoro, Aida Nematzadeh, Elena Gribovskaya, Domenic Donato, Angeliki\\nLazaridou, Arthur Mensch, Jean-Baptiste Lespiau, Maria Tsimpoukelli, Nikolai Grigorev, Doug Fritz, Thibault Sottiaux, Mantas Pajarskas, Toby Pohlen,\\nZhitao Gong, Daniel Toyama, Cyprien de Masson d’Autume, Yujia Li, Tayfun Terzi, Vladimir Mikulik, Igor Babuschkin, Aidan Clark, Diego de Las\\nCasas, Aurelia Guy, Chris Jones, James Bradbury, Matthew Johnson, Blake Hechtman, Laura Weidinger, Iason Gabriel, William Isaac, Ed Lockhart,\\nSimon Osindero, Laura Rimell, Chris Dyer, Oriol Vinyals, Kareem Ayoub, Jeff Stanway, Lorrayne Bennett, Demis Hassabis, Koray Kavukcuoglu, and\\nGeoffrey Irving. 2022. Scaling Language Models: Methods, Analysis & Insights from Training Gopher. https://doi.org/10.48550/arXiv.2112.11446\\narXiv:2112.11446 [cs].'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 21, 'page_label': '22'}, page_content='Geoffrey Irving. 2022. Scaling Language Models: Methods, Analysis & Insights from Training Gopher. https://doi.org/10.48550/arXiv.2112.11446\\narXiv:2112.11446 [cs].\\nDeborah Raji, Emily Denton, Emily M. Bender, Alex Hanna, and Amandalynne Paullada. 2021. AI and the Everything in the Whole Wide World\\nBenchmark. Proceedings of the Neural Information Processing Systems Track on Datasets and Benchmarks 1 (Dec. 2021). https://datasets-benchmarks-\\nproceedings.neurips.cc/paper/2021/hash/084b6fbb10729ed4da8c3d3f5a3ae7c9-Abstract-round2.html\\nInioluwa Deborah Raji and Joy Buolamwini. 2019. Actionable Auditing. In Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and Society . ACM.\\nhttps://doi.org/10.1145/3306618.3314244\\nInioluwa Deborah Raji, I. Elizabeth Kumar, Aaron Horowitz, and Andrew Selbst. 2022. The Fallacy of AI Functionality. In2022 ACM Conference on Fairness,\\nAccountability, and Transparency . ACM. https://doi.org/10.1145/3531146.3533158'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 21, 'page_label': '22'}, page_content='Accountability, and Transparency . ACM. https://doi.org/10.1145/3531146.3533158\\nInioluwa Deborah Raji, Andrew Smart, Rebecca N. White, Margaret Mitchell, Timnit Gebru, Ben Hutchinson, Jamila Smith-Loud, Daniel Theron, and\\nParker Barnes. 2020. Closing the AI accountability gap. In Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency . ACM.\\nhttps://doi.org/10.1145/3351095.3372873\\nScott Reed, Konrad Zolna, Emilio Parisotto, Sergio Gómez Colmenarejo, Alexander Novikov, Gabriel Barth-maron, Mai Giménez, Yury Sulsky, Jackie Kay,\\nJost Tobias Springenberg, Tom Eccles, Jake Bruce, Ali Razavi, Ashley Edwards, Nicolas Heess, Yutian Chen, Raia Hadsell, Oriol Vinyals, Mahyar Bordbar,\\nand Nando de Freitas. 2022. A Generalist Agent. Transactions on Machine Learning Research (2022). https://openreview.net/forum?id=1ikK0kHjvj\\nManoel Horta Ribeiro, Raphael Ottoni, Robert West, Virgílio A. F. Almeida, and Wagner Meira. 2020. Auditing radicalization pathways on YouTube. In'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 21, 'page_label': '22'}, page_content='Manoel Horta Ribeiro, Raphael Ottoni, Robert West, Virgílio A. F. Almeida, and Wagner Meira. 2020. Auditing radicalization pathways on YouTube. In\\nProceedings of the 2020 Conference on Fairness, Accountability, and Transparency . ACM. https://doi.org/10.1145/3351095.3372879\\nPaul Robinette, Wenchen Li, Robert Allen, Ayanna M Howard, and Alan R Wagner. 2016. Overtrust of robots in emergency evacuation scenarios. In 2016\\n11th ACM/IEEE international conference on human-robot interaction (HRI) . IEEE, 101–108.\\nStuart J. Russell and Peter Norvig. 2021. Artificial Intelligence: A Modern Approach (4 ed.).\\nMarkus Schlosser. 2019. Agency. In The Stanford Encyclopedia of Philosophy (winter 2019 ed.), Edward N. Zalta (Ed.). Metaphysics Research Lab, Stanford\\nUniversity. https://plato.stanford.edu/archives/win2019/entries/agency/\\nRon Schmelzer. 2019. Amazon Dives Deep into Reinforcement Learning. Forbes (June 2019). https://www.forbes.com/sites/cognitiveworld/2019/06/14/'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 21, 'page_label': '22'}, page_content='Ron Schmelzer. 2019. Amazon Dives Deep into Reinforcement Learning. Forbes (June 2019). https://www.forbes.com/sites/cognitiveworld/2019/06/14/\\namazon-dives-deep-into-reinforcement-learning/ Section: AI & Big Data.\\nJulian Schrittwieser, Ioannis Antonoglou, Thomas Hubert, Karen Simonyan, Laurent Sifre, Simon Schmitt, Arthur Guez, Edward Lockhart, Demis Hassabis,\\nThore Graepel, Timothy Lillicrap, and David Silver. 2020. Mastering Atari, Go, chess and shogi by planning with a learned model. Nature 588, 7839\\n(Dec. 2020), 604–609. https://doi.org/10.1038/s41586-020-03051-4 Number: 7839 Publisher: Nature Publishing Group.\\nAnne Schulz, P Howard, and R Nielsen. 2019. Industry, Experts, or Industry Experts? Academic Sourcing in News Coverage of AI. (2019). Publisher:\\nReuters Institute for the Study of Journalism.\\nAndrew D. Selbst, Danah Boyd, Sorelle A. Friedler, Suresh Venkatasubramanian, and Janet Vertesi. 2019. Fairness and Abstraction in Sociotechnical'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 21, 'page_label': '22'}, page_content='Reuters Institute for the Study of Journalism.\\nAndrew D. Selbst, Danah Boyd, Sorelle A. Friedler, Suresh Venkatasubramanian, and Janet Vertesi. 2019. Fairness and Abstraction in Sociotechnical\\nSystems. In Proceedings of the Conference on Fairness, Accountability, and Transparency . ACM. https://doi.org/10.1145/3287560.3287598\\nMark Sendak, Madeleine Clare Elish, Michael Gao, Joseph Futoma, William Ratliff, Marshall Nichols, Armando Bedoya, Suresh Balu, and Cara O’Brien.\\n2020. \"The human body is a black box\". In Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency . ACM. https://doi.org/10.\\n1145/3351095.3372827\\nRohin Shah, Vikrant Varma, Ramana Kumar, Mary Phuong, Victoria Krakovna, Jonathan Uesato, and Zac Kenton. 2022. Goal Misgeneralization: Why\\nCorrect Specifications Aren’t Enough For Correct Goals. https://doi.org/10.48550/arXiv.2210.01790 arXiv:2210.01790 [cs].'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 21, 'page_label': '22'}, page_content='Correct Specifications Aren’t Enough For Correct Goals. https://doi.org/10.48550/arXiv.2210.01790 arXiv:2210.01790 [cs].\\nRenee Shelby, Shalaleh Rismani, Kathryn Henne, AJung Moon, Negar Rostamzadeh, Paul Nicholas, N’Mah Yilla, Jess Gallegos, Andrew Smart, Emilio\\nGarcia, and Gurleen Virk. 2022. Sociotechnical Harms: Scoping a Taxonomy for Harm Reduction. https://doi.org/10.48550/arXiv.2210.05791\\narXiv:2210.05791 [cs].\\nDavid Silver, Aja Huang, Chris J. Maddison, Arthur Guez, Laurent Sifre, George van den Driessche, Julian Schrittwieser, Ioannis Antonoglou, Veda\\nPanneershelvam, Marc Lanctot, Sander Dieleman, Dominik Grewe, John Nham, Nal Kalchbrenner, Ilya Sutskever, Timothy Lillicrap, Madeleine Leach,\\nKoray Kavukcuoglu, Thore Graepel, and Demis Hassabis. 2016. Mastering the game of Go with deep neural networks and tree search. Nature 529,\\n7587 (Jan. 2016), 484–489. https://doi.org/10.1038/nature16961 Number: 7587 Publisher: Nature Publishing Group.'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 21, 'page_label': '22'}, page_content='7587 (Jan. 2016), 484–489. https://doi.org/10.1038/nature16961 Number: 7587 Publisher: Nature Publishing Group.\\nDavid Silver, Thomas Hubert, Julian Schrittwieser, Ioannis Antonoglou, Matthew Lai, Arthur Guez, Marc Lanctot, Laurent Sifre, Dharshan Kumaran,\\nThore Graepel, Timothy Lillicrap, Karen Simonyan, and Demis Hassabis. 2017. Mastering Chess and Shogi by Self-Play with a General Reinforcement\\nLearning Algorithm. https://doi.org/10.48550/arXiv.1712.01815 arXiv:1712.01815 [cs].\\nJoar Max Viktor Skalse, Nikolaus H. R. Howe, Dmitrii Krasheninnikov, and David Krueger. 2022. Defining and Characterizing Reward Hacking. InAdvances\\nin Neural Information Processing Systems , Alice H. Oh, Alekh Agarwal, Danielle Belgrave, and Kyunghyun Cho (Eds.). https://arxiv.org/abs/2209.13085\\nElizabeth S Spelke and Katherine D Kinzler. 2007. Core knowledge. Developmental science 10, 1 (2007), 89–96. Publisher: Wiley Online Library.'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 21, 'page_label': '22'}, page_content='Elizabeth S Spelke and Katherine D Kinzler. 2007. Core knowledge. Developmental science 10, 1 (2007), 89–96. Publisher: Wiley Online Library.\\nAarohi Srivastava, Abhinav Rastogi, Abhishek Rao, Abu Awal Md Shoeb, Abubakar Abid, Adam Fisch, Adam R. Brown, Adam Santoro, Aditya Gupta, Adrià\\nGarriga-Alonso, Agnieszka Kluska, Aitor Lewkowycz, Akshat Agarwal, Alethea Power, Alex Ray, Alex Warstadt, Alexander W. Kocurek, Ali Safaya,\\nManuscript submitted to ACM'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 22, 'page_label': '23'}, page_content='Harms from Increasingly Agentic Algorithmic Systems 23\\nAli Tazarv, Alice Xiang, Alicia Parrish, Allen Nie, Aman Hussain, Amanda Askell, Amanda Dsouza, Ambrose Slone, Ameet Rahane, Anantharaman S.\\nIyer, Anders Andreassen, Andrea Madotto, Andrea Santilli, Andreas Stuhlmüller, Andrew Dai, Andrew La, Andrew Lampinen, Andy Zou, Angela Jiang,\\nAngelica Chen, Anh Vuong, Animesh Gupta, Anna Gottardi, Antonio Norelli, Anu Venkatesh, Arash Gholamidavoodi, Arfa Tabassum, Arul Menezes,\\nArun Kirubarajan, Asher Mullokandov, Ashish Sabharwal, Austin Herrick, Avia Efrat, Aykut Erdem, Ayla Karakaş, B. Ryan Roberts, Bao Sheng\\nLoe, Barret Zoph, Bartłomiej Bojanowski, Batuhan Özyurt, Behnam Hedayatnia, Behnam Neyshabur, Benjamin Inden, Benno Stein, Berk Ekmekci,\\nBill Yuchen Lin, Blake Howald, Cameron Diao, Cameron Dour, Catherine Stinson, Cedrick Argueta, César Ferri Ramírez, Chandan Singh, Charles'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 22, 'page_label': '23'}, page_content='Bill Yuchen Lin, Blake Howald, Cameron Diao, Cameron Dour, Catherine Stinson, Cedrick Argueta, César Ferri Ramírez, Chandan Singh, Charles\\nRathkopf, Chenlin Meng, Chitta Baral, Chiyu Wu, Chris Callison-Burch, Chris Waites, Christian Voigt, Christopher D. Manning, Christopher Potts,\\nCindy Ramirez, Clara E. Rivera, Clemencia Siro, Colin Raffel, Courtney Ashcraft, Cristina Garbacea, Damien Sileo, Dan Garrette, Dan Hendrycks, Dan\\nKilman, Dan Roth, Daniel Freeman, Daniel Khashabi, Daniel Levy, Daniel Moseguí González, Danielle Perszyk, Danny Hernandez, Danqi Chen, Daphne\\nIppolito, Dar Gilboa, David Dohan, David Drakard, David Jurgens, Debajyoti Datta, Deep Ganguli, Denis Emelin, Denis Kleyko, Deniz Yuret, Derek\\nChen, Derek Tam, Dieuwke Hupkes, Diganta Misra, Dilyar Buzan, Dimitri Coelho Mollo, Diyi Yang, Dong-Ho Lee, Ekaterina Shutova, Ekin Dogus\\nCubuk, Elad Segal, Eleanor Hagerman, Elizabeth Barnes, Elizabeth Donoway, Ellie Pavlick, Emanuele Rodola, Emma Lam, Eric Chu, Eric Tang, Erkut'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 22, 'page_label': '23'}, page_content='Cubuk, Elad Segal, Eleanor Hagerman, Elizabeth Barnes, Elizabeth Donoway, Ellie Pavlick, Emanuele Rodola, Emma Lam, Eric Chu, Eric Tang, Erkut\\nErdem, Ernie Chang, Ethan A. Chi, Ethan Dyer, Ethan Jerzak, Ethan Kim, Eunice Engefu Manyasi, Evgenii Zheltonozhskii, Fanyue Xia, Fatemeh\\nSiar, Fernando Martínez-Plumed, Francesca Happé, Francois Chollet, Frieda Rong, Gaurav Mishra, Genta Indra Winata, Gerard de Melo, Germán\\nKruszewski, Giambattista Parascandolo, Giorgio Mariani, Gloria Wang, Gonzalo Jaimovitch-López, Gregor Betz, Guy Gur-Ari, Hana Galijasevic,\\nHannah Kim, Hannah Rashkin, Hannaneh Hajishirzi, Harsh Mehta, Hayden Bogar, Henry Shevlin, Hinrich Schütze, Hiromu Yakura, Hongming Zhang,\\nHugh Mee Wong, Ian Ng, Isaac Noble, Jaap Jumelet, Jack Geissinger, Jackson Kernion, Jacob Hilton, Jaehoon Lee, Jaime Fernández Fisac, James B.\\nSimon, James Koppel, James Zheng, James Zou, Jan Kocoń, Jana Thompson, Jared Kaplan, Jarema Radom, Jascha Sohl-Dickstein, Jason Phang, Jason'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 22, 'page_label': '23'}, page_content='Simon, James Koppel, James Zheng, James Zou, Jan Kocoń, Jana Thompson, Jared Kaplan, Jarema Radom, Jascha Sohl-Dickstein, Jason Phang, Jason\\nWei, Jason Yosinski, Jekaterina Novikova, Jelle Bosscher, Jennifer Marsh, Jeremy Kim, Jeroen Taal, Jesse Engel, Jesujoba Alabi, Jiacheng Xu, Jiaming\\nSong, Jillian Tang, Joan Waweru, John Burden, John Miller, John U. Balis, Jonathan Berant, Jörg Frohberg, Jos Rozen, Jose Hernandez-Orallo, Joseph\\nBoudeman, Joseph Jones, Joshua B. Tenenbaum, Joshua S. Rule, Joyce Chua, Kamil Kanclerz, Karen Livescu, Karl Krauth, Karthik Gopalakrishnan,\\nKaterina Ignatyeva, Katja Markert, Kaustubh D. Dhole, Kevin Gimpel, Kevin Omondi, Kory Mathewson, Kristen Chiafullo, Ksenia Shkaruta, Kumar\\nShridhar, Kyle McDonell, Kyle Richardson, Laria Reynolds, Leo Gao, Li Zhang, Liam Dugan, Lianhui Qin, Lidia Contreras-Ochando, Louis-Philippe'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 22, 'page_label': '23'}, page_content='Shridhar, Kyle McDonell, Kyle Richardson, Laria Reynolds, Leo Gao, Li Zhang, Liam Dugan, Lianhui Qin, Lidia Contreras-Ochando, Louis-Philippe\\nMorency, Luca Moschella, Lucas Lam, Lucy Noble, Ludwig Schmidt, Luheng He, Luis Oliveros Colón, Luke Metz, Lütfi Kerem Şenel, Maarten Bosma,\\nMaarten Sap, Maartje ter Hoeve, Maheen Farooqi, Manaal Faruqui, Mantas Mazeika, Marco Baturan, Marco Marelli, Marco Maru, Maria Jose Ramírez\\nQuintana, Marie Tolkiehn, Mario Giulianelli, Martha Lewis, Martin Potthast, Matthew L. Leavitt, Matthias Hagen, Mátyás Schubert, Medina Orduna\\nBaitemirova, Melody Arnaud, Melvin McElrath, Michael A. Yee, Michael Cohen, Michael Gu, Michael Ivanitskiy, Michael Starritt, Michael Strube,\\nMichał Swędrowski, Michele Bevilacqua, Michihiro Yasunaga, Mihir Kale, Mike Cain, Mimee Xu, Mirac Suzgun, Mo Tiwari, Mohit Bansal, Moin\\nAminnaseri, Mor Geva, Mozhdeh Gheini, Mukund Varma T, Nanyun Peng, Nathan Chi, Nayeon Lee, Neta Gur-Ari Krakover, Nicholas Cameron,'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 22, 'page_label': '23'}, page_content='Aminnaseri, Mor Geva, Mozhdeh Gheini, Mukund Varma T, Nanyun Peng, Nathan Chi, Nayeon Lee, Neta Gur-Ari Krakover, Nicholas Cameron,\\nNicholas Roberts, Nick Doiron, Nikita Nangia, Niklas Deckers, Niklas Muennighoff, Nitish Shirish Keskar, Niveditha S. Iyer, Noah Constant, Noah\\nFiedel, Nuan Wen, Oliver Zhang, Omar Agha, Omar Elbaghdadi, Omer Levy, Owain Evans, Pablo Antonio Moreno Casares, Parth Doshi, Pascale Fung,\\nPaul Pu Liang, Paul Vicol, Pegah Alipoormolabashi, Peiyuan Liao, Percy Liang, Peter Chang, Peter Eckersley, Phu Mon Htut, Pinyu Hwang, Piotr\\nMiłkowski, Piyush Patil, Pouya Pezeshkpour, Priti Oli, Qiaozhu Mei, Qing Lyu, Qinlang Chen, Rabin Banjade, Rachel Etta Rudolph, Raefer Gabriel,\\nRahel Habacker, Ramón Risco Delgado, Raphaël Millière, Rhythm Garg, Richard Barnes, Rif A. Saurous, Riku Arakawa, Robbe Raymaekers, Robert\\nFrank, Rohan Sikand, Roman Novak, Roman Sitelew, Ronan LeBras, Rosanne Liu, Rowan Jacobs, Rui Zhang, Ruslan Salakhutdinov, Ryan Chi, Ryan'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 22, 'page_label': '23'}, page_content='Frank, Rohan Sikand, Roman Novak, Roman Sitelew, Ronan LeBras, Rosanne Liu, Rowan Jacobs, Rui Zhang, Ruslan Salakhutdinov, Ryan Chi, Ryan\\nLee, Ryan Stovall, Ryan Teehan, Rylan Yang, Sahib Singh, Saif M. Mohammad, Sajant Anand, Sam Dillavou, Sam Shleifer, Sam Wiseman, Samuel\\nGruetter, Samuel R. Bowman, Samuel S. Schoenholz, Sanghyun Han, Sanjeev Kwatra, Sarah A. Rous, Sarik Ghazarian, Sayan Ghosh, Sean Casey,\\nSebastian Bischoff, Sebastian Gehrmann, Sebastian Schuster, Sepideh Sadeghi, Shadi Hamdan, Sharon Zhou, Shashank Srivastava, Sherry Shi, Shikhar\\nSingh, Shima Asaadi, Shixiang Shane Gu, Shubh Pachchigar, Shubham Toshniwal, Shyam Upadhyay, Shyamolima, Debnath, Siamak Shakeri, Simon\\nThormeyer, Simone Melzi, Siva Reddy, Sneha Priscilla Makini, Soo-Hwan Lee, Spencer Torene, Sriharsha Hatwar, Stanislas Dehaene, Stefan Divic,\\nStefano Ermon, Stella Biderman, Stephanie Lin, Stephen Prasad, Steven T. Piantadosi, Stuart M. Shieber, Summer Misherghi, Svetlana Kiritchenko,'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 22, 'page_label': '23'}, page_content='Stefano Ermon, Stella Biderman, Stephanie Lin, Stephen Prasad, Steven T. Piantadosi, Stuart M. Shieber, Summer Misherghi, Svetlana Kiritchenko,\\nSwaroop Mishra, Tal Linzen, Tal Schuster, Tao Li, Tao Yu, Tariq Ali, Tatsu Hashimoto, Te-Lin Wu, Théo Desbordes, Theodore Rothschild, Thomas\\nPhan, Tianle Wang, Tiberius Nkinyili, Timo Schick, Timofei Kornev, Timothy Telleen-Lawton, Titus Tunduny, Tobias Gerstenberg, Trenton Chang,\\nTrishala Neeraj, Tushar Khot, Tyler Shultz, Uri Shaham, Vedant Misra, Vera Demberg, Victoria Nyamai, Vikas Raunak, Vinay Ramasesh, Vinay Uday\\nPrabhu, Vishakh Padmakumar, Vivek Srikumar, William Fedus, William Saunders, William Zhang, Wout Vossen, Xiang Ren, Xiaoyu Tong, Xinran\\nZhao, Xinyi Wu, Xudong Shen, Yadollah Yaghoobzadeh, Yair Lakretz, Yangqiu Song, Yasaman Bahri, Yejin Choi, Yichi Yang, Yiding Hao, Yifu Chen,\\nYonatan Belinkov, Yu Hou, Yufang Hou, Yuntao Bai, Zachary Seid, Zhuoye Zhao, Zijian Wang, Zijie J. Wang, Zirui Wang, and Ziyi Wu. 2022. Beyond'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 22, 'page_label': '23'}, page_content='Yonatan Belinkov, Yu Hou, Yufang Hou, Yuntao Bai, Zachary Seid, Zhuoye Zhao, Zijian Wang, Zijie J. Wang, Zirui Wang, and Ziyi Wu. 2022. Beyond\\nthe Imitation Game: Quantifying and extrapolating the capabilities of language models. https://doi.org/10.48550/arXiv.2206.04615 arXiv:2206.04615\\n[cs, stat].\\nLogan Stapleton, Min Hun Lee, Diana Qing, Marya Wright, Alexandra Chouldechova, Ken Holstein, Zhiwei Steven Wu, and Haiyi Zhu. 2022. Imagining\\nnew futures beyond predictive systems in child welfare: A qualitative study with impacted stakeholders. In 2022 ACM Conference on Fairness,\\nAccountability, and Transparency . ACM. https://doi.org/10.1145/3531146.3533177\\nsteven t. piantadosi [@spiantado]. 2022. Yes, ChatGPT is amazing and impressive. No, @OpenAI has not come close to addressing the problem of bias.\\nFilters appear to be bypassed with simple tricks, and superficially masked. And what is lurking inside is egregious. @Abebab @sama tw racism,'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 22, 'page_label': '23'}, page_content='Filters appear to be bypassed with simple tricks, and superficially masked. And what is lurking inside is egregious. @Abebab @sama tw racism,\\nsexism. https://t.co/V4fw1fY9dY. https://twitter.com/spiantado/status/1599462375887114240\\nManuscript submitted to ACM'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 23, 'page_label': '24'}, page_content='24 Chan et al.\\nJonathan M. Stokes, Kevin Yang, Kyle Swanson, Wengong Jin, Andres Cubillos-Ruiz, Nina M. Donghia, Craig R. MacNair, Shawn French, Lindsey A.\\nCarfrae, Zohar Bloom-Ackermann, Victoria M. Tran, Anush Chiappino-Pepe, Ahmed H. Badran, Ian W. Andrews, Emma J. Chory, George M. Church,\\nEric D. Brown, Tommi S. Jaakkola, Regina Barzilay, and James J. Collins. 2020. A Deep Learning Approach to Antibiotic Discovery. Cell 180, 4 (Feb.\\n2020), 688–702.e13. https://doi.org/10.1016/j.cell.2020.01.021\\nYulia W. Sullivan and Samuel Fosso Wamba. 2022. Moral Judgments in the Age of Artificial Intelligence. Journal of Business Ethics 178, 4 (July 2022),\\n917–943. https://doi.org/10.1007/s10551-022-05053-w\\nRichard Sutton. 2022. https://twitter.com/richardssutton/status/1575619651563708418\\nRichard S Sutton and Andrew G Barto. 2018. Reinforcement learning: An introduction . MIT press.'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 23, 'page_label': '24'}, page_content='Richard Sutton. 2022. https://twitter.com/richardssutton/status/1575619651563708418\\nRichard S Sutton and Andrew G Barto. 2018. Reinforcement learning: An introduction . MIT press.\\nRichard S. Sutton, Michael Bowling, and Patrick M. Pilarski. 2022. The Alberta Plan for AI Research. https://doi.org/10.48550/arXiv.2208.11173\\narXiv:2208.11173 [cs].\\nTom Sühr, Sophie Hilgard, and Himabindu Lakkaraju. 2021. Does Fair Ranking Improve Minority Outcomes? Understanding the Interplay of Human and\\nAlgorithmic Biases in Online Hiring. In Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society . ACM. https://doi.org/10.1145/3461702.\\n3462602\\nAdaptive Agent Team, Jakob Bauer, Kate Baumli, Satinder Baveja, Feryal Behbahani, Avishkar Bhoopchand, Nathalie Bradley-Schmieg, Michael\\nChang, Natalie Clay, Adrian Collister, Vibhavari Dasagi, Lucy Gonzalez, Karol Gregor, Edward Hughes, Sheleem Kashem, Maria Loks-Thompson,'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 23, 'page_label': '24'}, page_content='Chang, Natalie Clay, Adrian Collister, Vibhavari Dasagi, Lucy Gonzalez, Karol Gregor, Edward Hughes, Sheleem Kashem, Maria Loks-Thompson,\\nHannah Openshaw, Jack Parker-Holder, Shreya Pathak, Nicolas Perez-Nieves, Nemanja Rakicevic, Tim Rocktäschel, Yannick Schroecker, Jakub\\nSygnowski, Karl Tuyls, Sarah York, Alexander Zacherl, and Lei Zhang. 2023. Human-Timescale Adaptation in an Open-Ended Task Space. https:\\n//doi.org/10.48550/arXiv.2301.07608 arXiv:2301.07608 [cs].\\nPhilip E Tetlock and Dan Gardner. 2016. Superforecasting: The Art and Science of Prediction . Random House.\\nRobert Trager. 2022. Deliberating Autonomous Weapons. Issues in Science and Technology XXXVIII, 4 (2022). https://issues.org/autonomous-weapons-\\nrussell-forum/\\nAndrew Tutt. 2017. An FDA for Algorithms.Administrative Law Review 69, 1 (2017), 83–124. https://heinonline.org/HOL/P?h=hein.journals/admin69&i=95'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 23, 'page_label': '24'}, page_content='russell-forum/\\nAndrew Tutt. 2017. An FDA for Algorithms.Administrative Law Review 69, 1 (2017), 83–124. https://heinonline.org/HOL/P?h=hein.journals/admin69&i=95\\nKarthik Valmeekam, Alberto Olmo, Sarath Sreedharan, and Subbarao Kambhampati. 2022. Large Language Models Still Can’t Plan (A Benchmark for\\nLLMs on Planning and Reasoning about Change). https://doi.org/10.48550/arXiv.2206.10498 arXiv:2206.10498 [cs].\\nAgnes Schim van der Loeff, Iggy Bassi, Sachin Kapila, and Jevgenij Gamper. 2019. AI Ethics for Systemic Issues: A Structural Approach. https:\\n//doi.org/10.48550/arXiv.1911.03216 arXiv:1911.03216 [cs].\\nLee Vinsel. 2021. You’re Doing It Wrong: Notes on Criticism and Technology Hype. https://sts-news.medium.com/youre-doing-it-wrong-notes-on-\\ncriticism-and-technology-hype-18b08b4307e5\\nHeather Vogell, Haru Coryne, and Ryan Little. 2022. How a secret rent algorithm pushes rents higher. https://www.propublica.org/article/yieldstar-rent-'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 23, 'page_label': '24'}, page_content='criticism-and-technology-hype-18b08b4307e5\\nHeather Vogell, Haru Coryne, and Ryan Little. 2022. How a secret rent algorithm pushes rents higher. https://www.propublica.org/article/yieldstar-rent-\\nincrease-realpage-rent Publication Title: ProPublica.\\nAxel Volkery and Teresa Ribeiro. 2009. Scenario planning in public policy: Understanding use, impacts and the role of institutional context factors.\\nTechnological forecasting and social change 76, 9 (2009), 1198–1207. Publisher: Elsevier.\\nEric Wallace, Shi Feng, Nikhil Kandpal, Matt Gardner, and Sameer Singh. 2019. Universal Adversarial Triggers for Attacking and Analyzing NLP. In\\nProceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language\\nProcessing (EMNLP-IJCNLP) . Association for Computational Linguistics, Hong Kong, China, 2153–2162. https://doi.org/10.18653/v1/D19-1221'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 23, 'page_label': '24'}, page_content='Processing (EMNLP-IJCNLP) . Association for Computational Linguistics, Hong Kong, China, 2153–2162. https://doi.org/10.18653/v1/D19-1221\\nJason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, Ed H.\\nChi, Tatsunori Hashimoto, Oriol Vinyals, Percy Liang, Jeff Dean, and William Fedus. 2022. Emergent Abilities of Large Language Models. Transactions\\non Machine Learning Research (2022). https://openreview.net/forum?id=yzkSU5zdwD\\nJason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed Chi, Quoc Le, and Denny Zhou. 2023. Chain-of-Thought Prompting\\nElicits Reasoning in Large Language Models. https://doi.org/10.48550/arXiv.2201.11903 arXiv:2201.11903 [cs].\\nLaura Weidinger, Jonathan Uesato, Maribeth Rauh, Conor Griffin, Po-Sen Huang, John Mellor, Amelia Glaese, Myra Cheng, Borja Balle, Atoosa Kasirzadeh,'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 23, 'page_label': '24'}, page_content='Laura Weidinger, Jonathan Uesato, Maribeth Rauh, Conor Griffin, Po-Sen Huang, John Mellor, Amelia Glaese, Myra Cheng, Borja Balle, Atoosa Kasirzadeh,\\nCourtney Biles, Sasha Brown, Zac Kenton, Will Hawkins, Tom Stepleton, Abeba Birhane, Lisa Anne Hendricks, Laura Rimell, William Isaac, Julia\\nHaas, Sean Legassick, Geoffrey Irving, and Iason Gabriel. 2022. Taxonomy of Risks posed by Language Models. In 2022 ACM Conference on Fairness,\\nAccountability, and Transparency . ACM. https://doi.org/10.1145/3531146.3533088\\nSean Welsh. 2019. Regulating Lethal and Harmful Autonomy. In Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and Society . ACM.\\nhttps://doi.org/10.1145/3306618.3314295\\nJoe Whittaker, Seán Looney, Alastair Reed, and Fabio Votta. 2021. Recommender systems and the amplification of extremist content. Internet Policy\\nReview 10, 2 (June 2021). https://policyreview.info/articles/analysis/recommender-systems-and-amplification-extremist-content'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 23, 'page_label': '24'}, page_content='Review 10, 2 (June 2021). https://policyreview.info/articles/analysis/recommender-systems-and-amplification-extremist-content\\nMaranke Wieringa. 2020. What to account for when accounting for algorithms. In Proceedings of the 2020 Conference on Fairness, Accountability, and\\nTransparency. ACM. https://doi.org/10.1145/3351095.3372833\\nRobert Wolfe and Aylin Caliskan. 2022. American == White in Multimodal Language-and-Image AI. In Proceedings of the 2022 AAAI/ACM Conference on\\nAI, Ethics, and Society . ACM. https://doi.org/10.1145/3514094.3534136\\nS. Wyatt. 2008. Technological determinism is dead; Long live technological determinism. In Handbook of Science and Technology Studies , E. Hackett,\\nO. Amsterdamska, M. Lynch, and J. Wajcman (Eds.). MIT Press, Cambridge, 165–180.\\nWeirui Ye, Shaohuai Liu, Thanard Kurutach, Pieter Abbeel, and Yang Gao. 2021. Mastering Atari Games with Limited Data. InAdvances in Neural Information'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 23, 'page_label': '24'}, page_content='Weirui Ye, Shaohuai Liu, Thanard Kurutach, Pieter Abbeel, and Yang Gao. 2021. Mastering Atari Games with Limited Data. InAdvances in Neural Information\\nProcessing Systems, Vol. 34. Curran Associates, Inc., 25476–25488. https://proceedings.neurips.cc/paper/2021/hash/d5eca8dc3820cad9fe56a3bafda65ca1-\\nManuscript submitted to ACM'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 24, 'page_label': '25'}, page_content='Harms from Increasingly Agentic Algorithmic Systems 25\\nAbstract.html\\nSunkyung Yoon, Mary Kleinman, Jessica Mertz, and Michael Brannick. 2019. Is social network site usage related to depression? A meta-analysis of\\nFacebook–depression relations. Journal of Affective Disorders 248 (April 2019), 65–72. https://doi.org/10.1016/j.jad.2019.01.026\\nMeg Young, Michael Katell, and P. M. Krafft. 2022. Confronting Power and Corporate Capture at the FAccT Conference. In 2022 ACM Conference on\\nFairness, Accountability, and Transparency . ACM. https://doi.org/10.1145/3531146.3533194\\nAndy Zeng, Maria Attarian, Brian Ichter, Krzysztof Choromanski, Adrian Wong, Stefan Welker, Federico Tombari, Aveek Purohit, Michael Ryoo, Vikas\\nSindhwani, Johnny Lee, Vincent Vanhoucke, and Pete Florence. 2022. Socratic Models: Composing Zero-Shot Multimodal Reasoning with Language.\\nhttps://doi.org/10.48550/arXiv.2204.00598 arXiv:2204.00598 [cs].'),\n",
       " Document(metadata={'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-02-22T02:04:41+00:00', 'moddate': '2023-02-22T02:04:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '\\\\\\\\?\\\\D:\\\\Desktop\\\\AMJ Group\\\\Teaching\\\\Class Materials\\\\AGS_Advanced_Generative_AI_Building_LLM_Applications_ILT_Material\\\\Demo\\\\L7_Benchmark_and_Evaluation_of_LLM_Capabilities_Part_1\\\\Gen_AI_Papers\\\\Chan et al. - 2023 - Harms from Increasingly Agentic Algorithmic Systems.pdf', 'total_pages': 25, 'page': 24, 'page_label': '25'}, page_content='https://doi.org/10.48550/arXiv.2204.00598 arXiv:2204.00598 [cs].\\nXueru Zhang and M. Liu. 2020. Fairness in Learning-Based Sequential Decision Algorithms: A Survey. ArXiv abs/2001.04861 (2020).\\nStephan Zheng, Alexander Trott, Sunil Srinivasa, David C. Parkes, and Richard Socher. 2021. The AI Economist: Optimal Economic Policy Design via\\nTwo-level Deep Reinforcement Learning. https://doi.org/10.48550/arXiv.2108.02755 arXiv:2108.02755 [cs, econ, q-fin].\\nMiri Zilka, Holli Sargeant, and Adrian Weller. 2022. Transparency, Governance and Regulation of Algorithmic Tools Deployed in the Criminal Justice\\nSystem: a UK Case Study. In Proceedings of the 2022 AAAI/ACM Conference on AI, Ethics, and Society . ACM. https://doi.org/10.1145/3514094.3534200\\nRemco Zwetsloot and Allan Dafoe. 2019. Thinking about risks from AI: Accidents, misuse and structure. Lawfare. February 11 (2019), 2019.\\nManuscript submitted to ACM')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RLZTwm7DuKe4"
   },
   "source": [
    "### **Step 3: Loading the OpenAI Embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "565"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Embeddings + FAISS index ---\n",
    "import os\n",
    "try:\n",
    "    from langchain_openai import OpenAIEmbeddings\n",
    "except ImportError:\n",
    "    from langchain.embeddings import OpenAIEmbeddings  # fallback for older LC\n",
    "\n",
    "# If needed for this session only:\n",
    "os.environ[\"OPENAI_API_KEY\"] = \n",
    "\n",
    "\n",
    "# Use default OpenAI embeddings (or specify model=\"text-embedding-3-small\")\n",
    "embeddings = OpenAIEmbeddings()  # model=\"text-embedding-3-small\"\n",
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "db = FAISS.from_documents(texts, embeddings)\n",
    "\n",
    "# Confirm index size\n",
    "db.index.ntotal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KqaG3jbAuS0K"
   },
   "source": [
    "### **Step 4: Creating and Loading the Database**\n",
    "\n",
    "*   Create a database to store the embedded text.\n",
    "*   Load the database to bring it back into memory from the disk.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "rDcTkjWOv11M"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "565"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Step 4: Creating and Loading the Database ---\n",
    "\n",
    "# Save the FAISS index\n",
    "db.save_local(\"faiss_index\")\n",
    "\n",
    "# Load the FAISS index back from disk\n",
    "db_reloaded = FAISS.load_local(\"faiss_index\", embeddings, allow_dangerous_deserialization=True)\n",
    "\n",
    "# Confirm it reloaded properly\n",
    "db_reloaded.index.ntotal\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nh2K3SO4wBkN"
   },
   "source": [
    "### **Step 5: Creating and Using the Retriever**\n",
    "\n",
    "*   Create a retriever using the vector database.\n",
    "*   Use the retriever to get relevant documents for a specific query.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "hOBLjcr5wX6X"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jim\\AppData\\Local\\Temp\\ipykernel_17296\\1168041564.py:8: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  docs = retriever.get_relevant_documents(\"What is Toolformer?\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Peter Clark, Oyvind Tafjord, and Kyle Richardson. 2020. Transformers as soft reasoners over\\nlanguage. IJCAI.\\nKarl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Jacob Hilton, Reiichiro Nakano, Christopher\\nHesse, and John Schulman. 2021. Training veriﬁers to solve math word problems. arXiv preprint\\narXiv:2110.14168.\\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of\\ndeep bidirectional transformers for language understanding. NAACL.\\nHonghua Dong, Jiayuan Mao,'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating retriever\n",
    "# --- Step 5: Creating and Using the Retriever ---\n",
    "\n",
    "# Create retriever from the reloaded FAISS index\n",
    "retriever = db_reloaded.as_retriever()\n",
    "\n",
    "# Example query\n",
    "docs = retriever.get_relevant_documents(\"What is Toolformer?\")\n",
    "\n",
    "# Peek at first result\n",
    "docs[0].page_content[:500]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MJDyfzRwwhEU"
   },
   "source": [
    "### **Step 6: Passing the Query**\n",
    "\n",
    "*   Pass the query to the vector database.\n",
    "*   Print the content of the most relevant document.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Vc3fqL4ZwmBX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "senting uncertainty about a word being predicted comes down to producing a vector whose\n",
      "components are scores or probabilities for each word (or discrete token) in the dictionary.\n",
      "But this approach doesn’t work for high-dimensional continuous modalities, such as video.\n",
      "To represent such data, it is necessary to eliminate irrelevant information about the variable\n",
      "to be modeled through an encoder, as in the JEPA. Furthermore, the high-dimensionality\n",
      "of the signal precludes the representation of uncertainty through a normalized distribution.\n",
      "Second, current models are only capable of very limited forms of reasoning. The absence\n",
      "of abstract latent variables in these models precludes the exploration of multiple interpre-\n",
      "tations of a percept and the search for optimal courses of action to achieve a goal. In fact,\n",
      "dynamically specifying a goal in such models is essentially impossible.\n",
      "8.3.2 Reward is not enough\n"
     ]
    }
   ],
   "source": [
    "# --- Step 6: Passing the Query ---\n",
    "\n",
    "query = \"A fundamental limitation of HMMs\"\n",
    "docs = db_reloaded.similarity_search(query, k=1)\n",
    "\n",
    "print(docs[0].page_content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jim\\AppData\\Local\\Temp\\ipykernel_17296\\3198519198.py:10: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  answer = qa.run(\"Summarize the key idea of Chain-of-Thought prompting\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Chain-of-Thought prompting is a method that improves the ability of large language models to perform complex reasoning by providing a series of intermediate reasoning steps, called a \"chain of thought,\" as exemplars in prompting. This approach has been shown to outperform standard prompting on various reasoning tasks, and it allows language models to decompose multi-step problems into smaller, more manageable steps.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=OpenAI(temperature=0),\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever\n",
    ")\n",
    "\n",
    "answer = qa.run(\"Summarize the key idea of Chain-of-Thought prompting\")\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uT00SGQrw3Dw"
   },
   "source": [
    "### **Conclusion**\n",
    "\n",
    "By the end of this demo, you have a clear understanding of how to use LangChain’s MultiPDF retriever with FAISS. You’ve learned how to load and process documents, create a database, make a retriever, and use the retriever to ask questions. This knowledge will help you effectively utilize LangChain’s capabilities in your projects."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
