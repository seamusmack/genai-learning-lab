{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "JjVaYKA3E4Sh",
   "metadata": {
    "id": "JjVaYKA3E4Sh"
   },
   "source": [
    "# __Demo: Zero-Shot Prompting with LangChain and OpenAI__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "L5xEJAD-FWkJ",
   "metadata": {
    "id": "L5xEJAD-FWkJ"
   },
   "source": [
    "## __Steps to Perform:__\n",
    "Step 1: Set up the OpenAI API Key\n",
    "\n",
    "Step 2: Define a Function to Get Completion\n",
    "\n",
    "Step 3: Define Your Prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oejbW3zZlqXB",
   "metadata": {
    "id": "oejbW3zZlqXB"
   },
   "source": [
    "### __Step 1: Set up the OpenAI API Key__\n",
    "- The code imports the necessary libraries.\n",
    "- The **os** is used for interacting with the operating system, and __openai__ is the library required to work with OpenAI's API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "172a828d-22d6-486b-be55-62c9258add5b",
   "metadata": {
    "id": "172a828d-22d6-486b-be55-62c9258add5b"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "01e63db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ OpenAI API key successfully loaded.\n"
     ]
    }
   ],
   "source": [
    "# Direct assignment of the OpenAI API key (for demo use only)\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "# Optional: Confirm successful load\n",
    "if openai.api_key:\n",
    "    print(\"‚úÖ OpenAI API key successfully loaded.\")\n",
    "else:\n",
    "    print(\"‚ùå API key not found. Please check your setup.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7c7c4e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old get_completion deleted.\n"
     ]
    }
   ],
   "source": [
    "# Delete old version if it's hanging around\n",
    "try:\n",
    "    del get_completion\n",
    "    print(\"Old get_completion deleted.\")\n",
    "except NameError:\n",
    "    print(\"get_completion not previously defined.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yI8QQCxCl-LQ",
   "metadata": {
    "id": "yI8QQCxCl-LQ"
   },
   "source": [
    "### __Step 2: Define a Function to Get Completion__\n",
    "The __get_completion__ function is responsible for sending a prompt to the OpenAI model and receiving its response.\n",
    "\n",
    "__Parameters:__\n",
    "  - __prompt__: It is the text input for which the model will generate a completion.\n",
    "  -  __model__: The gpt-3.5-turbo model is used to perform the tasks.\n",
    "\n",
    "The __openai.ChatCompletion.create__ function is used to send a request to the OpenAI API.\n",
    "- This request includes the model, the input messages (formatted as a list of dictionaries with user roles and content), and a temperature setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e778a5d4-77e5-4d61-a77d-3fed1e8d830a",
   "metadata": {
    "id": "e778a5d4-77e5-4d61-a77d-3fed1e8d830a"
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# ‚úÖ Directly pass your key to the new client\n",
    "client = OpenAI(api_key=\"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\")\n",
    "\n",
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0.1,\n",
    "            top_p=0.8,\n",
    "            max_tokens=512\n",
    "        )\n",
    "        return response\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe55c20-acf7-45b0-9d64-9b4e89938fc7",
   "metadata": {},
   "source": [
    "Inside the above fucntion, we will discuss the Messages part first\n",
    "\n",
    "Structure is :\n",
    "\n",
    "**Role** --> Defining who is speaking\n",
    "\n",
    "    System : Sets the behavious of the model\n",
    "    User : Who inputs the data or instruction\n",
    "    Assistant : The models's Response\n",
    "\n",
    "Content : The actual text or instruction which is passed by us."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XJS0DNh0nonO",
   "metadata": {
    "id": "XJS0DNh0nonO"
   },
   "source": [
    "### __Step 3: Define Your Prompt__\n",
    "- The prompt variable is defined with a simple translation task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3ef6aa68-a8aa-45c6-b70b-3060e9253b90",
   "metadata": {
    "id": "3ef6aa68-a8aa-45c6-b70b-3060e9253b90",
    "outputId": "8d98a6c9-99b7-48e7-a2ea-fcf68b053879"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial intelligence (AI) refers to the simulation of human intelligence processes by machines, particularly computer systems. These processes include learning, reasoning, problem-solving, perception, and language understanding. AI technologies enable machines to perform tasks that typically require human intelligence, such as visual perception, speech recognition, decision-making, and language translation.\n",
      "\n",
      "AI systems are designed to analyze large amounts of data, recognize patterns, and make predictions or decisions based on that data. They can be trained to perform specific tasks through machine learning algorithms, which allow them to improve their performance over time without being explicitly programmed.\n",
      "\n",
      "There are different types of AI, including narrow AI, which is designed for specific tasks, and general AI, which aims to replicate human intelligence across a wide range of tasks. AI technologies are being used in various industries, such as healthcare, finance, transportation, and entertainment, to automate processes, improve efficiency, and enhance decision-making.\n",
      "\n",
      "Overall, artificial intelligence has the potential to revolutionize the way we live and work, but it also raises ethical and societal concerns related to privacy, bias, and job displacement.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Explain artificial intelligence\"\n",
    "response = get_completion(prompt)\n",
    "\n",
    "if hasattr(response, \"choices\"):\n",
    "    print(response.choices[0].message.content)\n",
    "else:\n",
    "    print(\"‚ùå Error:\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf8b09a-e09a-4405-b342-0cafee23feca",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8447f2-7697-46f9-9557-ae8357590e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.choices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72c66ce-df7b-4df1-ba69-e79485dafc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.choices[0].message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e44044-391f-4237-a193-55fc42a511aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6e1beb11-7c32-44e8-bf11-6d678dd383c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trigonometry is a branch of mathematics that deals with the relationships between the sides and angles of triangles. It is used to study and solve problems involving triangles, such as finding the lengths of sides, determining angles, and analyzing periodic phenomena.\n",
      "\n",
      "The three main trigonometric functions are sine, cosine, and tangent, which are defined in relation to the angles of a right triangle. These functions can be used to calculate the lengths of sides and angles of a triangle, as well as to solve various types of trigonometric equations.\n",
      "\n",
      "Trigonometry is widely used in various fields such as physics, engineering, architecture, and astronomy, as it provides a way to analyze and solve problems involving angles and distances. It is also used in navigation, surveying, and computer graphics, among other applications.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"explain trigonometry\"\n",
    "response = get_completion(prompt)\n",
    "\n",
    "if hasattr(response, \"choices\"):\n",
    "    print(response.choices[0].message.content)\n",
    "else:\n",
    "    print(\"‚ùå Error:\", response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f442b52c-c41e-4e9a-ba68-8fbeb3a83efb",
   "metadata": {},
   "source": [
    "### Step 5: Define a Prompt Generator Function\n",
    "\n",
    "This function dynamically creates a zero-shot prompt based on:\n",
    "- The `task_type` (e.g., summarization, sentiment, instruction)\n",
    "- The main input `content`\n",
    "- An optional `style` (e.g., \"concise\", \"creative\", etc.)\n",
    "\n",
    "The output prompt can be passed directly into the LLM.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bf2445c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def prompt_generator(task_type: str, content: str, style: str = None) -> str:\n",
    "    \"\"\"\n",
    "    Dynamically generate a prompt for different zero-shot tasks.\n",
    "\n",
    "    Parameters:\n",
    "        task_type (str): Type of task ('summarization', 'sentiment', 'instruction')\n",
    "        content (str): The core input text to include in the prompt\n",
    "        style (str, optional): Optional modifier like 'concise' or 'creative'\n",
    "\n",
    "    Returns:\n",
    "        str: A formatted prompt string ready to send to the LLM\n",
    "    \"\"\"\n",
    "    templates = {\n",
    "        \"summarization\": [\n",
    "            \"Summarize the following text:\\n{text}\",\n",
    "            \"Provide a 3-sentence summary of the following:\\n{text}\"\n",
    "        ],\n",
    "        \"sentiment\": [\n",
    "            \"What is the sentiment of this text?\\n{text}\",\n",
    "            \"Analyze the tone: is it positive, negative, or neutral?\\n{text}\"\n",
    "        ],\n",
    "        \"instruction\": [\n",
    "            \"You are a helpful assistant. Follow this instruction:\\n{instruction}\",\n",
    "            \"Execute the following command as an AI agent:\\n{instruction}\"\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    task_type = task_type.lower()\n",
    "    if task_type not in templates:\n",
    "        raise ValueError(f\"‚ùå Unsupported task_type '{task_type}'. Choose from: {list(templates.keys())}\")\n",
    "\n",
    "    template = random.choice(templates[task_type])\n",
    "\n",
    "    if \"{text}\" in template:\n",
    "        prompt = template.format(text=content)\n",
    "    elif \"{instruction}\" in template:\n",
    "        prompt = template.format(instruction=content)\n",
    "    else:\n",
    "        prompt = content  # fallback\n",
    "\n",
    "    if style:\n",
    "        prompt = f\"[Style: {style}]\\n{prompt}\"\n",
    "\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a2d2dc",
   "metadata": {},
   "source": [
    "### Step 6: Generate and Execute a Prompt\n",
    "\n",
    "Here we use the `prompt_generator()` to dynamically build a task-specific prompt,  \n",
    "then send it to the LLM using `get_completion()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e67f3801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Generated Prompt:\n",
      " [Style: concise]\n",
      "Summarize the following text:\n",
      "Artificial intelligence is rapidly transforming industries through automation, optimization, and real-time decision making.\n",
      "\n",
      "üß† LLM Response:\n",
      "\n",
      "AI is quickly changing industries by automating tasks, optimizing processes, and making decisions in real-time.\n"
     ]
    }
   ],
   "source": [
    "# Define task input\n",
    "task_type = \"summarization\"\n",
    "content = \"Artificial intelligence is rapidly transforming industries through automation, optimization, and real-time decision making.\"\n",
    "style = \"concise\"\n",
    "\n",
    "# Step 1: Generate a prompt using our utility\n",
    "generated_prompt = prompt_generator(task_type, content, style)\n",
    "\n",
    "print(\"üîπ Generated Prompt:\\n\", generated_prompt)\n",
    "print(\"\\nüß† LLM Response:\\n\")\n",
    "\n",
    "# Step 2: Run it through the model\n",
    "response = get_completion(generated_prompt)\n",
    "\n",
    "# Step 3: Print the model's response\n",
    "if hasattr(response, \"choices\"):\n",
    "    print(response.choices[0].message.content)\n",
    "else:\n",
    "    print(\"‚ùå Error:\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdde69bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
