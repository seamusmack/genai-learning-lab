{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86840402",
   "metadata": {},
   "source": [
    "Setup (install + env)\n",
    "What this does\n",
    "Installs the modern provider package and core bits. Sets your key for the session.\n",
    "Why\n",
    "Avoids legacy imports (langchain.chat_models) and version drift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546066a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q -U langchain langchain-openai tiktoken\n",
    "\n",
    "import os\n",
    "# Option A: set here for the session\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "# Optional: if you use org/project scoping\n",
    "# os.environ[\"OPENAI_ORG_ID\"] = \"org_...\"\n",
    "# os.environ[\"OPENAI_PROJECT\"] = \"proj_...\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67a0df8",
   "metadata": {},
   "source": [
    "Step 1 — Imports and model\n",
    "What this does\n",
    "Brings in the ReAct agent constructor, executor, a small output parser helper, and the OpenAI chat model wrapper.\n",
    "\n",
    "Why\n",
    "create_react_agent builds a prompt that teaches the LLM to think-then-act with tools; AgentExecutor runs the loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0344ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39a31f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c187177",
   "metadata": {},
   "source": [
    "Step 2 — Define “Operations” tools (safe, local)\n",
    "What this does\n",
    "Defines three realistic ops tools:\n",
    "\n",
    "status_board — read-only status of systems.\n",
    "\n",
    "runbook_search — look up SOP steps from a tiny in-memory KB.\n",
    "\n",
    "calc — quick arithmetic (for SLO/latency math).\n",
    "\n",
    "Why\n",
    "Agents are only as good as their action space. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417f98b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mock sources the tools will read\n",
    "SYSTEM_STATUS: Dict[str, Dict[str, str]] = {\n",
    "    \"api\":      {\"state\": \"degraded\", \"note\": \"5xx spiking in us-east\"},\n",
    "    \"db\":       {\"state\": \"healthy\",  \"note\": \"replication lag < 50ms\"},\n",
    "    \"cache\":    {\"state\": \"healthy\",  \"note\": \"hit rate 98.7%\"},\n",
    "    \"ingestor\": {\"state\": \"down\",     \"note\": \"stuck on batch 42\"},\n",
    "}\n",
    "\n",
    "RUNBOOKS: Dict[str, List[str]] = {\n",
    "    \"ingestor_restart\": [\n",
    "        \"Confirm batch id with `GET /ingestor/status`\",\n",
    "        \"Drain queue: set `ingestor.accept=false`\",\n",
    "        \"Restart service `svc_ingestor`\",\n",
    "        \"Re-enable accepts and watch metrics for 5 minutes\",\n",
    "    ],\n",
    "    \"api_5xx_spike\": [\n",
    "        \"Check last deploy time; if <30m, roll back\",\n",
    "        \"Enable circuit breaker for slow DB deps\",\n",
    "        \"Warm cache with top 100 endpoints\",\n",
    "        \"If spike persists >10m, page on-call DB\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "@tool(\"status_board\", return_direct=False)\n",
    "def status_board(service: str) -> str:\n",
    "    \"\"\"Get the current state and note for a named service (e.g., 'api', 'db', 'cache', 'ingestor').\"\"\"\n",
    "    s = SYSTEM_STATUS.get(service.lower())\n",
    "    if not s:\n",
    "        return f\"service '{service}' not found. Available: {list(SYSTEM_STATUS.keys())}\"\n",
    "    return f\"{service}: state={s['state']}; note={s['note']}\"\n",
    "\n",
    "@tool(\"runbook_search\", return_direct=False)\n",
    "def runbook_search(keyword: str) -> str:\n",
    "    \"\"\"Return a short SOP matching a keyword (e.g., 'ingestor', '5xx', 'restart').\"\"\"\n",
    "    kw = keyword.lower()\n",
    "    hits = []\n",
    "    for name, steps in RUNBOOKS.items():\n",
    "        if kw in name or any(kw in step.lower() for step in steps):\n",
    "            hits.append(f\"{name}:\\n- \" + \"\\n- \".join(steps))\n",
    "    return \"\\n\\n\".join(hits) if hits else f\"No runbook match for '{keyword}'.\"\n",
    "\n",
    "@tool(\"calc\", return_direct=False)\n",
    "def calc(expression: str) -> str:\n",
    "    \"\"\"Evaluate a simple arithmetic expression, e.g., '99.9 - 98.7' or '350*0.95'.\"\"\"\n",
    "    try:\n",
    "        # Extremely limited eval; safe for simple classroom math\n",
    "        value = eval(expression, {\"__builtins__\": {}}, {})\n",
    "        return str(value)\n",
    "    except Exception as e:\n",
    "        return f\"calc error: {e}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf6f8f1",
   "metadata": {},
   "source": [
    "Step 3 — System prompt (operations persona)\n",
    "What this does\n",
    "Gives the agent concise, ops-focused behavior: choose tools only when needed; return clear, actionable answers.\n",
    "\n",
    "Why\n",
    "Agents need explicit tool-use guidance to avoid chattiness or hallucinated tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0845b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"You are an on-call operations manager.\n",
    "You decide when to use tools. Use tools for facts (status, runbooks, calculations).\n",
    "Be concise, actionable, and include clear next steps when appropriate.\n",
    "If a tool returns multiple options, summarize and recommend one.\n",
    "If you lack data, say so and propose a next diagnostic step.\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a313dd99",
   "metadata": {},
   "source": [
    "Step 4 — Build the ReAct agent\n",
    "What this does\n",
    "Creates the ReAct agent with our tools and system instructions, then wraps it in an executor.\n",
    "\n",
    "Why\n",
    "create_react_agent crafts a reasoning+acting prompt from tool schemas and our system text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11994180",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent, AgentType\n",
    "\n",
    "tools = [status_board, runbook_search, calc]\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,  # built-in ReAct prompt\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True,\n",
    ")\n",
    "print(\"Agent ready.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d272b6",
   "metadata": {},
   "source": [
    "Step 5 — First run: diagnose a 5xx spike\n",
    "What this does\n",
    "Shows the agent choosing status_board then runbook_search, and recommending next steps.\n",
    "\n",
    "Why\n",
    "Demonstrates tool selection and summarization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9022283",
   "metadata": {},
   "outputs": [],
   "source": [
    "query1 = \"We're seeing 5xx errors on the API in us-east. What should I check and do first?\"\n",
    "resp1 = agent.invoke({\"input\": query1})\n",
    "print(resp1[\"output\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ba8e4a",
   "metadata": {},
   "source": [
    "Step 6 — Second run: restart a stuck ingestor\n",
    "What this does\n",
    "Shows a different tool path and a calculation example.\n",
    "\n",
    "Why\n",
    "Demonstrates that the action sequence varies by question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a905879e",
   "metadata": {},
   "outputs": [],
   "source": [
    "query2 = \"Ingestor is stuck on batch 42—walk me through the restart and sanity checks.\"\n",
    "resp2 = agent.invoke({\"input\": query2})\n",
    "print(resp2[\"output\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae175aa6",
   "metadata": {},
   "source": [
    "Step 7 — Quick SLO math with calc\n",
    "What this does\n",
    "Small arithmetic to support an ops decision.\n",
    "\n",
    "Why\n",
    "Shows multi-tool repertoire beyond text lookup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7f1b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "query3 = \"If cache hit rate drops from 98.7% to 95%, by how much does origin load increase (roughly)?\"\n",
    "resp3 = agent.invoke({\"input\": query3})\n",
    "print(resp3[\"output\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3553f00",
   "metadata": {},
   "source": [
    "Step 8 — Extend at runtime (optional)\n",
    "What this does\n",
    "Demonstrates how you’d add a new tool (e.g., log snippet finder) without changing the rest of the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d266a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "\n",
    "@tool(\"logs_find\", return_direct=False)\n",
    "def logs_find(keyword: str) -> str:\n",
    "    \"\"\"Return a mock log excerpt matching a keyword.\"\"\"\n",
    "    sample = [\n",
    "        \"12:01 GET /v1/orders 500 upstream timeout\",\n",
    "        \"12:02 GET /v1/orders 200 OK\",\n",
    "        \"12:03 POST /v1/ingest 502 bad gateway\",\n",
    "    ]\n",
    "    kw = keyword.lower()\n",
    "    hits = [l for l in sample if kw in l.lower()]\n",
    "    return \"\\n\".join(hits) if hits else \"no matches\"\n",
    "\n",
    "# Add the tool and re-initialize the agent (no react_agent in this path)\n",
    "tools.append(logs_find)\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True,\n",
    ")\n",
    "print(\"Agent reloaded with logs_find.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40782ca4",
   "metadata": {},
   "source": [
    "Troubleshooting notes\n",
    "If you hit ModuleNotFoundError on langchain_openai, install langchain-openai and restart the kernel.\n",
    "\n",
    "If the agent “hallucinates” a tool name, it means the tool descriptions weren’t clear; tighten the docstrings.\n",
    "\n",
    "For real ops, back tools with real endpoints (Prometheus, Grafana, incident API). The interface doesn’t change—only the function bodies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d04056b",
   "metadata": {},
   "source": [
    "Install Gradio in your environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aae8a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U gradio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ae0245",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "# Make sure this matches your existing agent instance from earlier cells\n",
    "# Example (must be run earlier in the notebook):\n",
    "# agent = AgentExecutor(agent=react_agent, tools=tools, verbose=True, handle_parsing_errors=True)\n",
    "\n",
    "def run_agent_stream(message, history):\n",
    "    try:\n",
    "        result = agent.invoke({\"input\": message})\n",
    "        output_text = result.get(\"output\", \"No output returned.\")\n",
    "        \n",
    "        # Stream word-by-word\n",
    "        for token in output_text.split():\n",
    "            yield token + \" \"\n",
    "    except Exception as e:\n",
    "        yield f\"Error: {e}\"\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    gr.ChatInterface(\n",
    "        fn=run_agent_stream,\n",
    "        title=\"Ops Agent Chat (Streaming)\",\n",
    "        chatbot=gr.Chatbot(),\n",
    "        textbox=gr.Textbox(placeholder=\"Ask about system status, runbooks, or calculations...\"),\n",
    "        type=\"generator\"  # Streaming mode\n",
    "    )\n",
    "\n",
    "demo.launch(share=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf9c45e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
