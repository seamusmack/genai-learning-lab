{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372baaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c27072e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35164a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89188363",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92eff1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install umap-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7732403e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e05037",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934870fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdba765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT Visualization Setup - Alternative to BertViz\n",
    "# This version works without the bertviz package\n",
    "\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import umap\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for better plots\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# =============================================================================\n",
    "# 1. BERT MODEL INITIALIZATION\n",
    "# =============================================================================\n",
    "\n",
    "def initialize_bert_model(model_name='bert-base-uncased'):\n",
    "    \"\"\"Initialize BERT model and tokenizer for visualization\"\"\"\n",
    "    print(f\"Loading {model_name}...\")\n",
    "    \n",
    "    tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "    model = BertModel.from_pretrained(model_name, output_attentions=True)\n",
    "    model.eval()\n",
    "    \n",
    "    print(\"Model loaded successfully!\")\n",
    "    return tokenizer, model\n",
    "\n",
    "# =============================================================================\n",
    "# 2. CUSTOM ATTENTION VISUALIZATION (Replaces BertViz functionality)\n",
    "# =============================================================================\n",
    "\n",
    "def create_attention_heatmap(text, tokenizer, model, layer=11, head=0):\n",
    "    \"\"\"Create custom attention heatmap\"\"\"\n",
    "    inputs = tokenizer.encode_plus(text, return_tensors='pt', add_special_tokens=True)\n",
    "    tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        attention = outputs.attentions[layer][0, head].numpy()\n",
    "    \n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(attention, \n",
    "                xticklabels=tokens, \n",
    "                yticklabels=tokens,\n",
    "                cmap='Blues',\n",
    "                annot=True,\n",
    "                fmt='.2f',\n",
    "                square=True)\n",
    "    plt.title(f'BERT Attention Heatmap - Layer {layer}, Head {head}')\n",
    "    plt.xlabel('Key Tokens')\n",
    "    plt.ylabel('Query Tokens')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def create_interactive_attention_plot(text, tokenizer, model, layer=11, head=0):\n",
    "    \"\"\"Create interactive attention visualization using Plotly\"\"\"\n",
    "    inputs = tokenizer.encode_plus(text, return_tensors='pt', add_special_tokens=True)\n",
    "    tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        attention = outputs.attentions[layer][0, head].numpy()\n",
    "    \n",
    "    fig = go.Figure(data=go.Heatmap(\n",
    "        z=attention,\n",
    "        x=tokens,\n",
    "        y=tokens,\n",
    "        colorscale='Blues',\n",
    "        text=attention,\n",
    "        texttemplate=\"%{text:.2f}\",\n",
    "        textfont={\"size\": 8},\n",
    "        hoverongaps=False\n",
    "    ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=f'Interactive BERT Attention - Layer {layer}, Head {head}',\n",
    "        xaxis_title='Key Tokens',\n",
    "        yaxis_title='Query Tokens',\n",
    "        width=800,\n",
    "        height=700\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "\n",
    "def visualize_multi_head_attention(text, tokenizer, model, layer=11):\n",
    "    \"\"\"Visualize all attention heads for a given layer\"\"\"\n",
    "    inputs = tokenizer.encode_plus(text, return_tensors='pt', add_special_tokens=True)\n",
    "    tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        layer_attention = outputs.attentions[layer][0]  # [num_heads, seq_len, seq_len]\n",
    "    \n",
    "    num_heads = layer_attention.shape[0]\n",
    "    fig, axes = plt.subplots(3, 4, figsize=(16, 12))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for head in range(min(num_heads, 12)):\n",
    "        attention = layer_attention[head].numpy()\n",
    "        \n",
    "        im = axes[head].imshow(attention, cmap='Blues')\n",
    "        axes[head].set_title(f'Head {head}')\n",
    "        axes[head].set_xticks(range(len(tokens)))\n",
    "        axes[head].set_yticks(range(len(tokens)))\n",
    "        axes[head].set_xticklabels(tokens, rotation=45, ha='right', fontsize=8)\n",
    "        axes[head].set_yticklabels(tokens, fontsize=8)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.suptitle(f'All Attention Heads - Layer {layer}', y=1.02, fontsize=16)\n",
    "    plt.show()\n",
    "\n",
    "# =============================================================================\n",
    "# 3. ATTENTION FLOW VISUALIZATION\n",
    "# =============================================================================\n",
    "\n",
    "def visualize_attention_flow(text, tokenizer, model, target_token_idx=1):\n",
    "    \"\"\"Visualize how attention to a specific token changes across layers\"\"\"\n",
    "    inputs = tokenizer.encode_plus(text, return_tensors='pt', add_special_tokens=True)\n",
    "    tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        attentions = outputs.attentions\n",
    "    \n",
    "    # Extract attention to target token across all layers\n",
    "    attention_to_target = []\n",
    "    layer_names = []\n",
    "    \n",
    "    for layer_idx, layer_attention in enumerate(attentions):\n",
    "        # Average across heads\n",
    "        avg_attention = layer_attention[0].mean(dim=0)  # [seq_len, seq_len]\n",
    "        attention_scores = avg_attention[:, target_token_idx].numpy()\n",
    "        attention_to_target.append(attention_scores)\n",
    "        layer_names.append(f'Layer {layer_idx}')\n",
    "    \n",
    "    # Create interactive plot\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    for i, (scores, layer_name) in enumerate(zip(attention_to_target, layer_names)):\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=tokens,\n",
    "            y=scores,\n",
    "            mode='lines+markers',\n",
    "            name=layer_name,\n",
    "            line=dict(width=2),\n",
    "            marker=dict(size=6)\n",
    "        ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=f'Attention Flow to Token: \"{tokens[target_token_idx]}\"',\n",
    "        xaxis_title='Tokens',\n",
    "        yaxis_title='Attention Score',\n",
    "        width=900,\n",
    "        height=600,\n",
    "        hovermode='x unified'\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "\n",
    "# =============================================================================\n",
    "# 4. EMBEDDING ANALYSIS\n",
    "# =============================================================================\n",
    "\n",
    "def get_bert_embeddings(texts, tokenizer, model, pooling='cls'):\n",
    "    \"\"\"Extract BERT embeddings for a list of texts\"\"\"\n",
    "    embeddings = []\n",
    "    \n",
    "    for text in texts:\n",
    "        inputs = tokenizer.encode_plus(text, \n",
    "                                     return_tensors='pt', \n",
    "                                     add_special_tokens=True,\n",
    "                                     max_length=512,\n",
    "                                     truncation=True,\n",
    "                                     padding='max_length')\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            hidden_states = outputs.last_hidden_state[0]  # [seq_len, hidden_size]\n",
    "            \n",
    "            if pooling == 'cls':\n",
    "                embedding = hidden_states[0].numpy()  # [CLS] token\n",
    "            elif pooling == 'mean':\n",
    "                # Mean pooling (excluding padding tokens)\n",
    "                mask = inputs['attention_mask'][0].numpy()\n",
    "                masked_hidden = hidden_states.numpy() * mask[:, None]\n",
    "                embedding = masked_hidden.sum(axis=0) / mask.sum()\n",
    "            else:\n",
    "                embedding = hidden_states[0].numpy()  # Default to CLS\n",
    "                \n",
    "            embeddings.append(embedding)\n",
    "    \n",
    "    return np.array(embeddings)\n",
    "\n",
    "def visualize_embeddings_2d(embeddings, labels=None, texts=None, method='umap'):\n",
    "    \"\"\"Visualize BERT embeddings in 2D\"\"\"\n",
    "    if method == 'umap':\n",
    "        reducer = umap.UMAP(n_components=2, random_state=42)\n",
    "        title = \"BERT Embeddings - UMAP\"\n",
    "    elif method == 'tsne':\n",
    "        reducer = TSNE(n_components=2, random_state=42, perplexity=min(30, len(embeddings)-1))\n",
    "        title = \"BERT Embeddings - t-SNE\"\n",
    "    else:  # PCA\n",
    "        reducer = PCA(n_components=2, random_state=42)\n",
    "        title = \"BERT Embeddings - PCA\"\n",
    "    \n",
    "    embedding_2d = reducer.fit_transform(embeddings)\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    \n",
    "    if labels is not None:\n",
    "        unique_labels = list(set(labels))\n",
    "        colors = px.colors.qualitative.Set1[:len(unique_labels)]\n",
    "        \n",
    "        for i, label in enumerate(unique_labels):\n",
    "            mask = [l == label for l in labels]\n",
    "            hover_text = [f\"Label: {label}<br>Text: {texts[j] if texts else f'Point {j}'}\" \n",
    "                         for j, m in enumerate(mask) if m]\n",
    "            \n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=embedding_2d[mask, 0],\n",
    "                y=embedding_2d[mask, 1],\n",
    "                mode='markers',\n",
    "                name=label,\n",
    "                marker=dict(size=10, color=colors[i]),\n",
    "                text=hover_text,\n",
    "                hovertemplate='%{text}<extra></extra>'\n",
    "            ))\n",
    "    else:\n",
    "        hover_text = [f\"Text: {texts[i] if texts else f'Point {i}'}\" for i in range(len(embeddings))]\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=embedding_2d[:, 0],\n",
    "            y=embedding_2d[:, 1],\n",
    "            mode='markers',\n",
    "            marker=dict(size=10, color='blue'),\n",
    "            text=hover_text,\n",
    "            hovertemplate='%{text}<extra></extra>'\n",
    "        ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        xaxis_title=f'{method.upper()} 1',\n",
    "        yaxis_title=f'{method.upper()} 2',\n",
    "        width=800,\n",
    "        height=600\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "\n",
    "# =============================================================================\n",
    "# 5. LAYER-WISE ANALYSIS\n",
    "# =============================================================================\n",
    "\n",
    "def analyze_layer_representations(text, tokenizer, model):\n",
    "    \"\"\"Analyze how representations change across BERT layers\"\"\"\n",
    "    inputs = tokenizer.encode_plus(text, return_tensors='pt', add_special_tokens=True)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs, output_hidden_states=True)\n",
    "        hidden_states = outputs.hidden_states\n",
    "    \n",
    "    # Extract [CLS] representations from each layer\n",
    "    cls_representations = []\n",
    "    for layer_output in hidden_states:\n",
    "        cls_rep = layer_output[0, 0, :].numpy()  # [CLS] token\n",
    "        cls_representations.append(cls_rep)\n",
    "    \n",
    "    cls_representations = np.array(cls_representations)\n",
    "    \n",
    "    # Compute similarities between consecutive layers\n",
    "    similarities = []\n",
    "    for i in range(len(cls_representations) - 1):\n",
    "        sim = np.dot(cls_representations[i], cls_representations[i+1]) / (\n",
    "            np.linalg.norm(cls_representations[i]) * np.linalg.norm(cls_representations[i+1])\n",
    "        )\n",
    "        similarities.append(sim)\n",
    "    \n",
    "    # Create interactive plot\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=list(range(1, len(similarities) + 1)),\n",
    "        y=similarities,\n",
    "        mode='lines+markers',\n",
    "        line=dict(width=3, color='blue'),\n",
    "        marker=dict(size=8, color='red')\n",
    "    ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title='Cosine Similarity Between Consecutive BERT Layers',\n",
    "        xaxis_title='Layer Transition',\n",
    "        yaxis_title='Cosine Similarity',\n",
    "        width=800,\n",
    "        height=500,\n",
    "        showlegend=False\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "    return cls_representations\n",
    "\n",
    "# =============================================================================\n",
    "# 6. DEMO FUNCTION\n",
    "# =============================================================================\n",
    "\n",
    "def run_bert_visualization_demo():\n",
    "    \"\"\"Run comprehensive BERT visualization demo\"\"\"\n",
    "    print(\"=== BERT Visualization Demo (Without BertViz) ===\\n\")\n",
    "    \n",
    "    # Initialize model\n",
    "    tokenizer, model = initialize_bert_model()\n",
    "    \n",
    "    # Sample text\n",
    "    sample_text = \"The quick brown fox jumps over the lazy dog.\"\n",
    "    print(f\"Analyzing text: '{sample_text}'\\n\")\n",
    "    \n",
    "    # 1. Basic attention heatmap\n",
    "    print(\"1. Creating attention heatmap...\")\n",
    "    create_attention_heatmap(sample_text, tokenizer, model, layer=11, head=0)\n",
    "    \n",
    "    # 2. Interactive attention plot\n",
    "    print(\"2. Creating interactive attention plot...\")\n",
    "    create_interactive_attention_plot(sample_text, tokenizer, model, layer=11, head=0)\n",
    "    \n",
    "    # 3. Multi-head visualization\n",
    "    print(\"3. Visualizing all attention heads...\")\n",
    "    visualize_multi_head_attention(sample_text, tokenizer, model, layer=11)\n",
    "    \n",
    "    # 4. Layer analysis\n",
    "    print(\"4. Analyzing layer representations...\")\n",
    "    analyze_layer_representations(sample_text, tokenizer, model)\n",
    "    \n",
    "    # 5. Embedding visualization\n",
    "    print(\"5. Visualizing embeddings...\")\n",
    "    sample_texts = [\n",
    "        \"I love machine learning and AI\",\n",
    "        \"Machine learning is fascinating to study\",\n",
    "        \"Deep learning models are powerful\",\n",
    "        \"Natural language processing is amazing\",\n",
    "        \"NLP applications are everywhere\",\n",
    "        \"I enjoy reading books\",\n",
    "        \"Literature and poetry are beautiful\",\n",
    "        \"Writing stories is creative\"\n",
    "    ]\n",
    "    \n",
    "    embeddings = get_bert_embeddings(sample_texts, tokenizer, model)\n",
    "    labels = ['Tech']*5 + ['Literature']*3\n",
    "    visualize_embeddings_2d(embeddings, labels, sample_texts, method='umap')\n",
    "    \n",
    "    print(\"\\n=== Demo Complete! ===\")\n",
    "\n",
    "# =============================================================================\n",
    "# 7. SIMPLIFIED WIDGET INTERFACE\n",
    "# =============================================================================\n",
    "\n",
    "def create_simple_bert_explorer():\n",
    "    \"\"\"Create a simple interface for BERT exploration\"\"\"\n",
    "    import ipywidgets as widgets\n",
    "    from IPython.display import display, clear_output\n",
    "    \n",
    "    # Initialize model once\n",
    "    tokenizer, model = initialize_bert_model()\n",
    "    \n",
    "    # Widgets\n",
    "    text_input = widgets.Textarea(\n",
    "        value=\"The quick brown fox jumps over the lazy dog.\",\n",
    "        placeholder=\"Enter text to analyze...\",\n",
    "        description=\"Text:\",\n",
    "        style={'description_width': 'initial'},\n",
    "        layout=widgets.Layout(width='70%', height='80px')\n",
    "    )\n",
    "    \n",
    "    layer_slider = widgets.IntSlider(value=11, min=0, max=11, description=\"Layer:\")\n",
    "    head_slider = widgets.IntSlider(value=0, min=0, max=11, description=\"Head:\")\n",
    "    \n",
    "    viz_dropdown = widgets.Dropdown(\n",
    "        options=['Attention Heatmap', 'Interactive Attention', 'Multi-Head View', 'Layer Analysis'],\n",
    "        value='Attention Heatmap',\n",
    "        description=\"Visualization:\"\n",
    "    )\n",
    "    \n",
    "    button = widgets.Button(description=\"Generate Visualization\", button_style='success')\n",
    "    output = widgets.Output()\n",
    "    \n",
    "    def on_button_click(b):\n",
    "        with output:\n",
    "            clear_output(wait=True)\n",
    "            text = text_input.value\n",
    "            layer = layer_slider.value\n",
    "            head = head_slider.value\n",
    "            viz_type = viz_dropdown.value\n",
    "            \n",
    "            try:\n",
    "                if viz_type == 'Attention Heatmap':\n",
    "                    create_attention_heatmap(text, tokenizer, model, layer, head)\n",
    "                elif viz_type == 'Interactive Attention':\n",
    "                    create_interactive_attention_plot(text, tokenizer, model, layer, head)\n",
    "                elif viz_type == 'Multi-Head View':\n",
    "                    visualize_multi_head_attention(text, tokenizer, model, layer)\n",
    "                elif viz_type == 'Layer Analysis':\n",
    "                    analyze_layer_representations(text, tokenizer, model)\n",
    "            except Exception as e:\n",
    "                print(f\"Error: {e}\")\n",
    "    \n",
    "    button.on_click(on_button_click)\n",
    "    \n",
    "    display(text_input, layer_slider, head_slider, viz_dropdown, button, output)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"BERT Visualization Setup Complete!\")\n",
    "    print(\"Available functions:\")\n",
    "    print(\"- run_bert_visualization_demo()\")\n",
    "    print(\"- create_simple_bert_explorer()\")\n",
    "    print(\"\\nNote: This version works without bertviz!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf62ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_simple_bert_explorer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927c6e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4061f3ff",
   "metadata": {},
   "source": [
    "The 12 Attention Head \"Specialists\"\n",
    "Early Heads (1-3): \"The Basics Crew\"\n",
    "\n",
    "Head 1: \"Word Boundaries\" - Focuses on separating words and subwords\n",
    "Head 2: \"Local Grammar\" - Looks at immediate word relationships (article → noun)\n",
    "Head 3: \"Punctuation Tracker\" - Pays attention to commas, periods, special tokens\n",
    "\n",
    "Middle Heads (4-6): \"The Syntax Squad\"\n",
    "\n",
    "Head 4: \"Subject-Verb Matcher\" - Connects subjects with their verbs\n",
    "Head 5: \"Modifier Linker\" - Links adjectives to nouns, adverbs to verbs\n",
    "Head 6: \"Dependency Parser\" - Tracks grammatical dependencies\n",
    "\n",
    "Deep Heads (7-9): \"The Meaning Makers\"\n",
    "\n",
    "Head 7: \"Coreference Resolver\" - Connects pronouns to what they refer to\n",
    "Head 8: \"Semantic Similarity\" - Groups words with similar meanings\n",
    "Head 9: \"Long-Distance Relations\" - Handles complex sentence structures\n",
    "\n",
    "Final Heads (10-12): \"The Big Picture Team\"\n",
    "\n",
    "Head 10: \"Entity Tracker\" - Focuses on named entities and important concepts\n",
    "Head 11: \"Sentence Integrator\" - Combines information for overall meaning\n",
    "Head 12: \"Context Collector\" - Gathers global context for the [CLS] token\n",
    "\n",
    "Important Notes:\n",
    "\n",
    "Layer Matters: These patterns vary by layer! Head 1 in Layer 3 does different things than Head 1 in Layer 11\n",
    "Context Dependent: The same head might focus on different things in different sentences\n",
    "Collaborative: Real understanding comes from all heads working together across all 12 layers\n",
    "Emergent Behavior: BERT wasn't programmed for these roles - they emerged naturally from training\n",
    "\n",
    "For Teaching:\n",
    "\"Think of BERT as having 144 different reading specialists (12 heads × 12 layers) that each developed their own expertise just from reading lots of text. Some became grammar experts, others meaning detectives, others relationship trackers - all working together to understand language!\"\n",
    "Try This in Your Visualization:\n",
    "\n",
    "Early layers (0-3): Look for basic word-level patterns\n",
    "Middle layers (4-8): Watch for syntactic relationships\n",
    "Late layers (9-11): Observe semantic and contextual integration\n",
    "\n",
    "Use your interactive explorer to see these specialists in action!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05226d06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
